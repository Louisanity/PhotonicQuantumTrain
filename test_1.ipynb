{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 135, and embedding size = 1023\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1825.0\" height=\"656.25\" viewBox=\"-30.0 0 1460.0 525.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,475.0 L25,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.083892</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.283419</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.731866</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.778354</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.593094</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.201287</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.462181</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.83981</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.840525</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.340643</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.012659</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.297058</text>\n",
       "<path d=\"M25,425 L53,425 L72,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,444 L97,425 L125,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,475 L53,475 L72,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,456 L97,475 L125,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,443 L100,443 L100,457 L50,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.755804</text>\n",
       "<path d=\"M50,443 L100,443 L100,447 L50,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,450 L103,450 L103,460 L93,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,425 L175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,440 L139,440 L153,410 L144,410 L130,440 L139,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.281177</text>\n",
       "<path d=\"M125,475 L175,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,490 L139,490 L153,460 L144,460 L130,490 L139,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.139485</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.173942</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.916748</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.59536</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.135019</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.166851</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.038536</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.244812</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.930228</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.589477</text>\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.163355</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.350429</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.544059</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.942031</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.937564</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.035733</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.308885</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.652881</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.696358</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.253911</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.302701</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.154007</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.868162</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.23183</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.064051</text>\n",
       "<path d=\"M175,475.0 L325,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,425 L353,425 L372,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,444 L397,425 L425,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,475 L353,475 L372,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,456 L397,475 L425,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,443 L400,443 L400,457 L350,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.825038</text>\n",
       "<path d=\"M350,443 L400,443 L400,447 L350,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,450 L403,450 L403,460 L393,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,425 L475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,440 L439,440 L453,410 L444,410 L430,440 L439,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.340164</text>\n",
       "<path d=\"M425,475 L475,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,490 L439,490 L453,460 L444,460 L430,490 L439,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.721093</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.065544</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.843597</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.760267</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.04304</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.956412</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.643315</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.898879</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.13357</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.108904</text>\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.926236</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.599429</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.465536</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.272352</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.129479</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.364314</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.933613</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.298775</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.584844</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.472624</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.105202</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.716985</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.999218</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.245223</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.469462</text>\n",
       "<path d=\"M475,475.0 L625,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,425 L653,425 L672,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,444 L697,425 L725,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,475 L653,475 L672,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,456 L697,475 L725,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,443 L700,443 L700,457 L650,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.562172</text>\n",
       "<path d=\"M650,443 L700,443 L700,447 L650,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,450 L703,450 L703,460 L693,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,425 L775,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,440 L739,440 L753,410 L744,410 L730,440 L739,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.709207</text>\n",
       "<path d=\"M725,475 L775,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,490 L739,490 L753,460 L744,460 L730,490 L739,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.592305</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.355061</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.784983</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.122489</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.332744</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.802506</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.532689</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.645776</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.015782</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.344902</text>\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.812153</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.875893</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.484693</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.590883</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.874257</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.323046</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.684348</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.812046</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.199467</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.841725</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.42732</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.082292</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.271635</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.732901</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.081212</text>\n",
       "<path d=\"M775,475.0 L925,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,425 L953,425 L972,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,444 L997,425 L1025,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,475 L953,475 L972,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,456 L997,475 L1025,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,443 L1000,443 L1000,457 L950,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.882038</text>\n",
       "<path d=\"M950,443 L1000,443 L1000,447 L950,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,450 L1003,450 L1003,460 L993,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,425 L1075,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,440 L1039,440 L1053,410 L1044,410 L1030,440 L1039,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.225333</text>\n",
       "<path d=\"M1025,475 L1075,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,490 L1039,490 L1053,460 L1044,460 L1030,490 L1039,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.003941</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.425302</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.091971</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.383371</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.681134</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.87266</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.671221</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.860545</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.596553</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.460916</text>\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.942899</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.951829</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.131492</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25 L1253,25 L1272,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,44 L1297,25 L1325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,75 L1253,75 L1272,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,56 L1297,75 L1325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,43 L1300,43 L1300,57 L1250,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.535408</text>\n",
       "<path d=\"M1250,43 L1300,43 L1300,47 L1250,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,50 L1303,50 L1303,60 L1293,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,25 L1375,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,40 L1339,40 L1353,10 L1344,10 L1330,40 L1339,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.82036</text>\n",
       "<path d=\"M1325,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,90 L1339,90 L1353,60 L1344,60 L1330,90 L1339,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.253543</text>\n",
       "<path d=\"M1225,125 L1253,125 L1272,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,144 L1297,125 L1325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,175 L1253,175 L1272,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,156 L1297,175 L1325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,143 L1300,143 L1300,157 L1250,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.005396</text>\n",
       "<path d=\"M1250,143 L1300,143 L1300,147 L1250,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,150 L1303,150 L1303,160 L1293,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,140 L1339,140 L1353,110 L1344,110 L1330,140 L1339,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.413552</text>\n",
       "<path d=\"M1325,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,190 L1339,190 L1353,160 L1344,160 L1330,190 L1339,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.555334</text>\n",
       "<path d=\"M1225,225 L1253,225 L1272,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,244 L1297,225 L1325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,275 L1253,275 L1272,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,256 L1297,275 L1325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,243 L1300,243 L1300,257 L1250,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.29481</text>\n",
       "<path d=\"M1250,243 L1300,243 L1300,247 L1250,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,250 L1303,250 L1303,260 L1293,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,240 L1339,240 L1353,210 L1344,210 L1330,240 L1339,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.843644</text>\n",
       "<path d=\"M1325,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,290 L1339,290 L1353,260 L1344,260 L1330,290 L1339,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.84593</text>\n",
       "<path d=\"M1225,325 L1253,325 L1272,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,344 L1297,325 L1325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,375 L1253,375 L1272,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,356 L1297,375 L1325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,343 L1300,343 L1300,357 L1250,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.052134</text>\n",
       "<path d=\"M1250,343 L1300,343 L1300,347 L1250,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,350 L1303,350 L1303,360 L1293,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,340 L1339,340 L1353,310 L1344,310 L1330,340 L1339,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.61156</text>\n",
       "<path d=\"M1325,375 L1375,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,390 L1339,390 L1353,360 L1344,360 L1330,390 L1339,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.435053</text>\n",
       "<path d=\"M1075,475.0 L1225,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,425 L1253,425 L1272,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,444 L1297,425 L1325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,475 L1253,475 L1272,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,456 L1297,475 L1325,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,443 L1300,443 L1300,457 L1250,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.646315</text>\n",
       "<path d=\"M1250,443 L1300,443 L1300,447 L1250,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,450 L1303,450 L1303,460 L1293,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,425 L1375,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,440 L1339,440 L1353,410 L1344,410 L1330,440 L1339,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.483112</text>\n",
       "<path d=\"M1325,475 L1375,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,490 L1339,490 L1353,460 L1344,460 L1330,490 L1339,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.242731</text>\n",
       "<path d=\"M1375,25.0 L1390,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,75.0 L1390,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,125.0 L1390,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,175.0 L1390,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,225.0 L1390,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,275.0 L1390,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,325.0 L1390,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,375.0 L1390,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,425.0 L1390,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,475.0 L1390,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1400\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1400\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1400\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1400\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1400\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1400\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1400\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1400\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1400\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"1400\" y=\"478.0\" font-size=\"10\" text-anchor=\"end\">9</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "<text x=\"0\" y=\"478.0\" font-size=\"10\" text-anchor=\"start\">9</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7fcf3a1bbb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs = BosonSampler(m = 10, n = 10, postselect = 1, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        2.9182e-05])\n"
     ]
    }
   ],
   "source": [
    "random_para_tensor = torch.randn(135)\n",
    "res = bs.run(\n",
    "    parameters=random_para_tensor,\n",
    "    samples=100000\n",
    ")\n",
    "\n",
    "trans_res = bs.translate_results(res = res)\n",
    "print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n"
     ]
    }
   ],
   "source": [
    "print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(4*4*4, 10)\n",
    "        # self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        # x = self.fc2(x)\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "    #     self.fc1 = nn.Linear(12*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  978\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/375], Loss: 1.4839\n",
      "Epoch [1/20], Step [200/375], Loss: 0.5596\n",
      "Epoch [1/20], Step [300/375], Loss: 0.1860\n",
      "Epoch [2/20], Step [100/375], Loss: 0.2086\n",
      "Epoch [2/20], Step [200/375], Loss: 0.4265\n",
      "Epoch [2/20], Step [300/375], Loss: 0.2727\n",
      "Epoch [3/20], Step [100/375], Loss: 0.1671\n",
      "Epoch [3/20], Step [200/375], Loss: 0.1757\n",
      "Epoch [3/20], Step [300/375], Loss: 0.0885\n",
      "Epoch [4/20], Step [100/375], Loss: 0.2409\n",
      "Epoch [4/20], Step [200/375], Loss: 0.1099\n",
      "Epoch [4/20], Step [300/375], Loss: 0.7688\n",
      "Epoch [5/20], Step [100/375], Loss: 0.4914\n",
      "Epoch [5/20], Step [200/375], Loss: 0.2222\n",
      "Epoch [5/20], Step [300/375], Loss: 0.1109\n",
      "Epoch [6/20], Step [100/375], Loss: 0.2406\n",
      "Epoch [6/20], Step [200/375], Loss: 0.1132\n",
      "Epoch [6/20], Step [300/375], Loss: 0.1834\n",
      "Epoch [7/20], Step [100/375], Loss: 0.0439\n",
      "Epoch [7/20], Step [200/375], Loss: 0.3453\n",
      "Epoch [7/20], Step [300/375], Loss: 0.1944\n",
      "Epoch [8/20], Step [100/375], Loss: 0.0328\n",
      "Epoch [8/20], Step [200/375], Loss: 0.1002\n",
      "Epoch [8/20], Step [300/375], Loss: 0.0419\n",
      "Epoch [9/20], Step [100/375], Loss: 0.3078\n",
      "Epoch [9/20], Step [200/375], Loss: 0.1218\n",
      "Epoch [9/20], Step [300/375], Loss: 0.2272\n",
      "Epoch [10/20], Step [100/375], Loss: 0.1300\n",
      "Epoch [10/20], Step [200/375], Loss: 0.0515\n",
      "Epoch [10/20], Step [300/375], Loss: 0.1445\n",
      "Epoch [11/20], Step [100/375], Loss: 0.0616\n",
      "Epoch [11/20], Step [200/375], Loss: 0.1378\n",
      "Epoch [11/20], Step [300/375], Loss: 0.5535\n",
      "Epoch [12/20], Step [100/375], Loss: 0.1800\n",
      "Epoch [12/20], Step [200/375], Loss: 0.0945\n",
      "Epoch [12/20], Step [300/375], Loss: 0.1109\n",
      "Epoch [13/20], Step [100/375], Loss: 0.0428\n",
      "Epoch [13/20], Step [200/375], Loss: 0.0293\n",
      "Epoch [13/20], Step [300/375], Loss: 0.0492\n",
      "Epoch [14/20], Step [100/375], Loss: 0.0242\n",
      "Epoch [14/20], Step [200/375], Loss: 0.0332\n",
      "Epoch [14/20], Step [300/375], Loss: 0.0287\n",
      "Epoch [15/20], Step [100/375], Loss: 0.1218\n",
      "Epoch [15/20], Step [200/375], Loss: 0.0363\n",
      "Epoch [15/20], Step [300/375], Loss: 0.0321\n",
      "Epoch [16/20], Step [100/375], Loss: 0.2196\n",
      "Epoch [16/20], Step [200/375], Loss: 0.0106\n",
      "Epoch [16/20], Step [300/375], Loss: 0.0069\n",
      "Epoch [17/20], Step [100/375], Loss: 0.0792\n",
      "Epoch [17/20], Step [200/375], Loss: 0.1179\n",
      "Epoch [17/20], Step [300/375], Loss: 0.0503\n",
      "Epoch [18/20], Step [100/375], Loss: 0.0251\n",
      "Epoch [18/20], Step [200/375], Loss: 0.1457\n",
      "Epoch [18/20], Step [300/375], Loss: 0.0992\n",
      "Epoch [19/20], Step [100/375], Loss: 0.0674\n",
      "Epoch [19/20], Step [200/375], Loss: 0.1177\n",
      "Epoch [19/20], Step [300/375], Loss: 0.0484\n",
      "Epoch [20/20], Step [100/375], Loss: 0.0127\n",
      "Epoch [20/20], Step [200/375], Loss: 0.0238\n",
      "Epoch [20/20], Step [300/375], Loss: 0.2449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 95.33%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  978\n",
      "Required qubit number:  10\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [20, 4], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        res = bs.run(\n",
    "            parameters=self.q_params,\n",
    "            samples=100000\n",
    "        )\n",
    "\n",
    "        trans_res = bs.translate_results(res = res)\n",
    "        probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # # Fully connected layer 2 parameters\n",
    "        # fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        # fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # # Fully connected 2\n",
    "        # x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  329\n",
      "# of trainable parameter in QNN model:  0\n",
      "# of trainable parameter in full model:  329\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "\n",
    "step = 1e-3               # Learning rate\n",
    "batch_size = 16       # Number of samples for each training step\n",
    "num_epochs = 50             # Number of training epochs\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params - num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/375], Loss: 25.7159, batch time: 0.51, accuracy:  6.25%\n",
      "Epoch [1/50], Step [2/375], Loss: 14.4448, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [3/375], Loss: 11.2881, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [4/375], Loss: 12.5399, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [5/375], Loss: 8.2103, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [6/375], Loss: 7.9912, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [7/375], Loss: 5.3897, batch time: 0.36, accuracy:  12.50%\n",
      "Epoch [1/50], Step [8/375], Loss: 8.8979, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [9/375], Loss: 6.5456, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [10/375], Loss: 6.7820, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [11/375], Loss: 4.1110, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [12/375], Loss: 3.4132, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [13/375], Loss: 4.5772, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [14/375], Loss: 2.8070, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [15/375], Loss: 2.9612, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [16/375], Loss: 2.5905, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [17/375], Loss: 2.8531, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [18/375], Loss: 2.7946, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [1/50], Step [19/375], Loss: 2.3823, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [20/375], Loss: 2.5242, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [1/50], Step [21/375], Loss: 2.5928, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [22/375], Loss: 2.4695, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [23/375], Loss: 2.5159, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [24/375], Loss: 2.4181, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [25/375], Loss: 2.3160, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [26/375], Loss: 2.3612, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [27/375], Loss: 2.3918, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [28/375], Loss: 2.3916, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [1/50], Step [29/375], Loss: 2.4770, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [30/375], Loss: 2.3945, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [31/375], Loss: 2.4685, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [32/375], Loss: 2.3910, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [33/375], Loss: 2.4107, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [34/375], Loss: 2.3583, batch time: 0.30, accuracy:  0.00%\n",
      "Epoch [1/50], Step [35/375], Loss: 2.4054, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [36/375], Loss: 2.3135, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [1/50], Step [37/375], Loss: 2.3665, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [38/375], Loss: 2.3353, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [39/375], Loss: 2.3104, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [40/375], Loss: 2.3173, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [41/375], Loss: 2.3096, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [42/375], Loss: 2.3100, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [43/375], Loss: 2.3767, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [44/375], Loss: 2.4160, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [45/375], Loss: 2.2893, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [46/375], Loss: 2.2877, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [1/50], Step [47/375], Loss: 2.2784, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [48/375], Loss: 2.2812, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [1/50], Step [49/375], Loss: 2.3532, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [50/375], Loss: 2.3290, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [51/375], Loss: 2.2722, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [52/375], Loss: 2.4742, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [1/50], Step [53/375], Loss: 2.3777, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [54/375], Loss: 2.3460, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [55/375], Loss: 2.2879, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [56/375], Loss: 2.2512, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [1/50], Step [57/375], Loss: 2.3443, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [58/375], Loss: 2.2658, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [59/375], Loss: 2.3793, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [60/375], Loss: 2.2799, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [1/50], Step [61/375], Loss: 2.3807, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [62/375], Loss: 2.2882, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [63/375], Loss: 2.3755, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [64/375], Loss: 2.3861, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [65/375], Loss: 2.3663, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [66/375], Loss: 2.3481, batch time: 0.33, accuracy:  0.00%\n",
      "Epoch [1/50], Step [67/375], Loss: 2.3282, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [68/375], Loss: 2.3178, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [69/375], Loss: 2.3242, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [70/375], Loss: 2.2625, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [71/375], Loss: 2.2757, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [72/375], Loss: 2.3420, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [73/375], Loss: 2.2950, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [74/375], Loss: 2.2915, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [75/375], Loss: 2.2944, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [76/375], Loss: 2.2860, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [77/375], Loss: 2.3045, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [78/375], Loss: 2.2956, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [79/375], Loss: 2.2992, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [80/375], Loss: 2.3036, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [81/375], Loss: 2.2963, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [82/375], Loss: 2.3281, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [83/375], Loss: 2.3535, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [84/375], Loss: 2.3142, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [85/375], Loss: 2.2521, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [1/50], Step [86/375], Loss: 2.3261, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [87/375], Loss: 2.3420, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [88/375], Loss: 2.2810, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [89/375], Loss: 2.3410, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [90/375], Loss: 2.3017, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [91/375], Loss: 2.2819, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [92/375], Loss: 2.3007, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [93/375], Loss: 2.3727, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [94/375], Loss: 2.3664, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [95/375], Loss: 2.3348, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [96/375], Loss: 2.2760, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [97/375], Loss: 2.3030, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [98/375], Loss: 2.3019, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [99/375], Loss: 2.3623, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [100/375], Loss: 2.2967, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [101/375], Loss: 2.2920, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [102/375], Loss: 2.2918, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [103/375], Loss: 2.3226, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [104/375], Loss: 2.3064, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [105/375], Loss: 2.3228, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [106/375], Loss: 2.3067, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [107/375], Loss: 2.3050, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [108/375], Loss: 2.3035, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [109/375], Loss: 2.3282, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [110/375], Loss: 2.2854, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [111/375], Loss: 2.2620, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [1/50], Step [112/375], Loss: 2.2848, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [113/375], Loss: 2.3073, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [114/375], Loss: 2.2906, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [115/375], Loss: 2.3221, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [116/375], Loss: 2.2990, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [117/375], Loss: 2.2774, batch time: 0.78, accuracy:  25.00%\n",
      "Epoch [1/50], Step [118/375], Loss: 2.3377, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [119/375], Loss: 2.3117, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [120/375], Loss: 2.2924, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [121/375], Loss: 2.3464, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [122/375], Loss: 2.2967, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [123/375], Loss: 2.2823, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [124/375], Loss: 2.3228, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [125/375], Loss: 2.3195, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [126/375], Loss: 2.3049, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [127/375], Loss: 2.3280, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [128/375], Loss: 2.3690, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [129/375], Loss: 2.2885, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [130/375], Loss: 2.3556, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [1/50], Step [131/375], Loss: 2.2601, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [132/375], Loss: 2.3022, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [133/375], Loss: 2.3441, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [134/375], Loss: 2.3671, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [135/375], Loss: 2.2285, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [136/375], Loss: 2.3318, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [137/375], Loss: 2.3133, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [138/375], Loss: 2.3032, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [139/375], Loss: 2.3638, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [140/375], Loss: 2.3384, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [141/375], Loss: 2.3477, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [142/375], Loss: 2.3140, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [143/375], Loss: 2.2927, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [144/375], Loss: 2.3193, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [145/375], Loss: 2.3096, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [146/375], Loss: 2.3100, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [147/375], Loss: 2.2827, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [148/375], Loss: 2.2848, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [149/375], Loss: 2.3021, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [150/375], Loss: 2.3130, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [151/375], Loss: 2.2893, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [152/375], Loss: 2.3286, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [153/375], Loss: 2.2960, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [154/375], Loss: 2.3093, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [155/375], Loss: 2.2872, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [156/375], Loss: 2.2999, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [157/375], Loss: 2.2979, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [158/375], Loss: 2.2978, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [159/375], Loss: 2.3072, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [160/375], Loss: 2.2989, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [161/375], Loss: 2.3250, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [162/375], Loss: 2.2901, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [1/50], Step [163/375], Loss: 2.2927, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [164/375], Loss: 2.3008, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [165/375], Loss: 2.3078, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [166/375], Loss: 2.2996, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [167/375], Loss: 2.3114, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [168/375], Loss: 2.3161, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [169/375], Loss: 2.2893, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [170/375], Loss: 2.3063, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [1/50], Step [171/375], Loss: 2.3046, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [172/375], Loss: 2.3162, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [173/375], Loss: 2.3138, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [174/375], Loss: 2.2951, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [175/375], Loss: 2.3063, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [176/375], Loss: 2.3062, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [177/375], Loss: 2.2952, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [178/375], Loss: 2.3004, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [179/375], Loss: 2.3046, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [180/375], Loss: 2.3117, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [181/375], Loss: 2.2976, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [182/375], Loss: 2.3023, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [183/375], Loss: 2.3008, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [184/375], Loss: 2.2981, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [185/375], Loss: 2.2849, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [1/50], Step [186/375], Loss: 2.3028, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [187/375], Loss: 2.3061, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [188/375], Loss: 2.2962, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [189/375], Loss: 2.2912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [190/375], Loss: 2.2966, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [191/375], Loss: 2.2967, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [192/375], Loss: 2.3100, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [193/375], Loss: 2.3112, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [194/375], Loss: 2.2929, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [195/375], Loss: 2.2946, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [196/375], Loss: 2.2871, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [197/375], Loss: 2.3050, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [198/375], Loss: 2.3006, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [199/375], Loss: 2.2937, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [200/375], Loss: 2.3111, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [201/375], Loss: 2.3028, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [202/375], Loss: 2.2733, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [203/375], Loss: 2.3144, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [204/375], Loss: 2.2997, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [205/375], Loss: 2.3082, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [206/375], Loss: 2.2924, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [207/375], Loss: 2.2991, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [208/375], Loss: 2.2900, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [209/375], Loss: 2.2811, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [1/50], Step [210/375], Loss: 2.3074, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [211/375], Loss: 2.3135, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [212/375], Loss: 2.2974, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [213/375], Loss: 2.3003, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [214/375], Loss: 2.2805, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [215/375], Loss: 2.2785, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [216/375], Loss: 2.3046, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [217/375], Loss: 2.3016, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [218/375], Loss: 2.2852, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [219/375], Loss: 2.2633, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [220/375], Loss: 2.2955, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [221/375], Loss: 2.2791, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [222/375], Loss: 2.3047, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [223/375], Loss: 2.3077, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [224/375], Loss: 2.3046, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [225/375], Loss: 2.3118, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [226/375], Loss: 2.2979, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [227/375], Loss: 2.2797, batch time: 0.76, accuracy:  12.50%\n",
      "Epoch [1/50], Step [228/375], Loss: 2.2844, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [229/375], Loss: 2.2842, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [230/375], Loss: 2.2821, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [231/375], Loss: 2.2901, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [232/375], Loss: 2.3207, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [233/375], Loss: 2.2973, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [234/375], Loss: 2.3239, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [235/375], Loss: 2.3058, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [236/375], Loss: 2.3438, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [237/375], Loss: 2.3190, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [238/375], Loss: 2.2795, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [239/375], Loss: 2.2829, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [240/375], Loss: 2.2922, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [1/50], Step [241/375], Loss: 2.2770, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [242/375], Loss: 2.2825, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [243/375], Loss: 2.3069, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [244/375], Loss: 2.3093, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [245/375], Loss: 2.2876, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [246/375], Loss: 2.2731, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [247/375], Loss: 2.2728, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [248/375], Loss: 2.2852, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [1/50], Step [249/375], Loss: 2.2747, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [250/375], Loss: 2.3310, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [251/375], Loss: 2.2886, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [252/375], Loss: 2.2832, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [1/50], Step [253/375], Loss: 2.3133, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [254/375], Loss: 2.2810, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [255/375], Loss: 2.3100, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [256/375], Loss: 2.2767, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [257/375], Loss: 2.2544, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [258/375], Loss: 2.3198, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [259/375], Loss: 2.2898, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [260/375], Loss: 2.2891, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [261/375], Loss: 2.2843, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [262/375], Loss: 2.3217, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [263/375], Loss: 2.2599, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [264/375], Loss: 2.2943, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [265/375], Loss: 2.3103, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [266/375], Loss: 2.2966, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [267/375], Loss: 2.3047, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [268/375], Loss: 2.2795, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [269/375], Loss: 2.3269, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [270/375], Loss: 2.3264, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [271/375], Loss: 2.3185, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [272/375], Loss: 2.3214, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [1/50], Step [273/375], Loss: 2.2784, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [274/375], Loss: 2.2976, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [275/375], Loss: 2.2922, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [276/375], Loss: 2.2650, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [277/375], Loss: 2.2671, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [278/375], Loss: 2.3013, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [279/375], Loss: 2.2867, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [280/375], Loss: 2.2878, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [281/375], Loss: 2.3142, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [282/375], Loss: 2.3153, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [283/375], Loss: 2.2777, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [284/375], Loss: 2.2692, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [285/375], Loss: 2.3595, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [286/375], Loss: 2.3001, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [287/375], Loss: 2.2726, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [288/375], Loss: 2.2705, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [289/375], Loss: 2.3022, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [290/375], Loss: 2.2893, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [291/375], Loss: 2.2825, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [292/375], Loss: 2.2947, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [293/375], Loss: 2.3463, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [294/375], Loss: 2.3233, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [295/375], Loss: 2.2673, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [296/375], Loss: 2.3254, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [297/375], Loss: 2.3297, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [298/375], Loss: 2.2775, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [299/375], Loss: 2.3178, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [300/375], Loss: 2.2802, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [301/375], Loss: 2.2621, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [302/375], Loss: 2.3418, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [303/375], Loss: 2.3144, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [304/375], Loss: 2.2881, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [1/50], Step [305/375], Loss: 2.2787, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [306/375], Loss: 2.2767, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [307/375], Loss: 2.3125, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [308/375], Loss: 2.3064, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [309/375], Loss: 2.3019, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [310/375], Loss: 2.2862, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [311/375], Loss: 2.3031, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [312/375], Loss: 2.2892, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [313/375], Loss: 2.3183, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [314/375], Loss: 2.3003, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [315/375], Loss: 2.2786, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [316/375], Loss: 2.3083, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [1/50], Step [317/375], Loss: 2.2959, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [318/375], Loss: 2.3177, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [319/375], Loss: 2.2965, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [320/375], Loss: 2.3000, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [1/50], Step [321/375], Loss: 2.2661, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [1/50], Step [322/375], Loss: 2.3178, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [323/375], Loss: 2.2944, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [324/375], Loss: 2.2945, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [1/50], Step [325/375], Loss: 2.3205, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [326/375], Loss: 2.2847, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [327/375], Loss: 2.3056, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [328/375], Loss: 2.3042, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [329/375], Loss: 2.2909, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [330/375], Loss: 2.2834, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [331/375], Loss: 2.3138, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [332/375], Loss: 2.2917, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [333/375], Loss: 2.2895, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [334/375], Loss: 2.2801, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [335/375], Loss: 2.3046, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [336/375], Loss: 2.3077, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [337/375], Loss: 2.3347, batch time: 0.76, accuracy:  6.25%\n",
      "Epoch [1/50], Step [338/375], Loss: 2.2762, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [339/375], Loss: 2.3294, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [340/375], Loss: 2.2955, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [341/375], Loss: 2.2874, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [342/375], Loss: 2.3011, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [343/375], Loss: 2.2641, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [344/375], Loss: 2.2949, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [345/375], Loss: 2.2893, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [346/375], Loss: 2.3148, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [1/50], Step [347/375], Loss: 2.2949, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [348/375], Loss: 2.2908, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [349/375], Loss: 2.2690, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [1/50], Step [350/375], Loss: 2.2797, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [1/50], Step [351/375], Loss: 2.3261, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [352/375], Loss: 2.2944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [353/375], Loss: 2.3297, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [354/375], Loss: 2.2841, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [355/375], Loss: 2.2914, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [356/375], Loss: 2.2891, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [357/375], Loss: 2.2954, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [358/375], Loss: 2.2967, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [1/50], Step [359/375], Loss: 2.2860, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [360/375], Loss: 2.2820, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [361/375], Loss: 2.2901, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [362/375], Loss: 2.2908, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [1/50], Step [363/375], Loss: 2.3104, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [1/50], Step [364/375], Loss: 2.3009, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [365/375], Loss: 2.2734, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [1/50], Step [366/375], Loss: 2.2932, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [1/50], Step [367/375], Loss: 2.2966, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [368/375], Loss: 2.3215, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [369/375], Loss: 2.2916, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [1/50], Step [370/375], Loss: 2.2594, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [1/50], Step [371/375], Loss: 2.3194, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [1/50], Step [372/375], Loss: 2.3138, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [373/375], Loss: 2.2766, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [1/50], Step [374/375], Loss: 2.2828, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [1/50], Step [375/375], Loss: 2.3013, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [2/50], Step [1/375], Loss: 2.2941, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [2/375], Loss: 2.2935, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [3/375], Loss: 2.2654, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [2/50], Step [4/375], Loss: 2.2962, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [5/375], Loss: 2.2831, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [2/50], Step [6/375], Loss: 2.2836, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [7/375], Loss: 2.3457, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [8/375], Loss: 2.2989, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [9/375], Loss: 2.2782, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [10/375], Loss: 2.2770, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [11/375], Loss: 2.3165, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [12/375], Loss: 2.3222, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [13/375], Loss: 2.2873, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [14/375], Loss: 2.2899, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [2/50], Step [15/375], Loss: 2.2611, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [16/375], Loss: 2.3248, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [17/375], Loss: 2.2884, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [18/375], Loss: 2.2643, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [19/375], Loss: 2.2793, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [2/50], Step [20/375], Loss: 2.2939, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [21/375], Loss: 2.2813, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [22/375], Loss: 2.3183, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [23/375], Loss: 2.2686, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [2/50], Step [24/375], Loss: 2.2534, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [25/375], Loss: 2.2260, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [26/375], Loss: 2.3168, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [27/375], Loss: 2.3496, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [28/375], Loss: 2.3090, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [29/375], Loss: 2.2871, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [30/375], Loss: 2.3096, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [31/375], Loss: 2.2811, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [32/375], Loss: 2.3069, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [2/50], Step [33/375], Loss: 2.3149, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [34/375], Loss: 2.2816, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [35/375], Loss: 2.2944, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [2/50], Step [36/375], Loss: 2.3400, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [37/375], Loss: 2.3462, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [38/375], Loss: 2.2663, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [39/375], Loss: 2.2986, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [40/375], Loss: 2.2643, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [41/375], Loss: 2.2886, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [42/375], Loss: 2.2965, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [2/50], Step [43/375], Loss: 2.3342, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [44/375], Loss: 2.3028, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [45/375], Loss: 2.2586, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [46/375], Loss: 2.2949, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [47/375], Loss: 2.2921, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [48/375], Loss: 2.3346, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [49/375], Loss: 2.2614, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [50/375], Loss: 2.2726, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [51/375], Loss: 2.3196, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [52/375], Loss: 2.2878, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [53/375], Loss: 2.3262, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [54/375], Loss: 2.2781, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [55/375], Loss: 2.3640, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [56/375], Loss: 2.3150, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [57/375], Loss: 2.2860, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [58/375], Loss: 2.2825, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [59/375], Loss: 2.2903, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [2/50], Step [60/375], Loss: 2.3196, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [61/375], Loss: 2.3387, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [62/375], Loss: 2.2702, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [63/375], Loss: 2.3188, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [64/375], Loss: 2.2961, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [65/375], Loss: 2.2862, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [66/375], Loss: 2.2663, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [67/375], Loss: 2.3189, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [2/50], Step [68/375], Loss: 2.2950, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [69/375], Loss: 2.2631, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [2/50], Step [70/375], Loss: 2.2945, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [71/375], Loss: 2.2707, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [2/50], Step [72/375], Loss: 2.3210, batch time: 0.76, accuracy:  6.25%\n",
      "Epoch [2/50], Step [73/375], Loss: 2.2998, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [74/375], Loss: 2.2909, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [75/375], Loss: 2.2765, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [2/50], Step [76/375], Loss: 2.2812, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [77/375], Loss: 2.2792, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [78/375], Loss: 2.3036, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [79/375], Loss: 2.2762, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [80/375], Loss: 2.2984, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [81/375], Loss: 2.2648, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [2/50], Step [82/375], Loss: 2.3110, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [83/375], Loss: 2.3137, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [84/375], Loss: 2.2972, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [85/375], Loss: 2.3024, batch time: 0.29, accuracy:  0.00%\n",
      "Epoch [2/50], Step [86/375], Loss: 2.2851, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [87/375], Loss: 2.2988, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [88/375], Loss: 2.3009, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [89/375], Loss: 2.3097, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [90/375], Loss: 2.2839, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [91/375], Loss: 2.2971, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [92/375], Loss: 2.3224, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [93/375], Loss: 2.2831, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [2/50], Step [94/375], Loss: 2.2933, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [95/375], Loss: 2.2963, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [96/375], Loss: 2.3269, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [97/375], Loss: 2.2958, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [98/375], Loss: 2.2815, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [99/375], Loss: 2.3008, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [100/375], Loss: 2.3012, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [101/375], Loss: 2.3006, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [102/375], Loss: 2.3118, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [103/375], Loss: 2.3129, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [104/375], Loss: 2.2954, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [105/375], Loss: 2.2730, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [2/50], Step [106/375], Loss: 2.2947, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [107/375], Loss: 2.3021, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [108/375], Loss: 2.2905, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [109/375], Loss: 2.2723, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [110/375], Loss: 2.2948, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [111/375], Loss: 2.2821, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [112/375], Loss: 2.2657, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [113/375], Loss: 2.2814, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [2/50], Step [114/375], Loss: 2.3159, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [115/375], Loss: 2.2938, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [116/375], Loss: 2.2970, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [117/375], Loss: 2.2667, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [118/375], Loss: 2.3073, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [119/375], Loss: 2.3178, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [120/375], Loss: 2.3176, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [121/375], Loss: 2.2877, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [122/375], Loss: 2.3400, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [123/375], Loss: 2.2963, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [124/375], Loss: 2.3087, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [125/375], Loss: 2.3050, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [126/375], Loss: 2.2759, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [127/375], Loss: 2.2850, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [128/375], Loss: 2.2748, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [129/375], Loss: 2.2501, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [2/50], Step [130/375], Loss: 2.2288, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [131/375], Loss: 2.2959, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [132/375], Loss: 2.2825, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [133/375], Loss: 2.2927, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [2/50], Step [134/375], Loss: 2.2424, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [135/375], Loss: 2.3283, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [136/375], Loss: 2.3123, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [137/375], Loss: 2.2458, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [138/375], Loss: 2.2394, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [139/375], Loss: 2.3095, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [140/375], Loss: 2.2669, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [141/375], Loss: 2.2824, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [142/375], Loss: 2.2703, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [143/375], Loss: 2.2153, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [144/375], Loss: 2.3291, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [145/375], Loss: 2.1838, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [146/375], Loss: 2.2326, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [2/50], Step [147/375], Loss: 2.3900, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [148/375], Loss: 2.2600, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [149/375], Loss: 2.3235, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [2/50], Step [150/375], Loss: 2.2642, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [151/375], Loss: 2.3847, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [152/375], Loss: 2.2854, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [153/375], Loss: 2.2713, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [154/375], Loss: 2.2214, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [155/375], Loss: 2.1804, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [156/375], Loss: 2.3642, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [157/375], Loss: 2.2460, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [158/375], Loss: 2.2802, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [159/375], Loss: 2.2616, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [160/375], Loss: 2.3383, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [161/375], Loss: 2.2455, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [2/50], Step [162/375], Loss: 2.1985, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [163/375], Loss: 2.2961, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [164/375], Loss: 2.2394, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [165/375], Loss: 2.2487, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [2/50], Step [166/375], Loss: 2.2507, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [167/375], Loss: 2.3062, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [168/375], Loss: 2.2535, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [169/375], Loss: 2.3410, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [170/375], Loss: 2.3257, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [171/375], Loss: 2.2637, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [172/375], Loss: 2.3645, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [173/375], Loss: 2.2961, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [174/375], Loss: 2.2705, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [175/375], Loss: 2.2440, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [2/50], Step [176/375], Loss: 2.2043, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [177/375], Loss: 2.2719, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [178/375], Loss: 2.3168, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [179/375], Loss: 2.3657, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [180/375], Loss: 2.2048, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [181/375], Loss: 2.2378, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [182/375], Loss: 2.1671, batch time: 0.75, accuracy:  18.75%\n",
      "Epoch [2/50], Step [183/375], Loss: 2.2121, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [184/375], Loss: 2.2041, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [185/375], Loss: 2.3323, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [186/375], Loss: 2.3202, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [187/375], Loss: 2.3730, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [188/375], Loss: 2.2519, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [189/375], Loss: 2.2487, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [190/375], Loss: 2.2276, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [191/375], Loss: 2.2957, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [192/375], Loss: 2.3446, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [193/375], Loss: 2.3337, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [194/375], Loss: 2.2678, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [195/375], Loss: 2.2577, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [196/375], Loss: 2.2085, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [197/375], Loss: 2.2922, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [198/375], Loss: 2.1366, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [199/375], Loss: 2.2985, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [200/375], Loss: 2.3786, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [201/375], Loss: 2.4143, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [202/375], Loss: 2.3873, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [203/375], Loss: 2.2949, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [204/375], Loss: 2.3281, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [205/375], Loss: 2.2217, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [206/375], Loss: 2.2646, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [207/375], Loss: 2.2976, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [208/375], Loss: 2.2448, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [209/375], Loss: 2.3967, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [210/375], Loss: 2.3648, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [211/375], Loss: 2.2562, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [212/375], Loss: 2.3077, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [213/375], Loss: 2.2786, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [214/375], Loss: 2.2884, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [215/375], Loss: 2.3135, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [216/375], Loss: 2.2615, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [217/375], Loss: 2.2688, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [218/375], Loss: 2.2696, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [219/375], Loss: 2.2803, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [220/375], Loss: 2.3059, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [221/375], Loss: 2.2295, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [222/375], Loss: 2.3319, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [2/50], Step [223/375], Loss: 2.3125, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [224/375], Loss: 2.2205, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [225/375], Loss: 2.3091, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [226/375], Loss: 2.3003, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [227/375], Loss: 2.2408, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [228/375], Loss: 2.2573, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [229/375], Loss: 2.2692, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [230/375], Loss: 2.2888, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [231/375], Loss: 2.3380, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [232/375], Loss: 2.2771, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [233/375], Loss: 2.3610, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [234/375], Loss: 2.3049, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [235/375], Loss: 2.3010, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [236/375], Loss: 2.3540, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [237/375], Loss: 2.2969, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [238/375], Loss: 2.3009, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [239/375], Loss: 2.2996, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [240/375], Loss: 2.2746, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [241/375], Loss: 2.2897, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [242/375], Loss: 2.2120, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [243/375], Loss: 2.3089, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [244/375], Loss: 2.2876, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [245/375], Loss: 2.2681, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [246/375], Loss: 2.3120, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [247/375], Loss: 2.2772, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [248/375], Loss: 2.2979, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [249/375], Loss: 2.3457, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [250/375], Loss: 2.3227, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [251/375], Loss: 2.2832, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [252/375], Loss: 2.2244, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [253/375], Loss: 2.2505, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [254/375], Loss: 2.2541, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [255/375], Loss: 2.2667, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [256/375], Loss: 2.2714, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [257/375], Loss: 2.2985, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [258/375], Loss: 2.3146, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [259/375], Loss: 2.3298, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [260/375], Loss: 2.3110, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [261/375], Loss: 2.2391, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [262/375], Loss: 2.2842, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [263/375], Loss: 2.2767, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [264/375], Loss: 2.2594, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [265/375], Loss: 2.2399, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [266/375], Loss: 2.3032, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [267/375], Loss: 2.2736, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [268/375], Loss: 2.3180, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [269/375], Loss: 2.2397, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [270/375], Loss: 2.2472, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [271/375], Loss: 2.2382, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [2/50], Step [272/375], Loss: 2.2567, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [273/375], Loss: 2.2571, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [274/375], Loss: 2.2759, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [275/375], Loss: 2.3501, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [276/375], Loss: 2.2177, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [2/50], Step [277/375], Loss: 2.1719, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [278/375], Loss: 2.2731, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [279/375], Loss: 2.3761, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [280/375], Loss: 2.1606, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [281/375], Loss: 2.1602, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [282/375], Loss: 2.3195, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [283/375], Loss: 2.1956, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [284/375], Loss: 2.2401, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [285/375], Loss: 2.3311, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [286/375], Loss: 2.2691, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [287/375], Loss: 2.3037, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [288/375], Loss: 2.3193, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [289/375], Loss: 2.2843, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [290/375], Loss: 2.2464, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [291/375], Loss: 2.2471, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [292/375], Loss: 2.3238, batch time: 0.76, accuracy:  6.25%\n",
      "Epoch [2/50], Step [293/375], Loss: 2.3128, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [294/375], Loss: 2.3538, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [295/375], Loss: 2.3313, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [296/375], Loss: 2.1188, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [297/375], Loss: 2.3427, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [298/375], Loss: 2.3328, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [299/375], Loss: 2.2146, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [300/375], Loss: 2.1689, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [301/375], Loss: 2.3056, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [302/375], Loss: 2.4326, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [303/375], Loss: 2.3352, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [304/375], Loss: 2.2865, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [305/375], Loss: 2.2893, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [306/375], Loss: 2.3205, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [307/375], Loss: 2.3798, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [308/375], Loss: 2.2519, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [309/375], Loss: 2.3293, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [310/375], Loss: 2.2675, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [311/375], Loss: 2.2791, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [312/375], Loss: 2.2774, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [313/375], Loss: 2.2566, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [2/50], Step [314/375], Loss: 2.2120, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [315/375], Loss: 2.3076, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [316/375], Loss: 2.2037, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [317/375], Loss: 2.2973, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [318/375], Loss: 2.2518, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [319/375], Loss: 2.2011, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [320/375], Loss: 2.3144, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [321/375], Loss: 2.2160, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [2/50], Step [322/375], Loss: 2.2929, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [323/375], Loss: 2.3864, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [324/375], Loss: 2.3399, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [325/375], Loss: 2.3224, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [326/375], Loss: 2.2392, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [327/375], Loss: 2.2160, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [328/375], Loss: 2.2289, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [329/375], Loss: 2.2586, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [2/50], Step [330/375], Loss: 2.2396, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [331/375], Loss: 2.2588, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [332/375], Loss: 2.2350, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [333/375], Loss: 2.2549, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [334/375], Loss: 2.2677, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [335/375], Loss: 2.2576, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [336/375], Loss: 2.2693, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [337/375], Loss: 2.2199, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [2/50], Step [338/375], Loss: 2.2968, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [339/375], Loss: 2.2802, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [340/375], Loss: 2.3839, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [341/375], Loss: 2.1663, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [2/50], Step [342/375], Loss: 2.2214, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [343/375], Loss: 2.2963, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [344/375], Loss: 2.3303, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [345/375], Loss: 2.2526, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [2/50], Step [346/375], Loss: 2.2262, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [347/375], Loss: 2.1970, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [2/50], Step [348/375], Loss: 2.3100, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [349/375], Loss: 2.2662, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [2/50], Step [350/375], Loss: 2.2466, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [351/375], Loss: 2.1750, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [352/375], Loss: 2.3766, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [2/50], Step [353/375], Loss: 2.3280, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [2/50], Step [354/375], Loss: 2.3954, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [2/50], Step [355/375], Loss: 2.3215, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [356/375], Loss: 2.3769, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [357/375], Loss: 2.2824, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [2/50], Step [358/375], Loss: 2.2845, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [359/375], Loss: 2.3084, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [360/375], Loss: 2.2912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [361/375], Loss: 2.2738, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [362/375], Loss: 2.2927, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [363/375], Loss: 2.4544, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [364/375], Loss: 2.2650, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [365/375], Loss: 2.3580, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [2/50], Step [366/375], Loss: 2.0789, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [2/50], Step [367/375], Loss: 2.3557, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [2/50], Step [368/375], Loss: 2.2674, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [2/50], Step [369/375], Loss: 2.3627, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [2/50], Step [370/375], Loss: 2.2853, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [2/50], Step [371/375], Loss: 2.2753, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [372/375], Loss: 2.2143, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [2/50], Step [373/375], Loss: 2.2685, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [2/50], Step [374/375], Loss: 2.2257, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [2/50], Step [375/375], Loss: 2.3441, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [1/375], Loss: 2.2156, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [2/375], Loss: 2.2827, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [3/375], Loss: 2.2858, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [4/375], Loss: 2.1237, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [5/375], Loss: 2.2515, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [6/375], Loss: 2.2943, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [7/375], Loss: 2.2303, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [8/375], Loss: 2.3076, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [9/375], Loss: 2.1775, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [10/375], Loss: 2.2402, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [3/50], Step [11/375], Loss: 2.2950, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [12/375], Loss: 2.2268, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [13/375], Loss: 2.2649, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [14/375], Loss: 2.2719, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [3/50], Step [15/375], Loss: 2.2719, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [16/375], Loss: 2.3336, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [17/375], Loss: 2.1003, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [18/375], Loss: 2.2650, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [19/375], Loss: 2.3003, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [20/375], Loss: 2.2312, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [21/375], Loss: 2.1639, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [22/375], Loss: 2.3243, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [23/375], Loss: 2.2747, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [24/375], Loss: 2.1709, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [25/375], Loss: 2.2320, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [26/375], Loss: 2.2295, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [27/375], Loss: 2.2878, batch time: 0.76, accuracy:  25.00%\n",
      "Epoch [3/50], Step [28/375], Loss: 2.2875, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [29/375], Loss: 2.1694, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [30/375], Loss: 2.2690, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [31/375], Loss: 2.2214, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [32/375], Loss: 2.3777, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [33/375], Loss: 2.1554, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [34/375], Loss: 2.0694, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [35/375], Loss: 2.4031, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [36/375], Loss: 2.3445, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [3/50], Step [37/375], Loss: 2.1818, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [38/375], Loss: 2.3319, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [39/375], Loss: 2.4723, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [40/375], Loss: 2.4069, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [41/375], Loss: 2.1323, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [42/375], Loss: 2.1492, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [43/375], Loss: 2.2268, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [44/375], Loss: 2.2211, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [45/375], Loss: 2.2762, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [46/375], Loss: 2.2410, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [47/375], Loss: 2.2175, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [48/375], Loss: 2.4065, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [49/375], Loss: 2.1648, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [50/375], Loss: 2.1561, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [51/375], Loss: 2.2752, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [52/375], Loss: 2.0897, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [3/50], Step [53/375], Loss: 2.1493, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [54/375], Loss: 2.0931, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [55/375], Loss: 2.1648, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [56/375], Loss: 2.2060, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [57/375], Loss: 2.1274, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [58/375], Loss: 2.4065, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [59/375], Loss: 2.1820, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [60/375], Loss: 2.1742, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [61/375], Loss: 2.3247, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [62/375], Loss: 2.3301, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [63/375], Loss: 2.1280, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [64/375], Loss: 2.3217, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [3/50], Step [65/375], Loss: 2.2815, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [66/375], Loss: 2.2430, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [67/375], Loss: 2.3475, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [68/375], Loss: 2.1879, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [69/375], Loss: 2.3594, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [70/375], Loss: 2.3600, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [3/50], Step [71/375], Loss: 2.0012, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [72/375], Loss: 2.3821, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [73/375], Loss: 2.1237, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [74/375], Loss: 2.3406, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [75/375], Loss: 2.1499, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [76/375], Loss: 2.1826, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [3/50], Step [77/375], Loss: 2.3218, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [78/375], Loss: 2.0067, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [79/375], Loss: 2.2764, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [80/375], Loss: 2.1418, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [81/375], Loss: 2.3946, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [82/375], Loss: 2.1238, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [83/375], Loss: 2.3977, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [84/375], Loss: 2.1696, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [85/375], Loss: 2.2145, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [86/375], Loss: 2.5073, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [87/375], Loss: 2.1611, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [88/375], Loss: 2.3668, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [89/375], Loss: 2.3540, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [90/375], Loss: 2.3068, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [91/375], Loss: 2.2071, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [92/375], Loss: 2.3227, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [93/375], Loss: 2.3506, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [94/375], Loss: 2.3655, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [95/375], Loss: 2.3200, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [96/375], Loss: 2.2784, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [97/375], Loss: 2.3764, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [98/375], Loss: 2.2694, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [99/375], Loss: 2.2188, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [100/375], Loss: 2.1513, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [101/375], Loss: 2.2647, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [102/375], Loss: 2.3363, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [103/375], Loss: 2.4453, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [104/375], Loss: 2.4049, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [105/375], Loss: 2.1626, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [106/375], Loss: 2.1827, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [107/375], Loss: 2.2622, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [108/375], Loss: 2.0701, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [3/50], Step [109/375], Loss: 2.3940, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [110/375], Loss: 2.5083, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [111/375], Loss: 2.3952, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [112/375], Loss: 2.2281, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [113/375], Loss: 2.3485, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [114/375], Loss: 2.2399, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [115/375], Loss: 2.2269, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [116/375], Loss: 2.2626, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [117/375], Loss: 2.1804, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [118/375], Loss: 2.1294, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [119/375], Loss: 2.2574, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [120/375], Loss: 2.2851, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [121/375], Loss: 2.3083, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [122/375], Loss: 2.2484, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [123/375], Loss: 2.2040, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [124/375], Loss: 2.2180, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [125/375], Loss: 2.2468, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [126/375], Loss: 2.1368, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [127/375], Loss: 2.2011, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [128/375], Loss: 2.2543, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [129/375], Loss: 2.1834, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [130/375], Loss: 2.1468, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [131/375], Loss: 2.2760, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [132/375], Loss: 2.1305, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [133/375], Loss: 2.4340, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [134/375], Loss: 2.1695, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [135/375], Loss: 2.3147, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [136/375], Loss: 2.3896, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [3/50], Step [137/375], Loss: 2.3767, batch time: 0.76, accuracy:  12.50%\n",
      "Epoch [3/50], Step [138/375], Loss: 2.3201, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [139/375], Loss: 2.0584, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [140/375], Loss: 2.3958, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [141/375], Loss: 2.1135, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [142/375], Loss: 2.4434, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [143/375], Loss: 2.2625, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [144/375], Loss: 2.2549, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [145/375], Loss: 2.3228, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [146/375], Loss: 2.2170, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [3/50], Step [147/375], Loss: 2.1618, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [148/375], Loss: 2.3488, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [149/375], Loss: 2.1823, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [150/375], Loss: 2.3291, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [151/375], Loss: 2.0847, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [152/375], Loss: 2.1153, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [153/375], Loss: 2.1724, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [154/375], Loss: 2.3014, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [155/375], Loss: 2.3357, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [156/375], Loss: 2.2969, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [157/375], Loss: 2.3464, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [158/375], Loss: 2.3460, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [159/375], Loss: 2.2697, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [160/375], Loss: 2.4087, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [161/375], Loss: 2.2341, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [162/375], Loss: 2.2785, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [3/50], Step [163/375], Loss: 2.2594, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [164/375], Loss: 2.3086, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [165/375], Loss: 2.3615, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [166/375], Loss: 2.1714, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [167/375], Loss: 2.1663, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [168/375], Loss: 2.4358, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [169/375], Loss: 2.0933, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [170/375], Loss: 2.1622, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [3/50], Step [171/375], Loss: 2.4096, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [172/375], Loss: 2.3812, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [173/375], Loss: 2.1449, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [174/375], Loss: 2.3461, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [175/375], Loss: 2.2034, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [176/375], Loss: 2.3288, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [177/375], Loss: 2.2788, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [178/375], Loss: 2.3091, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [179/375], Loss: 2.2339, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [180/375], Loss: 2.2717, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [181/375], Loss: 2.3582, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [182/375], Loss: 2.1033, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [183/375], Loss: 2.2060, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [184/375], Loss: 2.0792, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [185/375], Loss: 2.1857, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [186/375], Loss: 2.2074, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [3/50], Step [187/375], Loss: 2.2360, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [188/375], Loss: 2.2227, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [189/375], Loss: 2.3230, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [190/375], Loss: 2.2847, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [3/50], Step [191/375], Loss: 2.2042, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [192/375], Loss: 2.4091, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [193/375], Loss: 2.1859, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [194/375], Loss: 2.2273, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [195/375], Loss: 2.2478, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [196/375], Loss: 2.2864, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [197/375], Loss: 2.2694, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [198/375], Loss: 2.4265, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [199/375], Loss: 2.1871, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [200/375], Loss: 2.1923, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [201/375], Loss: 2.2899, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [202/375], Loss: 2.1066, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [3/50], Step [203/375], Loss: 2.3089, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [204/375], Loss: 2.2840, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [205/375], Loss: 2.2620, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [206/375], Loss: 2.0791, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [207/375], Loss: 2.3018, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [208/375], Loss: 2.1968, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [209/375], Loss: 2.0923, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [3/50], Step [210/375], Loss: 2.1060, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [211/375], Loss: 2.2785, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [212/375], Loss: 2.1051, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [213/375], Loss: 2.2219, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [214/375], Loss: 2.4032, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [3/50], Step [215/375], Loss: 2.2376, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [216/375], Loss: 2.2999, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [217/375], Loss: 2.6825, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [218/375], Loss: 2.3386, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [219/375], Loss: 2.0217, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [220/375], Loss: 2.2173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [221/375], Loss: 2.2555, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [222/375], Loss: 2.3202, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [223/375], Loss: 2.0602, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [224/375], Loss: 2.1895, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [225/375], Loss: 2.2550, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [226/375], Loss: 2.4397, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [3/50], Step [227/375], Loss: 2.1137, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [228/375], Loss: 2.1860, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [229/375], Loss: 1.9666, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [3/50], Step [230/375], Loss: 2.3050, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [231/375], Loss: 2.1813, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [232/375], Loss: 2.2899, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [233/375], Loss: 2.1481, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [234/375], Loss: 2.1624, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [235/375], Loss: 2.2050, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [236/375], Loss: 2.4096, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [237/375], Loss: 2.0981, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [238/375], Loss: 2.2512, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [239/375], Loss: 2.3091, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [240/375], Loss: 2.2727, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [241/375], Loss: 2.3593, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [242/375], Loss: 2.0806, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [243/375], Loss: 2.3081, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [244/375], Loss: 2.4243, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [245/375], Loss: 2.2445, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [246/375], Loss: 2.4114, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [247/375], Loss: 2.2886, batch time: 0.76, accuracy:  18.75%\n",
      "Epoch [3/50], Step [248/375], Loss: 2.2803, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [249/375], Loss: 2.2226, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [250/375], Loss: 2.2821, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [251/375], Loss: 2.1661, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [252/375], Loss: 2.0368, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [253/375], Loss: 2.3614, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [254/375], Loss: 2.3151, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [255/375], Loss: 2.3422, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [256/375], Loss: 2.1412, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [257/375], Loss: 2.1457, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [258/375], Loss: 2.3588, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [259/375], Loss: 2.3161, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [260/375], Loss: 2.1033, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [261/375], Loss: 2.3257, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [262/375], Loss: 2.1283, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [263/375], Loss: 2.0709, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [264/375], Loss: 2.0519, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [265/375], Loss: 2.3579, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [266/375], Loss: 2.0649, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [267/375], Loss: 2.2811, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [268/375], Loss: 2.3644, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [269/375], Loss: 2.3225, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [270/375], Loss: 2.3013, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [271/375], Loss: 2.3948, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [272/375], Loss: 2.1512, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [273/375], Loss: 2.3537, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [274/375], Loss: 2.2382, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [275/375], Loss: 2.2635, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [276/375], Loss: 2.0570, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [3/50], Step [277/375], Loss: 2.2574, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [278/375], Loss: 2.3361, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [279/375], Loss: 2.0069, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [3/50], Step [280/375], Loss: 2.1275, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [281/375], Loss: 2.1547, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [282/375], Loss: 1.9821, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [283/375], Loss: 2.2823, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [284/375], Loss: 2.3440, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [3/50], Step [285/375], Loss: 2.2919, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [286/375], Loss: 2.4400, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [287/375], Loss: 2.3441, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [288/375], Loss: 2.2263, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [289/375], Loss: 2.1389, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [290/375], Loss: 2.2857, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [291/375], Loss: 2.1055, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [292/375], Loss: 2.1293, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [293/375], Loss: 2.3893, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [294/375], Loss: 2.1107, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [295/375], Loss: 2.3522, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [296/375], Loss: 2.4019, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [297/375], Loss: 2.3085, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [298/375], Loss: 2.3839, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [299/375], Loss: 2.1113, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [300/375], Loss: 2.2673, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [3/50], Step [301/375], Loss: 2.1450, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [302/375], Loss: 2.3566, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [303/375], Loss: 2.2128, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [304/375], Loss: 2.4127, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [305/375], Loss: 2.2569, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [306/375], Loss: 2.2264, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [307/375], Loss: 2.3587, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [308/375], Loss: 2.3333, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [309/375], Loss: 2.1153, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [310/375], Loss: 2.0788, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [311/375], Loss: 2.3691, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [312/375], Loss: 2.0949, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [3/50], Step [313/375], Loss: 2.2705, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [314/375], Loss: 2.4993, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [3/50], Step [315/375], Loss: 2.3244, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [316/375], Loss: 2.3234, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [317/375], Loss: 2.3770, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [3/50], Step [318/375], Loss: 2.2027, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [319/375], Loss: 2.2060, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [320/375], Loss: 2.1579, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [321/375], Loss: 2.2996, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [322/375], Loss: 2.2844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [323/375], Loss: 2.1127, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [3/50], Step [324/375], Loss: 2.1657, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [3/50], Step [325/375], Loss: 2.3098, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [326/375], Loss: 2.4313, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [327/375], Loss: 2.1370, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [328/375], Loss: 2.2764, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [3/50], Step [329/375], Loss: 2.1566, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [330/375], Loss: 2.2593, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [331/375], Loss: 2.2198, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [3/50], Step [332/375], Loss: 2.2291, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [333/375], Loss: 2.1667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [334/375], Loss: 2.0809, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [335/375], Loss: 2.4990, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [336/375], Loss: 2.2073, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [337/375], Loss: 2.3145, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [338/375], Loss: 2.1552, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [339/375], Loss: 2.4012, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [340/375], Loss: 2.3233, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [341/375], Loss: 2.4064, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [342/375], Loss: 2.2714, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [343/375], Loss: 2.3341, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [344/375], Loss: 2.2227, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [345/375], Loss: 2.3696, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [3/50], Step [346/375], Loss: 2.0230, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [347/375], Loss: 2.1438, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [348/375], Loss: 2.4229, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [3/50], Step [349/375], Loss: 1.9965, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [3/50], Step [350/375], Loss: 2.1609, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [351/375], Loss: 2.2504, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [352/375], Loss: 2.1443, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [353/375], Loss: 2.1063, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [354/375], Loss: 2.2537, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [355/375], Loss: 2.1886, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [356/375], Loss: 2.2655, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [357/375], Loss: 2.1530, batch time: 0.76, accuracy:  31.25%\n",
      "Epoch [3/50], Step [358/375], Loss: 2.2845, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [359/375], Loss: 2.2960, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [360/375], Loss: 2.1225, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [3/50], Step [361/375], Loss: 2.2556, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [362/375], Loss: 2.1823, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [363/375], Loss: 2.1907, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [3/50], Step [364/375], Loss: 2.0654, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [3/50], Step [365/375], Loss: 2.3339, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [366/375], Loss: 2.3303, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [3/50], Step [367/375], Loss: 2.1842, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [368/375], Loss: 2.2639, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [3/50], Step [369/375], Loss: 2.0675, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [3/50], Step [370/375], Loss: 2.1157, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [3/50], Step [371/375], Loss: 2.4165, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [3/50], Step [372/375], Loss: 2.1175, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [3/50], Step [373/375], Loss: 2.4362, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [3/50], Step [374/375], Loss: 2.1968, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [3/50], Step [375/375], Loss: 2.1503, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [1/375], Loss: 2.5141, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [2/375], Loss: 2.1099, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [3/375], Loss: 1.9072, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [4/50], Step [4/375], Loss: 2.3348, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [5/375], Loss: 2.4674, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [6/375], Loss: 2.2101, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [7/375], Loss: 2.2728, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [8/375], Loss: 2.0880, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [9/375], Loss: 2.1453, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [10/375], Loss: 2.4039, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [11/375], Loss: 2.1703, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [12/375], Loss: 2.3212, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [13/375], Loss: 2.1068, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [14/375], Loss: 2.3145, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [15/375], Loss: 2.1686, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [16/375], Loss: 2.3347, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [17/375], Loss: 2.1305, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [18/375], Loss: 2.1921, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [19/375], Loss: 2.0713, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [20/375], Loss: 2.5347, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [21/375], Loss: 2.2232, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [22/375], Loss: 2.2510, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [23/375], Loss: 2.3354, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [4/50], Step [24/375], Loss: 2.3882, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [25/375], Loss: 2.1614, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [26/375], Loss: 2.3023, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [27/375], Loss: 2.1598, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [28/375], Loss: 2.2563, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [29/375], Loss: 2.2914, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [30/375], Loss: 2.0276, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [4/50], Step [31/375], Loss: 2.3273, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [32/375], Loss: 2.4379, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [33/375], Loss: 2.1642, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [34/375], Loss: 2.1819, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [35/375], Loss: 2.1757, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [36/375], Loss: 2.4981, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [37/375], Loss: 2.1825, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [38/375], Loss: 2.1085, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [39/375], Loss: 2.1738, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [40/375], Loss: 2.3228, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [41/375], Loss: 2.0590, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [42/375], Loss: 2.2981, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [43/375], Loss: 2.2586, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [4/50], Step [44/375], Loss: 2.1484, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [45/375], Loss: 2.2178, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [46/375], Loss: 2.3043, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [47/375], Loss: 2.3682, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [48/375], Loss: 2.3620, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [49/375], Loss: 2.1229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [50/375], Loss: 2.1709, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [51/375], Loss: 2.1810, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [52/375], Loss: 2.3031, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [53/375], Loss: 2.2699, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [54/375], Loss: 2.3194, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [55/375], Loss: 2.0662, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [4/50], Step [56/375], Loss: 1.9918, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [57/375], Loss: 2.3081, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [58/375], Loss: 2.1045, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [59/375], Loss: 2.1812, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [4/50], Step [60/375], Loss: 2.3190, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [61/375], Loss: 2.2761, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [62/375], Loss: 2.0648, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [63/375], Loss: 2.0539, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [64/375], Loss: 2.1760, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [65/375], Loss: 2.4655, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [66/375], Loss: 2.4694, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [67/375], Loss: 2.1470, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [68/375], Loss: 2.3400, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [69/375], Loss: 2.2184, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [70/375], Loss: 2.2314, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [71/375], Loss: 2.3428, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [72/375], Loss: 2.3397, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [73/375], Loss: 2.1128, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [74/375], Loss: 2.0840, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [75/375], Loss: 2.1143, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [76/375], Loss: 2.2656, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [77/375], Loss: 2.3372, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [78/375], Loss: 2.3031, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [79/375], Loss: 2.2458, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [80/375], Loss: 2.3194, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [81/375], Loss: 2.2223, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [82/375], Loss: 2.5197, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [83/375], Loss: 2.3642, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [84/375], Loss: 2.0651, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [85/375], Loss: 2.2575, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [86/375], Loss: 2.1861, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [87/375], Loss: 2.3017, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [88/375], Loss: 2.1845, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [89/375], Loss: 2.3660, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [90/375], Loss: 2.0340, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [4/50], Step [91/375], Loss: 2.2465, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [92/375], Loss: 2.2265, batch time: 0.91, accuracy:  12.50%\n",
      "Epoch [4/50], Step [93/375], Loss: 2.3290, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [94/375], Loss: 2.1462, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [95/375], Loss: 2.4780, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [4/50], Step [96/375], Loss: 2.3455, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [97/375], Loss: 2.2151, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [98/375], Loss: 2.3696, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [99/375], Loss: 2.2398, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [100/375], Loss: 2.0775, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [4/50], Step [101/375], Loss: 2.3388, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [4/50], Step [102/375], Loss: 2.2525, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [103/375], Loss: 2.3872, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [104/375], Loss: 2.3226, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [105/375], Loss: 2.1867, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [106/375], Loss: 2.1410, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [107/375], Loss: 2.2354, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [108/375], Loss: 2.2044, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [109/375], Loss: 2.0234, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [4/50], Step [110/375], Loss: 2.1150, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [111/375], Loss: 2.1932, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [112/375], Loss: 2.2868, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [113/375], Loss: 2.2078, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [114/375], Loss: 2.1677, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [115/375], Loss: 2.2737, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [116/375], Loss: 2.1658, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [117/375], Loss: 2.2512, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [118/375], Loss: 2.1500, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [119/375], Loss: 2.2240, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [120/375], Loss: 2.0441, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [121/375], Loss: 2.3562, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [122/375], Loss: 2.0879, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [123/375], Loss: 2.0511, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [4/50], Step [124/375], Loss: 2.3674, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [125/375], Loss: 2.0294, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [126/375], Loss: 1.8637, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [127/375], Loss: 2.4858, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [128/375], Loss: 2.3973, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [129/375], Loss: 2.2931, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [130/375], Loss: 2.2616, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [131/375], Loss: 2.3248, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [132/375], Loss: 2.0296, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [133/375], Loss: 2.1587, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [134/375], Loss: 2.1397, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [135/375], Loss: 2.1638, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [136/375], Loss: 2.1591, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [137/375], Loss: 2.1378, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [138/375], Loss: 2.2493, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [139/375], Loss: 2.0194, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [140/375], Loss: 2.2403, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [141/375], Loss: 2.3585, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [142/375], Loss: 2.3746, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [143/375], Loss: 2.3741, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [144/375], Loss: 1.9511, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [145/375], Loss: 2.0670, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [4/50], Step [146/375], Loss: 2.3386, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [147/375], Loss: 2.2278, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [148/375], Loss: 2.2249, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [149/375], Loss: 2.2325, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [150/375], Loss: 2.2274, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [151/375], Loss: 2.2801, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [152/375], Loss: 2.3786, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [153/375], Loss: 2.1323, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [154/375], Loss: 2.1973, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [155/375], Loss: 2.5010, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [156/375], Loss: 2.2994, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [157/375], Loss: 2.1461, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [158/375], Loss: 2.0754, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [159/375], Loss: 2.1338, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [160/375], Loss: 2.1765, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [161/375], Loss: 2.2251, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [162/375], Loss: 2.4196, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [163/375], Loss: 2.4463, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [164/375], Loss: 2.2870, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [165/375], Loss: 2.2018, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [166/375], Loss: 2.2185, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [4/50], Step [167/375], Loss: 2.1852, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [168/375], Loss: 2.1821, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [169/375], Loss: 2.3649, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [4/50], Step [170/375], Loss: 2.3530, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [171/375], Loss: 2.1041, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [172/375], Loss: 2.3005, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [173/375], Loss: 2.1907, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [4/50], Step [174/375], Loss: 2.2647, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [175/375], Loss: 2.1549, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [176/375], Loss: 2.2778, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [177/375], Loss: 2.2819, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [178/375], Loss: 2.0720, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [4/50], Step [179/375], Loss: 2.2785, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [180/375], Loss: 2.3054, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [181/375], Loss: 2.2399, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [182/375], Loss: 2.4140, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [183/375], Loss: 2.1646, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [184/375], Loss: 2.2495, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [185/375], Loss: 2.2843, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [186/375], Loss: 2.2570, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [187/375], Loss: 2.3579, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [188/375], Loss: 2.0895, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [189/375], Loss: 2.0910, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [4/50], Step [190/375], Loss: 2.1660, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [191/375], Loss: 2.3481, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [192/375], Loss: 2.2393, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [193/375], Loss: 2.2115, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [4/50], Step [194/375], Loss: 2.4387, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [195/375], Loss: 2.2403, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [196/375], Loss: 2.3773, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [197/375], Loss: 2.3023, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [198/375], Loss: 2.3713, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [199/375], Loss: 2.2831, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [4/50], Step [200/375], Loss: 2.3148, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [201/375], Loss: 2.4249, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [202/375], Loss: 2.2095, batch time: 0.76, accuracy:  25.00%\n",
      "Epoch [4/50], Step [203/375], Loss: 2.3706, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [204/375], Loss: 2.1394, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [205/375], Loss: 2.2908, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [4/50], Step [206/375], Loss: 2.2079, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [207/375], Loss: 2.2572, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [208/375], Loss: 2.3795, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [209/375], Loss: 2.3888, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [210/375], Loss: 2.2903, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [211/375], Loss: 1.9715, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [4/50], Step [212/375], Loss: 2.1509, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [213/375], Loss: 2.2667, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [214/375], Loss: 2.2072, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [215/375], Loss: 2.3648, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [4/50], Step [216/375], Loss: 2.1539, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [4/50], Step [217/375], Loss: 2.1162, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [218/375], Loss: 2.3039, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [219/375], Loss: 2.2892, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [220/375], Loss: 2.2098, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [221/375], Loss: 2.2767, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [222/375], Loss: 2.3100, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [223/375], Loss: 2.2109, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [224/375], Loss: 2.3019, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [4/50], Step [225/375], Loss: 2.1950, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [4/50], Step [226/375], Loss: 2.2103, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [227/375], Loss: 2.4119, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [228/375], Loss: 2.1350, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [4/50], Step [229/375], Loss: 2.3166, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [230/375], Loss: 2.1719, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [231/375], Loss: 2.1667, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [4/50], Step [232/375], Loss: 2.3937, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [233/375], Loss: 2.4735, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [234/375], Loss: 2.3588, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [4/50], Step [235/375], Loss: 2.3149, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [236/375], Loss: 2.2245, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [237/375], Loss: 2.2540, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [238/375], Loss: 2.4275, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [239/375], Loss: 2.3273, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [4/50], Step [240/375], Loss: 2.3636, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [241/375], Loss: 2.2232, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [242/375], Loss: 2.0836, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [4/50], Step [243/375], Loss: 2.2561, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [244/375], Loss: 2.0938, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [245/375], Loss: 2.2111, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [246/375], Loss: 2.2220, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [247/375], Loss: 2.2693, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [248/375], Loss: 2.1795, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [249/375], Loss: 2.2573, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [250/375], Loss: 2.2121, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [251/375], Loss: 2.2870, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [4/50], Step [252/375], Loss: 2.3707, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [253/375], Loss: 2.3936, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [254/375], Loss: 2.2680, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [4/50], Step [255/375], Loss: 2.1273, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [256/375], Loss: 2.1819, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [257/375], Loss: 2.2563, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [258/375], Loss: 2.2447, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [259/375], Loss: 2.1638, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [4/50], Step [260/375], Loss: 2.3173, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [261/375], Loss: 2.1748, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [262/375], Loss: 2.3484, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [263/375], Loss: 2.3621, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [264/375], Loss: 2.4487, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [265/375], Loss: 2.3118, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [266/375], Loss: 2.4722, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [267/375], Loss: 2.2380, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [4/50], Step [268/375], Loss: 2.2930, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [269/375], Loss: 2.2193, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [270/375], Loss: 2.2811, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [4/50], Step [271/375], Loss: 2.3516, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [272/375], Loss: 2.2785, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [273/375], Loss: 2.2068, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [4/50], Step [274/375], Loss: 2.2558, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [275/375], Loss: 2.2717, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [4/50], Step [276/375], Loss: 2.2323, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [277/375], Loss: 2.3273, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [278/375], Loss: 2.4498, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [279/375], Loss: 2.1846, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [280/375], Loss: 2.3204, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [281/375], Loss: 2.3159, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [282/375], Loss: 2.3233, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [283/375], Loss: 2.3151, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [4/50], Step [284/375], Loss: 2.2895, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [285/375], Loss: 2.4100, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [4/50], Step [286/375], Loss: 2.1625, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [287/375], Loss: 2.4142, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [288/375], Loss: 2.3459, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [289/375], Loss: 2.3379, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [290/375], Loss: 2.2330, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [4/50], Step [291/375], Loss: 2.2375, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [292/375], Loss: 2.3236, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [293/375], Loss: 2.0167, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [294/375], Loss: 2.2935, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [295/375], Loss: 2.2802, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [296/375], Loss: 2.1902, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [297/375], Loss: 2.0329, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [4/50], Step [298/375], Loss: 2.3880, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [299/375], Loss: 2.2312, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [300/375], Loss: 2.3444, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [301/375], Loss: 2.3549, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [302/375], Loss: 2.3296, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [303/375], Loss: 2.3153, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [304/375], Loss: 2.2127, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [305/375], Loss: 2.2636, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [306/375], Loss: 2.3534, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [4/50], Step [307/375], Loss: 2.1162, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [4/50], Step [308/375], Loss: 2.3367, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [309/375], Loss: 2.3559, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [310/375], Loss: 2.2144, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [4/50], Step [311/375], Loss: 2.3820, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [4/50], Step [312/375], Loss: 2.3219, batch time: 0.79, accuracy:  6.25%\n",
      "Epoch [4/50], Step [313/375], Loss: 2.1606, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [314/375], Loss: 2.2509, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [315/375], Loss: 2.2209, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [4/50], Step [316/375], Loss: 2.1838, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [317/375], Loss: 2.3222, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [318/375], Loss: 2.2058, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [319/375], Loss: 2.4196, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [320/375], Loss: 2.1673, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [321/375], Loss: 2.2621, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [322/375], Loss: 2.1501, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [4/50], Step [323/375], Loss: 2.2575, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [324/375], Loss: 2.1124, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [325/375], Loss: 2.1912, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [326/375], Loss: 2.2614, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [327/375], Loss: 2.3348, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [328/375], Loss: 2.2572, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [329/375], Loss: 2.1884, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [330/375], Loss: 2.3648, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [331/375], Loss: 2.1515, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [332/375], Loss: 2.0823, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [333/375], Loss: 2.3007, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [334/375], Loss: 2.0619, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [4/50], Step [335/375], Loss: 2.2300, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [336/375], Loss: 2.1031, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [337/375], Loss: 2.0356, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [338/375], Loss: 2.0589, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [339/375], Loss: 2.1685, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [340/375], Loss: 2.1594, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [341/375], Loss: 2.2370, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [342/375], Loss: 2.1343, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [343/375], Loss: 2.1341, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [344/375], Loss: 2.1699, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [345/375], Loss: 2.2941, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [346/375], Loss: 1.9533, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [347/375], Loss: 2.2910, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [348/375], Loss: 2.2943, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [349/375], Loss: 2.2318, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [4/50], Step [350/375], Loss: 2.3234, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [351/375], Loss: 2.0967, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [352/375], Loss: 2.2406, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [353/375], Loss: 2.3591, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [4/50], Step [354/375], Loss: 2.3194, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [355/375], Loss: 2.3712, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [356/375], Loss: 2.2627, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [357/375], Loss: 2.1168, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [4/50], Step [358/375], Loss: 2.0395, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [359/375], Loss: 2.2697, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [360/375], Loss: 2.1545, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [361/375], Loss: 2.5045, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [4/50], Step [362/375], Loss: 2.1946, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [363/375], Loss: 2.3580, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [364/375], Loss: 2.1599, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [365/375], Loss: 2.3206, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [4/50], Step [366/375], Loss: 2.2790, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [367/375], Loss: 2.2215, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [4/50], Step [368/375], Loss: 2.4383, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [4/50], Step [369/375], Loss: 2.3666, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [4/50], Step [370/375], Loss: 2.0920, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [4/50], Step [371/375], Loss: 2.1205, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [4/50], Step [372/375], Loss: 2.2504, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [4/50], Step [373/375], Loss: 2.1614, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [4/50], Step [374/375], Loss: 2.3783, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [4/50], Step [375/375], Loss: 2.3250, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [1/375], Loss: 2.2936, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [2/375], Loss: 2.1939, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [3/375], Loss: 2.3430, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [4/375], Loss: 2.2264, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [5/375], Loss: 2.1462, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [6/375], Loss: 2.3797, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [7/375], Loss: 2.2377, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [8/375], Loss: 2.1986, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [9/375], Loss: 2.2347, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [10/375], Loss: 2.3377, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [11/375], Loss: 2.3814, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [12/375], Loss: 2.1947, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [13/375], Loss: 2.3080, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [14/375], Loss: 2.2341, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [15/375], Loss: 2.2281, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [16/375], Loss: 2.1572, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [17/375], Loss: 2.0852, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [18/375], Loss: 2.4268, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [19/375], Loss: 2.2263, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [20/375], Loss: 2.2881, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [21/375], Loss: 2.2161, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [22/375], Loss: 2.3211, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [23/375], Loss: 2.2289, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [24/375], Loss: 2.0437, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [25/375], Loss: 2.3600, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [26/375], Loss: 2.4431, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [27/375], Loss: 2.2627, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [28/375], Loss: 2.2716, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [29/375], Loss: 2.2485, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [30/375], Loss: 2.2187, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [31/375], Loss: 2.2031, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [32/375], Loss: 2.1778, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [33/375], Loss: 2.1446, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [34/375], Loss: 2.0820, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [35/375], Loss: 2.1998, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [36/375], Loss: 2.1967, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [37/375], Loss: 2.1618, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [38/375], Loss: 2.3801, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [39/375], Loss: 2.4252, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [40/375], Loss: 2.2948, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [41/375], Loss: 2.0061, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [42/375], Loss: 2.3837, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [43/375], Loss: 2.1485, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [44/375], Loss: 2.0627, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [45/375], Loss: 2.1869, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [46/375], Loss: 2.1536, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [47/375], Loss: 2.2820, batch time: 0.81, accuracy:  12.50%\n",
      "Epoch [5/50], Step [48/375], Loss: 2.2770, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [49/375], Loss: 2.0960, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [50/375], Loss: 2.2673, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [51/375], Loss: 2.3872, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [52/375], Loss: 2.3688, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [53/375], Loss: 2.1141, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [5/50], Step [54/375], Loss: 2.3342, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [5/50], Step [55/375], Loss: 2.1607, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [56/375], Loss: 2.1887, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [5/50], Step [57/375], Loss: 2.2727, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [58/375], Loss: 2.1044, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [59/375], Loss: 2.3260, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [60/375], Loss: 2.2621, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [5/50], Step [61/375], Loss: 2.0993, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [62/375], Loss: 2.1639, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [63/375], Loss: 2.0889, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [64/375], Loss: 2.1853, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [5/50], Step [65/375], Loss: 2.2908, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [66/375], Loss: 2.2346, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [67/375], Loss: 2.0267, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [68/375], Loss: 2.1351, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [69/375], Loss: 2.2414, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [70/375], Loss: 2.2082, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [71/375], Loss: 2.2868, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [72/375], Loss: 2.2289, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [73/375], Loss: 2.2291, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [74/375], Loss: 2.1703, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [75/375], Loss: 2.1838, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [76/375], Loss: 2.3347, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [77/375], Loss: 2.4518, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [78/375], Loss: 2.3640, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [79/375], Loss: 2.3439, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [80/375], Loss: 2.1186, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [81/375], Loss: 2.3916, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [82/375], Loss: 2.1794, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [83/375], Loss: 2.2777, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [84/375], Loss: 2.1175, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [85/375], Loss: 2.2524, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [86/375], Loss: 2.2191, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [87/375], Loss: 2.2489, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [88/375], Loss: 2.2668, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [89/375], Loss: 2.1133, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [90/375], Loss: 2.2447, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [91/375], Loss: 2.2485, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [92/375], Loss: 2.2925, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [93/375], Loss: 2.2431, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [94/375], Loss: 2.3599, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [95/375], Loss: 2.2608, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [96/375], Loss: 2.3364, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [97/375], Loss: 2.0125, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [5/50], Step [98/375], Loss: 2.1805, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [99/375], Loss: 2.2528, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [100/375], Loss: 2.3481, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [5/50], Step [101/375], Loss: 2.1471, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [102/375], Loss: 2.3571, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [103/375], Loss: 2.5498, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [104/375], Loss: 2.2929, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [5/50], Step [105/375], Loss: 2.2019, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [106/375], Loss: 2.2577, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [107/375], Loss: 2.1752, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [108/375], Loss: 2.1496, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [5/50], Step [109/375], Loss: 2.3575, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [110/375], Loss: 2.3304, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [111/375], Loss: 2.1006, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [112/375], Loss: 2.4405, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [113/375], Loss: 2.1685, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [114/375], Loss: 2.3302, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [115/375], Loss: 2.2356, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [116/375], Loss: 2.1392, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [117/375], Loss: 2.2112, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [118/375], Loss: 2.1080, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [119/375], Loss: 2.2156, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [120/375], Loss: 2.0650, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [121/375], Loss: 2.2490, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [122/375], Loss: 2.2387, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [123/375], Loss: 2.2584, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [124/375], Loss: 2.3351, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [5/50], Step [125/375], Loss: 2.4055, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [126/375], Loss: 2.0459, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [127/375], Loss: 2.6038, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [128/375], Loss: 2.3598, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [129/375], Loss: 2.2141, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [130/375], Loss: 2.2509, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [131/375], Loss: 1.8850, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [5/50], Step [132/375], Loss: 2.2880, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [133/375], Loss: 2.3269, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [134/375], Loss: 2.2694, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [135/375], Loss: 2.2647, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [136/375], Loss: 2.2138, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [137/375], Loss: 2.3090, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [138/375], Loss: 2.3106, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [139/375], Loss: 2.2126, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [140/375], Loss: 2.3724, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [141/375], Loss: 2.2041, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [142/375], Loss: 2.2559, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [143/375], Loss: 2.2002, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [144/375], Loss: 2.2156, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [145/375], Loss: 2.1650, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [146/375], Loss: 2.3090, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [147/375], Loss: 2.1322, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [148/375], Loss: 2.1082, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [149/375], Loss: 2.2860, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [150/375], Loss: 2.1469, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [151/375], Loss: 2.1673, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [152/375], Loss: 2.1607, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [153/375], Loss: 2.2846, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [154/375], Loss: 2.1496, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [5/50], Step [155/375], Loss: 2.3294, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [156/375], Loss: 2.5260, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [157/375], Loss: 2.3150, batch time: 0.76, accuracy:  25.00%\n",
      "Epoch [5/50], Step [158/375], Loss: 2.0517, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [159/375], Loss: 2.1167, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [160/375], Loss: 2.2017, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [161/375], Loss: 2.3540, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [162/375], Loss: 2.4430, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [163/375], Loss: 2.2346, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [164/375], Loss: 2.3458, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [165/375], Loss: 2.2583, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [166/375], Loss: 2.0799, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [5/50], Step [167/375], Loss: 2.2875, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [168/375], Loss: 2.2575, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [169/375], Loss: 2.2046, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [170/375], Loss: 2.3149, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [171/375], Loss: 2.1389, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [172/375], Loss: 2.2090, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [173/375], Loss: 2.3959, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [174/375], Loss: 2.2254, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [175/375], Loss: 2.2795, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [5/50], Step [176/375], Loss: 2.2945, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [177/375], Loss: 2.4396, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [178/375], Loss: 2.3632, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [179/375], Loss: 2.0298, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [180/375], Loss: 2.2705, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [181/375], Loss: 2.1785, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [182/375], Loss: 2.1332, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [5/50], Step [183/375], Loss: 2.3138, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [184/375], Loss: 2.2920, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [185/375], Loss: 2.1387, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [186/375], Loss: 2.1207, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [187/375], Loss: 2.3139, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [188/375], Loss: 2.4039, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [189/375], Loss: 2.2093, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [190/375], Loss: 2.2974, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [191/375], Loss: 2.2576, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [192/375], Loss: 2.3358, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [193/375], Loss: 2.2451, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [194/375], Loss: 2.2377, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [195/375], Loss: 2.3191, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [196/375], Loss: 2.1453, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [197/375], Loss: 2.2653, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [198/375], Loss: 2.1147, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [199/375], Loss: 2.3880, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [5/50], Step [200/375], Loss: 2.3471, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [201/375], Loss: 2.3190, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [202/375], Loss: 2.0959, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [5/50], Step [203/375], Loss: 2.3229, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [204/375], Loss: 2.1539, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [205/375], Loss: 2.1466, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [206/375], Loss: 2.2500, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [207/375], Loss: 2.1792, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [208/375], Loss: 2.1999, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [209/375], Loss: 2.2558, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [210/375], Loss: 2.2732, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [211/375], Loss: 2.1750, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [212/375], Loss: 2.3676, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [213/375], Loss: 2.2862, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [214/375], Loss: 2.2133, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [215/375], Loss: 2.2132, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [216/375], Loss: 2.2605, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [217/375], Loss: 2.0960, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [218/375], Loss: 2.2477, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [219/375], Loss: 2.0380, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [220/375], Loss: 2.1924, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [221/375], Loss: 2.3269, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [222/375], Loss: 2.2682, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [223/375], Loss: 2.1088, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [224/375], Loss: 1.9167, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [5/50], Step [225/375], Loss: 2.3842, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [226/375], Loss: 2.2284, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [227/375], Loss: 2.1193, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [228/375], Loss: 2.1897, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [229/375], Loss: 2.3484, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [230/375], Loss: 2.1247, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [231/375], Loss: 2.3685, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [232/375], Loss: 2.4626, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [233/375], Loss: 2.1173, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [234/375], Loss: 2.2961, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [5/50], Step [235/375], Loss: 2.2326, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [236/375], Loss: 2.0794, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [237/375], Loss: 2.0347, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [238/375], Loss: 2.1299, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [5/50], Step [239/375], Loss: 2.4139, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [240/375], Loss: 2.2668, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [241/375], Loss: 2.2921, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [242/375], Loss: 2.2382, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [243/375], Loss: 2.3316, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [244/375], Loss: 2.3966, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [245/375], Loss: 2.2758, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [246/375], Loss: 2.1892, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [247/375], Loss: 2.7080, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [248/375], Loss: 2.1910, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [249/375], Loss: 2.3055, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [250/375], Loss: 2.2245, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [251/375], Loss: 2.3980, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [252/375], Loss: 2.1889, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [253/375], Loss: 2.0742, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [254/375], Loss: 2.2604, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [255/375], Loss: 2.2469, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [5/50], Step [256/375], Loss: 2.1435, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [257/375], Loss: 2.2897, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [258/375], Loss: 2.3399, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [259/375], Loss: 2.2066, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [260/375], Loss: 2.1293, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [261/375], Loss: 2.2597, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [262/375], Loss: 2.2564, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [263/375], Loss: 2.1284, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [264/375], Loss: 2.1954, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [265/375], Loss: 2.3287, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [266/375], Loss: 2.0351, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [5/50], Step [267/375], Loss: 2.0834, batch time: 0.76, accuracy:  37.50%\n",
      "Epoch [5/50], Step [268/375], Loss: 2.2897, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [5/50], Step [269/375], Loss: 2.3607, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [270/375], Loss: 2.2503, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [5/50], Step [271/375], Loss: 2.3343, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [272/375], Loss: 2.1199, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [273/375], Loss: 2.2019, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [5/50], Step [274/375], Loss: 2.2754, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [275/375], Loss: 2.3958, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [276/375], Loss: 2.2499, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [5/50], Step [277/375], Loss: 2.1105, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [278/375], Loss: 2.2388, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [279/375], Loss: 2.2205, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [280/375], Loss: 2.4171, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [281/375], Loss: 2.3020, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [282/375], Loss: 2.2413, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [283/375], Loss: 2.2401, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [284/375], Loss: 2.1513, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [285/375], Loss: 2.3103, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [286/375], Loss: 2.3050, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [287/375], Loss: 2.0697, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [288/375], Loss: 2.3736, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [5/50], Step [289/375], Loss: 2.4546, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [290/375], Loss: 2.2765, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [5/50], Step [291/375], Loss: 2.1682, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [292/375], Loss: 2.1620, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [293/375], Loss: 2.3571, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [294/375], Loss: 2.4257, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [295/375], Loss: 2.2959, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [296/375], Loss: 2.4614, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [297/375], Loss: 2.1869, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [298/375], Loss: 2.1109, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [299/375], Loss: 2.3768, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [300/375], Loss: 2.3135, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [301/375], Loss: 2.3282, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [302/375], Loss: 2.2320, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [303/375], Loss: 2.1609, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [304/375], Loss: 2.2033, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [305/375], Loss: 2.0005, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [306/375], Loss: 2.1431, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [307/375], Loss: 2.3585, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [308/375], Loss: 2.3046, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [309/375], Loss: 2.3486, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [310/375], Loss: 2.0593, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [311/375], Loss: 2.2878, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [312/375], Loss: 2.1429, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [5/50], Step [313/375], Loss: 2.2888, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [5/50], Step [314/375], Loss: 2.1500, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [315/375], Loss: 2.2574, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [316/375], Loss: 2.3341, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [5/50], Step [317/375], Loss: 2.2085, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [318/375], Loss: 2.1837, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [319/375], Loss: 2.3370, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [320/375], Loss: 2.1884, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [5/50], Step [321/375], Loss: 2.1357, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [322/375], Loss: 2.1132, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [323/375], Loss: 2.1644, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [324/375], Loss: 2.2994, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [325/375], Loss: 2.0960, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [326/375], Loss: 2.3039, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [327/375], Loss: 2.5826, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [328/375], Loss: 2.2625, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [329/375], Loss: 2.2436, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [330/375], Loss: 2.2647, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [331/375], Loss: 2.1418, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [5/50], Step [332/375], Loss: 2.3820, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [333/375], Loss: 2.2266, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [334/375], Loss: 2.3662, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [335/375], Loss: 2.4899, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [336/375], Loss: 2.0171, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [5/50], Step [337/375], Loss: 2.3465, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [338/375], Loss: 2.2659, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [339/375], Loss: 2.3497, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [340/375], Loss: 2.2806, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [5/50], Step [341/375], Loss: 2.2401, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [342/375], Loss: 2.2489, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [5/50], Step [343/375], Loss: 2.0310, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [5/50], Step [344/375], Loss: 2.3292, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [5/50], Step [345/375], Loss: 2.3044, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [346/375], Loss: 2.2630, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [347/375], Loss: 2.2871, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [348/375], Loss: 2.3202, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [349/375], Loss: 2.2095, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [350/375], Loss: 2.2209, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [351/375], Loss: 2.3662, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [352/375], Loss: 2.1983, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [353/375], Loss: 2.2691, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [354/375], Loss: 2.1483, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [355/375], Loss: 2.1050, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [356/375], Loss: 2.1625, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [357/375], Loss: 2.3820, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [358/375], Loss: 2.2657, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [5/50], Step [359/375], Loss: 2.0755, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [360/375], Loss: 2.2658, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [5/50], Step [361/375], Loss: 2.5246, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [5/50], Step [362/375], Loss: 2.3038, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [363/375], Loss: 2.1533, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [364/375], Loss: 2.2313, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [5/50], Step [365/375], Loss: 2.1653, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [5/50], Step [366/375], Loss: 2.3716, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [367/375], Loss: 2.3190, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [368/375], Loss: 2.2347, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [369/375], Loss: 2.3282, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [5/50], Step [370/375], Loss: 2.1093, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [5/50], Step [371/375], Loss: 2.2027, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [372/375], Loss: 2.5411, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [5/50], Step [373/375], Loss: 2.1524, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [374/375], Loss: 2.1378, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [5/50], Step [375/375], Loss: 2.2833, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [1/375], Loss: 2.2898, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [2/375], Loss: 2.1630, batch time: 0.77, accuracy:  25.00%\n",
      "Epoch [6/50], Step [3/375], Loss: 2.2021, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [4/375], Loss: 2.1618, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [5/375], Loss: 2.2941, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [6/375], Loss: 2.3724, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [6/50], Step [7/375], Loss: 2.1483, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [8/375], Loss: 2.3088, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [6/50], Step [9/375], Loss: 2.3391, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [10/375], Loss: 2.2962, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [11/375], Loss: 2.2062, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [12/375], Loss: 2.3494, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [13/375], Loss: 2.2373, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [14/375], Loss: 2.2844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [15/375], Loss: 2.3247, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [16/375], Loss: 2.2072, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [17/375], Loss: 2.3729, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [18/375], Loss: 2.1523, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [19/375], Loss: 2.3749, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [20/375], Loss: 2.4279, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [21/375], Loss: 2.3133, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [22/375], Loss: 2.2608, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [23/375], Loss: 2.1678, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [6/50], Step [24/375], Loss: 2.1665, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [25/375], Loss: 2.3304, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [26/375], Loss: 2.1955, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [27/375], Loss: 2.1754, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [28/375], Loss: 2.3822, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [29/375], Loss: 2.2258, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [30/375], Loss: 2.2191, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [31/375], Loss: 2.2763, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [32/375], Loss: 2.2060, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [33/375], Loss: 2.0952, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [34/375], Loss: 2.2432, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [35/375], Loss: 2.1305, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [36/375], Loss: 2.3412, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [37/375], Loss: 2.2732, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [38/375], Loss: 2.0259, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [39/375], Loss: 2.2482, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [40/375], Loss: 2.2291, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [41/375], Loss: 2.3557, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [42/375], Loss: 2.3030, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [43/375], Loss: 2.3871, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [44/375], Loss: 2.1654, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [45/375], Loss: 2.2459, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [46/375], Loss: 2.2181, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [47/375], Loss: 2.2110, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [48/375], Loss: 2.2207, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [49/375], Loss: 2.2678, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [50/375], Loss: 2.2482, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [51/375], Loss: 2.1793, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [52/375], Loss: 2.1944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [53/375], Loss: 2.3314, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [54/375], Loss: 2.3791, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [55/375], Loss: 2.3008, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [56/375], Loss: 2.4344, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [57/375], Loss: 2.2957, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [58/375], Loss: 2.3392, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [59/375], Loss: 2.3885, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [60/375], Loss: 2.2844, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [61/375], Loss: 2.2723, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [62/375], Loss: 2.2189, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [63/375], Loss: 2.2258, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [64/375], Loss: 2.1256, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [65/375], Loss: 2.3923, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [66/375], Loss: 2.2408, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [67/375], Loss: 2.1246, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [68/375], Loss: 2.2840, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [69/375], Loss: 2.2447, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [70/375], Loss: 2.2675, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [71/375], Loss: 2.2796, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [72/375], Loss: 2.3333, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [73/375], Loss: 2.3686, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [74/375], Loss: 2.2751, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [75/375], Loss: 2.2366, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [76/375], Loss: 2.2575, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [77/375], Loss: 2.2040, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [78/375], Loss: 2.1649, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [79/375], Loss: 2.2493, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [80/375], Loss: 2.2138, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [81/375], Loss: 2.0656, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [82/375], Loss: 2.1598, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [83/375], Loss: 2.3617, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [84/375], Loss: 2.2792, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [85/375], Loss: 2.2247, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [86/375], Loss: 2.2358, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [87/375], Loss: 2.2687, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [88/375], Loss: 2.1841, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [89/375], Loss: 2.2259, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [90/375], Loss: 2.2702, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [91/375], Loss: 2.3519, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [92/375], Loss: 2.2301, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [93/375], Loss: 2.2670, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [94/375], Loss: 2.1284, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [95/375], Loss: 2.2370, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [96/375], Loss: 2.3623, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [97/375], Loss: 2.3260, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [98/375], Loss: 2.2306, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [99/375], Loss: 2.1209, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [6/50], Step [100/375], Loss: 2.2732, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [101/375], Loss: 2.2404, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [102/375], Loss: 2.2154, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [103/375], Loss: 2.2202, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [104/375], Loss: 2.1183, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [105/375], Loss: 2.2763, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [106/375], Loss: 2.2457, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [107/375], Loss: 2.2359, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [108/375], Loss: 2.3372, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [109/375], Loss: 2.2779, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [110/375], Loss: 2.3485, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [111/375], Loss: 2.1355, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [6/50], Step [112/375], Loss: 2.1652, batch time: 0.77, accuracy:  18.75%\n",
      "Epoch [6/50], Step [113/375], Loss: 2.1451, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [114/375], Loss: 2.1179, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [115/375], Loss: 2.0432, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [6/50], Step [116/375], Loss: 2.1758, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [117/375], Loss: 2.3642, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [118/375], Loss: 2.0925, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [119/375], Loss: 2.2278, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [120/375], Loss: 2.2861, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [121/375], Loss: 2.4618, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [122/375], Loss: 2.2576, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [123/375], Loss: 1.9446, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [124/375], Loss: 2.1937, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [125/375], Loss: 1.8677, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [6/50], Step [126/375], Loss: 2.4665, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [127/375], Loss: 2.3438, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [128/375], Loss: 2.0949, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [129/375], Loss: 2.1051, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [6/50], Step [130/375], Loss: 1.9043, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [131/375], Loss: 2.4688, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [132/375], Loss: 1.9008, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [133/375], Loss: 2.2402, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [134/375], Loss: 1.9789, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [135/375], Loss: 2.2507, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [136/375], Loss: 2.0605, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [137/375], Loss: 2.5412, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [138/375], Loss: 2.2200, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [139/375], Loss: 2.4369, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [6/50], Step [140/375], Loss: 2.1835, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [141/375], Loss: 2.2887, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [142/375], Loss: 2.0940, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [143/375], Loss: 2.1170, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [144/375], Loss: 2.2577, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [145/375], Loss: 2.0891, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [146/375], Loss: 2.2807, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [147/375], Loss: 2.1357, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [148/375], Loss: 2.3474, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [149/375], Loss: 2.4079, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [150/375], Loss: 2.1553, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [151/375], Loss: 2.2796, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [152/375], Loss: 2.4419, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [153/375], Loss: 2.1665, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [6/50], Step [154/375], Loss: 2.2132, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [155/375], Loss: 2.4200, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [156/375], Loss: 2.0412, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [157/375], Loss: 2.4356, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [158/375], Loss: 2.0678, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [6/50], Step [159/375], Loss: 2.2631, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [160/375], Loss: 2.3576, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [161/375], Loss: 2.3284, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [162/375], Loss: 2.0658, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [163/375], Loss: 2.0925, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [164/375], Loss: 2.2650, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [165/375], Loss: 2.3833, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [166/375], Loss: 2.0540, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [167/375], Loss: 2.2847, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [168/375], Loss: 2.2707, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [169/375], Loss: 2.1737, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [170/375], Loss: 2.2024, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [171/375], Loss: 2.2817, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [172/375], Loss: 2.2355, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [173/375], Loss: 2.3270, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [6/50], Step [174/375], Loss: 2.2477, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [175/375], Loss: 2.2820, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [176/375], Loss: 2.2770, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [177/375], Loss: 2.2635, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [178/375], Loss: 2.0564, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [179/375], Loss: 2.1690, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [180/375], Loss: 2.2173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [181/375], Loss: 2.3514, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [182/375], Loss: 2.3368, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [183/375], Loss: 2.2744, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [184/375], Loss: 2.3419, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [185/375], Loss: 2.2975, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [186/375], Loss: 2.2018, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [187/375], Loss: 2.3586, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [188/375], Loss: 2.1995, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [189/375], Loss: 2.2796, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [190/375], Loss: 2.2396, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [191/375], Loss: 2.2650, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [192/375], Loss: 2.4314, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [193/375], Loss: 2.2613, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [194/375], Loss: 2.3488, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [195/375], Loss: 2.3388, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [196/375], Loss: 2.0153, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [197/375], Loss: 2.1872, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [198/375], Loss: 2.2919, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [199/375], Loss: 2.2231, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [200/375], Loss: 2.2463, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [201/375], Loss: 2.4378, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [202/375], Loss: 2.2069, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [203/375], Loss: 2.2806, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [204/375], Loss: 2.2418, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [205/375], Loss: 2.4275, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [6/50], Step [206/375], Loss: 2.3033, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [207/375], Loss: 2.1242, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [208/375], Loss: 2.2946, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [209/375], Loss: 2.3127, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [210/375], Loss: 2.2503, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [211/375], Loss: 2.2510, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [212/375], Loss: 2.3889, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [213/375], Loss: 2.1865, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [214/375], Loss: 2.2326, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [215/375], Loss: 2.3520, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [216/375], Loss: 2.2964, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [217/375], Loss: 2.2578, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [218/375], Loss: 2.1716, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [219/375], Loss: 2.4215, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [220/375], Loss: 2.3430, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [221/375], Loss: 2.2342, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [222/375], Loss: 2.2860, batch time: 0.77, accuracy:  12.50%\n",
      "Epoch [6/50], Step [223/375], Loss: 2.3526, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [224/375], Loss: 2.3453, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [225/375], Loss: 2.2722, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [226/375], Loss: 2.2794, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [227/375], Loss: 2.2382, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [228/375], Loss: 2.1930, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [229/375], Loss: 2.2311, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [230/375], Loss: 2.3356, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [231/375], Loss: 2.1668, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [232/375], Loss: 2.2255, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [233/375], Loss: 2.2152, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [6/50], Step [234/375], Loss: 2.1645, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [235/375], Loss: 2.2752, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [236/375], Loss: 2.2722, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [237/375], Loss: 2.1215, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [238/375], Loss: 2.3730, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [239/375], Loss: 2.3481, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [240/375], Loss: 2.3557, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [241/375], Loss: 2.2234, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [242/375], Loss: 2.2009, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [243/375], Loss: 2.1163, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [6/50], Step [244/375], Loss: 2.1084, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [245/375], Loss: 2.0421, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [246/375], Loss: 2.3298, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [247/375], Loss: 2.3474, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [248/375], Loss: 2.1880, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [249/375], Loss: 2.3137, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [250/375], Loss: 2.3141, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [251/375], Loss: 2.2431, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [252/375], Loss: 2.1151, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [253/375], Loss: 2.0161, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [254/375], Loss: 2.3453, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [255/375], Loss: 2.2345, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [256/375], Loss: 2.1800, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [257/375], Loss: 2.2805, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [258/375], Loss: 2.1813, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [259/375], Loss: 2.4391, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [260/375], Loss: 2.3773, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [261/375], Loss: 2.2771, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [262/375], Loss: 2.4284, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [263/375], Loss: 2.0715, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [6/50], Step [264/375], Loss: 1.9868, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [265/375], Loss: 2.2970, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [266/375], Loss: 2.2243, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [267/375], Loss: 2.0542, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [6/50], Step [268/375], Loss: 2.2905, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [269/375], Loss: 2.2519, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [270/375], Loss: 2.4257, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [271/375], Loss: 2.1342, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [6/50], Step [272/375], Loss: 2.0954, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [6/50], Step [273/375], Loss: 2.1555, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [274/375], Loss: 2.2386, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [275/375], Loss: 2.1295, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [276/375], Loss: 2.3374, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [277/375], Loss: 2.4035, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [278/375], Loss: 2.2490, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [279/375], Loss: 2.0588, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [6/50], Step [280/375], Loss: 2.2423, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [281/375], Loss: 2.2459, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [282/375], Loss: 2.2726, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [283/375], Loss: 2.2536, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [284/375], Loss: 2.2994, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [285/375], Loss: 2.3101, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [286/375], Loss: 2.3487, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [287/375], Loss: 2.1683, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [288/375], Loss: 2.3477, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [289/375], Loss: 2.1984, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [290/375], Loss: 2.2546, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [291/375], Loss: 2.2163, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [6/50], Step [292/375], Loss: 2.3557, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [293/375], Loss: 2.2783, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [294/375], Loss: 2.2004, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [295/375], Loss: 2.0883, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [6/50], Step [296/375], Loss: 2.3407, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [297/375], Loss: 2.0444, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [6/50], Step [298/375], Loss: 2.1502, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [6/50], Step [299/375], Loss: 2.1200, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [6/50], Step [300/375], Loss: 2.2908, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [301/375], Loss: 2.2483, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [302/375], Loss: 2.2596, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [303/375], Loss: 2.3828, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [304/375], Loss: 2.3431, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [6/50], Step [305/375], Loss: 2.2181, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [306/375], Loss: 2.2776, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [307/375], Loss: 2.2048, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [308/375], Loss: 2.1546, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [309/375], Loss: 2.3760, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [310/375], Loss: 2.1866, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [311/375], Loss: 2.2043, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [312/375], Loss: 2.0280, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [313/375], Loss: 2.2572, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [314/375], Loss: 2.2688, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [315/375], Loss: 2.4292, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [6/50], Step [316/375], Loss: 2.0979, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [317/375], Loss: 2.0365, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [318/375], Loss: 2.2768, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [319/375], Loss: 2.0398, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [6/50], Step [320/375], Loss: 2.2690, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [321/375], Loss: 2.2868, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [322/375], Loss: 2.3524, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [323/375], Loss: 2.3131, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [324/375], Loss: 2.1646, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [325/375], Loss: 2.0483, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [326/375], Loss: 2.2483, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [327/375], Loss: 2.3457, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [6/50], Step [328/375], Loss: 2.2880, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [329/375], Loss: 2.0532, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [330/375], Loss: 2.2891, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [331/375], Loss: 2.2740, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [6/50], Step [332/375], Loss: 2.0584, batch time: 0.77, accuracy:  31.25%\n",
      "Epoch [6/50], Step [333/375], Loss: 2.2398, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [334/375], Loss: 2.2567, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [335/375], Loss: 2.2626, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [336/375], Loss: 2.2098, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [337/375], Loss: 2.2589, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [338/375], Loss: 2.3605, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [6/50], Step [339/375], Loss: 2.2208, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [340/375], Loss: 2.0831, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [341/375], Loss: 2.3627, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [6/50], Step [342/375], Loss: 2.4337, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [343/375], Loss: 2.0558, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [344/375], Loss: 2.3322, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [345/375], Loss: 2.2897, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [346/375], Loss: 2.1408, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [347/375], Loss: 2.3273, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [348/375], Loss: 2.2003, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [6/50], Step [349/375], Loss: 2.4155, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [6/50], Step [350/375], Loss: 2.2577, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [6/50], Step [351/375], Loss: 2.0013, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [352/375], Loss: 2.2297, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [353/375], Loss: 2.1766, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [6/50], Step [354/375], Loss: 2.2555, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [355/375], Loss: 2.4575, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [356/375], Loss: 2.5178, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [357/375], Loss: 2.0755, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [6/50], Step [358/375], Loss: 2.4445, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [6/50], Step [359/375], Loss: 2.2733, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [360/375], Loss: 2.1625, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [361/375], Loss: 2.2849, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [6/50], Step [362/375], Loss: 2.1025, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [6/50], Step [363/375], Loss: 2.1880, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [364/375], Loss: 2.2084, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [6/50], Step [365/375], Loss: 2.2698, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [6/50], Step [366/375], Loss: 2.2351, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [367/375], Loss: 2.1805, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [6/50], Step [368/375], Loss: 2.4106, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [6/50], Step [369/375], Loss: 2.3299, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [6/50], Step [370/375], Loss: 2.3258, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [371/375], Loss: 2.2866, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [6/50], Step [372/375], Loss: 2.1407, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [6/50], Step [373/375], Loss: 2.1990, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [6/50], Step [374/375], Loss: 2.2206, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [6/50], Step [375/375], Loss: 2.2567, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [1/375], Loss: 2.3638, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [2/375], Loss: 2.2838, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [3/375], Loss: 2.2429, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [4/375], Loss: 2.0758, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [5/375], Loss: 2.3076, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [6/375], Loss: 2.2815, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [7/375], Loss: 2.2167, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [8/375], Loss: 2.3121, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [9/375], Loss: 2.4240, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [10/375], Loss: 2.0134, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [7/50], Step [11/375], Loss: 2.1465, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [12/375], Loss: 2.3227, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [13/375], Loss: 2.2403, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [14/375], Loss: 2.2254, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [15/375], Loss: 2.3032, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [16/375], Loss: 2.4569, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [17/375], Loss: 2.1865, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [18/375], Loss: 2.2755, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [19/375], Loss: 2.3154, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [20/375], Loss: 2.1910, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [21/375], Loss: 2.1701, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [22/375], Loss: 2.0935, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [23/375], Loss: 2.1546, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [24/375], Loss: 2.1069, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [25/375], Loss: 2.4091, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [26/375], Loss: 2.3150, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [27/375], Loss: 2.1709, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [28/375], Loss: 2.2636, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [29/375], Loss: 2.1060, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [30/375], Loss: 1.9994, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [7/50], Step [31/375], Loss: 2.1547, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [32/375], Loss: 2.2560, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [33/375], Loss: 2.2966, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [34/375], Loss: 2.0843, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [7/50], Step [35/375], Loss: 2.0508, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [7/50], Step [36/375], Loss: 2.4399, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [37/375], Loss: 2.4736, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [38/375], Loss: 2.0797, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [7/50], Step [39/375], Loss: 2.2769, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [40/375], Loss: 2.2746, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [41/375], Loss: 2.4271, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [42/375], Loss: 2.0384, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [7/50], Step [43/375], Loss: 2.2951, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [44/375], Loss: 2.3266, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [45/375], Loss: 2.2161, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [46/375], Loss: 2.2109, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [47/375], Loss: 2.1212, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [48/375], Loss: 2.2739, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [49/375], Loss: 2.0890, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [50/375], Loss: 2.2437, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [51/375], Loss: 2.4159, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [52/375], Loss: 2.4138, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [53/375], Loss: 2.1179, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [54/375], Loss: 2.2410, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [55/375], Loss: 2.3824, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [56/375], Loss: 1.9702, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [57/375], Loss: 2.1792, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [58/375], Loss: 2.1618, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [59/375], Loss: 2.0413, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [60/375], Loss: 2.1936, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [61/375], Loss: 2.4077, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [62/375], Loss: 2.5243, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [7/50], Step [63/375], Loss: 2.2623, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [64/375], Loss: 2.3437, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [65/375], Loss: 2.2656, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [66/375], Loss: 2.2318, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [67/375], Loss: 2.3051, batch time: 0.77, accuracy:  18.75%\n",
      "Epoch [7/50], Step [68/375], Loss: 2.3725, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [69/375], Loss: 2.5259, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [70/375], Loss: 2.3272, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [71/375], Loss: 2.2281, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [72/375], Loss: 2.1708, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [73/375], Loss: 2.3856, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [74/375], Loss: 2.1986, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [75/375], Loss: 2.3024, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [76/375], Loss: 2.3487, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [7/50], Step [77/375], Loss: 2.2927, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [78/375], Loss: 2.2718, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [79/375], Loss: 2.1614, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [80/375], Loss: 2.3310, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [81/375], Loss: 2.3678, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [82/375], Loss: 2.1972, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [83/375], Loss: 2.1366, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [84/375], Loss: 2.1819, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [85/375], Loss: 2.1933, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [86/375], Loss: 2.3979, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [87/375], Loss: 2.3213, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [88/375], Loss: 2.2647, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [89/375], Loss: 2.1967, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [90/375], Loss: 2.3078, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [91/375], Loss: 2.3121, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [92/375], Loss: 2.2761, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [93/375], Loss: 2.2713, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [94/375], Loss: 2.2653, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [95/375], Loss: 2.1349, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [96/375], Loss: 2.1912, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [97/375], Loss: 2.4036, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [98/375], Loss: 2.1439, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [99/375], Loss: 2.2588, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [100/375], Loss: 2.3600, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [7/50], Step [101/375], Loss: 2.3577, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [102/375], Loss: 2.2236, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [103/375], Loss: 1.9665, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [7/50], Step [104/375], Loss: 2.1641, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [105/375], Loss: 2.1730, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [106/375], Loss: 2.3494, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [107/375], Loss: 2.1182, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [108/375], Loss: 2.3351, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [7/50], Step [109/375], Loss: 2.1543, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [7/50], Step [110/375], Loss: 2.2046, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [111/375], Loss: 2.3284, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [112/375], Loss: 2.0087, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [7/50], Step [113/375], Loss: 2.3094, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [114/375], Loss: 2.0492, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [115/375], Loss: 2.2056, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [116/375], Loss: 2.3502, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [7/50], Step [117/375], Loss: 2.2986, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [118/375], Loss: 2.3745, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [119/375], Loss: 2.0423, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [120/375], Loss: 2.0683, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [121/375], Loss: 2.2539, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [122/375], Loss: 2.2643, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [123/375], Loss: 2.0832, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [124/375], Loss: 2.3033, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [125/375], Loss: 2.4302, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [7/50], Step [126/375], Loss: 2.2435, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [127/375], Loss: 2.2065, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [128/375], Loss: 2.1812, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [129/375], Loss: 2.3457, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [130/375], Loss: 2.4370, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [131/375], Loss: 2.2002, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [132/375], Loss: 2.2967, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [133/375], Loss: 2.2747, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [134/375], Loss: 2.2324, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [135/375], Loss: 2.2481, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [136/375], Loss: 2.3846, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [137/375], Loss: 2.3366, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [138/375], Loss: 2.4188, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [139/375], Loss: 2.2230, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [140/375], Loss: 2.2302, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [141/375], Loss: 2.3099, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [142/375], Loss: 2.1641, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [143/375], Loss: 2.2086, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [144/375], Loss: 2.2088, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [7/50], Step [145/375], Loss: 2.3118, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [146/375], Loss: 2.1468, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [7/50], Step [147/375], Loss: 2.4546, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [148/375], Loss: 2.2223, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [149/375], Loss: 2.1132, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [7/50], Step [150/375], Loss: 2.2301, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [151/375], Loss: 2.1746, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [152/375], Loss: 2.3737, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [153/375], Loss: 2.2403, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [154/375], Loss: 2.2328, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [155/375], Loss: 2.2413, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [156/375], Loss: 2.2276, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [7/50], Step [157/375], Loss: 2.2663, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [158/375], Loss: 2.3474, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [159/375], Loss: 2.4033, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [160/375], Loss: 2.2997, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [161/375], Loss: 2.2597, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [162/375], Loss: 2.1314, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [163/375], Loss: 2.2611, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [164/375], Loss: 2.2891, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [165/375], Loss: 2.1699, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [166/375], Loss: 2.1765, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [167/375], Loss: 2.2771, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [168/375], Loss: 2.1948, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [169/375], Loss: 2.2306, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [170/375], Loss: 2.3318, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [171/375], Loss: 2.1002, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [172/375], Loss: 2.2184, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [173/375], Loss: 2.3608, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [174/375], Loss: 2.5671, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [175/375], Loss: 1.9641, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [7/50], Step [176/375], Loss: 2.3637, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [177/375], Loss: 2.1462, batch time: 0.77, accuracy:  31.25%\n",
      "Epoch [7/50], Step [178/375], Loss: 2.3468, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [179/375], Loss: 2.3086, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [180/375], Loss: 2.1986, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [7/50], Step [181/375], Loss: 2.2754, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [182/375], Loss: 2.3429, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [183/375], Loss: 2.2465, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [7/50], Step [184/375], Loss: 2.3679, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [185/375], Loss: 2.3512, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [186/375], Loss: 2.1083, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [7/50], Step [187/375], Loss: 2.2216, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [188/375], Loss: 2.2713, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [189/375], Loss: 2.3904, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [190/375], Loss: 2.2610, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [191/375], Loss: 2.1788, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [192/375], Loss: 2.1149, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [193/375], Loss: 2.2651, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [194/375], Loss: 2.2563, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [7/50], Step [195/375], Loss: 2.2661, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [196/375], Loss: 2.1651, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [197/375], Loss: 2.1122, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [198/375], Loss: 2.2922, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [199/375], Loss: 2.2958, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [200/375], Loss: 2.3368, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [201/375], Loss: 2.3851, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [202/375], Loss: 2.1897, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [203/375], Loss: 2.3452, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [204/375], Loss: 2.2054, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [205/375], Loss: 2.0223, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [206/375], Loss: 2.1468, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [207/375], Loss: 2.1810, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [208/375], Loss: 2.2485, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [209/375], Loss: 2.2575, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [210/375], Loss: 2.3428, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [7/50], Step [211/375], Loss: 2.3681, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [212/375], Loss: 2.2517, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [213/375], Loss: 2.1502, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [214/375], Loss: 2.4277, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [7/50], Step [215/375], Loss: 2.2261, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [216/375], Loss: 2.3916, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [217/375], Loss: 2.2582, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [218/375], Loss: 2.1405, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [7/50], Step [219/375], Loss: 2.2829, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [220/375], Loss: 2.2250, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [221/375], Loss: 2.2214, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [222/375], Loss: 2.2241, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [223/375], Loss: 2.4046, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [224/375], Loss: 2.2529, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [225/375], Loss: 2.1701, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [226/375], Loss: 2.1357, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [227/375], Loss: 2.1102, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [7/50], Step [228/375], Loss: 2.4077, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [229/375], Loss: 2.3584, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [230/375], Loss: 2.2799, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [231/375], Loss: 2.2932, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [232/375], Loss: 2.3696, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [233/375], Loss: 2.3667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [234/375], Loss: 2.2130, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [235/375], Loss: 2.3735, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [236/375], Loss: 2.3274, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [237/375], Loss: 2.1871, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [238/375], Loss: 2.1574, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [239/375], Loss: 2.3887, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [240/375], Loss: 2.2336, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [241/375], Loss: 2.2138, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [242/375], Loss: 2.2292, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [243/375], Loss: 2.1645, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [244/375], Loss: 2.2295, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [245/375], Loss: 2.2173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [246/375], Loss: 2.2847, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [247/375], Loss: 2.1476, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [248/375], Loss: 2.3528, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [7/50], Step [249/375], Loss: 2.1219, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [250/375], Loss: 2.1873, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [7/50], Step [251/375], Loss: 2.1671, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [252/375], Loss: 2.1373, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [253/375], Loss: 2.0670, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [7/50], Step [254/375], Loss: 2.2269, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [255/375], Loss: 2.2021, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [256/375], Loss: 2.1560, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [257/375], Loss: 2.0819, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [258/375], Loss: 2.2257, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [259/375], Loss: 2.4774, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [260/375], Loss: 2.1458, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [261/375], Loss: 2.4268, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [262/375], Loss: 2.3380, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [263/375], Loss: 2.3187, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [264/375], Loss: 2.2607, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [265/375], Loss: 2.0268, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [266/375], Loss: 2.2011, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [7/50], Step [267/375], Loss: 2.1382, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [268/375], Loss: 2.2968, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [269/375], Loss: 2.4864, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [270/375], Loss: 2.4009, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [7/50], Step [271/375], Loss: 2.2209, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [272/375], Loss: 2.0142, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [273/375], Loss: 2.0887, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [274/375], Loss: 2.2239, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [275/375], Loss: 2.3076, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [276/375], Loss: 2.1433, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [277/375], Loss: 2.2003, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [278/375], Loss: 2.4014, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [279/375], Loss: 2.4932, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [280/375], Loss: 2.2615, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [281/375], Loss: 2.1809, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [282/375], Loss: 2.2973, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [283/375], Loss: 2.2480, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [284/375], Loss: 2.1987, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [285/375], Loss: 2.1422, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [286/375], Loss: 2.1715, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [287/375], Loss: 2.1695, batch time: 0.77, accuracy:  18.75%\n",
      "Epoch [7/50], Step [288/375], Loss: 2.2995, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [289/375], Loss: 2.1619, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [290/375], Loss: 2.2959, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [7/50], Step [291/375], Loss: 2.4742, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [292/375], Loss: 2.1735, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [293/375], Loss: 2.3020, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [294/375], Loss: 2.2744, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [295/375], Loss: 2.2816, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [296/375], Loss: 2.1316, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [7/50], Step [297/375], Loss: 2.2066, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [7/50], Step [298/375], Loss: 2.0468, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [7/50], Step [299/375], Loss: 2.3240, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [300/375], Loss: 2.0599, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [7/50], Step [301/375], Loss: 2.2133, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [302/375], Loss: 2.3053, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [7/50], Step [303/375], Loss: 2.2619, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [304/375], Loss: 2.0950, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [7/50], Step [305/375], Loss: 2.2868, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [306/375], Loss: 2.2466, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [307/375], Loss: 2.1896, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [308/375], Loss: 2.3532, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [309/375], Loss: 2.2387, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [310/375], Loss: 2.3655, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [311/375], Loss: 2.2657, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [312/375], Loss: 2.2035, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [313/375], Loss: 2.1118, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [314/375], Loss: 2.0841, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [315/375], Loss: 2.1367, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [316/375], Loss: 2.1811, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [317/375], Loss: 2.2355, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [318/375], Loss: 2.1989, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [319/375], Loss: 2.4415, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [320/375], Loss: 2.4789, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [321/375], Loss: 2.2967, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [322/375], Loss: 2.5759, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [7/50], Step [323/375], Loss: 2.1939, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [324/375], Loss: 2.2769, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [325/375], Loss: 2.1537, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [326/375], Loss: 2.1786, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [327/375], Loss: 2.3631, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [328/375], Loss: 2.4580, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [7/50], Step [329/375], Loss: 2.4158, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [330/375], Loss: 2.2032, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [331/375], Loss: 2.2865, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [332/375], Loss: 2.2969, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [7/50], Step [333/375], Loss: 2.1939, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [334/375], Loss: 2.2866, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [335/375], Loss: 2.3111, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [336/375], Loss: 2.2697, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [337/375], Loss: 2.0104, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [338/375], Loss: 2.1847, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [7/50], Step [339/375], Loss: 2.0808, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [340/375], Loss: 2.1920, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [7/50], Step [341/375], Loss: 2.2920, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [342/375], Loss: 2.4018, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [7/50], Step [343/375], Loss: 2.3352, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [7/50], Step [344/375], Loss: 2.1967, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [7/50], Step [345/375], Loss: 2.1326, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [346/375], Loss: 2.2694, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [347/375], Loss: 2.0944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [348/375], Loss: 2.2391, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [349/375], Loss: 2.1742, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [350/375], Loss: 2.1784, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [7/50], Step [351/375], Loss: 2.4768, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [352/375], Loss: 2.2660, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [7/50], Step [353/375], Loss: 2.1638, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [354/375], Loss: 2.3717, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [7/50], Step [355/375], Loss: 2.1911, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [356/375], Loss: 2.2577, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [357/375], Loss: 2.0685, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [7/50], Step [358/375], Loss: 2.2386, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [359/375], Loss: 2.3198, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [360/375], Loss: 2.2214, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [7/50], Step [361/375], Loss: 1.9229, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [7/50], Step [362/375], Loss: 2.4756, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [7/50], Step [363/375], Loss: 2.1798, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [364/375], Loss: 2.2894, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [365/375], Loss: 2.3563, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [366/375], Loss: 2.2115, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [367/375], Loss: 2.2204, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [7/50], Step [368/375], Loss: 2.2026, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [7/50], Step [369/375], Loss: 2.4548, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [7/50], Step [370/375], Loss: 2.0454, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [7/50], Step [371/375], Loss: 2.2244, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [372/375], Loss: 2.2040, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [7/50], Step [373/375], Loss: 2.3127, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [7/50], Step [374/375], Loss: 2.2455, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [7/50], Step [375/375], Loss: 2.4824, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [1/375], Loss: 2.1628, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [8/50], Step [2/375], Loss: 2.3689, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [3/375], Loss: 2.2343, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [8/50], Step [4/375], Loss: 2.3267, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [5/375], Loss: 2.2596, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [6/375], Loss: 2.1427, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [7/375], Loss: 2.2938, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [8/375], Loss: 2.3668, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [9/375], Loss: 2.3118, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [10/375], Loss: 2.1789, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [11/375], Loss: 2.1967, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [12/375], Loss: 2.2923, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [13/375], Loss: 2.1875, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [14/375], Loss: 2.1990, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [15/375], Loss: 2.3482, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [16/375], Loss: 2.3441, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [17/375], Loss: 2.2873, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [18/375], Loss: 2.2984, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [19/375], Loss: 2.1021, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [20/375], Loss: 2.1863, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [21/375], Loss: 2.4104, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [22/375], Loss: 2.3118, batch time: 0.77, accuracy:  18.75%\n",
      "Epoch [8/50], Step [23/375], Loss: 2.2154, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [24/375], Loss: 2.1604, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [25/375], Loss: 2.2308, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [26/375], Loss: 2.2506, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [27/375], Loss: 2.3156, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [28/375], Loss: 2.3735, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [8/50], Step [29/375], Loss: 2.1883, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [30/375], Loss: 2.3601, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [31/375], Loss: 2.1969, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [8/50], Step [32/375], Loss: 2.2919, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [33/375], Loss: 2.3525, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [34/375], Loss: 2.2951, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [35/375], Loss: 2.1190, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [8/50], Step [36/375], Loss: 2.1714, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [37/375], Loss: 2.2713, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [38/375], Loss: 2.2204, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [39/375], Loss: 2.1453, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [40/375], Loss: 2.1489, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [41/375], Loss: 2.1953, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [42/375], Loss: 2.2741, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [43/375], Loss: 2.3356, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [44/375], Loss: 2.2392, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [45/375], Loss: 2.1617, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [46/375], Loss: 2.3356, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [47/375], Loss: 2.0868, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [48/375], Loss: 2.0980, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [49/375], Loss: 2.2918, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [50/375], Loss: 2.2582, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [51/375], Loss: 2.3048, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [52/375], Loss: 2.3054, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [53/375], Loss: 2.0687, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [8/50], Step [54/375], Loss: 2.3765, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [55/375], Loss: 2.1802, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [56/375], Loss: 2.1663, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [57/375], Loss: 2.1615, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [58/375], Loss: 2.3356, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [59/375], Loss: 2.1310, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [60/375], Loss: 2.3108, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [61/375], Loss: 2.1030, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [62/375], Loss: 2.3752, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [63/375], Loss: 2.3767, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [64/375], Loss: 2.1422, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [65/375], Loss: 2.4695, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [66/375], Loss: 2.4942, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [67/375], Loss: 2.1157, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [68/375], Loss: 2.3610, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [69/375], Loss: 2.2835, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [70/375], Loss: 2.1421, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [71/375], Loss: 2.2335, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [72/375], Loss: 2.3965, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [73/375], Loss: 2.2748, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [74/375], Loss: 2.3201, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [75/375], Loss: 2.4440, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [8/50], Step [76/375], Loss: 2.2505, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [77/375], Loss: 2.2830, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [78/375], Loss: 2.2913, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [79/375], Loss: 2.2463, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [80/375], Loss: 2.1241, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [81/375], Loss: 2.1558, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [82/375], Loss: 2.1324, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [83/375], Loss: 2.3234, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [84/375], Loss: 2.2812, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [85/375], Loss: 2.2867, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [86/375], Loss: 2.1223, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [87/375], Loss: 2.1658, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [8/50], Step [88/375], Loss: 2.2129, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [89/375], Loss: 2.2517, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [90/375], Loss: 2.4198, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [91/375], Loss: 2.2279, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [92/375], Loss: 2.3438, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [93/375], Loss: 2.2226, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [94/375], Loss: 2.1891, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [95/375], Loss: 2.3522, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [96/375], Loss: 2.4266, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [97/375], Loss: 2.1578, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [98/375], Loss: 2.1625, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [99/375], Loss: 2.0926, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [8/50], Step [100/375], Loss: 2.2982, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [101/375], Loss: 2.3571, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [102/375], Loss: 2.2560, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [103/375], Loss: 2.2753, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [104/375], Loss: 2.3286, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [105/375], Loss: 2.4338, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [106/375], Loss: 2.1468, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [107/375], Loss: 2.3522, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [108/375], Loss: 2.3096, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [109/375], Loss: 2.2739, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [110/375], Loss: 2.1615, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [111/375], Loss: 2.1704, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [112/375], Loss: 2.3258, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [113/375], Loss: 2.2234, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [114/375], Loss: 2.1171, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [115/375], Loss: 2.2531, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [116/375], Loss: 2.3330, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [117/375], Loss: 2.3304, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [118/375], Loss: 2.1914, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [119/375], Loss: 2.3774, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [8/50], Step [120/375], Loss: 2.4719, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [121/375], Loss: 2.1864, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [122/375], Loss: 2.3045, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [123/375], Loss: 2.2798, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [124/375], Loss: 2.1830, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [125/375], Loss: 2.1840, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [126/375], Loss: 2.2847, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [127/375], Loss: 2.3443, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [128/375], Loss: 2.2300, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [129/375], Loss: 2.2837, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [130/375], Loss: 2.3476, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [131/375], Loss: 2.3215, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [132/375], Loss: 2.2940, batch time: 0.86, accuracy:  18.75%\n",
      "Epoch [8/50], Step [133/375], Loss: 2.3073, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [134/375], Loss: 2.2331, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [135/375], Loss: 2.0868, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [8/50], Step [136/375], Loss: 2.2162, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [137/375], Loss: 2.2590, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [138/375], Loss: 2.2771, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [139/375], Loss: 2.1974, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [140/375], Loss: 2.3327, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [141/375], Loss: 2.2572, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [8/50], Step [142/375], Loss: 2.1150, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [143/375], Loss: 2.2083, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [144/375], Loss: 2.2374, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [145/375], Loss: 2.1805, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [146/375], Loss: 2.1633, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [147/375], Loss: 2.3884, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [148/375], Loss: 2.4441, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [8/50], Step [149/375], Loss: 2.4879, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [150/375], Loss: 2.1462, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [151/375], Loss: 2.3290, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [152/375], Loss: 2.1717, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [8/50], Step [153/375], Loss: 2.2607, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [154/375], Loss: 2.2447, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [155/375], Loss: 2.1956, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [156/375], Loss: 2.2696, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [157/375], Loss: 2.3630, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [158/375], Loss: 2.3705, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [159/375], Loss: 2.3521, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [160/375], Loss: 2.2941, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [161/375], Loss: 2.4343, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [162/375], Loss: 2.2588, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [163/375], Loss: 2.2692, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [164/375], Loss: 2.2230, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [165/375], Loss: 2.3641, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [8/50], Step [166/375], Loss: 2.2464, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [167/375], Loss: 2.3165, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [168/375], Loss: 2.2983, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [169/375], Loss: 2.3598, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [170/375], Loss: 2.2802, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [171/375], Loss: 2.2471, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [172/375], Loss: 2.2566, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [173/375], Loss: 2.2159, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [174/375], Loss: 2.2843, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [175/375], Loss: 2.2593, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [176/375], Loss: 2.2158, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [177/375], Loss: 2.3977, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [178/375], Loss: 2.3503, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [179/375], Loss: 2.2541, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [180/375], Loss: 2.2229, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [181/375], Loss: 2.1786, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [8/50], Step [182/375], Loss: 2.3917, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [8/50], Step [183/375], Loss: 2.2789, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [184/375], Loss: 2.1953, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [185/375], Loss: 2.4209, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [186/375], Loss: 2.2410, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [187/375], Loss: 2.2758, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [188/375], Loss: 2.2993, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [189/375], Loss: 2.3470, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [190/375], Loss: 2.2819, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [191/375], Loss: 2.0550, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [192/375], Loss: 2.1919, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [193/375], Loss: 2.0514, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [8/50], Step [194/375], Loss: 2.1272, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [195/375], Loss: 2.2957, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [196/375], Loss: 2.1280, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [8/50], Step [197/375], Loss: 2.1644, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [198/375], Loss: 2.3138, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [199/375], Loss: 2.2386, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [200/375], Loss: 2.1624, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [201/375], Loss: 2.1327, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [8/50], Step [202/375], Loss: 2.2367, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [203/375], Loss: 2.1830, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [204/375], Loss: 2.1996, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [205/375], Loss: 2.1098, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [206/375], Loss: 2.3539, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [207/375], Loss: 2.2955, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [208/375], Loss: 2.2287, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [209/375], Loss: 2.1355, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [210/375], Loss: 2.2844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [211/375], Loss: 2.2993, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [212/375], Loss: 2.0508, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [213/375], Loss: 2.1484, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [8/50], Step [214/375], Loss: 2.1958, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [215/375], Loss: 2.1193, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [8/50], Step [216/375], Loss: 2.2856, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [217/375], Loss: 2.2498, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [218/375], Loss: 2.1787, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [219/375], Loss: 2.3723, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [220/375], Loss: 2.1831, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [221/375], Loss: 2.1217, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [8/50], Step [222/375], Loss: 2.0331, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [223/375], Loss: 2.3192, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [224/375], Loss: 2.1223, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [225/375], Loss: 2.3074, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [8/50], Step [226/375], Loss: 2.1494, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [227/375], Loss: 1.9764, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [228/375], Loss: 2.4156, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [229/375], Loss: 2.2320, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [230/375], Loss: 2.3022, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [231/375], Loss: 1.9959, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [232/375], Loss: 2.2326, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [233/375], Loss: 2.1891, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [234/375], Loss: 2.3634, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [235/375], Loss: 2.3288, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [236/375], Loss: 2.3145, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [237/375], Loss: 2.3669, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [238/375], Loss: 2.4407, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [239/375], Loss: 2.4782, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [240/375], Loss: 2.2638, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [241/375], Loss: 2.2307, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [8/50], Step [242/375], Loss: 2.2526, batch time: 0.90, accuracy:  18.75%\n",
      "Epoch [8/50], Step [243/375], Loss: 2.2320, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [244/375], Loss: 2.4066, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [245/375], Loss: 2.2512, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [8/50], Step [246/375], Loss: 2.0501, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [8/50], Step [247/375], Loss: 2.2787, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [248/375], Loss: 2.2590, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [8/50], Step [249/375], Loss: 2.2107, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [250/375], Loss: 2.2077, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [8/50], Step [251/375], Loss: 2.1365, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [8/50], Step [252/375], Loss: 2.3217, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [253/375], Loss: 1.9773, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [8/50], Step [254/375], Loss: 2.2217, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [255/375], Loss: 2.1907, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [256/375], Loss: 2.1330, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [257/375], Loss: 2.2881, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [258/375], Loss: 2.1476, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [259/375], Loss: 2.3107, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [8/50], Step [260/375], Loss: 2.0243, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [261/375], Loss: 2.3414, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [262/375], Loss: 2.1713, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [263/375], Loss: 2.3458, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [264/375], Loss: 2.2740, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [265/375], Loss: 2.3416, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [266/375], Loss: 2.2988, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [267/375], Loss: 2.3476, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [268/375], Loss: 2.4162, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [269/375], Loss: 2.3204, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [270/375], Loss: 2.2586, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [271/375], Loss: 2.1855, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [272/375], Loss: 2.2213, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [273/375], Loss: 2.0913, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [274/375], Loss: 2.2799, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [275/375], Loss: 2.2006, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [276/375], Loss: 2.4340, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [8/50], Step [277/375], Loss: 2.5244, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [278/375], Loss: 2.1459, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [279/375], Loss: 2.2534, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [280/375], Loss: 2.1135, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [281/375], Loss: 2.3291, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [282/375], Loss: 2.2845, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [283/375], Loss: 2.3619, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [8/50], Step [284/375], Loss: 2.3937, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [285/375], Loss: 2.2088, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [286/375], Loss: 2.1995, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [287/375], Loss: 2.2042, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [288/375], Loss: 2.1811, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [289/375], Loss: 2.2953, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [290/375], Loss: 2.1125, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [291/375], Loss: 2.1612, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [292/375], Loss: 2.2528, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [293/375], Loss: 2.2768, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [294/375], Loss: 2.1896, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [295/375], Loss: 2.1317, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [8/50], Step [296/375], Loss: 2.1067, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [8/50], Step [297/375], Loss: 2.2602, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [298/375], Loss: 2.2653, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [299/375], Loss: 2.2765, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [300/375], Loss: 2.3402, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [301/375], Loss: 2.1924, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [302/375], Loss: 2.2896, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [303/375], Loss: 2.3734, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [8/50], Step [304/375], Loss: 2.3272, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [305/375], Loss: 2.3347, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [306/375], Loss: 2.1743, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [307/375], Loss: 2.3387, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [308/375], Loss: 2.0628, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [309/375], Loss: 2.3279, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [8/50], Step [310/375], Loss: 2.2463, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [311/375], Loss: 2.3966, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [312/375], Loss: 2.3973, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [8/50], Step [313/375], Loss: 2.1562, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [314/375], Loss: 2.1074, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [315/375], Loss: 2.1086, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [316/375], Loss: 2.3231, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [317/375], Loss: 2.1723, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [318/375], Loss: 2.1704, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [319/375], Loss: 2.3093, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [320/375], Loss: 2.1289, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [321/375], Loss: 2.2702, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [322/375], Loss: 2.2815, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [323/375], Loss: 2.1681, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [324/375], Loss: 2.3527, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [325/375], Loss: 2.0311, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [326/375], Loss: 1.9583, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [8/50], Step [327/375], Loss: 2.1842, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [328/375], Loss: 2.5169, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [329/375], Loss: 2.2241, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [330/375], Loss: 2.2655, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [331/375], Loss: 2.2042, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [332/375], Loss: 2.1443, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [333/375], Loss: 2.2144, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [334/375], Loss: 2.1551, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [335/375], Loss: 2.3633, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [8/50], Step [336/375], Loss: 2.2894, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [337/375], Loss: 2.1979, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [338/375], Loss: 2.2957, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [8/50], Step [339/375], Loss: 2.1270, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [8/50], Step [340/375], Loss: 2.2266, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [341/375], Loss: 2.0982, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [8/50], Step [342/375], Loss: 2.0730, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [343/375], Loss: 2.1642, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [8/50], Step [344/375], Loss: 2.5618, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [345/375], Loss: 2.2882, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [346/375], Loss: 2.1368, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [347/375], Loss: 2.1935, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [8/50], Step [348/375], Loss: 2.2123, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [349/375], Loss: 2.0790, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [350/375], Loss: 2.1027, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [351/375], Loss: 2.3674, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [352/375], Loss: 2.3229, batch time: 0.80, accuracy:  18.75%\n",
      "Epoch [8/50], Step [353/375], Loss: 2.3765, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [8/50], Step [354/375], Loss: 2.0716, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [355/375], Loss: 2.2185, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [8/50], Step [356/375], Loss: 2.0734, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [357/375], Loss: 2.2571, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [8/50], Step [358/375], Loss: 2.0916, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [8/50], Step [359/375], Loss: 2.3631, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [8/50], Step [360/375], Loss: 2.4933, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [361/375], Loss: 2.0744, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [8/50], Step [362/375], Loss: 1.9826, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [8/50], Step [363/375], Loss: 2.1333, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [364/375], Loss: 2.1416, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [8/50], Step [365/375], Loss: 2.0843, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [8/50], Step [366/375], Loss: 2.4650, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [367/375], Loss: 2.1265, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [8/50], Step [368/375], Loss: 2.4713, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [8/50], Step [369/375], Loss: 2.1683, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [8/50], Step [370/375], Loss: 2.1257, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [371/375], Loss: 2.3910, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [8/50], Step [372/375], Loss: 2.1113, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [8/50], Step [373/375], Loss: 2.4241, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [8/50], Step [374/375], Loss: 2.2287, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [8/50], Step [375/375], Loss: 2.3923, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [1/375], Loss: 2.1733, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [2/375], Loss: 2.3293, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [3/375], Loss: 2.2743, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [4/375], Loss: 2.1820, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [5/375], Loss: 2.0965, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [6/375], Loss: 2.1474, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [7/375], Loss: 2.2598, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [8/375], Loss: 2.0744, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [9/375], Loss: 2.2965, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [10/375], Loss: 2.1592, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [11/375], Loss: 2.1231, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [12/375], Loss: 2.3364, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [13/375], Loss: 2.1693, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [14/375], Loss: 2.4472, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [15/375], Loss: 1.9153, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [16/375], Loss: 2.2373, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [17/375], Loss: 2.3479, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [18/375], Loss: 2.3343, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [19/375], Loss: 2.2218, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [20/375], Loss: 2.2268, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [21/375], Loss: 2.2355, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [22/375], Loss: 2.4381, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [23/375], Loss: 2.2635, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [24/375], Loss: 2.2011, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [25/375], Loss: 2.2490, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [26/375], Loss: 2.3492, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [27/375], Loss: 2.4549, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [28/375], Loss: 2.4294, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [29/375], Loss: 2.1896, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [30/375], Loss: 2.4872, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [31/375], Loss: 2.3669, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [32/375], Loss: 2.3276, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [33/375], Loss: 2.1700, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [34/375], Loss: 2.1673, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [35/375], Loss: 2.3760, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [36/375], Loss: 2.2988, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [37/375], Loss: 2.3615, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [38/375], Loss: 2.2479, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [39/375], Loss: 2.1646, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [40/375], Loss: 2.2431, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [41/375], Loss: 2.1504, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [9/50], Step [42/375], Loss: 2.2195, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [43/375], Loss: 2.2515, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [44/375], Loss: 2.0681, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [9/50], Step [45/375], Loss: 2.2383, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [46/375], Loss: 2.2583, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [47/375], Loss: 2.0990, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [48/375], Loss: 2.4200, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [49/375], Loss: 2.3176, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [50/375], Loss: 2.3341, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [51/375], Loss: 2.2232, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [52/375], Loss: 2.2722, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [53/375], Loss: 2.2634, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [54/375], Loss: 2.0625, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [55/375], Loss: 2.2922, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [56/375], Loss: 2.2686, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [57/375], Loss: 2.2784, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [58/375], Loss: 2.1911, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [59/375], Loss: 2.3178, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [60/375], Loss: 2.2598, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [61/375], Loss: 2.2525, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [62/375], Loss: 2.2400, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [63/375], Loss: 1.9967, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [64/375], Loss: 2.2266, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [65/375], Loss: 2.3079, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [66/375], Loss: 2.2544, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [67/375], Loss: 2.4357, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [9/50], Step [68/375], Loss: 2.1635, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [69/375], Loss: 2.4150, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [70/375], Loss: 2.2418, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [71/375], Loss: 2.0741, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [72/375], Loss: 2.2064, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [73/375], Loss: 2.1203, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [74/375], Loss: 2.2044, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [75/375], Loss: 2.3554, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [76/375], Loss: 2.3250, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [77/375], Loss: 2.2505, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [78/375], Loss: 2.1224, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [79/375], Loss: 2.3972, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [80/375], Loss: 2.2760, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [81/375], Loss: 2.3097, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [82/375], Loss: 2.2998, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [83/375], Loss: 2.3260, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [84/375], Loss: 2.2856, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [85/375], Loss: 2.2221, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [86/375], Loss: 2.3935, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [87/375], Loss: 2.2719, batch time: 0.89, accuracy:  12.50%\n",
      "Epoch [9/50], Step [88/375], Loss: 2.2045, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [89/375], Loss: 1.9396, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [9/50], Step [90/375], Loss: 2.2800, batch time: 0.28, accuracy:  0.00%\n",
      "Epoch [9/50], Step [91/375], Loss: 2.2678, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [92/375], Loss: 2.1875, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [93/375], Loss: 2.2151, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [9/50], Step [94/375], Loss: 2.4203, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [95/375], Loss: 2.1850, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [96/375], Loss: 2.4295, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [9/50], Step [97/375], Loss: 2.2167, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [98/375], Loss: 2.5223, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [99/375], Loss: 2.3027, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [100/375], Loss: 2.1710, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [101/375], Loss: 2.1698, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [102/375], Loss: 2.2890, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [103/375], Loss: 2.1979, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [104/375], Loss: 2.2383, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [105/375], Loss: 2.3540, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [106/375], Loss: 2.2246, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [107/375], Loss: 2.2532, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [108/375], Loss: 1.9386, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [9/50], Step [109/375], Loss: 2.0032, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [110/375], Loss: 2.2173, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [111/375], Loss: 2.3059, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [112/375], Loss: 2.1056, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [9/50], Step [113/375], Loss: 2.2564, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [114/375], Loss: 2.3193, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [115/375], Loss: 2.3978, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [116/375], Loss: 2.2603, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [117/375], Loss: 2.1964, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [118/375], Loss: 2.2638, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [119/375], Loss: 2.3993, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [120/375], Loss: 2.2608, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [121/375], Loss: 2.2506, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [122/375], Loss: 2.2526, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [123/375], Loss: 2.2001, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [124/375], Loss: 2.2572, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [125/375], Loss: 2.1972, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [126/375], Loss: 2.2924, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [127/375], Loss: 2.2880, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [128/375], Loss: 2.2065, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [129/375], Loss: 2.1534, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [130/375], Loss: 2.2578, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [131/375], Loss: 2.2520, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [132/375], Loss: 2.2960, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [133/375], Loss: 2.2664, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [134/375], Loss: 2.2870, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [135/375], Loss: 2.1095, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [9/50], Step [136/375], Loss: 2.1387, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [9/50], Step [137/375], Loss: 2.3261, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [138/375], Loss: 2.3027, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [139/375], Loss: 2.1939, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [140/375], Loss: 2.1476, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [9/50], Step [141/375], Loss: 2.2322, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [142/375], Loss: 2.2167, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [143/375], Loss: 2.2210, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [144/375], Loss: 2.3501, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [145/375], Loss: 2.1373, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [146/375], Loss: 2.2258, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [147/375], Loss: 2.1393, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [148/375], Loss: 2.3724, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [149/375], Loss: 2.1490, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [150/375], Loss: 2.2510, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [151/375], Loss: 2.2579, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [152/375], Loss: 2.3582, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [153/375], Loss: 2.3364, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [154/375], Loss: 2.2802, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [155/375], Loss: 2.1925, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [156/375], Loss: 2.3955, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [157/375], Loss: 2.2012, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [158/375], Loss: 2.1859, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [159/375], Loss: 2.1206, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [160/375], Loss: 2.2265, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [161/375], Loss: 2.2805, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [162/375], Loss: 2.2369, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [163/375], Loss: 2.3384, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [164/375], Loss: 2.4101, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [165/375], Loss: 2.3599, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [166/375], Loss: 2.3841, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [167/375], Loss: 2.0913, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [168/375], Loss: 2.0365, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [9/50], Step [169/375], Loss: 2.2369, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [170/375], Loss: 2.1342, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [171/375], Loss: 2.2741, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [172/375], Loss: 2.0491, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [9/50], Step [173/375], Loss: 2.2012, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [174/375], Loss: 2.3052, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [175/375], Loss: 2.0913, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [176/375], Loss: 2.0444, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [9/50], Step [177/375], Loss: 2.2366, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [178/375], Loss: 2.3471, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [179/375], Loss: 2.1916, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [180/375], Loss: 2.4277, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [9/50], Step [181/375], Loss: 2.3210, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [182/375], Loss: 2.3742, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [183/375], Loss: 2.2736, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [184/375], Loss: 2.3009, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [185/375], Loss: 2.2262, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [186/375], Loss: 2.3851, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [187/375], Loss: 2.1979, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [188/375], Loss: 2.1199, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [189/375], Loss: 2.3957, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [190/375], Loss: 2.1662, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [191/375], Loss: 2.1158, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [192/375], Loss: 2.1982, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [193/375], Loss: 2.2586, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [194/375], Loss: 2.2647, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [195/375], Loss: 2.3482, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [196/375], Loss: 2.3741, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [9/50], Step [197/375], Loss: 2.1697, batch time: 0.83, accuracy:  25.00%\n",
      "Epoch [9/50], Step [198/375], Loss: 2.1307, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [9/50], Step [199/375], Loss: 2.2942, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [200/375], Loss: 2.3359, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [9/50], Step [201/375], Loss: 2.1637, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [202/375], Loss: 2.2584, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [203/375], Loss: 2.2583, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [204/375], Loss: 2.3126, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [205/375], Loss: 2.2368, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [206/375], Loss: 2.3220, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [9/50], Step [207/375], Loss: 2.1456, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [208/375], Loss: 2.2158, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [209/375], Loss: 2.2716, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [210/375], Loss: 2.2686, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [211/375], Loss: 2.4050, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [212/375], Loss: 2.2229, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [213/375], Loss: 2.2825, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [214/375], Loss: 2.4352, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [9/50], Step [215/375], Loss: 2.3476, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [216/375], Loss: 2.2968, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [217/375], Loss: 2.1558, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [218/375], Loss: 2.1329, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [9/50], Step [219/375], Loss: 2.2358, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [220/375], Loss: 2.2589, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [221/375], Loss: 2.2764, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [222/375], Loss: 2.1090, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [223/375], Loss: 2.3444, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [9/50], Step [224/375], Loss: 2.2036, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [225/375], Loss: 2.0944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [226/375], Loss: 2.1209, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [9/50], Step [227/375], Loss: 2.3378, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [228/375], Loss: 2.2229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [229/375], Loss: 2.1290, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [230/375], Loss: 2.3461, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [231/375], Loss: 2.1120, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [232/375], Loss: 2.2056, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [233/375], Loss: 2.1511, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [234/375], Loss: 2.3795, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [235/375], Loss: 2.1772, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [236/375], Loss: 2.2965, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [237/375], Loss: 2.3903, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [238/375], Loss: 2.2952, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [239/375], Loss: 2.3115, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [240/375], Loss: 2.3568, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [241/375], Loss: 2.2815, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [242/375], Loss: 2.2896, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [9/50], Step [243/375], Loss: 2.2717, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [244/375], Loss: 2.0593, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [245/375], Loss: 2.3978, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [246/375], Loss: 2.1623, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [247/375], Loss: 2.1495, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [248/375], Loss: 2.3339, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [249/375], Loss: 2.3701, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [250/375], Loss: 2.3729, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [9/50], Step [251/375], Loss: 2.1773, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [252/375], Loss: 2.0030, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [9/50], Step [253/375], Loss: 2.3472, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [9/50], Step [254/375], Loss: 2.2665, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [9/50], Step [255/375], Loss: 2.2521, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [256/375], Loss: 2.1974, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [257/375], Loss: 2.2178, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [258/375], Loss: 2.1556, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [9/50], Step [259/375], Loss: 2.1417, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [260/375], Loss: 2.1157, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [261/375], Loss: 2.1809, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [262/375], Loss: 2.4142, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [9/50], Step [263/375], Loss: 2.1769, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [9/50], Step [264/375], Loss: 2.3079, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [9/50], Step [265/375], Loss: 2.1379, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [266/375], Loss: 2.2992, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [9/50], Step [267/375], Loss: 2.2188, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [268/375], Loss: 2.0854, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [9/50], Step [269/375], Loss: 2.1631, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [9/50], Step [270/375], Loss: 2.4501, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [9/50], Step [271/375], Loss: 2.2690, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [272/375], Loss: 2.2786, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [273/375], Loss: 2.2638, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [274/375], Loss: 2.2427, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [275/375], Loss: 2.1327, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [276/375], Loss: 2.3547, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [277/375], Loss: 2.4155, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [278/375], Loss: 2.3138, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [279/375], Loss: 2.3452, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [280/375], Loss: 2.1226, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [281/375], Loss: 2.1141, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [282/375], Loss: 2.0848, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [9/50], Step [283/375], Loss: 2.3397, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [284/375], Loss: 2.1300, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [285/375], Loss: 2.1057, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [286/375], Loss: 2.4235, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [287/375], Loss: 2.0886, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [288/375], Loss: 2.4397, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [289/375], Loss: 2.3306, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [290/375], Loss: 2.1741, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [9/50], Step [291/375], Loss: 2.2135, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [292/375], Loss: 2.1034, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [293/375], Loss: 2.0723, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [294/375], Loss: 2.3200, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [9/50], Step [295/375], Loss: 2.2735, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [296/375], Loss: 2.1153, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [297/375], Loss: 2.3095, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [298/375], Loss: 1.9980, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [299/375], Loss: 2.1383, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [300/375], Loss: 2.1603, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [301/375], Loss: 2.1857, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [302/375], Loss: 2.3307, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [9/50], Step [303/375], Loss: 2.4292, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [304/375], Loss: 2.2323, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [305/375], Loss: 2.3657, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [306/375], Loss: 2.2997, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [307/375], Loss: 2.1992, batch time: 0.78, accuracy:  18.75%\n",
      "Epoch [9/50], Step [308/375], Loss: 2.3381, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [309/375], Loss: 2.3739, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [9/50], Step [310/375], Loss: 2.1661, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [9/50], Step [311/375], Loss: 2.0590, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [9/50], Step [312/375], Loss: 2.0950, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [313/375], Loss: 2.1597, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [9/50], Step [314/375], Loss: 2.0523, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [315/375], Loss: 2.1440, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [316/375], Loss: 2.0808, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [317/375], Loss: 2.4101, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [318/375], Loss: 2.3001, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [319/375], Loss: 2.4283, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [9/50], Step [320/375], Loss: 2.3411, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [9/50], Step [321/375], Loss: 2.1985, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [9/50], Step [322/375], Loss: 2.3832, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [323/375], Loss: 2.4665, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [9/50], Step [324/375], Loss: 2.1158, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [325/375], Loss: 2.3170, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [326/375], Loss: 2.1774, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [327/375], Loss: 2.1218, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [9/50], Step [328/375], Loss: 2.0719, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [9/50], Step [329/375], Loss: 2.3984, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [330/375], Loss: 2.1595, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [331/375], Loss: 2.1289, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [9/50], Step [332/375], Loss: 2.3516, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [9/50], Step [333/375], Loss: 2.2192, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [334/375], Loss: 2.1179, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [335/375], Loss: 2.1721, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [9/50], Step [336/375], Loss: 2.2600, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [9/50], Step [337/375], Loss: 2.2355, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [338/375], Loss: 2.2196, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [339/375], Loss: 2.2792, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [340/375], Loss: 1.9416, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [9/50], Step [341/375], Loss: 2.2271, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [342/375], Loss: 2.3352, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [343/375], Loss: 2.1336, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [344/375], Loss: 2.3045, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [345/375], Loss: 2.1122, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [346/375], Loss: 2.3408, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [347/375], Loss: 2.2477, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [348/375], Loss: 2.3792, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [9/50], Step [349/375], Loss: 2.3292, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [350/375], Loss: 2.3569, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [351/375], Loss: 2.3163, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [9/50], Step [352/375], Loss: 2.3844, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [9/50], Step [353/375], Loss: 2.1311, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [354/375], Loss: 2.2683, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [355/375], Loss: 2.1179, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [356/375], Loss: 2.1501, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [9/50], Step [357/375], Loss: 2.4938, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [358/375], Loss: 2.2930, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [359/375], Loss: 2.1391, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [360/375], Loss: 2.0499, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [361/375], Loss: 2.1238, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [362/375], Loss: 2.3163, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [363/375], Loss: 2.2978, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [364/375], Loss: 2.0977, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [9/50], Step [365/375], Loss: 2.3489, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [366/375], Loss: 2.1796, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [9/50], Step [367/375], Loss: 2.4094, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [368/375], Loss: 1.9595, batch time: 0.26, accuracy:  50.00%\n",
      "Epoch [9/50], Step [369/375], Loss: 2.3620, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [9/50], Step [370/375], Loss: 2.4317, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [9/50], Step [371/375], Loss: 2.1293, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [372/375], Loss: 2.1522, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [9/50], Step [373/375], Loss: 2.4133, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [9/50], Step [374/375], Loss: 2.1522, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [9/50], Step [375/375], Loss: 2.2687, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [1/375], Loss: 2.2524, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [2/375], Loss: 2.0756, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [3/375], Loss: 2.2546, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [4/375], Loss: 2.4374, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [5/375], Loss: 2.3130, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [6/375], Loss: 2.0815, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [7/375], Loss: 2.2798, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [8/375], Loss: 2.3568, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [9/375], Loss: 2.3012, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [10/375], Loss: 2.2632, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [11/375], Loss: 2.3394, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [12/375], Loss: 2.3430, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [13/375], Loss: 2.2973, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [14/375], Loss: 2.2357, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [15/375], Loss: 2.1082, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [16/375], Loss: 2.4027, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [17/375], Loss: 2.3391, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [10/50], Step [18/375], Loss: 2.3034, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [19/375], Loss: 2.3352, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [20/375], Loss: 2.3740, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [21/375], Loss: 2.0523, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [10/50], Step [22/375], Loss: 2.4136, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [23/375], Loss: 2.5058, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [24/375], Loss: 2.2678, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [25/375], Loss: 2.6357, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [10/50], Step [26/375], Loss: 2.2485, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [27/375], Loss: 2.3126, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [28/375], Loss: 2.3236, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [29/375], Loss: 2.1897, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [30/375], Loss: 2.0540, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [31/375], Loss: 2.2461, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [32/375], Loss: 2.2834, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [33/375], Loss: 2.2515, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [34/375], Loss: 2.1157, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [35/375], Loss: 2.2117, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [36/375], Loss: 2.1285, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [10/50], Step [37/375], Loss: 2.1780, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [38/375], Loss: 2.1005, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [10/50], Step [39/375], Loss: 2.4361, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [10/50], Step [40/375], Loss: 2.1545, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [41/375], Loss: 2.3510, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [10/50], Step [42/375], Loss: 2.4710, batch time: 0.79, accuracy:  0.00%\n",
      "Epoch [10/50], Step [43/375], Loss: 2.4046, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [44/375], Loss: 2.2486, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [45/375], Loss: 2.2473, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [10/50], Step [46/375], Loss: 2.3086, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [47/375], Loss: 2.1827, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [48/375], Loss: 2.2990, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [10/50], Step [49/375], Loss: 2.2664, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [50/375], Loss: 2.2329, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [51/375], Loss: 2.3201, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [10/50], Step [52/375], Loss: 2.2464, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [53/375], Loss: 2.2327, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [54/375], Loss: 2.3493, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [55/375], Loss: 2.2977, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [56/375], Loss: 2.1350, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [57/375], Loss: 2.1167, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [10/50], Step [58/375], Loss: 2.2016, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [59/375], Loss: 2.2628, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [60/375], Loss: 2.2856, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [61/375], Loss: 2.3188, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [62/375], Loss: 2.2205, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [63/375], Loss: 2.3203, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [10/50], Step [64/375], Loss: 2.2726, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [65/375], Loss: 2.2259, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [66/375], Loss: 2.2415, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [67/375], Loss: 2.2833, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [10/50], Step [68/375], Loss: 2.2846, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [69/375], Loss: 2.1932, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [70/375], Loss: 2.0548, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [71/375], Loss: 2.2367, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [72/375], Loss: 2.3288, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [73/375], Loss: 2.2759, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [74/375], Loss: 2.1197, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [75/375], Loss: 2.1699, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [76/375], Loss: 2.1794, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [77/375], Loss: 2.2099, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [78/375], Loss: 2.3372, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [79/375], Loss: 2.2301, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [10/50], Step [80/375], Loss: 2.3857, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [81/375], Loss: 2.2288, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [82/375], Loss: 2.2625, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [83/375], Loss: 2.1681, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [84/375], Loss: 2.3200, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [85/375], Loss: 2.0323, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [86/375], Loss: 2.1986, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [87/375], Loss: 2.1906, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [88/375], Loss: 2.0247, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [89/375], Loss: 2.1353, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [90/375], Loss: 2.4333, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [91/375], Loss: 2.2874, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [92/375], Loss: 2.3284, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [93/375], Loss: 2.4706, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [94/375], Loss: 2.4047, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [95/375], Loss: 2.3030, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [10/50], Step [96/375], Loss: 2.1909, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [97/375], Loss: 2.3693, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [98/375], Loss: 2.3071, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [99/375], Loss: 2.2167, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [100/375], Loss: 2.2417, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [101/375], Loss: 2.4662, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [102/375], Loss: 2.3013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [103/375], Loss: 2.2295, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [104/375], Loss: 2.2167, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [105/375], Loss: 2.1861, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [106/375], Loss: 2.0129, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [107/375], Loss: 2.1079, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [108/375], Loss: 2.2453, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [109/375], Loss: 2.2178, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [110/375], Loss: 2.3545, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [111/375], Loss: 2.2481, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [112/375], Loss: 2.2211, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [113/375], Loss: 2.2691, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [114/375], Loss: 2.2577, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [115/375], Loss: 2.0687, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [116/375], Loss: 2.2899, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [117/375], Loss: 2.2788, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [118/375], Loss: 2.3078, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [119/375], Loss: 2.3283, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [120/375], Loss: 2.3955, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [121/375], Loss: 2.3247, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [122/375], Loss: 2.3855, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [123/375], Loss: 2.2732, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [124/375], Loss: 2.2100, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [125/375], Loss: 2.3369, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [126/375], Loss: 2.2752, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [127/375], Loss: 2.1639, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [128/375], Loss: 2.0621, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [129/375], Loss: 2.2011, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [130/375], Loss: 2.3020, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [131/375], Loss: 2.1385, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [10/50], Step [132/375], Loss: 2.1856, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [133/375], Loss: 2.2353, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [10/50], Step [134/375], Loss: 2.1995, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [135/375], Loss: 2.2040, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [136/375], Loss: 2.3990, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [137/375], Loss: 2.1968, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [138/375], Loss: 2.2224, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [139/375], Loss: 2.0337, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [10/50], Step [140/375], Loss: 2.2163, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [141/375], Loss: 2.1524, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [142/375], Loss: 2.1296, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [143/375], Loss: 2.3294, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [10/50], Step [144/375], Loss: 2.3990, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [145/375], Loss: 2.2858, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [146/375], Loss: 2.0980, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [147/375], Loss: 2.1498, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [148/375], Loss: 2.0475, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [149/375], Loss: 2.3130, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [150/375], Loss: 2.2898, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [151/375], Loss: 2.1107, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [152/375], Loss: 2.2325, batch time: 0.90, accuracy:  25.00%\n",
      "Epoch [10/50], Step [153/375], Loss: 2.2523, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [154/375], Loss: 2.1982, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [155/375], Loss: 2.2461, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [10/50], Step [156/375], Loss: 2.2222, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [157/375], Loss: 2.1857, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [158/375], Loss: 2.2885, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [10/50], Step [159/375], Loss: 2.2516, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [160/375], Loss: 2.3555, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [161/375], Loss: 2.2592, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [162/375], Loss: 2.2572, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [163/375], Loss: 2.0622, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [164/375], Loss: 2.1515, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [165/375], Loss: 2.3009, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [166/375], Loss: 2.1682, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [167/375], Loss: 2.3012, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [168/375], Loss: 2.1918, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [169/375], Loss: 2.1488, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [170/375], Loss: 2.1078, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [171/375], Loss: 2.2386, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [172/375], Loss: 2.2435, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [173/375], Loss: 2.1721, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [174/375], Loss: 2.2502, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [175/375], Loss: 2.6783, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [176/375], Loss: 2.4099, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [177/375], Loss: 2.0038, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [178/375], Loss: 2.4024, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [179/375], Loss: 2.1535, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [180/375], Loss: 2.1936, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [181/375], Loss: 2.2240, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [10/50], Step [182/375], Loss: 2.2170, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [183/375], Loss: 1.9735, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [184/375], Loss: 2.3114, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [185/375], Loss: 2.2358, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [186/375], Loss: 2.2590, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [187/375], Loss: 2.4203, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [188/375], Loss: 2.3003, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [189/375], Loss: 2.0936, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [10/50], Step [190/375], Loss: 2.1384, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [191/375], Loss: 2.2578, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [192/375], Loss: 2.2305, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [193/375], Loss: 2.4068, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [194/375], Loss: 2.2973, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [195/375], Loss: 2.3257, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [196/375], Loss: 2.2358, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [197/375], Loss: 2.1354, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [10/50], Step [198/375], Loss: 2.1580, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [199/375], Loss: 2.3535, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [200/375], Loss: 2.2497, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [201/375], Loss: 2.2346, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [202/375], Loss: 2.4774, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [203/375], Loss: 2.2507, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [204/375], Loss: 2.1839, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [205/375], Loss: 2.3036, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [206/375], Loss: 2.3686, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [207/375], Loss: 2.3005, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [208/375], Loss: 2.0904, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [209/375], Loss: 2.3599, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [210/375], Loss: 2.2567, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [211/375], Loss: 2.3167, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [212/375], Loss: 2.1717, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [213/375], Loss: 2.2492, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [214/375], Loss: 2.3003, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [215/375], Loss: 2.1912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [216/375], Loss: 2.3296, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [217/375], Loss: 2.4178, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [218/375], Loss: 2.2795, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [219/375], Loss: 2.1634, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [220/375], Loss: 2.2931, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [221/375], Loss: 2.2767, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [222/375], Loss: 2.2440, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [223/375], Loss: 2.2061, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [224/375], Loss: 2.2458, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [225/375], Loss: 2.2815, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [10/50], Step [226/375], Loss: 2.3775, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [227/375], Loss: 2.1431, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [228/375], Loss: 2.2727, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [229/375], Loss: 2.1708, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [230/375], Loss: 2.4024, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [231/375], Loss: 2.1914, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [232/375], Loss: 2.1931, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [233/375], Loss: 2.2896, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [234/375], Loss: 2.2304, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [235/375], Loss: 2.2743, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [236/375], Loss: 2.2048, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [237/375], Loss: 2.1596, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [238/375], Loss: 1.9691, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [10/50], Step [239/375], Loss: 2.2668, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [240/375], Loss: 2.2192, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [241/375], Loss: 2.2091, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [242/375], Loss: 2.3505, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [243/375], Loss: 2.2267, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [244/375], Loss: 2.0538, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [245/375], Loss: 2.1101, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [10/50], Step [246/375], Loss: 2.1980, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [247/375], Loss: 2.4018, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [248/375], Loss: 2.2781, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [249/375], Loss: 2.2526, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [250/375], Loss: 2.3040, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [251/375], Loss: 2.2492, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [252/375], Loss: 2.2412, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [253/375], Loss: 2.3070, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [254/375], Loss: 2.2290, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [255/375], Loss: 2.0357, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [256/375], Loss: 2.4563, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [257/375], Loss: 2.2508, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [258/375], Loss: 2.2725, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [259/375], Loss: 2.4587, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [260/375], Loss: 2.4345, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [261/375], Loss: 2.2532, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [262/375], Loss: 2.0259, batch time: 0.82, accuracy:  31.25%\n",
      "Epoch [10/50], Step [263/375], Loss: 2.2483, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [264/375], Loss: 2.1837, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [265/375], Loss: 2.1942, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [10/50], Step [266/375], Loss: 1.9379, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [10/50], Step [267/375], Loss: 2.0531, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [268/375], Loss: 2.3473, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [10/50], Step [269/375], Loss: 2.3985, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [270/375], Loss: 2.2430, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [271/375], Loss: 2.2038, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [10/50], Step [272/375], Loss: 2.4314, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [10/50], Step [273/375], Loss: 2.1572, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [274/375], Loss: 2.3145, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [275/375], Loss: 2.2127, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [10/50], Step [276/375], Loss: 2.2666, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [277/375], Loss: 2.1493, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [278/375], Loss: 2.0259, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [10/50], Step [279/375], Loss: 2.1234, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [10/50], Step [280/375], Loss: 2.1031, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [281/375], Loss: 2.4049, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [282/375], Loss: 2.2253, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [283/375], Loss: 2.1688, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [10/50], Step [284/375], Loss: 2.0721, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [285/375], Loss: 2.2840, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [286/375], Loss: 2.3296, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [287/375], Loss: 2.4243, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [10/50], Step [288/375], Loss: 2.3421, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [289/375], Loss: 2.4257, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [290/375], Loss: 2.3026, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [291/375], Loss: 2.1859, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [292/375], Loss: 2.2884, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [293/375], Loss: 2.1499, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [294/375], Loss: 2.1683, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [295/375], Loss: 2.3625, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [10/50], Step [296/375], Loss: 2.4134, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [297/375], Loss: 2.3818, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [298/375], Loss: 2.3474, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [299/375], Loss: 2.2183, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [300/375], Loss: 2.1000, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [301/375], Loss: 2.2919, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [302/375], Loss: 2.3531, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [303/375], Loss: 2.2126, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [304/375], Loss: 2.2438, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [305/375], Loss: 2.1775, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [306/375], Loss: 2.2518, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [10/50], Step [307/375], Loss: 2.1947, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [308/375], Loss: 2.1992, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [309/375], Loss: 2.1189, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [10/50], Step [310/375], Loss: 2.2880, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [311/375], Loss: 2.3355, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [312/375], Loss: 2.1818, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [313/375], Loss: 2.2384, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [314/375], Loss: 2.2073, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [315/375], Loss: 2.1712, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [316/375], Loss: 2.1592, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [10/50], Step [317/375], Loss: 2.2958, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [318/375], Loss: 2.1992, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [319/375], Loss: 2.2769, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [320/375], Loss: 1.8633, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [10/50], Step [321/375], Loss: 2.1628, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [10/50], Step [322/375], Loss: 2.1145, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [323/375], Loss: 2.3370, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [10/50], Step [324/375], Loss: 2.1131, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [325/375], Loss: 2.0962, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [326/375], Loss: 2.2627, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [327/375], Loss: 2.2650, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [328/375], Loss: 2.2333, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [329/375], Loss: 2.1707, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [330/375], Loss: 2.1290, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [331/375], Loss: 2.3428, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [332/375], Loss: 2.4846, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [333/375], Loss: 2.3227, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [334/375], Loss: 2.4072, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [335/375], Loss: 2.1526, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [336/375], Loss: 2.1771, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [337/375], Loss: 2.2652, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [338/375], Loss: 2.2295, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [339/375], Loss: 2.1183, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [10/50], Step [340/375], Loss: 2.1747, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [341/375], Loss: 2.2280, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [342/375], Loss: 2.1654, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [343/375], Loss: 2.3480, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [10/50], Step [344/375], Loss: 2.1695, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [10/50], Step [345/375], Loss: 2.2539, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [10/50], Step [346/375], Loss: 2.2141, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [347/375], Loss: 2.3008, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [348/375], Loss: 2.2498, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [349/375], Loss: 2.1841, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [350/375], Loss: 2.3656, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [10/50], Step [351/375], Loss: 2.1730, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [352/375], Loss: 2.1025, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [353/375], Loss: 2.2574, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [10/50], Step [354/375], Loss: 2.2235, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [10/50], Step [355/375], Loss: 2.3099, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [10/50], Step [356/375], Loss: 2.1764, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [357/375], Loss: 2.2173, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [358/375], Loss: 1.9737, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [10/50], Step [359/375], Loss: 2.2593, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [10/50], Step [360/375], Loss: 2.2920, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [361/375], Loss: 2.1271, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [362/375], Loss: 2.1936, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [10/50], Step [363/375], Loss: 2.2722, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [364/375], Loss: 1.9398, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [10/50], Step [365/375], Loss: 2.2034, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [10/50], Step [366/375], Loss: 2.2479, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [367/375], Loss: 2.0769, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [10/50], Step [368/375], Loss: 2.5570, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [10/50], Step [369/375], Loss: 2.3101, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [370/375], Loss: 2.1169, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [10/50], Step [371/375], Loss: 2.3329, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [10/50], Step [372/375], Loss: 2.5224, batch time: 0.81, accuracy:  0.00%\n",
      "Epoch [10/50], Step [373/375], Loss: 2.2083, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [374/375], Loss: 2.1183, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [10/50], Step [375/375], Loss: 2.4028, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [11/50], Step [1/375], Loss: 2.1900, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [2/375], Loss: 2.2955, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [3/375], Loss: 2.4122, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [11/50], Step [4/375], Loss: 2.2239, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [5/375], Loss: 2.3530, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [6/375], Loss: 2.3192, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [11/50], Step [7/375], Loss: 2.2657, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [8/375], Loss: 2.1376, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [9/375], Loss: 2.3382, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [10/375], Loss: 2.2590, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [11/375], Loss: 2.1019, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [12/375], Loss: 2.1097, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [13/375], Loss: 2.1741, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [14/375], Loss: 2.2419, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [15/375], Loss: 2.1922, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [16/375], Loss: 2.2368, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [17/375], Loss: 2.3405, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [18/375], Loss: 2.2966, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [19/375], Loss: 2.2011, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [20/375], Loss: 2.3779, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [21/375], Loss: 2.2789, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [22/375], Loss: 2.3000, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [23/375], Loss: 2.4438, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [24/375], Loss: 2.3283, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [25/375], Loss: 2.2533, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [26/375], Loss: 2.3220, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [27/375], Loss: 2.2912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [28/375], Loss: 2.0077, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [29/375], Loss: 2.3045, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [30/375], Loss: 2.2825, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [31/375], Loss: 2.2588, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [32/375], Loss: 2.2484, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [33/375], Loss: 2.2140, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [34/375], Loss: 2.2664, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [35/375], Loss: 2.2901, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [36/375], Loss: 2.0616, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [37/375], Loss: 2.1807, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [38/375], Loss: 2.1802, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [39/375], Loss: 2.0833, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [40/375], Loss: 2.0965, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [11/50], Step [41/375], Loss: 2.3051, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [42/375], Loss: 2.0940, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [43/375], Loss: 2.3148, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [44/375], Loss: 2.2147, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [45/375], Loss: 2.2529, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [46/375], Loss: 2.2496, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [47/375], Loss: 2.3077, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [48/375], Loss: 2.3495, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [49/375], Loss: 2.5170, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [50/375], Loss: 2.3835, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [11/50], Step [51/375], Loss: 2.6019, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [52/375], Loss: 2.1385, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [53/375], Loss: 2.0975, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [54/375], Loss: 2.2241, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [11/50], Step [55/375], Loss: 2.1624, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [56/375], Loss: 1.9722, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [57/375], Loss: 2.4107, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [58/375], Loss: 2.1012, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [59/375], Loss: 2.2344, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [60/375], Loss: 2.4813, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [61/375], Loss: 2.4817, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [11/50], Step [62/375], Loss: 2.3303, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [11/50], Step [63/375], Loss: 1.9619, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [11/50], Step [64/375], Loss: 2.3302, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [65/375], Loss: 2.1486, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [66/375], Loss: 2.4157, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [11/50], Step [67/375], Loss: 2.1894, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [68/375], Loss: 2.1291, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [69/375], Loss: 2.1743, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [70/375], Loss: 2.2539, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [11/50], Step [71/375], Loss: 2.2389, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [72/375], Loss: 2.2799, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [73/375], Loss: 2.3671, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [74/375], Loss: 2.0058, batch time: 0.26, accuracy:  50.00%\n",
      "Epoch [11/50], Step [75/375], Loss: 2.2616, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [76/375], Loss: 2.3363, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [77/375], Loss: 2.3019, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [78/375], Loss: 2.3386, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [11/50], Step [79/375], Loss: 2.2491, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [80/375], Loss: 2.3342, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [81/375], Loss: 2.0739, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [82/375], Loss: 2.1372, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [11/50], Step [83/375], Loss: 2.1569, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [84/375], Loss: 2.1771, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [85/375], Loss: 2.2374, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [86/375], Loss: 2.1277, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [11/50], Step [87/375], Loss: 2.4419, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [88/375], Loss: 2.3124, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [89/375], Loss: 2.2010, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [90/375], Loss: 2.2590, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [91/375], Loss: 2.1098, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [92/375], Loss: 2.2047, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [93/375], Loss: 2.2166, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [94/375], Loss: 2.2683, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [95/375], Loss: 2.2690, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [96/375], Loss: 2.4113, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [97/375], Loss: 2.2136, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [98/375], Loss: 2.2563, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [99/375], Loss: 2.2332, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [100/375], Loss: 2.3152, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [101/375], Loss: 2.2277, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [102/375], Loss: 2.2992, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [103/375], Loss: 2.2185, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [104/375], Loss: 2.2035, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [105/375], Loss: 2.2294, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [106/375], Loss: 2.2725, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [107/375], Loss: 1.9780, batch time: 0.78, accuracy:  50.00%\n",
      "Epoch [11/50], Step [108/375], Loss: 2.1838, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [109/375], Loss: 2.2343, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [110/375], Loss: 2.0939, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [11/50], Step [111/375], Loss: 2.2974, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [112/375], Loss: 2.2988, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [113/375], Loss: 2.1116, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [11/50], Step [114/375], Loss: 2.2682, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [115/375], Loss: 2.2691, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [116/375], Loss: 2.2788, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [11/50], Step [117/375], Loss: 2.3245, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [11/50], Step [118/375], Loss: 2.1773, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [119/375], Loss: 2.2891, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [120/375], Loss: 2.1480, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [11/50], Step [121/375], Loss: 2.1429, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [122/375], Loss: 2.3411, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [123/375], Loss: 2.1242, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [124/375], Loss: 2.3587, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [11/50], Step [125/375], Loss: 2.2720, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [126/375], Loss: 2.3338, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [127/375], Loss: 2.1129, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [128/375], Loss: 2.2504, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [129/375], Loss: 2.1762, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [130/375], Loss: 2.3513, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [131/375], Loss: 2.2888, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [132/375], Loss: 2.2640, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [133/375], Loss: 2.1654, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [134/375], Loss: 2.2975, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [135/375], Loss: 2.2220, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [136/375], Loss: 2.4121, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [11/50], Step [137/375], Loss: 2.2248, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [138/375], Loss: 2.2156, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [139/375], Loss: 2.1421, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [140/375], Loss: 1.8763, batch time: 0.27, accuracy:  56.25%\n",
      "Epoch [11/50], Step [141/375], Loss: 2.4245, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [142/375], Loss: 2.1083, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [143/375], Loss: 2.1942, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [144/375], Loss: 2.2908, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [11/50], Step [145/375], Loss: 2.1424, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [146/375], Loss: 2.1948, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [147/375], Loss: 2.2339, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [148/375], Loss: 2.2702, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [149/375], Loss: 2.1416, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [150/375], Loss: 2.2062, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [151/375], Loss: 2.7088, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [152/375], Loss: 2.3706, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [153/375], Loss: 2.1607, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [154/375], Loss: 2.2651, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [155/375], Loss: 2.2115, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [156/375], Loss: 2.3357, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [157/375], Loss: 2.0899, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [158/375], Loss: 2.3631, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [159/375], Loss: 2.2385, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [160/375], Loss: 2.3783, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [161/375], Loss: 2.3529, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [162/375], Loss: 2.3000, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [163/375], Loss: 2.3052, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [164/375], Loss: 2.1605, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [165/375], Loss: 2.4208, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [11/50], Step [166/375], Loss: 2.1753, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [167/375], Loss: 2.1229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [168/375], Loss: 2.3713, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [169/375], Loss: 2.2909, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [170/375], Loss: 2.2096, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [171/375], Loss: 2.2066, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [172/375], Loss: 2.3779, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [173/375], Loss: 2.3142, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [174/375], Loss: 2.3136, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [175/375], Loss: 2.2832, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [176/375], Loss: 2.2448, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [11/50], Step [177/375], Loss: 2.1238, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [178/375], Loss: 2.2430, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [179/375], Loss: 2.2546, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [180/375], Loss: 2.3857, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [11/50], Step [181/375], Loss: 2.1407, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [182/375], Loss: 2.2788, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [183/375], Loss: 1.9847, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [11/50], Step [184/375], Loss: 2.3757, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [11/50], Step [185/375], Loss: 2.2936, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [186/375], Loss: 2.1696, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [187/375], Loss: 2.0937, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [188/375], Loss: 2.3041, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [11/50], Step [189/375], Loss: 2.2407, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [190/375], Loss: 2.3017, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [191/375], Loss: 2.1859, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [192/375], Loss: 2.4280, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [193/375], Loss: 2.0823, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [194/375], Loss: 2.2185, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [195/375], Loss: 2.3269, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [196/375], Loss: 2.2075, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [197/375], Loss: 2.4047, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [198/375], Loss: 2.1516, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [199/375], Loss: 2.3013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [200/375], Loss: 1.9497, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [201/375], Loss: 2.3040, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [202/375], Loss: 2.4558, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [203/375], Loss: 2.0781, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [204/375], Loss: 2.4364, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [205/375], Loss: 2.1651, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [206/375], Loss: 2.2821, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [207/375], Loss: 2.3166, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [208/375], Loss: 2.0712, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [11/50], Step [209/375], Loss: 2.3395, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [210/375], Loss: 2.2819, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [211/375], Loss: 2.1823, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [212/375], Loss: 2.2221, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [213/375], Loss: 2.1813, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [214/375], Loss: 2.2084, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [215/375], Loss: 2.0955, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [216/375], Loss: 2.2507, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [217/375], Loss: 2.0232, batch time: 0.78, accuracy:  31.25%\n",
      "Epoch [11/50], Step [218/375], Loss: 2.1146, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [219/375], Loss: 2.4811, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [220/375], Loss: 2.2748, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [11/50], Step [221/375], Loss: 2.2640, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [222/375], Loss: 2.2071, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [223/375], Loss: 2.2463, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [11/50], Step [224/375], Loss: 2.2124, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [225/375], Loss: 2.3744, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [226/375], Loss: 2.1467, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [11/50], Step [227/375], Loss: 2.2277, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [228/375], Loss: 2.2533, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [229/375], Loss: 2.4015, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [11/50], Step [230/375], Loss: 2.3059, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [11/50], Step [231/375], Loss: 2.2941, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [232/375], Loss: 2.2498, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [233/375], Loss: 2.1969, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [234/375], Loss: 2.3420, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [11/50], Step [235/375], Loss: 2.2401, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [236/375], Loss: 2.2218, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [237/375], Loss: 2.0869, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [238/375], Loss: 2.0456, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [11/50], Step [239/375], Loss: 2.2581, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [240/375], Loss: 2.1564, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [241/375], Loss: 2.1565, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [242/375], Loss: 2.1888, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [243/375], Loss: 2.3896, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [244/375], Loss: 1.8136, batch time: 0.24, accuracy:  62.50%\n",
      "Epoch [11/50], Step [245/375], Loss: 2.1312, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [246/375], Loss: 2.2097, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [247/375], Loss: 2.1857, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [248/375], Loss: 2.2365, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [249/375], Loss: 2.1350, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [250/375], Loss: 2.4073, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [11/50], Step [251/375], Loss: 2.0724, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [252/375], Loss: 2.1830, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [253/375], Loss: 2.3139, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [254/375], Loss: 2.2917, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [255/375], Loss: 2.0311, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [256/375], Loss: 2.0722, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [257/375], Loss: 2.2997, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [258/375], Loss: 2.2993, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [259/375], Loss: 2.1829, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [260/375], Loss: 2.0143, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [261/375], Loss: 2.3837, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [262/375], Loss: 2.4464, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [263/375], Loss: 2.0947, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [264/375], Loss: 2.5489, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [265/375], Loss: 2.2889, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [266/375], Loss: 2.1656, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [267/375], Loss: 2.2858, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [268/375], Loss: 2.2827, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [269/375], Loss: 2.1435, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [11/50], Step [270/375], Loss: 2.1814, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [271/375], Loss: 2.1501, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [272/375], Loss: 2.2794, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [273/375], Loss: 2.3698, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [274/375], Loss: 2.3376, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [275/375], Loss: 2.1673, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [276/375], Loss: 2.4685, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [11/50], Step [277/375], Loss: 2.2845, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [278/375], Loss: 2.3225, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [11/50], Step [279/375], Loss: 2.2189, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [280/375], Loss: 2.1445, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [281/375], Loss: 2.3063, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [282/375], Loss: 2.2409, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [283/375], Loss: 2.2721, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [284/375], Loss: 2.1096, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [285/375], Loss: 2.3370, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [286/375], Loss: 2.0719, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [287/375], Loss: 2.3446, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [288/375], Loss: 2.3410, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [289/375], Loss: 2.3466, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [290/375], Loss: 2.0516, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [11/50], Step [291/375], Loss: 2.2647, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [11/50], Step [292/375], Loss: 2.1703, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [293/375], Loss: 2.3229, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [294/375], Loss: 2.1710, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [295/375], Loss: 2.3088, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [296/375], Loss: 2.1202, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [297/375], Loss: 2.2251, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [298/375], Loss: 2.5335, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [11/50], Step [299/375], Loss: 2.3106, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [300/375], Loss: 2.4246, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [301/375], Loss: 2.2137, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [302/375], Loss: 2.2374, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [303/375], Loss: 2.2549, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [304/375], Loss: 2.1217, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [305/375], Loss: 2.3770, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [306/375], Loss: 2.3812, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [307/375], Loss: 2.3106, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [308/375], Loss: 2.3485, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [309/375], Loss: 2.4382, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [310/375], Loss: 2.2183, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [311/375], Loss: 2.2009, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [312/375], Loss: 2.1869, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [313/375], Loss: 2.1914, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [314/375], Loss: 2.3009, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [315/375], Loss: 2.2713, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [316/375], Loss: 2.1256, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [11/50], Step [317/375], Loss: 2.2226, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [318/375], Loss: 2.3387, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [319/375], Loss: 2.1437, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [320/375], Loss: 2.1510, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [321/375], Loss: 2.1630, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [322/375], Loss: 2.3235, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [323/375], Loss: 2.4034, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [324/375], Loss: 2.3371, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [325/375], Loss: 2.2824, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [326/375], Loss: 2.2666, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [327/375], Loss: 2.1947, batch time: 0.79, accuracy:  25.00%\n",
      "Epoch [11/50], Step [328/375], Loss: 2.2630, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [329/375], Loss: 2.2101, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [330/375], Loss: 2.3175, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [11/50], Step [331/375], Loss: 2.1232, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [11/50], Step [332/375], Loss: 2.3205, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [333/375], Loss: 2.2543, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [11/50], Step [334/375], Loss: 2.1675, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [335/375], Loss: 2.3178, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [336/375], Loss: 2.3674, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [11/50], Step [337/375], Loss: 2.2480, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [338/375], Loss: 2.1868, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [339/375], Loss: 2.1991, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [340/375], Loss: 2.1755, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [11/50], Step [341/375], Loss: 2.1518, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [11/50], Step [342/375], Loss: 2.3643, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [11/50], Step [343/375], Loss: 2.2145, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [344/375], Loss: 2.1589, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [11/50], Step [345/375], Loss: 2.2730, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [11/50], Step [346/375], Loss: 2.1804, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [347/375], Loss: 2.2619, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [348/375], Loss: 2.2155, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [349/375], Loss: 2.1803, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [11/50], Step [350/375], Loss: 2.4434, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [11/50], Step [351/375], Loss: 2.0220, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [352/375], Loss: 2.1748, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [353/375], Loss: 2.3559, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [354/375], Loss: 2.3742, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [11/50], Step [355/375], Loss: 2.2753, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [11/50], Step [356/375], Loss: 2.2681, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [11/50], Step [357/375], Loss: 2.0700, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [11/50], Step [358/375], Loss: 2.2687, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [359/375], Loss: 2.3269, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [360/375], Loss: 2.3512, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [11/50], Step [361/375], Loss: 2.1439, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [362/375], Loss: 2.1456, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [363/375], Loss: 2.2178, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [364/375], Loss: 2.3403, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [11/50], Step [365/375], Loss: 2.0489, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [366/375], Loss: 2.1718, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [11/50], Step [367/375], Loss: 2.3012, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [368/375], Loss: 2.0549, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [11/50], Step [369/375], Loss: 2.3015, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [370/375], Loss: 2.4224, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [11/50], Step [371/375], Loss: 2.1519, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [11/50], Step [372/375], Loss: 2.2004, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [11/50], Step [373/375], Loss: 2.1775, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [11/50], Step [374/375], Loss: 2.2769, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [11/50], Step [375/375], Loss: 2.2151, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [1/375], Loss: 2.3091, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [2/375], Loss: 2.1339, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [3/375], Loss: 2.1484, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [4/375], Loss: 2.3883, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [5/375], Loss: 2.3738, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [6/375], Loss: 2.3288, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [7/375], Loss: 2.4971, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [12/50], Step [8/375], Loss: 2.2994, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [9/375], Loss: 2.2193, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [10/375], Loss: 2.3332, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [11/375], Loss: 2.2336, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [12/375], Loss: 2.3651, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [13/375], Loss: 2.1430, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [14/375], Loss: 2.2221, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [15/375], Loss: 2.3421, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [16/375], Loss: 2.3631, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [17/375], Loss: 2.1491, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [18/375], Loss: 2.3046, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [19/375], Loss: 2.2166, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [20/375], Loss: 2.1728, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [21/375], Loss: 2.2384, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [22/375], Loss: 2.2299, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [23/375], Loss: 2.3383, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [24/375], Loss: 2.3740, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [25/375], Loss: 2.5460, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [26/375], Loss: 2.3374, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [27/375], Loss: 2.2661, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [28/375], Loss: 2.2717, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [29/375], Loss: 2.2581, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [30/375], Loss: 2.3534, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [31/375], Loss: 2.3352, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [32/375], Loss: 2.2212, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [33/375], Loss: 2.1985, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [34/375], Loss: 2.3049, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [35/375], Loss: 2.1862, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [36/375], Loss: 2.3476, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [37/375], Loss: 2.2360, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [38/375], Loss: 2.3503, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [39/375], Loss: 2.3172, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [40/375], Loss: 2.1741, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [41/375], Loss: 2.1139, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [12/50], Step [42/375], Loss: 2.2884, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [43/375], Loss: 2.1772, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [44/375], Loss: 2.1794, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [45/375], Loss: 2.2674, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [46/375], Loss: 2.3393, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [47/375], Loss: 2.3282, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [48/375], Loss: 2.2205, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [49/375], Loss: 2.2771, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [12/50], Step [50/375], Loss: 2.1681, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [51/375], Loss: 2.2714, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [52/375], Loss: 1.9728, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [12/50], Step [53/375], Loss: 2.2999, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [54/375], Loss: 2.1671, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [55/375], Loss: 2.2156, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [56/375], Loss: 2.2829, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [57/375], Loss: 2.0333, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [58/375], Loss: 2.4177, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [59/375], Loss: 1.9916, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [12/50], Step [60/375], Loss: 2.0320, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [12/50], Step [61/375], Loss: 2.2057, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [62/375], Loss: 2.2247, batch time: 0.92, accuracy:  31.25%\n",
      "Epoch [12/50], Step [63/375], Loss: 1.9157, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [12/50], Step [64/375], Loss: 2.2672, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [65/375], Loss: 2.1675, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [12/50], Step [66/375], Loss: 2.0648, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [67/375], Loss: 2.1715, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [68/375], Loss: 2.2370, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [12/50], Step [69/375], Loss: 2.0217, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [12/50], Step [70/375], Loss: 2.1122, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [71/375], Loss: 2.3760, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [12/50], Step [72/375], Loss: 2.2807, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [73/375], Loss: 2.1814, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [74/375], Loss: 2.3711, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [75/375], Loss: 2.1695, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [76/375], Loss: 1.6635, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [12/50], Step [77/375], Loss: 2.3689, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [78/375], Loss: 2.2266, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [79/375], Loss: 2.5047, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [12/50], Step [80/375], Loss: 2.4344, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [81/375], Loss: 2.4129, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [82/375], Loss: 2.1958, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [83/375], Loss: 2.2889, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [12/50], Step [84/375], Loss: 2.2178, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [85/375], Loss: 2.3801, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [86/375], Loss: 2.1781, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [87/375], Loss: 2.2556, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [12/50], Step [88/375], Loss: 2.3315, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [89/375], Loss: 2.2915, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [90/375], Loss: 2.4041, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [91/375], Loss: 2.3978, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [92/375], Loss: 2.2824, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [93/375], Loss: 2.2529, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [94/375], Loss: 2.1688, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [95/375], Loss: 2.2569, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [96/375], Loss: 2.3010, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [97/375], Loss: 2.2957, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [98/375], Loss: 2.2501, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [99/375], Loss: 2.0703, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [100/375], Loss: 2.0669, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [101/375], Loss: 2.3377, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [102/375], Loss: 2.1882, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [103/375], Loss: 2.2610, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [104/375], Loss: 2.2839, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [105/375], Loss: 2.2018, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [106/375], Loss: 2.3139, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [107/375], Loss: 2.1756, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [12/50], Step [108/375], Loss: 2.2374, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [109/375], Loss: 2.1808, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [110/375], Loss: 2.1580, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [111/375], Loss: 2.1513, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [12/50], Step [112/375], Loss: 2.2940, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [113/375], Loss: 2.2558, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [114/375], Loss: 2.2901, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [115/375], Loss: 2.4240, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [12/50], Step [116/375], Loss: 2.1578, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [117/375], Loss: 2.4117, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [12/50], Step [118/375], Loss: 2.1263, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [12/50], Step [119/375], Loss: 2.2657, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [12/50], Step [120/375], Loss: 2.2229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [121/375], Loss: 2.1954, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [122/375], Loss: 2.4104, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [123/375], Loss: 2.2102, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [124/375], Loss: 2.2729, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [125/375], Loss: 2.4037, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [126/375], Loss: 2.1310, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [127/375], Loss: 2.4213, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [128/375], Loss: 2.3388, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [129/375], Loss: 2.1898, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [130/375], Loss: 2.5403, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [131/375], Loss: 2.1370, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [132/375], Loss: 2.1789, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [133/375], Loss: 2.2223, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [134/375], Loss: 2.0800, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [135/375], Loss: 2.1864, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [12/50], Step [136/375], Loss: 2.1507, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [137/375], Loss: 2.2270, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [138/375], Loss: 2.0992, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [139/375], Loss: 2.2591, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [140/375], Loss: 2.1278, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [12/50], Step [141/375], Loss: 2.3092, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [142/375], Loss: 2.1865, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [143/375], Loss: 2.3087, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [144/375], Loss: 2.5029, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [12/50], Step [145/375], Loss: 2.3218, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [146/375], Loss: 2.4397, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [147/375], Loss: 2.3832, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [12/50], Step [148/375], Loss: 2.2096, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [149/375], Loss: 2.1145, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [150/375], Loss: 2.1587, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [151/375], Loss: 2.1427, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [152/375], Loss: 2.1363, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [153/375], Loss: 2.2581, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [154/375], Loss: 2.2734, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [155/375], Loss: 2.4402, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [12/50], Step [156/375], Loss: 2.3588, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [157/375], Loss: 2.2195, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [158/375], Loss: 1.9927, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [159/375], Loss: 2.2289, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [160/375], Loss: 2.2286, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [161/375], Loss: 2.1546, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [162/375], Loss: 2.2901, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [163/375], Loss: 2.2649, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [164/375], Loss: 2.0970, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [165/375], Loss: 2.3074, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [166/375], Loss: 2.2941, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [167/375], Loss: 2.2445, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [168/375], Loss: 2.2292, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [169/375], Loss: 2.1575, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [170/375], Loss: 2.0931, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [171/375], Loss: 2.1875, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [12/50], Step [172/375], Loss: 2.4134, batch time: 0.79, accuracy:  18.75%\n",
      "Epoch [12/50], Step [173/375], Loss: 2.1325, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [174/375], Loss: 2.2856, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [175/375], Loss: 2.4070, batch time: 0.29, accuracy:  0.00%\n",
      "Epoch [12/50], Step [176/375], Loss: 2.1260, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [177/375], Loss: 2.2462, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [178/375], Loss: 1.9989, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [12/50], Step [179/375], Loss: 2.4718, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [180/375], Loss: 2.3205, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [181/375], Loss: 2.3824, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [12/50], Step [182/375], Loss: 2.1124, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [183/375], Loss: 2.2933, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [184/375], Loss: 2.1072, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [185/375], Loss: 2.0841, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [12/50], Step [186/375], Loss: 2.1528, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [187/375], Loss: 2.1059, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [188/375], Loss: 2.5232, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [189/375], Loss: 2.2244, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [12/50], Step [190/375], Loss: 2.0424, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [12/50], Step [191/375], Loss: 2.2621, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [192/375], Loss: 2.0980, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [193/375], Loss: 2.3608, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [12/50], Step [194/375], Loss: 2.3147, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [195/375], Loss: 2.2811, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [196/375], Loss: 2.3870, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [197/375], Loss: 2.4560, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [198/375], Loss: 2.1024, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [199/375], Loss: 2.2116, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [200/375], Loss: 2.3196, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [201/375], Loss: 2.2418, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [202/375], Loss: 2.1476, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [203/375], Loss: 2.2533, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [204/375], Loss: 2.1072, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [205/375], Loss: 2.0699, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [206/375], Loss: 2.5469, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [12/50], Step [207/375], Loss: 2.3143, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [12/50], Step [208/375], Loss: 2.5114, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [209/375], Loss: 2.3420, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [210/375], Loss: 2.6972, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [211/375], Loss: 2.1076, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [212/375], Loss: 2.2415, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [213/375], Loss: 2.1881, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [214/375], Loss: 2.1413, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [215/375], Loss: 2.2417, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [216/375], Loss: 2.4411, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [217/375], Loss: 2.2254, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [218/375], Loss: 2.3034, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [219/375], Loss: 2.1882, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [220/375], Loss: 2.3503, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [221/375], Loss: 2.1219, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [222/375], Loss: 2.2645, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [223/375], Loss: 2.2927, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [224/375], Loss: 2.1819, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [225/375], Loss: 2.3515, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [226/375], Loss: 2.3140, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [227/375], Loss: 2.3530, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [228/375], Loss: 2.3121, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [229/375], Loss: 2.2028, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [230/375], Loss: 2.1996, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [231/375], Loss: 2.3195, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [232/375], Loss: 2.3339, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [233/375], Loss: 2.4287, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [12/50], Step [234/375], Loss: 2.2465, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [235/375], Loss: 2.3174, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [236/375], Loss: 2.2056, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [237/375], Loss: 2.3027, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [238/375], Loss: 2.2790, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [239/375], Loss: 2.1701, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [240/375], Loss: 2.2775, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [241/375], Loss: 2.3845, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [12/50], Step [242/375], Loss: 2.1870, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [243/375], Loss: 2.1747, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [244/375], Loss: 2.1804, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [245/375], Loss: 2.2853, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [12/50], Step [246/375], Loss: 2.1368, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [247/375], Loss: 2.2317, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [248/375], Loss: 2.1949, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [249/375], Loss: 2.2597, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [250/375], Loss: 2.1844, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [12/50], Step [251/375], Loss: 2.1815, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [252/375], Loss: 2.4155, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [253/375], Loss: 2.2721, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [12/50], Step [254/375], Loss: 2.3804, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [255/375], Loss: 2.2563, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [256/375], Loss: 2.2578, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [12/50], Step [257/375], Loss: 2.2577, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [258/375], Loss: 2.2953, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [259/375], Loss: 2.2616, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [260/375], Loss: 2.1502, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [261/375], Loss: 2.3653, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [12/50], Step [262/375], Loss: 2.2447, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [263/375], Loss: 2.3551, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [264/375], Loss: 2.3703, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [265/375], Loss: 2.2000, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [266/375], Loss: 2.1891, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [267/375], Loss: 2.3714, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [268/375], Loss: 2.3094, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [269/375], Loss: 2.2319, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [270/375], Loss: 2.1307, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [271/375], Loss: 2.3209, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [272/375], Loss: 2.0272, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [273/375], Loss: 2.1523, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [274/375], Loss: 2.0754, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [275/375], Loss: 2.2844, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [12/50], Step [276/375], Loss: 2.1793, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [277/375], Loss: 2.1969, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [12/50], Step [278/375], Loss: 2.1573, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [279/375], Loss: 2.4455, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [12/50], Step [280/375], Loss: 2.1481, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [12/50], Step [281/375], Loss: 2.2260, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [282/375], Loss: 2.2979, batch time: 1.06, accuracy:  18.75%\n",
      "Epoch [12/50], Step [283/375], Loss: 2.1292, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [284/375], Loss: 2.1665, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [285/375], Loss: 2.0878, batch time: 0.39, accuracy:  31.25%\n",
      "Epoch [12/50], Step [286/375], Loss: 2.2707, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [12/50], Step [287/375], Loss: 2.2722, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [288/375], Loss: 2.2836, batch time: 0.39, accuracy:  18.75%\n",
      "Epoch [12/50], Step [289/375], Loss: 2.2270, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [12/50], Step [290/375], Loss: 2.1106, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [291/375], Loss: 2.2598, batch time: 0.39, accuracy:  25.00%\n",
      "Epoch [12/50], Step [292/375], Loss: 2.2296, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [293/375], Loss: 2.2383, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [294/375], Loss: 2.3776, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [12/50], Step [295/375], Loss: 2.1970, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [296/375], Loss: 2.2343, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [297/375], Loss: 2.0654, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [12/50], Step [298/375], Loss: 2.3904, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [12/50], Step [299/375], Loss: 2.2063, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [300/375], Loss: 2.4548, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [12/50], Step [301/375], Loss: 2.5568, batch time: 0.35, accuracy:  0.00%\n",
      "Epoch [12/50], Step [302/375], Loss: 2.1059, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [303/375], Loss: 2.3095, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [12/50], Step [304/375], Loss: 2.2437, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [12/50], Step [305/375], Loss: 2.3617, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [306/375], Loss: 2.1669, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [12/50], Step [307/375], Loss: 2.3848, batch time: 0.37, accuracy:  6.25%\n",
      "Epoch [12/50], Step [308/375], Loss: 2.0656, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [12/50], Step [309/375], Loss: 2.2437, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [310/375], Loss: 2.0855, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [12/50], Step [311/375], Loss: 2.2580, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [312/375], Loss: 2.2057, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [12/50], Step [313/375], Loss: 2.1206, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [314/375], Loss: 2.3226, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [12/50], Step [315/375], Loss: 2.0980, batch time: 0.37, accuracy:  37.50%\n",
      "Epoch [12/50], Step [316/375], Loss: 2.2941, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [12/50], Step [317/375], Loss: 2.2337, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [12/50], Step [318/375], Loss: 2.1088, batch time: 0.35, accuracy:  43.75%\n",
      "Epoch [12/50], Step [319/375], Loss: 2.2608, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [320/375], Loss: 2.3153, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [12/50], Step [321/375], Loss: 2.2631, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [12/50], Step [322/375], Loss: 2.3261, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [12/50], Step [323/375], Loss: 2.2227, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [12/50], Step [324/375], Loss: 2.1223, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [325/375], Loss: 2.3937, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [326/375], Loss: 2.1743, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [12/50], Step [327/375], Loss: 2.2571, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [12/50], Step [328/375], Loss: 2.3704, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [12/50], Step [329/375], Loss: 2.2549, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [12/50], Step [330/375], Loss: 2.1942, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [12/50], Step [331/375], Loss: 2.1893, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [12/50], Step [332/375], Loss: 2.2671, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [12/50], Step [333/375], Loss: 1.9466, batch time: 0.34, accuracy:  43.75%\n",
      "Epoch [12/50], Step [334/375], Loss: 2.2239, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [12/50], Step [335/375], Loss: 2.3523, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [12/50], Step [336/375], Loss: 2.2501, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [12/50], Step [337/375], Loss: 2.3366, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [12/50], Step [338/375], Loss: 2.3635, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [12/50], Step [339/375], Loss: 2.2305, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [12/50], Step [340/375], Loss: 2.2015, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [12/50], Step [341/375], Loss: 2.1914, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [12/50], Step [342/375], Loss: 2.0306, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [12/50], Step [343/375], Loss: 2.1659, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [12/50], Step [344/375], Loss: 2.2117, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [345/375], Loss: 2.1457, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [346/375], Loss: 2.1132, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [12/50], Step [347/375], Loss: 2.5233, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [12/50], Step [348/375], Loss: 2.3696, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [12/50], Step [349/375], Loss: 2.2859, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [350/375], Loss: 2.2932, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [351/375], Loss: 2.1893, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [352/375], Loss: 2.2008, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [353/375], Loss: 2.3244, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [354/375], Loss: 2.3054, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [355/375], Loss: 2.2547, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [12/50], Step [356/375], Loss: 2.3487, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [12/50], Step [357/375], Loss: 2.0767, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [358/375], Loss: 2.2744, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [359/375], Loss: 2.1012, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [12/50], Step [360/375], Loss: 2.2927, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [361/375], Loss: 2.1779, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [362/375], Loss: 2.2254, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [363/375], Loss: 2.1031, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [12/50], Step [364/375], Loss: 2.2180, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [365/375], Loss: 2.4037, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [12/50], Step [366/375], Loss: 2.1304, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [12/50], Step [367/375], Loss: 2.0924, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [12/50], Step [368/375], Loss: 2.0360, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [12/50], Step [369/375], Loss: 2.3720, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [12/50], Step [370/375], Loss: 2.4521, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [12/50], Step [371/375], Loss: 2.2339, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [12/50], Step [372/375], Loss: 2.3599, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [12/50], Step [373/375], Loss: 2.1824, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [374/375], Loss: 2.0907, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [12/50], Step [375/375], Loss: 2.3164, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [1/375], Loss: 2.2726, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [2/375], Loss: 2.1652, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [3/375], Loss: 2.4617, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [4/375], Loss: 2.1925, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [5/375], Loss: 2.0975, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [6/375], Loss: 2.1435, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [13/50], Step [7/375], Loss: 2.3604, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [8/375], Loss: 2.2512, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [9/375], Loss: 2.2531, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [10/375], Loss: 2.2945, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [11/375], Loss: 2.0890, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [12/375], Loss: 1.9932, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [13/50], Step [13/375], Loss: 2.0911, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [14/375], Loss: 2.3508, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [15/375], Loss: 2.1568, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [16/375], Loss: 2.0051, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [13/50], Step [17/375], Loss: 2.2520, batch time: 0.80, accuracy:  12.50%\n",
      "Epoch [13/50], Step [18/375], Loss: 2.3272, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [19/375], Loss: 1.9714, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [20/375], Loss: 2.1725, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [13/50], Step [21/375], Loss: 2.0050, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [13/50], Step [22/375], Loss: 2.3095, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [23/375], Loss: 2.0916, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [13/50], Step [24/375], Loss: 2.3692, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [25/375], Loss: 2.3251, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [26/375], Loss: 2.0743, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [13/50], Step [27/375], Loss: 2.5011, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [28/375], Loss: 2.3033, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [29/375], Loss: 1.9638, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [13/50], Step [30/375], Loss: 2.2679, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [13/50], Step [31/375], Loss: 2.0494, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [32/375], Loss: 2.4512, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [13/50], Step [33/375], Loss: 2.2995, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [34/375], Loss: 2.2892, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [13/50], Step [35/375], Loss: 2.4094, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [36/375], Loss: 2.3103, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [37/375], Loss: 1.9271, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [13/50], Step [38/375], Loss: 2.2473, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [13/50], Step [39/375], Loss: 2.2635, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [40/375], Loss: 2.0841, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [41/375], Loss: 2.3121, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [42/375], Loss: 2.1775, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [43/375], Loss: 2.2575, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [44/375], Loss: 2.2925, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [45/375], Loss: 2.3533, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [46/375], Loss: 2.3069, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [47/375], Loss: 2.3490, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [48/375], Loss: 2.4033, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [49/375], Loss: 2.1913, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [50/375], Loss: 2.2411, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [51/375], Loss: 2.2099, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [52/375], Loss: 2.3638, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [53/375], Loss: 2.0060, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [13/50], Step [54/375], Loss: 2.1922, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [13/50], Step [55/375], Loss: 2.4664, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [56/375], Loss: 2.2956, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [57/375], Loss: 2.2459, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [58/375], Loss: 2.2460, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [13/50], Step [59/375], Loss: 2.2820, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [60/375], Loss: 2.2945, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [61/375], Loss: 2.3772, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [62/375], Loss: 2.2509, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [63/375], Loss: 2.3708, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [64/375], Loss: 2.1383, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [65/375], Loss: 2.2588, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [66/375], Loss: 2.2351, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [67/375], Loss: 2.2217, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [68/375], Loss: 2.2363, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [69/375], Loss: 2.2530, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [70/375], Loss: 2.2837, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [13/50], Step [71/375], Loss: 2.1696, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [72/375], Loss: 2.3171, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [73/375], Loss: 2.3073, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [74/375], Loss: 2.1410, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [75/375], Loss: 2.2017, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [76/375], Loss: 2.3248, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [77/375], Loss: 2.1788, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [13/50], Step [78/375], Loss: 2.3156, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [79/375], Loss: 2.2363, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [80/375], Loss: 2.3253, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [81/375], Loss: 2.1443, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [82/375], Loss: 2.3648, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [83/375], Loss: 2.2041, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [84/375], Loss: 2.3100, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [85/375], Loss: 2.1198, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [86/375], Loss: 2.3003, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [87/375], Loss: 2.0521, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [88/375], Loss: 2.0842, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [89/375], Loss: 2.4875, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [90/375], Loss: 2.0277, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [91/375], Loss: 2.5398, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [92/375], Loss: 2.5508, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [93/375], Loss: 2.2573, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [94/375], Loss: 2.3209, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [95/375], Loss: 2.2752, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [96/375], Loss: 2.0235, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [97/375], Loss: 2.2267, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [98/375], Loss: 2.2695, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [99/375], Loss: 2.2910, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [100/375], Loss: 2.0364, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [13/50], Step [101/375], Loss: 2.4463, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [102/375], Loss: 2.3909, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [13/50], Step [103/375], Loss: 2.1968, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [104/375], Loss: 2.3100, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [105/375], Loss: 2.2604, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [106/375], Loss: 2.1997, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [107/375], Loss: 2.2413, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [108/375], Loss: 2.2578, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [109/375], Loss: 2.3876, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [110/375], Loss: 2.1019, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [13/50], Step [111/375], Loss: 2.2630, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [112/375], Loss: 2.1941, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [113/375], Loss: 2.2571, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [114/375], Loss: 2.3384, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [13/50], Step [115/375], Loss: 2.2292, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [116/375], Loss: 2.2707, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [117/375], Loss: 2.0779, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [118/375], Loss: 2.4711, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [13/50], Step [119/375], Loss: 2.4034, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [120/375], Loss: 2.4536, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [121/375], Loss: 2.2197, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [122/375], Loss: 2.2779, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [123/375], Loss: 2.3957, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [124/375], Loss: 2.1889, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [125/375], Loss: 2.1609, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [126/375], Loss: 2.2335, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [127/375], Loss: 2.1445, batch time: 0.79, accuracy:  25.00%\n",
      "Epoch [13/50], Step [128/375], Loss: 2.3065, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [129/375], Loss: 2.3123, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [13/50], Step [130/375], Loss: 2.1094, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [13/50], Step [131/375], Loss: 2.2434, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [132/375], Loss: 2.2484, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [133/375], Loss: 2.3077, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [13/50], Step [134/375], Loss: 2.3178, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [135/375], Loss: 2.2227, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [136/375], Loss: 2.2480, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [13/50], Step [137/375], Loss: 2.3203, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [138/375], Loss: 2.1619, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [139/375], Loss: 2.1972, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [140/375], Loss: 2.2305, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [141/375], Loss: 2.1968, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [142/375], Loss: 2.1712, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [143/375], Loss: 2.3996, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [144/375], Loss: 2.1780, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [145/375], Loss: 2.3650, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [146/375], Loss: 2.3809, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [147/375], Loss: 2.1636, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [148/375], Loss: 2.2801, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [149/375], Loss: 2.3115, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [150/375], Loss: 2.1853, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [151/375], Loss: 2.3633, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [152/375], Loss: 2.1461, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [13/50], Step [153/375], Loss: 2.3205, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [154/375], Loss: 2.4022, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [155/375], Loss: 2.3702, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [156/375], Loss: 2.2470, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [13/50], Step [157/375], Loss: 2.1679, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [13/50], Step [158/375], Loss: 2.3033, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [159/375], Loss: 2.2179, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [160/375], Loss: 2.2127, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [161/375], Loss: 1.9890, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [162/375], Loss: 2.1356, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [163/375], Loss: 2.3009, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [164/375], Loss: 2.3777, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [165/375], Loss: 2.1593, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [166/375], Loss: 2.2494, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [167/375], Loss: 2.1994, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [168/375], Loss: 2.4549, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [169/375], Loss: 2.1702, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [170/375], Loss: 2.3082, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [171/375], Loss: 2.2586, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [172/375], Loss: 2.2213, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [173/375], Loss: 2.2396, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [174/375], Loss: 2.1210, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [175/375], Loss: 2.0179, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [176/375], Loss: 2.1946, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [177/375], Loss: 2.2332, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [178/375], Loss: 2.5097, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [179/375], Loss: 2.3448, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [180/375], Loss: 2.2974, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [181/375], Loss: 2.2819, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [182/375], Loss: 2.4208, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [183/375], Loss: 2.1425, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [184/375], Loss: 2.2772, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [185/375], Loss: 2.2268, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [186/375], Loss: 2.4335, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [187/375], Loss: 2.3392, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [188/375], Loss: 2.2106, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [189/375], Loss: 2.1692, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [190/375], Loss: 2.1435, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [13/50], Step [191/375], Loss: 2.1905, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [192/375], Loss: 2.1552, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [13/50], Step [193/375], Loss: 2.1885, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [194/375], Loss: 2.0828, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [195/375], Loss: 2.1757, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [196/375], Loss: 2.2164, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [13/50], Step [197/375], Loss: 2.0102, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [13/50], Step [198/375], Loss: 2.3301, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [199/375], Loss: 2.2205, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [200/375], Loss: 2.2140, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [201/375], Loss: 2.4550, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [202/375], Loss: 2.2098, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [203/375], Loss: 2.2403, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [204/375], Loss: 2.0541, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [13/50], Step [205/375], Loss: 2.2117, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [206/375], Loss: 2.0235, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [13/50], Step [207/375], Loss: 2.3240, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [208/375], Loss: 2.2624, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [209/375], Loss: 2.3667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [210/375], Loss: 2.1953, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [211/375], Loss: 2.2142, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [212/375], Loss: 2.2567, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [213/375], Loss: 2.4408, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [214/375], Loss: 2.2753, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [215/375], Loss: 2.1751, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [216/375], Loss: 2.2583, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [217/375], Loss: 2.1479, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [218/375], Loss: 2.3405, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [219/375], Loss: 2.3208, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [220/375], Loss: 2.4430, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [221/375], Loss: 2.2372, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [222/375], Loss: 2.3134, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [223/375], Loss: 2.2676, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [224/375], Loss: 2.1509, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [225/375], Loss: 2.2624, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [226/375], Loss: 2.1924, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [227/375], Loss: 2.4390, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [228/375], Loss: 2.2462, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [229/375], Loss: 2.3015, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [230/375], Loss: 2.1189, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [231/375], Loss: 2.2374, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [232/375], Loss: 2.2312, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [233/375], Loss: 2.1140, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [234/375], Loss: 2.1818, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [235/375], Loss: 2.2788, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [236/375], Loss: 1.9017, batch time: 0.26, accuracy:  56.25%\n",
      "Epoch [13/50], Step [237/375], Loss: 2.2765, batch time: 0.92, accuracy:  25.00%\n",
      "Epoch [13/50], Step [238/375], Loss: 2.2133, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [239/375], Loss: 2.2306, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [240/375], Loss: 2.4133, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [13/50], Step [241/375], Loss: 2.1371, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [13/50], Step [242/375], Loss: 2.1948, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [243/375], Loss: 1.9347, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [13/50], Step [244/375], Loss: 2.2320, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [245/375], Loss: 2.4718, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [246/375], Loss: 2.2917, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [13/50], Step [247/375], Loss: 2.2346, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [248/375], Loss: 2.2816, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [249/375], Loss: 2.2904, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [250/375], Loss: 2.4293, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [13/50], Step [251/375], Loss: 2.1694, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [252/375], Loss: 2.1436, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [253/375], Loss: 2.3842, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [254/375], Loss: 2.0378, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [13/50], Step [255/375], Loss: 2.2169, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [256/375], Loss: 1.9232, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [257/375], Loss: 2.2345, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [258/375], Loss: 2.1939, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [259/375], Loss: 2.2609, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [260/375], Loss: 2.2765, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [261/375], Loss: 2.2133, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [13/50], Step [262/375], Loss: 2.2888, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [13/50], Step [263/375], Loss: 2.2829, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [13/50], Step [264/375], Loss: 2.2708, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [265/375], Loss: 2.1418, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [266/375], Loss: 2.2432, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [13/50], Step [267/375], Loss: 2.2764, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [268/375], Loss: 2.3498, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [269/375], Loss: 2.2461, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [270/375], Loss: 1.9213, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [13/50], Step [271/375], Loss: 2.2238, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [272/375], Loss: 2.2118, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [13/50], Step [273/375], Loss: 1.9762, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [274/375], Loss: 2.2036, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [275/375], Loss: 2.2837, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [276/375], Loss: 2.2337, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [277/375], Loss: 2.3374, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [278/375], Loss: 2.4022, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [13/50], Step [279/375], Loss: 2.4940, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [280/375], Loss: 2.3096, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [13/50], Step [281/375], Loss: 2.2622, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [282/375], Loss: 2.1038, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [13/50], Step [283/375], Loss: 2.3178, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [284/375], Loss: 2.2097, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [285/375], Loss: 2.2945, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [286/375], Loss: 2.2255, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [287/375], Loss: 2.3105, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [288/375], Loss: 2.1329, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [289/375], Loss: 2.2162, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [290/375], Loss: 2.3162, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [291/375], Loss: 2.0326, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [13/50], Step [292/375], Loss: 2.2902, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [293/375], Loss: 2.1275, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [294/375], Loss: 2.4231, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [295/375], Loss: 2.2959, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [296/375], Loss: 2.2427, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [297/375], Loss: 2.0585, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [298/375], Loss: 2.1437, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [299/375], Loss: 2.4639, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [300/375], Loss: 2.2580, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [301/375], Loss: 2.1338, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [302/375], Loss: 2.3612, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [303/375], Loss: 2.2244, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [304/375], Loss: 2.2806, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [305/375], Loss: 2.4206, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [306/375], Loss: 2.1956, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [307/375], Loss: 2.2181, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [308/375], Loss: 2.2663, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [309/375], Loss: 2.4358, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [13/50], Step [310/375], Loss: 2.0444, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [311/375], Loss: 2.0547, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [312/375], Loss: 2.3203, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [313/375], Loss: 2.3171, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [314/375], Loss: 2.3373, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [13/50], Step [315/375], Loss: 2.2490, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [316/375], Loss: 2.3581, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [317/375], Loss: 2.1696, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [318/375], Loss: 2.3484, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [13/50], Step [319/375], Loss: 2.3347, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [320/375], Loss: 2.1232, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [321/375], Loss: 2.1696, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [322/375], Loss: 2.3136, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [13/50], Step [323/375], Loss: 2.2083, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [324/375], Loss: 2.3723, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [325/375], Loss: 2.2771, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [326/375], Loss: 2.2666, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [13/50], Step [327/375], Loss: 2.3598, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [328/375], Loss: 2.2775, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [329/375], Loss: 2.2756, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [330/375], Loss: 2.2987, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [331/375], Loss: 2.1369, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [332/375], Loss: 2.1326, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [333/375], Loss: 2.3170, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [334/375], Loss: 2.1135, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [335/375], Loss: 2.1261, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [336/375], Loss: 2.2361, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [337/375], Loss: 2.0892, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [338/375], Loss: 2.0823, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [339/375], Loss: 2.2496, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [340/375], Loss: 2.2164, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [341/375], Loss: 2.2682, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [342/375], Loss: 2.4254, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [13/50], Step [343/375], Loss: 2.4161, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [344/375], Loss: 2.2020, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [345/375], Loss: 2.2466, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [13/50], Step [346/375], Loss: 2.1247, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [13/50], Step [347/375], Loss: 2.0959, batch time: 0.80, accuracy:  25.00%\n",
      "Epoch [13/50], Step [348/375], Loss: 2.3014, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [349/375], Loss: 2.3141, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [350/375], Loss: 2.4013, batch time: 0.29, accuracy:  0.00%\n",
      "Epoch [13/50], Step [351/375], Loss: 2.3357, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [352/375], Loss: 2.1641, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [353/375], Loss: 2.2254, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [13/50], Step [354/375], Loss: 2.2730, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [13/50], Step [355/375], Loss: 2.3681, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [356/375], Loss: 2.2904, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [13/50], Step [357/375], Loss: 2.3448, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [358/375], Loss: 2.0948, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [13/50], Step [359/375], Loss: 2.3412, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [360/375], Loss: 2.2254, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [13/50], Step [361/375], Loss: 2.1596, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [362/375], Loss: 2.3013, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [363/375], Loss: 2.2220, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [364/375], Loss: 2.0170, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [13/50], Step [365/375], Loss: 2.3379, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [13/50], Step [366/375], Loss: 2.2381, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [367/375], Loss: 2.1302, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [13/50], Step [368/375], Loss: 2.2986, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [13/50], Step [369/375], Loss: 2.2054, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [13/50], Step [370/375], Loss: 2.2686, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [371/375], Loss: 2.1782, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [13/50], Step [372/375], Loss: 2.1762, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [13/50], Step [373/375], Loss: 2.2728, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [13/50], Step [374/375], Loss: 2.4271, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [13/50], Step [375/375], Loss: 2.3316, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [1/375], Loss: 2.1418, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [2/375], Loss: 2.1730, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [14/50], Step [3/375], Loss: 2.2859, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [4/375], Loss: 2.1914, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [5/375], Loss: 2.3473, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [6/375], Loss: 2.3374, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [7/375], Loss: 2.3623, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [8/375], Loss: 2.3390, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [9/375], Loss: 2.2495, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [10/375], Loss: 2.3143, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [14/50], Step [11/375], Loss: 2.1357, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [12/375], Loss: 2.1270, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [14/50], Step [13/375], Loss: 2.2095, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [14/50], Step [14/375], Loss: 2.2116, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [15/375], Loss: 2.1654, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [16/375], Loss: 2.0666, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [17/375], Loss: 2.0387, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [14/50], Step [18/375], Loss: 2.2583, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [19/375], Loss: 2.1768, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [20/375], Loss: 2.1904, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [21/375], Loss: 2.2469, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [22/375], Loss: 2.1492, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [23/375], Loss: 2.2804, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [24/375], Loss: 2.3445, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [25/375], Loss: 2.3772, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [14/50], Step [26/375], Loss: 2.0274, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [27/375], Loss: 2.1413, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [28/375], Loss: 2.0948, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [29/375], Loss: 2.2475, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [14/50], Step [30/375], Loss: 1.9449, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [31/375], Loss: 2.4269, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [32/375], Loss: 2.1562, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [33/375], Loss: 2.1604, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [34/375], Loss: 2.2699, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [35/375], Loss: 2.1983, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [36/375], Loss: 2.0343, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [37/375], Loss: 2.1917, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [38/375], Loss: 2.1892, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [39/375], Loss: 2.2925, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [40/375], Loss: 2.4119, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [41/375], Loss: 2.2334, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [42/375], Loss: 2.1404, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [43/375], Loss: 2.3772, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [44/375], Loss: 2.2406, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [45/375], Loss: 2.5546, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [14/50], Step [46/375], Loss: 2.1425, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [47/375], Loss: 2.3048, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [48/375], Loss: 2.2848, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [49/375], Loss: 2.1998, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [50/375], Loss: 2.0493, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [51/375], Loss: 2.3389, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [52/375], Loss: 2.2454, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [53/375], Loss: 2.3667, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [14/50], Step [54/375], Loss: 2.1598, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [55/375], Loss: 2.0831, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [56/375], Loss: 2.3201, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [57/375], Loss: 2.1125, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [14/50], Step [58/375], Loss: 2.2654, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [59/375], Loss: 1.9622, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [60/375], Loss: 2.2779, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [61/375], Loss: 2.2585, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [62/375], Loss: 1.9604, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [63/375], Loss: 2.2376, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [64/375], Loss: 2.2478, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [65/375], Loss: 2.2407, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [66/375], Loss: 2.3032, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [67/375], Loss: 2.2462, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [68/375], Loss: 2.5131, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [69/375], Loss: 2.2761, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [70/375], Loss: 2.2750, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [71/375], Loss: 2.3265, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [72/375], Loss: 2.2629, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [73/375], Loss: 2.4990, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [74/375], Loss: 2.2069, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [75/375], Loss: 2.1834, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [76/375], Loss: 2.1914, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [77/375], Loss: 2.0616, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [14/50], Step [78/375], Loss: 2.2083, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [79/375], Loss: 2.1759, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [80/375], Loss: 2.1716, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [81/375], Loss: 2.2977, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [14/50], Step [82/375], Loss: 2.2977, batch time: 0.79, accuracy:  18.75%\n",
      "Epoch [14/50], Step [83/375], Loss: 2.3867, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [14/50], Step [84/375], Loss: 2.1602, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [14/50], Step [85/375], Loss: 2.5480, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [14/50], Step [86/375], Loss: 2.2900, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [87/375], Loss: 2.1499, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [88/375], Loss: 2.1314, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [14/50], Step [89/375], Loss: 2.2880, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [90/375], Loss: 2.3181, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [91/375], Loss: 2.1564, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [14/50], Step [92/375], Loss: 2.1799, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [93/375], Loss: 2.3002, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [14/50], Step [94/375], Loss: 2.3513, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [95/375], Loss: 2.2082, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [96/375], Loss: 2.5054, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [97/375], Loss: 2.2834, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [98/375], Loss: 2.3066, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [99/375], Loss: 2.1489, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [14/50], Step [100/375], Loss: 2.2676, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [101/375], Loss: 2.1859, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [102/375], Loss: 2.1814, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [103/375], Loss: 2.2088, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [104/375], Loss: 2.4271, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [105/375], Loss: 2.1973, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [14/50], Step [106/375], Loss: 2.3149, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [107/375], Loss: 2.1339, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [108/375], Loss: 2.1231, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [109/375], Loss: 2.0906, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [110/375], Loss: 2.2910, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [111/375], Loss: 2.2027, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [112/375], Loss: 2.2901, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [113/375], Loss: 2.2001, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [114/375], Loss: 2.2706, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [115/375], Loss: 2.2580, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [116/375], Loss: 2.1720, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [117/375], Loss: 2.2892, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [118/375], Loss: 2.0199, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [14/50], Step [119/375], Loss: 2.1926, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [120/375], Loss: 2.2636, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [121/375], Loss: 2.2229, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [122/375], Loss: 2.4817, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [123/375], Loss: 2.2919, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [124/375], Loss: 2.3896, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [125/375], Loss: 2.2350, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [126/375], Loss: 2.0107, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [127/375], Loss: 2.1998, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [128/375], Loss: 2.1497, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [129/375], Loss: 2.4110, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [130/375], Loss: 2.3654, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [131/375], Loss: 2.3092, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [132/375], Loss: 2.4201, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [133/375], Loss: 2.2228, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [134/375], Loss: 2.3657, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [135/375], Loss: 2.2116, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [136/375], Loss: 2.2270, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [137/375], Loss: 2.3305, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [138/375], Loss: 2.3063, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [139/375], Loss: 2.2095, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [140/375], Loss: 2.3528, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [141/375], Loss: 2.3278, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [142/375], Loss: 2.1762, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [143/375], Loss: 2.3315, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [144/375], Loss: 2.4120, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [145/375], Loss: 2.3320, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [146/375], Loss: 2.2032, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [147/375], Loss: 2.2997, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [148/375], Loss: 2.1213, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [149/375], Loss: 2.3109, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [150/375], Loss: 2.2003, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [151/375], Loss: 2.3000, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [152/375], Loss: 2.2809, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [153/375], Loss: 2.3052, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [154/375], Loss: 2.2809, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [155/375], Loss: 2.1500, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [14/50], Step [156/375], Loss: 2.2713, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [157/375], Loss: 2.1728, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [158/375], Loss: 2.3642, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [159/375], Loss: 2.3376, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [160/375], Loss: 2.2481, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [161/375], Loss: 2.3264, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [162/375], Loss: 2.1731, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [163/375], Loss: 2.2256, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [164/375], Loss: 2.2211, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [165/375], Loss: 2.2468, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [166/375], Loss: 2.1177, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [167/375], Loss: 2.3009, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [168/375], Loss: 2.1017, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [169/375], Loss: 2.1122, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [170/375], Loss: 2.3336, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [171/375], Loss: 2.2688, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [172/375], Loss: 2.2622, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [173/375], Loss: 2.2347, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [174/375], Loss: 2.2304, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [175/375], Loss: 2.3426, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [14/50], Step [176/375], Loss: 2.3713, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [177/375], Loss: 2.2261, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [178/375], Loss: 2.2466, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [179/375], Loss: 2.2137, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [180/375], Loss: 1.9696, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [181/375], Loss: 2.2946, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [182/375], Loss: 2.3117, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [183/375], Loss: 2.2199, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [184/375], Loss: 2.2739, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [185/375], Loss: 2.0784, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [14/50], Step [186/375], Loss: 2.1417, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [187/375], Loss: 2.1455, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [188/375], Loss: 2.2255, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [189/375], Loss: 2.3608, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [190/375], Loss: 2.0501, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [191/375], Loss: 2.1582, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [14/50], Step [192/375], Loss: 2.4460, batch time: 0.79, accuracy:  6.25%\n",
      "Epoch [14/50], Step [193/375], Loss: 2.0819, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [194/375], Loss: 2.2036, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [195/375], Loss: 2.1529, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [14/50], Step [196/375], Loss: 2.1626, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [197/375], Loss: 2.2664, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [198/375], Loss: 2.2592, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [14/50], Step [199/375], Loss: 2.2929, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [200/375], Loss: 2.0395, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [201/375], Loss: 2.3245, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [14/50], Step [202/375], Loss: 2.1456, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [203/375], Loss: 2.2695, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [204/375], Loss: 2.1598, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [205/375], Loss: 2.2376, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [206/375], Loss: 2.3140, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [207/375], Loss: 2.1385, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [208/375], Loss: 2.3325, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [209/375], Loss: 2.3268, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [210/375], Loss: 2.2172, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [211/375], Loss: 2.0859, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [212/375], Loss: 2.2003, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [213/375], Loss: 2.2752, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [214/375], Loss: 2.1660, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [14/50], Step [215/375], Loss: 2.0684, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [216/375], Loss: 2.3719, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [217/375], Loss: 2.1358, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [14/50], Step [218/375], Loss: 2.4265, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [219/375], Loss: 2.3655, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [220/375], Loss: 2.2135, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [221/375], Loss: 2.0226, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [14/50], Step [222/375], Loss: 2.1979, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [223/375], Loss: 2.4278, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [224/375], Loss: 2.2092, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [225/375], Loss: 2.2449, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [226/375], Loss: 2.2806, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [14/50], Step [227/375], Loss: 2.1281, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [228/375], Loss: 2.3788, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [229/375], Loss: 2.1910, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [230/375], Loss: 2.3220, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [231/375], Loss: 2.3614, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [232/375], Loss: 2.3118, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [233/375], Loss: 2.3456, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [234/375], Loss: 2.2001, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [235/375], Loss: 2.3324, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [236/375], Loss: 2.0454, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [237/375], Loss: 2.3553, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [238/375], Loss: 2.2497, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [239/375], Loss: 2.2685, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [240/375], Loss: 2.1059, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [241/375], Loss: 2.3634, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [242/375], Loss: 2.2904, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [243/375], Loss: 2.1422, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [244/375], Loss: 2.1998, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [245/375], Loss: 2.1826, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [14/50], Step [246/375], Loss: 2.1770, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [247/375], Loss: 2.2540, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [248/375], Loss: 2.2165, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [249/375], Loss: 2.4679, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [14/50], Step [250/375], Loss: 2.3081, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [251/375], Loss: 2.3732, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [252/375], Loss: 2.2857, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [253/375], Loss: 2.2159, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [14/50], Step [254/375], Loss: 2.3472, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [255/375], Loss: 2.1248, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [256/375], Loss: 2.3829, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [257/375], Loss: 2.3123, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [258/375], Loss: 2.4414, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [14/50], Step [259/375], Loss: 2.4257, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [260/375], Loss: 2.0771, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [261/375], Loss: 2.2659, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [262/375], Loss: 2.1554, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [14/50], Step [263/375], Loss: 2.3407, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [14/50], Step [264/375], Loss: 2.1927, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [265/375], Loss: 2.4205, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [266/375], Loss: 2.2074, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [267/375], Loss: 2.0998, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [268/375], Loss: 2.2242, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [269/375], Loss: 2.1891, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [14/50], Step [270/375], Loss: 2.2512, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [271/375], Loss: 2.2065, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [272/375], Loss: 2.0670, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [14/50], Step [273/375], Loss: 2.3445, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [14/50], Step [274/375], Loss: 2.1611, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [14/50], Step [275/375], Loss: 2.2012, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [14/50], Step [276/375], Loss: 2.2456, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [277/375], Loss: 2.3222, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [14/50], Step [278/375], Loss: 2.2567, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [279/375], Loss: 2.2495, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [280/375], Loss: 2.2348, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [14/50], Step [281/375], Loss: 2.2631, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [14/50], Step [282/375], Loss: 2.2616, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [14/50], Step [283/375], Loss: 2.3420, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [14/50], Step [284/375], Loss: 2.1632, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [285/375], Loss: 2.1305, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [14/50], Step [286/375], Loss: 2.2278, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [14/50], Step [287/375], Loss: 2.3773, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [14/50], Step [288/375], Loss: 2.1951, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [289/375], Loss: 2.1419, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [14/50], Step [290/375], Loss: 2.4150, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [291/375], Loss: 2.2593, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [14/50], Step [292/375], Loss: 2.0080, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [293/375], Loss: 2.2170, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [14/50], Step [294/375], Loss: 2.2579, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [295/375], Loss: 2.2235, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [14/50], Step [296/375], Loss: 2.1924, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [297/375], Loss: 2.2537, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [14/50], Step [298/375], Loss: 2.3737, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [299/375], Loss: 2.2558, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [300/375], Loss: 2.2993, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [14/50], Step [301/375], Loss: 2.4006, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [14/50], Step [302/375], Loss: 2.3616, batch time: 1.07, accuracy:  12.50%\n",
      "Epoch [14/50], Step [303/375], Loss: 2.2482, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [304/375], Loss: 2.2660, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [305/375], Loss: 2.1178, batch time: 0.39, accuracy:  25.00%\n",
      "Epoch [14/50], Step [306/375], Loss: 2.3306, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [307/375], Loss: 2.3029, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [308/375], Loss: 2.0913, batch time: 0.39, accuracy:  31.25%\n",
      "Epoch [14/50], Step [309/375], Loss: 2.3591, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [310/375], Loss: 2.1943, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [311/375], Loss: 2.2116, batch time: 0.39, accuracy:  12.50%\n",
      "Epoch [14/50], Step [312/375], Loss: 2.3833, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [313/375], Loss: 2.1155, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [314/375], Loss: 2.2515, batch time: 0.36, accuracy:  25.00%\n",
      "Epoch [14/50], Step [315/375], Loss: 2.3152, batch time: 0.38, accuracy:  12.50%\n",
      "Epoch [14/50], Step [316/375], Loss: 2.2456, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [317/375], Loss: 2.1323, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [318/375], Loss: 2.0881, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [14/50], Step [319/375], Loss: 2.1699, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [14/50], Step [320/375], Loss: 2.1544, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [321/375], Loss: 2.1933, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [322/375], Loss: 2.3004, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [323/375], Loss: 2.3543, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [14/50], Step [324/375], Loss: 2.2356, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [325/375], Loss: 2.1722, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [326/375], Loss: 2.2120, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [327/375], Loss: 2.0844, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [14/50], Step [328/375], Loss: 2.2489, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [329/375], Loss: 2.3339, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [330/375], Loss: 2.3371, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [331/375], Loss: 2.4491, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [14/50], Step [332/375], Loss: 2.1993, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [333/375], Loss: 2.2104, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [334/375], Loss: 2.1229, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [335/375], Loss: 2.1860, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [14/50], Step [336/375], Loss: 2.2021, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [337/375], Loss: 2.1738, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [338/375], Loss: 2.4900, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [339/375], Loss: 2.0098, batch time: 0.37, accuracy:  37.50%\n",
      "Epoch [14/50], Step [340/375], Loss: 2.2263, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [341/375], Loss: 2.0014, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [342/375], Loss: 2.1165, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [343/375], Loss: 2.2428, batch time: 0.37, accuracy:  6.25%\n",
      "Epoch [14/50], Step [344/375], Loss: 2.1092, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [14/50], Step [345/375], Loss: 2.3304, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [346/375], Loss: 2.2138, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [347/375], Loss: 2.3606, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [14/50], Step [348/375], Loss: 2.2447, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [349/375], Loss: 2.0923, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [350/375], Loss: 2.2788, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [14/50], Step [351/375], Loss: 2.3755, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [14/50], Step [352/375], Loss: 2.1256, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [353/375], Loss: 2.0596, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [14/50], Step [354/375], Loss: 2.2173, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [355/375], Loss: 2.2976, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [14/50], Step [356/375], Loss: 2.1391, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [357/375], Loss: 2.2968, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [14/50], Step [358/375], Loss: 2.1785, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [14/50], Step [359/375], Loss: 2.4266, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [14/50], Step [360/375], Loss: 2.1784, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [361/375], Loss: 2.3319, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [14/50], Step [362/375], Loss: 2.3580, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [363/375], Loss: 2.1547, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [14/50], Step [364/375], Loss: 2.2047, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [365/375], Loss: 2.1748, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [14/50], Step [366/375], Loss: 2.1991, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [14/50], Step [367/375], Loss: 2.3776, batch time: 0.37, accuracy:  6.25%\n",
      "Epoch [14/50], Step [368/375], Loss: 2.3816, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [369/375], Loss: 2.4308, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [14/50], Step [370/375], Loss: 2.0051, batch time: 0.34, accuracy:  50.00%\n",
      "Epoch [14/50], Step [371/375], Loss: 2.2691, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [14/50], Step [372/375], Loss: 2.2210, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [14/50], Step [373/375], Loss: 2.2548, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [14/50], Step [374/375], Loss: 2.6121, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [14/50], Step [375/375], Loss: 2.3413, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [15/50], Step [1/375], Loss: 2.3350, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [2/375], Loss: 2.2964, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [15/50], Step [3/375], Loss: 2.2617, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [15/50], Step [4/375], Loss: 2.0273, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [15/50], Step [5/375], Loss: 2.3224, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [6/375], Loss: 2.4346, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [15/50], Step [7/375], Loss: 2.1715, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [15/50], Step [8/375], Loss: 2.4641, batch time: 0.37, accuracy:  0.00%\n",
      "Epoch [15/50], Step [9/375], Loss: 2.2557, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [10/375], Loss: 2.2160, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [11/375], Loss: 2.2538, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [12/375], Loss: 2.3325, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [15/50], Step [13/375], Loss: 2.2175, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [15/50], Step [14/375], Loss: 2.1765, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [15/375], Loss: 2.1011, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [15/50], Step [16/375], Loss: 2.0509, batch time: 0.37, accuracy:  37.50%\n",
      "Epoch [15/50], Step [17/375], Loss: 2.2984, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [18/375], Loss: 2.3592, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [15/50], Step [19/375], Loss: 2.2693, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [20/375], Loss: 2.2932, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [15/50], Step [21/375], Loss: 2.3176, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [22/375], Loss: 2.1904, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [23/375], Loss: 2.2290, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [15/50], Step [24/375], Loss: 2.2290, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [15/50], Step [25/375], Loss: 2.3597, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [26/375], Loss: 2.3805, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [15/50], Step [27/375], Loss: 2.3241, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [28/375], Loss: 2.2098, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [15/50], Step [29/375], Loss: 2.2718, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [30/375], Loss: 2.2971, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [31/375], Loss: 2.3172, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [15/50], Step [32/375], Loss: 2.1023, batch time: 0.37, accuracy:  37.50%\n",
      "Epoch [15/50], Step [33/375], Loss: 2.0513, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [15/50], Step [34/375], Loss: 2.2822, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [35/375], Loss: 2.3118, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [15/50], Step [36/375], Loss: 2.2683, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [15/50], Step [37/375], Loss: 2.2406, batch time: 1.07, accuracy:  31.25%\n",
      "Epoch [15/50], Step [38/375], Loss: 2.1626, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [39/375], Loss: 2.2992, batch time: 0.36, accuracy:  12.50%\n",
      "Epoch [15/50], Step [40/375], Loss: 2.3425, batch time: 0.36, accuracy:  6.25%\n",
      "Epoch [15/50], Step [41/375], Loss: 2.2968, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [42/375], Loss: 2.2396, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [43/375], Loss: 2.1658, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [15/50], Step [44/375], Loss: 2.2030, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [45/375], Loss: 2.1119, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [46/375], Loss: 2.1052, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [15/50], Step [47/375], Loss: 2.2108, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [48/375], Loss: 2.4255, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [49/375], Loss: 2.3492, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [15/50], Step [50/375], Loss: 2.2029, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [15/50], Step [51/375], Loss: 2.0819, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [15/50], Step [52/375], Loss: 2.4830, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [53/375], Loss: 2.3913, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [54/375], Loss: 2.1601, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [15/50], Step [55/375], Loss: 2.1111, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [56/375], Loss: 2.3782, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [57/375], Loss: 2.1680, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [58/375], Loss: 2.1263, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [15/50], Step [59/375], Loss: 2.0322, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [15/50], Step [60/375], Loss: 2.1972, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [61/375], Loss: 2.4720, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [62/375], Loss: 2.2351, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [15/50], Step [63/375], Loss: 2.0717, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [15/50], Step [64/375], Loss: 2.2724, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [65/375], Loss: 2.2188, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [66/375], Loss: 2.2970, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [67/375], Loss: 2.5055, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [68/375], Loss: 2.2629, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [69/375], Loss: 2.3270, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [70/375], Loss: 2.1511, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [15/50], Step [71/375], Loss: 2.3569, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [72/375], Loss: 2.2178, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [73/375], Loss: 2.1056, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [74/375], Loss: 2.1680, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [75/375], Loss: 2.1870, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [76/375], Loss: 2.2561, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [77/375], Loss: 2.2851, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [78/375], Loss: 2.2289, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [79/375], Loss: 2.2578, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [80/375], Loss: 2.3019, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [81/375], Loss: 2.2042, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [82/375], Loss: 2.3859, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [15/50], Step [83/375], Loss: 2.2380, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [84/375], Loss: 2.1842, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [85/375], Loss: 2.0418, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [86/375], Loss: 2.2690, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [15/50], Step [87/375], Loss: 2.5026, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [15/50], Step [88/375], Loss: 2.1829, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [15/50], Step [89/375], Loss: 2.2232, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [90/375], Loss: 2.2810, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [15/50], Step [91/375], Loss: 2.2829, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [92/375], Loss: 2.2369, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [93/375], Loss: 2.1929, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [94/375], Loss: 2.1802, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [15/50], Step [95/375], Loss: 2.2349, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [96/375], Loss: 2.2788, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [97/375], Loss: 2.3951, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [98/375], Loss: 2.1342, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [99/375], Loss: 2.1149, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [100/375], Loss: 2.1371, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [101/375], Loss: 2.1937, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [15/50], Step [102/375], Loss: 2.3074, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [15/50], Step [103/375], Loss: 2.1889, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [104/375], Loss: 2.2657, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [105/375], Loss: 2.1529, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [106/375], Loss: 2.3041, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [15/50], Step [107/375], Loss: 2.1392, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [108/375], Loss: 2.2927, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [109/375], Loss: 2.2685, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [110/375], Loss: 2.4341, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [111/375], Loss: 2.0863, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [15/50], Step [112/375], Loss: 2.1999, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [113/375], Loss: 2.2407, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [114/375], Loss: 1.9792, batch time: 0.26, accuracy:  56.25%\n",
      "Epoch [15/50], Step [115/375], Loss: 2.0933, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [116/375], Loss: 2.2653, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [117/375], Loss: 2.2524, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [118/375], Loss: 2.3447, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [119/375], Loss: 2.1941, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [120/375], Loss: 2.2838, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [121/375], Loss: 2.1950, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [122/375], Loss: 2.1615, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [123/375], Loss: 2.1429, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [15/50], Step [124/375], Loss: 2.1714, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [125/375], Loss: 2.2065, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [126/375], Loss: 2.1811, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [127/375], Loss: 2.4281, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [128/375], Loss: 2.1147, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [129/375], Loss: 2.2156, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [130/375], Loss: 2.2543, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [131/375], Loss: 2.3076, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [132/375], Loss: 2.2140, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [133/375], Loss: 2.2263, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [134/375], Loss: 2.2122, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [135/375], Loss: 2.2666, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [136/375], Loss: 2.0931, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [137/375], Loss: 2.4210, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [138/375], Loss: 2.1210, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [139/375], Loss: 2.4041, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [140/375], Loss: 2.2122, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [141/375], Loss: 2.1188, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [142/375], Loss: 2.4659, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [15/50], Step [143/375], Loss: 2.1873, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [144/375], Loss: 2.1353, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [145/375], Loss: 2.3749, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [146/375], Loss: 2.0996, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [147/375], Loss: 2.0881, batch time: 0.80, accuracy:  25.00%\n",
      "Epoch [15/50], Step [148/375], Loss: 2.0630, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [149/375], Loss: 2.2223, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [150/375], Loss: 2.3459, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [15/50], Step [151/375], Loss: 2.1850, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [152/375], Loss: 2.1854, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [153/375], Loss: 2.2572, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [15/50], Step [154/375], Loss: 2.5146, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [15/50], Step [155/375], Loss: 2.3160, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [156/375], Loss: 2.1802, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [15/50], Step [157/375], Loss: 2.3128, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [158/375], Loss: 2.2109, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [159/375], Loss: 2.4059, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [160/375], Loss: 2.4117, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [15/50], Step [161/375], Loss: 2.2909, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [162/375], Loss: 2.2275, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [163/375], Loss: 2.1125, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [164/375], Loss: 2.3473, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [15/50], Step [165/375], Loss: 2.4845, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [166/375], Loss: 2.2598, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [167/375], Loss: 2.1288, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [168/375], Loss: 2.2048, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [169/375], Loss: 2.1642, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [170/375], Loss: 2.3693, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [15/50], Step [171/375], Loss: 2.1992, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [172/375], Loss: 2.4337, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [173/375], Loss: 2.2962, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [174/375], Loss: 2.1097, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [175/375], Loss: 2.1362, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [176/375], Loss: 2.1972, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [15/50], Step [177/375], Loss: 2.1890, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [178/375], Loss: 2.2040, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [179/375], Loss: 2.3027, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [180/375], Loss: 2.1350, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [181/375], Loss: 2.0577, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [182/375], Loss: 2.1597, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [15/50], Step [183/375], Loss: 2.1402, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [184/375], Loss: 2.1683, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [15/50], Step [185/375], Loss: 2.2955, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [15/50], Step [186/375], Loss: 2.2266, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [187/375], Loss: 2.2027, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [188/375], Loss: 2.2545, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [189/375], Loss: 2.3186, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [190/375], Loss: 2.2465, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [191/375], Loss: 2.0989, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [192/375], Loss: 2.3469, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [15/50], Step [193/375], Loss: 2.2045, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [194/375], Loss: 2.0554, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [195/375], Loss: 2.0230, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [196/375], Loss: 2.2171, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [15/50], Step [197/375], Loss: 2.0212, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [15/50], Step [198/375], Loss: 2.1987, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [199/375], Loss: 2.3506, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [200/375], Loss: 2.2836, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [201/375], Loss: 2.2022, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [202/375], Loss: 2.4390, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [203/375], Loss: 2.4288, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [204/375], Loss: 2.0568, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [15/50], Step [205/375], Loss: 2.3939, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [206/375], Loss: 2.1898, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [207/375], Loss: 2.3156, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [208/375], Loss: 2.2308, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [15/50], Step [209/375], Loss: 2.2216, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [210/375], Loss: 2.1202, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [211/375], Loss: 2.3247, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [212/375], Loss: 2.0594, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [15/50], Step [213/375], Loss: 2.4548, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [15/50], Step [214/375], Loss: 2.1726, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [215/375], Loss: 2.0873, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [15/50], Step [216/375], Loss: 2.2100, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [15/50], Step [217/375], Loss: 2.3701, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [218/375], Loss: 2.1232, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [219/375], Loss: 2.4192, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [220/375], Loss: 2.2123, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [15/50], Step [221/375], Loss: 2.3314, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [15/50], Step [222/375], Loss: 2.3480, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [223/375], Loss: 2.2528, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [15/50], Step [224/375], Loss: 2.2291, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [225/375], Loss: 2.0512, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [15/50], Step [226/375], Loss: 2.1308, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [15/50], Step [227/375], Loss: 2.4027, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [228/375], Loss: 2.3765, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [229/375], Loss: 2.1738, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [15/50], Step [230/375], Loss: 2.3796, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [15/50], Step [231/375], Loss: 2.1373, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [15/50], Step [232/375], Loss: 2.2181, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [233/375], Loss: 2.2850, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [15/50], Step [234/375], Loss: 2.2216, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [15/50], Step [235/375], Loss: 2.3089, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [236/375], Loss: 2.2486, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [237/375], Loss: 2.1697, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [15/50], Step [238/375], Loss: 2.1701, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [239/375], Loss: 2.1103, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [15/50], Step [240/375], Loss: 2.2449, batch time: 0.36, accuracy:  18.75%\n",
      "Epoch [15/50], Step [241/375], Loss: 2.3589, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [15/50], Step [242/375], Loss: 2.4761, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [243/375], Loss: 2.2910, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [15/50], Step [244/375], Loss: 2.2294, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [15/50], Step [245/375], Loss: 2.2530, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [246/375], Loss: 1.9913, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [247/375], Loss: 2.3283, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [248/375], Loss: 2.1771, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [15/50], Step [249/375], Loss: 2.1464, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [15/50], Step [250/375], Loss: 2.2330, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [15/50], Step [251/375], Loss: 2.1796, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [15/50], Step [252/375], Loss: 2.2436, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [15/50], Step [253/375], Loss: 2.2042, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [254/375], Loss: 2.5039, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [255/375], Loss: 2.3143, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [256/375], Loss: 2.2700, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [257/375], Loss: 2.3790, batch time: 0.88, accuracy:  6.25%\n",
      "Epoch [15/50], Step [258/375], Loss: 2.2138, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [259/375], Loss: 2.1440, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [260/375], Loss: 2.1714, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [15/50], Step [261/375], Loss: 2.3504, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [262/375], Loss: 2.0811, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [15/50], Step [263/375], Loss: 2.2793, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [15/50], Step [264/375], Loss: 2.3153, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [15/50], Step [265/375], Loss: 2.1994, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [266/375], Loss: 2.2776, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [15/50], Step [267/375], Loss: 2.3861, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [268/375], Loss: 2.2234, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [15/50], Step [269/375], Loss: 2.4209, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [270/375], Loss: 2.1547, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [271/375], Loss: 2.3039, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [272/375], Loss: 2.2812, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [273/375], Loss: 2.2939, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [15/50], Step [274/375], Loss: 2.1562, batch time: 0.36, accuracy:  25.00%\n",
      "Epoch [15/50], Step [275/375], Loss: 2.1940, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [276/375], Loss: 2.3411, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [15/50], Step [277/375], Loss: 2.3957, batch time: 0.33, accuracy:  0.00%\n",
      "Epoch [15/50], Step [278/375], Loss: 2.2517, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [15/50], Step [279/375], Loss: 2.3424, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [15/50], Step [280/375], Loss: 2.2232, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [281/375], Loss: 2.4514, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [282/375], Loss: 2.0945, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [15/50], Step [283/375], Loss: 2.1255, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [15/50], Step [284/375], Loss: 2.2901, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [285/375], Loss: 2.2704, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [286/375], Loss: 2.2607, batch time: 0.36, accuracy:  18.75%\n",
      "Epoch [15/50], Step [287/375], Loss: 2.4057, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [288/375], Loss: 2.3209, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [289/375], Loss: 2.3026, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [290/375], Loss: 2.2579, batch time: 0.36, accuracy:  18.75%\n",
      "Epoch [15/50], Step [291/375], Loss: 2.3056, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [15/50], Step [292/375], Loss: 2.3099, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [293/375], Loss: 2.0863, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [15/50], Step [294/375], Loss: 2.2893, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [15/50], Step [295/375], Loss: 2.3372, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [296/375], Loss: 2.1551, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [297/375], Loss: 2.1347, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [15/50], Step [298/375], Loss: 2.1660, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [15/50], Step [299/375], Loss: 2.0556, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [15/50], Step [300/375], Loss: 2.2425, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [301/375], Loss: 2.3407, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [302/375], Loss: 2.1682, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [15/50], Step [303/375], Loss: 2.1584, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [304/375], Loss: 2.2423, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [305/375], Loss: 2.2873, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [306/375], Loss: 1.9719, batch time: 0.35, accuracy:  50.00%\n",
      "Epoch [15/50], Step [307/375], Loss: 2.2742, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [308/375], Loss: 2.3799, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [309/375], Loss: 2.0213, batch time: 0.31, accuracy:  37.50%\n",
      "Epoch [15/50], Step [310/375], Loss: 2.1194, batch time: 0.36, accuracy:  31.25%\n",
      "Epoch [15/50], Step [311/375], Loss: 2.1728, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [15/50], Step [312/375], Loss: 2.2103, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [15/50], Step [313/375], Loss: 2.2475, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [314/375], Loss: 2.2646, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [315/375], Loss: 2.2087, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [316/375], Loss: 2.3934, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [317/375], Loss: 2.4619, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [318/375], Loss: 2.1919, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [319/375], Loss: 2.1904, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [320/375], Loss: 1.9970, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [15/50], Step [321/375], Loss: 2.1380, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [15/50], Step [322/375], Loss: 2.3442, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [323/375], Loss: 2.0679, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [15/50], Step [324/375], Loss: 2.3847, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [15/50], Step [325/375], Loss: 2.0793, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [326/375], Loss: 2.1152, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [327/375], Loss: 2.2504, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [15/50], Step [328/375], Loss: 2.3283, batch time: 0.33, accuracy:  0.00%\n",
      "Epoch [15/50], Step [329/375], Loss: 2.1411, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [330/375], Loss: 2.2308, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [331/375], Loss: 2.2211, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [332/375], Loss: 2.2698, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [333/375], Loss: 2.3788, batch time: 0.31, accuracy:  0.00%\n",
      "Epoch [15/50], Step [334/375], Loss: 2.3327, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [335/375], Loss: 2.1302, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [336/375], Loss: 2.1603, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [15/50], Step [337/375], Loss: 2.3518, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [338/375], Loss: 2.3511, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [339/375], Loss: 2.2860, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [340/375], Loss: 2.0852, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [15/50], Step [341/375], Loss: 2.1930, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [342/375], Loss: 2.2262, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [15/50], Step [343/375], Loss: 2.2163, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [344/375], Loss: 2.2394, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [15/50], Step [345/375], Loss: 2.3771, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [346/375], Loss: 2.3373, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [15/50], Step [347/375], Loss: 2.0517, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [348/375], Loss: 2.3999, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [349/375], Loss: 2.2260, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [15/50], Step [350/375], Loss: 2.1095, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [15/50], Step [351/375], Loss: 2.1881, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [15/50], Step [352/375], Loss: 2.3064, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [15/50], Step [353/375], Loss: 2.3719, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [15/50], Step [354/375], Loss: 2.1549, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [355/375], Loss: 2.3639, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [15/50], Step [356/375], Loss: 2.4612, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [357/375], Loss: 2.2323, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [358/375], Loss: 2.3332, batch time: 0.35, accuracy:  0.00%\n",
      "Epoch [15/50], Step [359/375], Loss: 2.2676, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [15/50], Step [360/375], Loss: 2.2192, batch time: 0.31, accuracy:  43.75%\n",
      "Epoch [15/50], Step [361/375], Loss: 2.3992, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [362/375], Loss: 2.3110, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [15/50], Step [363/375], Loss: 2.1924, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [364/375], Loss: 2.2708, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [365/375], Loss: 2.3554, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [15/50], Step [366/375], Loss: 2.1119, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [15/50], Step [367/375], Loss: 2.3287, batch time: 0.87, accuracy:  18.75%\n",
      "Epoch [15/50], Step [368/375], Loss: 2.2308, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [15/50], Step [369/375], Loss: 2.1581, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [15/50], Step [370/375], Loss: 2.2112, batch time: 0.36, accuracy:  31.25%\n",
      "Epoch [15/50], Step [371/375], Loss: 2.3019, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [15/50], Step [372/375], Loss: 2.2433, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [15/50], Step [373/375], Loss: 2.2821, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [15/50], Step [374/375], Loss: 2.2949, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [15/50], Step [375/375], Loss: 2.1102, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [1/375], Loss: 2.2391, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [16/50], Step [2/375], Loss: 2.2024, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [3/375], Loss: 2.3467, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [4/375], Loss: 2.2522, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [16/50], Step [5/375], Loss: 2.3442, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [16/50], Step [6/375], Loss: 2.0813, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [7/375], Loss: 2.2342, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [8/375], Loss: 2.4978, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [9/375], Loss: 2.0606, batch time: 0.35, accuracy:  43.75%\n",
      "Epoch [16/50], Step [10/375], Loss: 2.2751, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [11/375], Loss: 2.1302, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [12/375], Loss: 2.2448, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [13/375], Loss: 2.0469, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [14/375], Loss: 2.2032, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [15/375], Loss: 2.3030, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [16/375], Loss: 2.2249, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [17/375], Loss: 2.1030, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [18/375], Loss: 2.1761, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [19/375], Loss: 2.1867, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [20/375], Loss: 2.3314, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [21/375], Loss: 2.2484, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [22/375], Loss: 2.1559, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [16/50], Step [23/375], Loss: 2.2783, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [24/375], Loss: 2.2610, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [16/50], Step [25/375], Loss: 2.2319, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [16/50], Step [26/375], Loss: 2.1855, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [27/375], Loss: 2.0560, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [28/375], Loss: 2.1543, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [29/375], Loss: 2.1112, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [16/50], Step [30/375], Loss: 2.2223, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [16/50], Step [31/375], Loss: 2.2127, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [32/375], Loss: 2.3844, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [33/375], Loss: 2.0818, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [34/375], Loss: 2.2107, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [35/375], Loss: 2.3561, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [36/375], Loss: 2.1162, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [37/375], Loss: 2.2115, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [38/375], Loss: 2.4492, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [39/375], Loss: 2.3139, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [40/375], Loss: 2.1729, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [41/375], Loss: 2.2250, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [42/375], Loss: 2.3355, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [43/375], Loss: 2.3458, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [44/375], Loss: 2.3044, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [45/375], Loss: 2.2147, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [46/375], Loss: 2.2194, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [47/375], Loss: 2.3529, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [48/375], Loss: 2.2764, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [49/375], Loss: 2.3231, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [50/375], Loss: 2.3519, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [51/375], Loss: 2.3244, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [52/375], Loss: 2.3302, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [53/375], Loss: 2.1996, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [54/375], Loss: 2.3864, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [16/50], Step [55/375], Loss: 2.2678, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [56/375], Loss: 2.3684, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [57/375], Loss: 2.0797, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [58/375], Loss: 2.3270, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [59/375], Loss: 2.2199, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [60/375], Loss: 2.0674, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [16/50], Step [61/375], Loss: 2.4392, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [16/50], Step [62/375], Loss: 2.0518, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [63/375], Loss: 2.3830, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [64/375], Loss: 2.0872, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [65/375], Loss: 2.1552, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [66/375], Loss: 2.3361, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [16/50], Step [67/375], Loss: 2.1547, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [68/375], Loss: 2.2828, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [69/375], Loss: 2.2630, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [16/50], Step [70/375], Loss: 2.1485, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [71/375], Loss: 2.3955, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [72/375], Loss: 2.3706, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [73/375], Loss: 2.3356, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [74/375], Loss: 2.0698, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [75/375], Loss: 2.3504, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [76/375], Loss: 2.2063, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [77/375], Loss: 2.2358, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [78/375], Loss: 2.1551, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [16/50], Step [79/375], Loss: 2.2979, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [80/375], Loss: 2.3696, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [81/375], Loss: 2.1430, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [82/375], Loss: 2.2909, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [16/50], Step [83/375], Loss: 2.0436, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [16/50], Step [84/375], Loss: 2.2077, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [85/375], Loss: 2.1123, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [16/50], Step [86/375], Loss: 2.2271, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [87/375], Loss: 2.0226, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [16/50], Step [88/375], Loss: 2.2570, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [89/375], Loss: 2.1540, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [90/375], Loss: 2.1346, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [91/375], Loss: 2.3173, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [92/375], Loss: 2.0649, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [93/375], Loss: 2.1399, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [94/375], Loss: 2.1309, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [16/50], Step [95/375], Loss: 2.3935, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [96/375], Loss: 2.3409, batch time: 0.31, accuracy:  0.00%\n",
      "Epoch [16/50], Step [97/375], Loss: 2.3414, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [16/50], Step [98/375], Loss: 2.3095, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [16/50], Step [99/375], Loss: 2.2603, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [100/375], Loss: 2.2601, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [101/375], Loss: 2.2025, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [102/375], Loss: 2.0362, batch time: 0.89, accuracy:  25.00%\n",
      "Epoch [16/50], Step [103/375], Loss: 2.0734, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [16/50], Step [104/375], Loss: 2.2607, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [105/375], Loss: 2.2560, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [16/50], Step [106/375], Loss: 2.1297, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [107/375], Loss: 2.1663, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [108/375], Loss: 2.1349, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [16/50], Step [109/375], Loss: 2.2977, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [110/375], Loss: 2.2595, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [111/375], Loss: 2.3012, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [16/50], Step [112/375], Loss: 2.2377, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [113/375], Loss: 2.2423, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [114/375], Loss: 2.3237, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [115/375], Loss: 2.2924, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [116/375], Loss: 2.0677, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [117/375], Loss: 2.2015, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [118/375], Loss: 2.2029, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [119/375], Loss: 2.4259, batch time: 0.36, accuracy:  0.00%\n",
      "Epoch [16/50], Step [120/375], Loss: 2.4374, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [121/375], Loss: 2.1217, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [16/50], Step [122/375], Loss: 2.1575, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [123/375], Loss: 2.2174, batch time: 0.36, accuracy:  18.75%\n",
      "Epoch [16/50], Step [124/375], Loss: 2.4024, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [16/50], Step [125/375], Loss: 2.1358, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [16/50], Step [126/375], Loss: 2.1782, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [127/375], Loss: 2.0569, batch time: 0.35, accuracy:  50.00%\n",
      "Epoch [16/50], Step [128/375], Loss: 2.2633, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [129/375], Loss: 2.3732, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [130/375], Loss: 2.1883, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [131/375], Loss: 2.5009, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [132/375], Loss: 2.2554, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [133/375], Loss: 2.2384, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [134/375], Loss: 2.2780, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [135/375], Loss: 2.2247, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [136/375], Loss: 2.1465, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [137/375], Loss: 2.2825, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [138/375], Loss: 2.2636, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [139/375], Loss: 2.2526, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [16/50], Step [140/375], Loss: 2.2054, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [141/375], Loss: 2.2604, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [142/375], Loss: 2.2501, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [143/375], Loss: 2.1630, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [144/375], Loss: 2.2204, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [145/375], Loss: 2.1534, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [146/375], Loss: 2.2519, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [147/375], Loss: 1.9347, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [16/50], Step [148/375], Loss: 2.3559, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [149/375], Loss: 2.4090, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [150/375], Loss: 2.4368, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [16/50], Step [151/375], Loss: 2.1835, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [16/50], Step [152/375], Loss: 2.1140, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [153/375], Loss: 2.1738, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [16/50], Step [154/375], Loss: 2.4311, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [155/375], Loss: 2.2327, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [16/50], Step [156/375], Loss: 2.1906, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [157/375], Loss: 2.1965, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [158/375], Loss: 2.2539, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [159/375], Loss: 2.3002, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [160/375], Loss: 2.2247, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [161/375], Loss: 2.2991, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [162/375], Loss: 2.3059, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [16/50], Step [163/375], Loss: 2.3707, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [16/50], Step [164/375], Loss: 2.3165, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [165/375], Loss: 2.3506, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [166/375], Loss: 2.2167, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [167/375], Loss: 2.2658, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [16/50], Step [168/375], Loss: 2.1540, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [169/375], Loss: 2.0953, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [170/375], Loss: 2.3991, batch time: 0.32, accuracy:  0.00%\n",
      "Epoch [16/50], Step [171/375], Loss: 2.0977, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [172/375], Loss: 2.2419, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [173/375], Loss: 2.1490, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [174/375], Loss: 2.2421, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [175/375], Loss: 2.2152, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [176/375], Loss: 2.2322, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [16/50], Step [177/375], Loss: 2.0813, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [178/375], Loss: 2.0483, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [16/50], Step [179/375], Loss: 2.2248, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [180/375], Loss: 2.2640, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [181/375], Loss: 2.3716, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [182/375], Loss: 2.1109, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [183/375], Loss: 2.0739, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [184/375], Loss: 2.3012, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [185/375], Loss: 2.1378, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [186/375], Loss: 2.4297, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [187/375], Loss: 2.3726, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [16/50], Step [188/375], Loss: 2.3456, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [189/375], Loss: 2.2608, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [190/375], Loss: 2.1600, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [191/375], Loss: 2.1643, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [192/375], Loss: 2.2504, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [193/375], Loss: 2.1911, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [194/375], Loss: 2.3497, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [195/375], Loss: 2.1158, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [196/375], Loss: 2.2850, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [197/375], Loss: 2.1193, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [198/375], Loss: 2.0932, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [16/50], Step [199/375], Loss: 2.1501, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [200/375], Loss: 2.2107, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [201/375], Loss: 2.6098, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [202/375], Loss: 2.2630, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [203/375], Loss: 2.1622, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [16/50], Step [204/375], Loss: 1.9613, batch time: 0.32, accuracy:  43.75%\n",
      "Epoch [16/50], Step [205/375], Loss: 2.2261, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [206/375], Loss: 2.2912, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [207/375], Loss: 2.3282, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [16/50], Step [208/375], Loss: 2.3231, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [209/375], Loss: 2.4217, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [210/375], Loss: 2.2029, batch time: 0.36, accuracy:  18.75%\n",
      "Epoch [16/50], Step [211/375], Loss: 2.3592, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [16/50], Step [212/375], Loss: 2.3046, batch time: 0.96, accuracy:  12.50%\n",
      "Epoch [16/50], Step [213/375], Loss: 2.3350, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [214/375], Loss: 2.2803, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [215/375], Loss: 2.2264, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [16/50], Step [216/375], Loss: 2.2639, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [217/375], Loss: 2.4239, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [218/375], Loss: 2.1343, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [16/50], Step [219/375], Loss: 2.3634, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [220/375], Loss: 2.1746, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [16/50], Step [221/375], Loss: 2.2643, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [16/50], Step [222/375], Loss: 2.2858, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [223/375], Loss: 2.3541, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [224/375], Loss: 2.1118, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [225/375], Loss: 2.4367, batch time: 0.36, accuracy:  6.25%\n",
      "Epoch [16/50], Step [226/375], Loss: 2.3201, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [227/375], Loss: 2.3067, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [16/50], Step [228/375], Loss: 2.3231, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [229/375], Loss: 2.1671, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [16/50], Step [230/375], Loss: 2.2093, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [231/375], Loss: 2.3398, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [232/375], Loss: 2.2091, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [233/375], Loss: 2.3432, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [234/375], Loss: 2.1787, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [235/375], Loss: 2.3269, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [236/375], Loss: 2.1869, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [237/375], Loss: 2.1103, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [16/50], Step [238/375], Loss: 2.1790, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [239/375], Loss: 2.0094, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [240/375], Loss: 2.1593, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [241/375], Loss: 2.3535, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [16/50], Step [242/375], Loss: 2.1506, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [243/375], Loss: 2.2537, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [244/375], Loss: 2.2072, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [245/375], Loss: 2.4689, batch time: 0.33, accuracy:  0.00%\n",
      "Epoch [16/50], Step [246/375], Loss: 2.2083, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [247/375], Loss: 2.3426, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [248/375], Loss: 2.1311, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [16/50], Step [249/375], Loss: 2.2050, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [250/375], Loss: 2.1313, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [251/375], Loss: 2.2486, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [252/375], Loss: 2.1672, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [253/375], Loss: 2.1450, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [254/375], Loss: 2.2900, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [255/375], Loss: 2.2777, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [256/375], Loss: 2.1281, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [16/50], Step [257/375], Loss: 2.3640, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [258/375], Loss: 2.1344, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [259/375], Loss: 2.2984, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [260/375], Loss: 2.2130, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [261/375], Loss: 2.1026, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [16/50], Step [262/375], Loss: 2.2253, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [263/375], Loss: 2.2581, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [16/50], Step [264/375], Loss: 2.2650, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [265/375], Loss: 2.1272, batch time: 0.36, accuracy:  43.75%\n",
      "Epoch [16/50], Step [266/375], Loss: 2.4098, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [267/375], Loss: 2.3086, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [268/375], Loss: 1.9908, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [16/50], Step [269/375], Loss: 2.2208, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [270/375], Loss: 2.3244, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [271/375], Loss: 2.5464, batch time: 0.33, accuracy:  0.00%\n",
      "Epoch [16/50], Step [272/375], Loss: 2.3282, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [273/375], Loss: 1.9403, batch time: 0.35, accuracy:  43.75%\n",
      "Epoch [16/50], Step [274/375], Loss: 2.2718, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [275/375], Loss: 2.3526, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [276/375], Loss: 2.0606, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [277/375], Loss: 2.3294, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [16/50], Step [278/375], Loss: 2.3653, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [279/375], Loss: 2.1764, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [280/375], Loss: 2.4113, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [16/50], Step [281/375], Loss: 2.0992, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [282/375], Loss: 2.3301, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [283/375], Loss: 2.2736, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [284/375], Loss: 2.0601, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [285/375], Loss: 2.3404, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [16/50], Step [286/375], Loss: 2.1658, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [16/50], Step [287/375], Loss: 2.2149, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [288/375], Loss: 2.3325, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [289/375], Loss: 2.2617, batch time: 0.36, accuracy:  12.50%\n",
      "Epoch [16/50], Step [290/375], Loss: 2.2096, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [291/375], Loss: 2.3128, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [292/375], Loss: 2.1599, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [293/375], Loss: 2.1751, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [294/375], Loss: 2.3235, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [295/375], Loss: 2.3021, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [296/375], Loss: 2.2953, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [297/375], Loss: 2.1852, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [16/50], Step [298/375], Loss: 2.2571, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [299/375], Loss: 2.1937, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [300/375], Loss: 2.2361, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [301/375], Loss: 2.2294, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [16/50], Step [302/375], Loss: 2.4081, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [16/50], Step [303/375], Loss: 2.2685, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [304/375], Loss: 2.3695, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [305/375], Loss: 2.1512, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [16/50], Step [306/375], Loss: 2.2049, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [307/375], Loss: 2.4026, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [16/50], Step [308/375], Loss: 2.2240, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [309/375], Loss: 2.0196, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [310/375], Loss: 2.2037, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [311/375], Loss: 2.1633, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [16/50], Step [312/375], Loss: 2.3635, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [16/50], Step [313/375], Loss: 2.1629, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [16/50], Step [314/375], Loss: 2.2889, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [315/375], Loss: 2.3017, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [16/50], Step [316/375], Loss: 2.2819, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [317/375], Loss: 2.1264, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [318/375], Loss: 2.2782, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [16/50], Step [319/375], Loss: 2.1894, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [16/50], Step [320/375], Loss: 2.2801, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [16/50], Step [321/375], Loss: 2.1971, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [16/50], Step [322/375], Loss: 2.2697, batch time: 0.90, accuracy:  12.50%\n",
      "Epoch [16/50], Step [323/375], Loss: 2.3264, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [16/50], Step [324/375], Loss: 2.4123, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [325/375], Loss: 2.4672, batch time: 0.28, accuracy:  0.00%\n",
      "Epoch [16/50], Step [326/375], Loss: 2.2374, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [16/50], Step [327/375], Loss: 2.3035, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [328/375], Loss: 2.3777, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [16/50], Step [329/375], Loss: 2.1865, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [330/375], Loss: 2.2445, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [331/375], Loss: 2.2845, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [16/50], Step [332/375], Loss: 2.3053, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [16/50], Step [333/375], Loss: 2.3457, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [16/50], Step [334/375], Loss: 2.3268, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [335/375], Loss: 2.0281, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [16/50], Step [336/375], Loss: 2.2368, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [337/375], Loss: 2.2331, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [16/50], Step [338/375], Loss: 2.4631, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [16/50], Step [339/375], Loss: 2.2798, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [16/50], Step [340/375], Loss: 2.3093, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [16/50], Step [341/375], Loss: 2.3536, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [16/50], Step [342/375], Loss: 2.2762, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [343/375], Loss: 2.2339, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [16/50], Step [344/375], Loss: 2.2351, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [345/375], Loss: 2.2758, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [16/50], Step [346/375], Loss: 2.3447, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [347/375], Loss: 2.1608, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [16/50], Step [348/375], Loss: 2.1069, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [16/50], Step [349/375], Loss: 2.2075, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [350/375], Loss: 2.3578, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [351/375], Loss: 2.2090, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [16/50], Step [352/375], Loss: 2.1628, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [16/50], Step [353/375], Loss: 2.3406, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [16/50], Step [354/375], Loss: 2.3177, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [16/50], Step [355/375], Loss: 2.1716, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [16/50], Step [356/375], Loss: 2.1624, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [16/50], Step [357/375], Loss: 2.3985, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [16/50], Step [358/375], Loss: 2.2723, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [359/375], Loss: 2.2080, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [16/50], Step [360/375], Loss: 2.1876, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [361/375], Loss: 2.2246, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [16/50], Step [362/375], Loss: 2.2202, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [363/375], Loss: 2.2937, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [16/50], Step [364/375], Loss: 2.2175, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [365/375], Loss: 2.3079, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [366/375], Loss: 2.2583, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [16/50], Step [367/375], Loss: 2.3191, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [16/50], Step [368/375], Loss: 2.3506, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [16/50], Step [369/375], Loss: 2.1561, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [16/50], Step [370/375], Loss: 2.1328, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [16/50], Step [371/375], Loss: 2.2906, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [16/50], Step [372/375], Loss: 2.0436, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [16/50], Step [373/375], Loss: 2.1784, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [16/50], Step [374/375], Loss: 2.1754, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [16/50], Step [375/375], Loss: 2.3128, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [1/375], Loss: 2.1114, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [2/375], Loss: 2.1437, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [3/375], Loss: 2.1808, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [4/375], Loss: 2.3170, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [5/375], Loss: 2.3547, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [6/375], Loss: 2.2678, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [7/375], Loss: 2.0887, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [8/375], Loss: 2.3938, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [9/375], Loss: 2.2951, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [10/375], Loss: 2.3607, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [11/375], Loss: 2.2466, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [12/375], Loss: 2.2869, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [13/375], Loss: 2.3133, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [14/375], Loss: 2.2498, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [15/375], Loss: 2.4534, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [16/375], Loss: 2.3812, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [17/375], Loss: 2.1511, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [18/375], Loss: 2.2257, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [19/375], Loss: 2.2450, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [20/375], Loss: 2.3858, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [21/375], Loss: 2.2807, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [22/375], Loss: 2.2501, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [23/375], Loss: 2.3258, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [24/375], Loss: 2.2436, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [25/375], Loss: 2.0492, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [26/375], Loss: 2.2369, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [27/375], Loss: 2.2184, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [28/375], Loss: 2.2517, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [29/375], Loss: 2.2498, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [30/375], Loss: 2.3617, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [31/375], Loss: 2.2345, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [32/375], Loss: 2.0753, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [17/50], Step [33/375], Loss: 2.2040, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [34/375], Loss: 2.3106, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [35/375], Loss: 2.1677, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [36/375], Loss: 2.3403, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [37/375], Loss: 2.1464, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [38/375], Loss: 2.2543, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [39/375], Loss: 2.2789, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [40/375], Loss: 2.3250, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [41/375], Loss: 2.3241, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [42/375], Loss: 2.1632, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [43/375], Loss: 2.3416, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [44/375], Loss: 2.2501, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [45/375], Loss: 2.2363, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [46/375], Loss: 2.2991, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [47/375], Loss: 2.2789, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [48/375], Loss: 2.2428, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [17/50], Step [49/375], Loss: 2.2601, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [50/375], Loss: 2.1359, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [17/50], Step [51/375], Loss: 2.2191, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [52/375], Loss: 2.1559, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [53/375], Loss: 2.3463, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [54/375], Loss: 2.2363, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [55/375], Loss: 2.3410, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [56/375], Loss: 2.0497, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [17/50], Step [57/375], Loss: 2.0524, batch time: 0.83, accuracy:  31.25%\n",
      "Epoch [17/50], Step [58/375], Loss: 2.2661, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [59/375], Loss: 2.2547, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [60/375], Loss: 2.1733, batch time: 0.29, accuracy:  37.50%\n",
      "Epoch [17/50], Step [61/375], Loss: 2.2379, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [62/375], Loss: 2.1674, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [63/375], Loss: 2.3142, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [17/50], Step [64/375], Loss: 2.1216, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [65/375], Loss: 2.3191, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [66/375], Loss: 2.3164, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [17/50], Step [67/375], Loss: 2.2610, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [68/375], Loss: 2.2650, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [69/375], Loss: 2.3078, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [70/375], Loss: 2.1735, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [71/375], Loss: 2.2400, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [72/375], Loss: 2.1823, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [73/375], Loss: 2.2240, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [74/375], Loss: 2.3665, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [17/50], Step [75/375], Loss: 2.1338, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [76/375], Loss: 2.1450, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [77/375], Loss: 2.4541, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [78/375], Loss: 2.2646, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [79/375], Loss: 2.1736, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [80/375], Loss: 2.4459, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [81/375], Loss: 2.3316, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [82/375], Loss: 2.1960, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [17/50], Step [83/375], Loss: 2.3648, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [84/375], Loss: 2.2991, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [85/375], Loss: 2.0139, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [17/50], Step [86/375], Loss: 2.3012, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [87/375], Loss: 2.2967, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [88/375], Loss: 2.2849, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [17/50], Step [89/375], Loss: 2.4131, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [90/375], Loss: 2.3286, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [17/50], Step [91/375], Loss: 2.2546, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [92/375], Loss: 2.2336, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [93/375], Loss: 2.2868, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [94/375], Loss: 2.2261, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [95/375], Loss: 2.2321, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [96/375], Loss: 2.4463, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [97/375], Loss: 2.3285, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [98/375], Loss: 2.2875, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [99/375], Loss: 2.1344, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [100/375], Loss: 2.2883, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [101/375], Loss: 2.3744, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [102/375], Loss: 2.2635, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [103/375], Loss: 2.3083, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [104/375], Loss: 2.2279, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [105/375], Loss: 2.2488, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [106/375], Loss: 2.2723, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [107/375], Loss: 2.1596, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [108/375], Loss: 2.2046, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [109/375], Loss: 2.2907, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [110/375], Loss: 2.2291, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [111/375], Loss: 2.1325, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [112/375], Loss: 2.3135, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [113/375], Loss: 2.3299, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [114/375], Loss: 2.0682, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [115/375], Loss: 2.1583, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [116/375], Loss: 2.2124, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [117/375], Loss: 2.2664, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [118/375], Loss: 2.1267, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [17/50], Step [119/375], Loss: 2.4890, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [120/375], Loss: 2.2330, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [121/375], Loss: 2.2297, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [122/375], Loss: 2.3049, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [123/375], Loss: 2.3823, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [124/375], Loss: 2.3595, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [125/375], Loss: 2.1373, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [126/375], Loss: 2.1485, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [127/375], Loss: 2.2261, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [128/375], Loss: 2.2485, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [129/375], Loss: 2.2664, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [130/375], Loss: 2.0831, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [17/50], Step [131/375], Loss: 2.2399, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [132/375], Loss: 2.1353, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [133/375], Loss: 2.2389, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [134/375], Loss: 2.2741, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [135/375], Loss: 2.2097, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [136/375], Loss: 2.2488, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [137/375], Loss: 2.0411, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [138/375], Loss: 2.1146, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [139/375], Loss: 2.2287, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [140/375], Loss: 2.2344, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [141/375], Loss: 2.2173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [142/375], Loss: 2.0163, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [17/50], Step [143/375], Loss: 2.1919, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [144/375], Loss: 2.3830, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [145/375], Loss: 2.1714, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [146/375], Loss: 2.1314, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [147/375], Loss: 2.1157, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [148/375], Loss: 2.2480, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [149/375], Loss: 2.5552, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [150/375], Loss: 2.0690, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [17/50], Step [151/375], Loss: 2.3423, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [152/375], Loss: 2.3544, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [153/375], Loss: 2.4296, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [154/375], Loss: 2.2295, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [155/375], Loss: 2.3014, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [156/375], Loss: 2.0919, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [157/375], Loss: 2.1990, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [158/375], Loss: 2.2507, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [159/375], Loss: 2.3659, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [160/375], Loss: 2.0932, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [161/375], Loss: 2.2953, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [162/375], Loss: 2.2764, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [163/375], Loss: 2.2768, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [164/375], Loss: 2.0951, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [165/375], Loss: 2.3242, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [166/375], Loss: 2.2497, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [167/375], Loss: 2.2271, batch time: 0.81, accuracy:  12.50%\n",
      "Epoch [17/50], Step [168/375], Loss: 2.2375, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [169/375], Loss: 2.2468, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [17/50], Step [170/375], Loss: 2.3227, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [17/50], Step [171/375], Loss: 2.1636, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [172/375], Loss: 2.1996, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [173/375], Loss: 2.3554, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [17/50], Step [174/375], Loss: 2.4595, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [175/375], Loss: 2.1741, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [176/375], Loss: 2.2943, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [17/50], Step [177/375], Loss: 2.1676, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [178/375], Loss: 2.2652, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [179/375], Loss: 2.2180, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [180/375], Loss: 2.1996, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [17/50], Step [181/375], Loss: 2.2885, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [182/375], Loss: 2.3656, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [183/375], Loss: 2.2352, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [184/375], Loss: 2.3560, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [185/375], Loss: 2.2187, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [186/375], Loss: 2.1359, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [187/375], Loss: 2.1255, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [188/375], Loss: 2.3750, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [189/375], Loss: 2.0899, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [190/375], Loss: 2.1841, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [191/375], Loss: 2.4429, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [192/375], Loss: 2.3582, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [193/375], Loss: 2.3606, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [194/375], Loss: 2.2196, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [195/375], Loss: 2.3235, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [196/375], Loss: 2.0894, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [197/375], Loss: 2.2495, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [198/375], Loss: 2.2037, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [199/375], Loss: 2.2891, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [200/375], Loss: 2.1812, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [201/375], Loss: 2.2144, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [202/375], Loss: 2.2629, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [203/375], Loss: 2.2318, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [204/375], Loss: 2.3413, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [205/375], Loss: 2.3344, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [206/375], Loss: 2.1687, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [207/375], Loss: 2.1801, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [208/375], Loss: 2.1108, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [17/50], Step [209/375], Loss: 2.2066, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [210/375], Loss: 2.0470, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [211/375], Loss: 2.3467, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [212/375], Loss: 2.2002, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [17/50], Step [213/375], Loss: 2.0420, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [17/50], Step [214/375], Loss: 2.3087, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [215/375], Loss: 2.1225, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [216/375], Loss: 2.3181, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [217/375], Loss: 2.1667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [218/375], Loss: 2.3580, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [219/375], Loss: 2.1040, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [220/375], Loss: 1.8851, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [17/50], Step [221/375], Loss: 2.2066, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [222/375], Loss: 2.6020, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [223/375], Loss: 2.3472, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [224/375], Loss: 2.1799, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [225/375], Loss: 2.2479, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [226/375], Loss: 2.3166, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [227/375], Loss: 2.1762, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [228/375], Loss: 2.2067, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [229/375], Loss: 2.2061, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [230/375], Loss: 2.1892, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [231/375], Loss: 2.2361, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [232/375], Loss: 1.8894, batch time: 0.26, accuracy:  50.00%\n",
      "Epoch [17/50], Step [233/375], Loss: 2.3146, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [234/375], Loss: 2.4659, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [235/375], Loss: 2.2838, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [236/375], Loss: 2.3903, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [237/375], Loss: 2.3293, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [238/375], Loss: 2.1849, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [239/375], Loss: 2.2669, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [240/375], Loss: 2.0286, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [17/50], Step [241/375], Loss: 2.2600, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [242/375], Loss: 2.0883, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [243/375], Loss: 2.3694, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [244/375], Loss: 2.1919, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [245/375], Loss: 2.2036, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [246/375], Loss: 2.2324, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [247/375], Loss: 2.3430, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [248/375], Loss: 2.3985, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [249/375], Loss: 2.2045, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [250/375], Loss: 2.4545, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [251/375], Loss: 2.3327, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [252/375], Loss: 2.2909, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [253/375], Loss: 2.3196, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [254/375], Loss: 2.1708, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [255/375], Loss: 2.2379, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [256/375], Loss: 2.2994, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [257/375], Loss: 2.0809, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [258/375], Loss: 2.2392, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [259/375], Loss: 2.1987, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [260/375], Loss: 2.2334, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [261/375], Loss: 2.2659, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [262/375], Loss: 2.3149, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [263/375], Loss: 2.1713, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [264/375], Loss: 2.2621, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [265/375], Loss: 2.2699, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [266/375], Loss: 2.1803, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [267/375], Loss: 2.2823, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [268/375], Loss: 2.4391, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [269/375], Loss: 1.9930, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [17/50], Step [270/375], Loss: 2.3443, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [271/375], Loss: 2.2509, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [272/375], Loss: 2.1559, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [273/375], Loss: 2.1783, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [274/375], Loss: 2.2650, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [275/375], Loss: 2.2877, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [276/375], Loss: 2.2973, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [17/50], Step [277/375], Loss: 2.2799, batch time: 0.85, accuracy:  18.75%\n",
      "Epoch [17/50], Step [278/375], Loss: 2.1715, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [279/375], Loss: 2.1469, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [280/375], Loss: 2.1792, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [17/50], Step [281/375], Loss: 2.3758, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [17/50], Step [282/375], Loss: 2.2978, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [283/375], Loss: 2.2817, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [17/50], Step [284/375], Loss: 2.1955, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [285/375], Loss: 2.0235, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [17/50], Step [286/375], Loss: 2.2042, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [17/50], Step [287/375], Loss: 1.9236, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [17/50], Step [288/375], Loss: 2.3536, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [289/375], Loss: 2.0323, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [17/50], Step [290/375], Loss: 2.2693, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [291/375], Loss: 2.2199, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [292/375], Loss: 2.1294, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [293/375], Loss: 2.0653, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [294/375], Loss: 2.2138, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [295/375], Loss: 2.2276, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [296/375], Loss: 2.2274, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [297/375], Loss: 2.2789, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [298/375], Loss: 1.9966, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [299/375], Loss: 2.4427, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [300/375], Loss: 1.9712, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [301/375], Loss: 2.2396, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [302/375], Loss: 2.0006, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [17/50], Step [303/375], Loss: 2.2275, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [304/375], Loss: 2.1850, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [305/375], Loss: 2.3867, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [306/375], Loss: 2.1799, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [17/50], Step [307/375], Loss: 2.1309, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [308/375], Loss: 2.3895, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [309/375], Loss: 2.3608, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [310/375], Loss: 2.0292, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [311/375], Loss: 2.0445, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [312/375], Loss: 2.1818, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [313/375], Loss: 2.0243, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [17/50], Step [314/375], Loss: 2.1794, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [315/375], Loss: 2.1289, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [17/50], Step [316/375], Loss: 2.5138, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [317/375], Loss: 2.2501, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [318/375], Loss: 2.4674, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [17/50], Step [319/375], Loss: 2.0992, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [320/375], Loss: 2.2545, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [321/375], Loss: 2.0672, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [322/375], Loss: 2.4840, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [17/50], Step [323/375], Loss: 2.2009, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [324/375], Loss: 2.0951, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [325/375], Loss: 2.2885, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [326/375], Loss: 2.1380, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [327/375], Loss: 2.4069, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [17/50], Step [328/375], Loss: 2.3182, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [17/50], Step [329/375], Loss: 2.2248, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [330/375], Loss: 2.2405, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [17/50], Step [331/375], Loss: 2.4576, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [332/375], Loss: 2.1370, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [333/375], Loss: 2.3587, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [334/375], Loss: 2.3285, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [17/50], Step [335/375], Loss: 2.1597, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [336/375], Loss: 2.2061, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [337/375], Loss: 2.1699, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [338/375], Loss: 2.1604, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [339/375], Loss: 2.2108, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [340/375], Loss: 2.1022, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [341/375], Loss: 2.3953, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [342/375], Loss: 2.2270, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [17/50], Step [343/375], Loss: 2.1082, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [344/375], Loss: 2.1468, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [345/375], Loss: 2.3263, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [346/375], Loss: 2.3264, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [17/50], Step [347/375], Loss: 2.2280, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [348/375], Loss: 2.1274, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [17/50], Step [349/375], Loss: 2.2615, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [350/375], Loss: 2.1603, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [351/375], Loss: 2.1999, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [352/375], Loss: 2.3890, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [353/375], Loss: 2.3931, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [354/375], Loss: 2.4489, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [17/50], Step [355/375], Loss: 2.1810, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [356/375], Loss: 2.2237, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [357/375], Loss: 2.2174, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [358/375], Loss: 2.1677, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [17/50], Step [359/375], Loss: 2.3657, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [360/375], Loss: 2.2544, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [17/50], Step [361/375], Loss: 2.3030, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [362/375], Loss: 2.1542, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [17/50], Step [363/375], Loss: 2.3183, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [364/375], Loss: 2.2735, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [365/375], Loss: 2.1197, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [17/50], Step [366/375], Loss: 2.3858, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [17/50], Step [367/375], Loss: 2.1046, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [17/50], Step [368/375], Loss: 2.2186, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [17/50], Step [369/375], Loss: 2.3943, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [17/50], Step [370/375], Loss: 2.2927, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [17/50], Step [371/375], Loss: 2.1247, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [17/50], Step [372/375], Loss: 2.3517, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [17/50], Step [373/375], Loss: 2.3164, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [17/50], Step [374/375], Loss: 2.2861, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [17/50], Step [375/375], Loss: 2.1807, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [1/375], Loss: 2.2713, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [2/375], Loss: 2.3028, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [3/375], Loss: 2.1856, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [4/375], Loss: 2.2165, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [5/375], Loss: 2.3533, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [6/375], Loss: 2.1499, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [7/375], Loss: 2.1750, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [18/50], Step [8/375], Loss: 2.2173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [9/375], Loss: 2.2446, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [10/375], Loss: 2.1506, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [11/375], Loss: 2.3678, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [12/375], Loss: 2.3129, batch time: 0.95, accuracy:  25.00%\n",
      "Epoch [18/50], Step [13/375], Loss: 2.2674, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [14/375], Loss: 2.1678, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [15/375], Loss: 2.0967, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [18/50], Step [16/375], Loss: 2.2843, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [17/375], Loss: 1.9479, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [18/375], Loss: 2.3641, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [18/50], Step [19/375], Loss: 2.1822, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [20/375], Loss: 2.1352, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [21/375], Loss: 2.1433, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [18/50], Step [22/375], Loss: 2.2879, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [23/375], Loss: 2.2984, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [24/375], Loss: 2.2978, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [25/375], Loss: 2.2432, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [26/375], Loss: 2.2842, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [27/375], Loss: 2.2841, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [28/375], Loss: 2.1695, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [29/375], Loss: 2.4354, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [18/50], Step [30/375], Loss: 2.0772, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [31/375], Loss: 2.2357, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [32/375], Loss: 2.0641, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [33/375], Loss: 2.2693, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [34/375], Loss: 2.3441, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [35/375], Loss: 2.5587, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [36/375], Loss: 2.2277, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [37/375], Loss: 1.9680, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [18/50], Step [38/375], Loss: 2.0649, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [39/375], Loss: 2.1480, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [40/375], Loss: 2.3296, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [41/375], Loss: 2.2043, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [42/375], Loss: 2.5556, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [43/375], Loss: 2.1980, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [44/375], Loss: 2.3716, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [45/375], Loss: 2.2764, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [46/375], Loss: 2.3656, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [47/375], Loss: 2.2528, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [48/375], Loss: 2.1706, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [49/375], Loss: 2.1937, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [50/375], Loss: 2.2221, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [51/375], Loss: 2.1192, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [52/375], Loss: 2.2640, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [53/375], Loss: 2.1396, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [54/375], Loss: 2.2893, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [55/375], Loss: 2.1585, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [56/375], Loss: 2.3585, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [57/375], Loss: 2.2178, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [58/375], Loss: 2.2308, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [59/375], Loss: 2.2613, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [60/375], Loss: 2.0672, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [61/375], Loss: 2.3987, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [18/50], Step [62/375], Loss: 2.1357, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [63/375], Loss: 2.0754, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [64/375], Loss: 2.3952, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [65/375], Loss: 2.3969, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [18/50], Step [66/375], Loss: 2.2862, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [67/375], Loss: 2.1369, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [68/375], Loss: 2.1577, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [69/375], Loss: 2.1575, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [70/375], Loss: 2.2698, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [71/375], Loss: 2.1426, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [72/375], Loss: 2.1398, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [73/375], Loss: 2.2937, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [74/375], Loss: 2.0845, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [75/375], Loss: 2.3352, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [76/375], Loss: 2.3829, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [77/375], Loss: 2.1155, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [78/375], Loss: 2.2832, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [79/375], Loss: 2.3098, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [80/375], Loss: 2.3672, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [81/375], Loss: 2.2362, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [82/375], Loss: 2.2066, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [83/375], Loss: 2.3042, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [84/375], Loss: 2.1450, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [85/375], Loss: 2.2447, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [86/375], Loss: 2.3806, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [87/375], Loss: 2.3018, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [88/375], Loss: 2.3231, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [89/375], Loss: 2.3447, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [18/50], Step [90/375], Loss: 2.1249, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [91/375], Loss: 2.2218, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [92/375], Loss: 2.3259, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [93/375], Loss: 2.1016, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [94/375], Loss: 2.3140, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [95/375], Loss: 2.0323, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [96/375], Loss: 2.0961, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [97/375], Loss: 2.3268, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [18/50], Step [98/375], Loss: 2.2787, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [99/375], Loss: 2.2727, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [100/375], Loss: 2.1442, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [101/375], Loss: 2.1286, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [102/375], Loss: 2.2369, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [103/375], Loss: 2.1528, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [104/375], Loss: 2.3277, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [105/375], Loss: 2.1782, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [106/375], Loss: 2.2269, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [107/375], Loss: 2.2340, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [108/375], Loss: 2.3201, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [109/375], Loss: 2.4293, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [110/375], Loss: 2.2193, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [111/375], Loss: 2.4707, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [112/375], Loss: 2.3093, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [113/375], Loss: 2.1192, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [18/50], Step [114/375], Loss: 2.3472, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [115/375], Loss: 2.2804, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [116/375], Loss: 2.3158, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [117/375], Loss: 2.1125, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [18/50], Step [118/375], Loss: 2.2211, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [119/375], Loss: 2.3493, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [120/375], Loss: 2.3855, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [121/375], Loss: 2.0587, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [122/375], Loss: 2.3575, batch time: 0.98, accuracy:  18.75%\n",
      "Epoch [18/50], Step [123/375], Loss: 2.3877, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [124/375], Loss: 2.2425, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [125/375], Loss: 1.9851, batch time: 0.29, accuracy:  37.50%\n",
      "Epoch [18/50], Step [126/375], Loss: 2.1281, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [127/375], Loss: 2.2611, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [128/375], Loss: 2.3554, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [18/50], Step [129/375], Loss: 2.1740, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [130/375], Loss: 2.3097, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [131/375], Loss: 2.2833, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [18/50], Step [132/375], Loss: 2.2918, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [133/375], Loss: 2.2534, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [134/375], Loss: 2.2675, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [135/375], Loss: 2.2997, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [18/50], Step [136/375], Loss: 2.0249, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [18/50], Step [137/375], Loss: 2.3455, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [138/375], Loss: 2.3286, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [139/375], Loss: 2.0872, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [18/50], Step [140/375], Loss: 2.2950, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [141/375], Loss: 2.0813, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [18/50], Step [142/375], Loss: 2.1802, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [143/375], Loss: 2.2631, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [144/375], Loss: 2.1547, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [145/375], Loss: 2.1872, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [146/375], Loss: 2.1275, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [147/375], Loss: 2.2984, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [148/375], Loss: 2.2437, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [149/375], Loss: 2.2975, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [150/375], Loss: 2.2073, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [151/375], Loss: 2.1897, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [152/375], Loss: 2.3071, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [153/375], Loss: 2.4986, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [154/375], Loss: 2.2841, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [155/375], Loss: 2.3451, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [156/375], Loss: 2.1841, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [157/375], Loss: 2.4075, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [18/50], Step [158/375], Loss: 2.6626, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [18/50], Step [159/375], Loss: 2.4219, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [18/50], Step [160/375], Loss: 2.3913, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [161/375], Loss: 2.4223, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [162/375], Loss: 2.2199, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [163/375], Loss: 2.1679, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [164/375], Loss: 2.2886, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [165/375], Loss: 2.3287, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [166/375], Loss: 2.0938, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [167/375], Loss: 2.2272, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [168/375], Loss: 2.0840, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [18/50], Step [169/375], Loss: 2.3466, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [170/375], Loss: 2.1297, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [171/375], Loss: 2.1156, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [172/375], Loss: 2.3017, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [173/375], Loss: 2.0288, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [18/50], Step [174/375], Loss: 2.1345, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [175/375], Loss: 2.2153, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [18/50], Step [176/375], Loss: 2.2486, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [177/375], Loss: 2.3234, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [178/375], Loss: 2.1434, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [179/375], Loss: 2.1776, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [180/375], Loss: 2.1053, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [181/375], Loss: 2.1418, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [182/375], Loss: 2.1003, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [183/375], Loss: 2.3767, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [18/50], Step [184/375], Loss: 2.1155, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [185/375], Loss: 2.3813, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [186/375], Loss: 2.1803, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [187/375], Loss: 2.2256, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [188/375], Loss: 2.2801, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [189/375], Loss: 2.3015, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [190/375], Loss: 2.1661, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [191/375], Loss: 2.4344, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [18/50], Step [192/375], Loss: 2.1868, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [193/375], Loss: 2.3882, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [18/50], Step [194/375], Loss: 1.9111, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [18/50], Step [195/375], Loss: 2.0947, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [196/375], Loss: 2.3757, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [197/375], Loss: 2.3744, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [198/375], Loss: 2.2293, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [199/375], Loss: 2.4103, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [18/50], Step [200/375], Loss: 2.4312, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [201/375], Loss: 2.0981, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [202/375], Loss: 2.3219, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [203/375], Loss: 2.3825, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [18/50], Step [204/375], Loss: 2.1880, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [205/375], Loss: 2.2301, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [206/375], Loss: 2.2292, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [207/375], Loss: 2.2741, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [208/375], Loss: 2.1562, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [209/375], Loss: 2.3473, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [210/375], Loss: 2.2408, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [211/375], Loss: 2.3383, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [18/50], Step [212/375], Loss: 2.1888, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [213/375], Loss: 2.2652, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [214/375], Loss: 2.3181, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [215/375], Loss: 2.3052, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [18/50], Step [216/375], Loss: 2.1395, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [217/375], Loss: 2.3029, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [218/375], Loss: 2.2044, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [219/375], Loss: 2.1433, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [220/375], Loss: 2.2664, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [221/375], Loss: 2.1011, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [222/375], Loss: 2.1423, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [223/375], Loss: 2.2438, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [224/375], Loss: 2.2385, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [225/375], Loss: 2.2129, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [226/375], Loss: 2.2296, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [227/375], Loss: 2.1665, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [228/375], Loss: 2.2301, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [229/375], Loss: 2.3074, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [230/375], Loss: 2.3510, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [231/375], Loss: 2.2759, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [232/375], Loss: 2.3357, batch time: 0.87, accuracy:  12.50%\n",
      "Epoch [18/50], Step [233/375], Loss: 2.1487, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [234/375], Loss: 2.0760, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [235/375], Loss: 2.3939, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [18/50], Step [236/375], Loss: 2.3694, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [18/50], Step [237/375], Loss: 2.4446, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [238/375], Loss: 2.2241, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [18/50], Step [239/375], Loss: 2.2066, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [240/375], Loss: 2.1743, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [241/375], Loss: 2.2815, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [18/50], Step [242/375], Loss: 2.2489, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [243/375], Loss: 2.4120, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [244/375], Loss: 2.3614, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [245/375], Loss: 2.2377, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [18/50], Step [246/375], Loss: 2.2524, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [247/375], Loss: 2.2518, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [248/375], Loss: 2.2202, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [249/375], Loss: 2.3650, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [250/375], Loss: 2.2493, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [251/375], Loss: 2.0950, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [252/375], Loss: 2.2637, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [253/375], Loss: 2.1535, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [254/375], Loss: 2.0366, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [18/50], Step [255/375], Loss: 2.4061, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [256/375], Loss: 2.0925, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [18/50], Step [257/375], Loss: 2.1414, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [258/375], Loss: 2.2516, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [259/375], Loss: 2.2919, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [260/375], Loss: 2.1779, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [261/375], Loss: 2.3736, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [18/50], Step [262/375], Loss: 2.1246, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [18/50], Step [263/375], Loss: 2.3479, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [264/375], Loss: 2.2987, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [265/375], Loss: 2.3897, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [266/375], Loss: 2.3947, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [267/375], Loss: 2.3217, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [268/375], Loss: 2.2095, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [269/375], Loss: 2.3421, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [270/375], Loss: 2.0290, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [18/50], Step [271/375], Loss: 2.1831, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [272/375], Loss: 2.3190, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [273/375], Loss: 2.3501, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [18/50], Step [274/375], Loss: 2.1051, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [275/375], Loss: 2.4518, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [276/375], Loss: 1.8820, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [18/50], Step [277/375], Loss: 2.3470, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [278/375], Loss: 2.1865, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [279/375], Loss: 2.2118, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [280/375], Loss: 2.1916, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [281/375], Loss: 2.2608, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [282/375], Loss: 2.1736, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [283/375], Loss: 2.0406, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [284/375], Loss: 2.2734, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [285/375], Loss: 2.1386, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [286/375], Loss: 2.1655, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [287/375], Loss: 2.2325, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [288/375], Loss: 2.1152, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [289/375], Loss: 2.0895, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [290/375], Loss: 1.9350, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [18/50], Step [291/375], Loss: 2.2565, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [292/375], Loss: 2.2678, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [293/375], Loss: 2.1949, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [294/375], Loss: 2.1582, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [295/375], Loss: 2.4228, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [296/375], Loss: 2.1682, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [297/375], Loss: 2.2335, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [298/375], Loss: 2.7180, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [299/375], Loss: 2.2281, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [18/50], Step [300/375], Loss: 2.2655, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [301/375], Loss: 2.3486, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [302/375], Loss: 2.2263, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [303/375], Loss: 2.2709, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [304/375], Loss: 2.3593, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [305/375], Loss: 2.1503, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [306/375], Loss: 2.1947, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [307/375], Loss: 2.2835, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [308/375], Loss: 2.5489, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [309/375], Loss: 2.3464, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [18/50], Step [310/375], Loss: 2.4877, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [311/375], Loss: 2.0014, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [18/50], Step [312/375], Loss: 2.3342, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [313/375], Loss: 2.2791, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [314/375], Loss: 2.2823, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [315/375], Loss: 2.1884, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [316/375], Loss: 2.0230, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [18/50], Step [317/375], Loss: 2.2646, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [318/375], Loss: 2.2164, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [319/375], Loss: 2.1389, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [320/375], Loss: 2.1564, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [321/375], Loss: 2.2707, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [18/50], Step [322/375], Loss: 2.2664, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [323/375], Loss: 2.2328, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [324/375], Loss: 2.1510, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [325/375], Loss: 2.1179, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [18/50], Step [326/375], Loss: 2.2486, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [327/375], Loss: 2.3102, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [328/375], Loss: 2.0091, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [18/50], Step [329/375], Loss: 2.0663, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [18/50], Step [330/375], Loss: 2.1725, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [331/375], Loss: 2.1957, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [332/375], Loss: 2.3073, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [333/375], Loss: 2.2134, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [334/375], Loss: 2.4066, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [335/375], Loss: 2.1741, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [336/375], Loss: 2.2998, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [337/375], Loss: 2.0759, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [338/375], Loss: 2.0745, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [339/375], Loss: 2.4289, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [340/375], Loss: 2.3086, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [341/375], Loss: 2.2999, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [18/50], Step [342/375], Loss: 2.1105, batch time: 0.81, accuracy:  18.75%\n",
      "Epoch [18/50], Step [343/375], Loss: 2.2450, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [344/375], Loss: 2.2805, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [345/375], Loss: 2.2173, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [18/50], Step [346/375], Loss: 2.1776, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [347/375], Loss: 1.9089, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [18/50], Step [348/375], Loss: 2.2103, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [18/50], Step [349/375], Loss: 2.1781, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [18/50], Step [350/375], Loss: 2.2498, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [351/375], Loss: 2.2984, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [18/50], Step [352/375], Loss: 2.1143, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [353/375], Loss: 2.2008, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [354/375], Loss: 2.3064, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [18/50], Step [355/375], Loss: 2.2707, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [18/50], Step [356/375], Loss: 2.1810, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [18/50], Step [357/375], Loss: 2.0834, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [18/50], Step [358/375], Loss: 2.5277, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [359/375], Loss: 2.2100, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [360/375], Loss: 2.4244, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [18/50], Step [361/375], Loss: 2.1704, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [362/375], Loss: 2.2017, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [363/375], Loss: 2.3220, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [18/50], Step [364/375], Loss: 2.2083, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [365/375], Loss: 2.1672, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [366/375], Loss: 2.3120, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [367/375], Loss: 2.1753, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [18/50], Step [368/375], Loss: 2.3230, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [18/50], Step [369/375], Loss: 2.2450, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [370/375], Loss: 2.4114, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [18/50], Step [371/375], Loss: 2.2312, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [18/50], Step [372/375], Loss: 2.0665, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [18/50], Step [373/375], Loss: 2.2800, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [18/50], Step [374/375], Loss: 2.1437, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [18/50], Step [375/375], Loss: 2.3501, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [1/375], Loss: 2.2666, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [2/375], Loss: 2.2254, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [3/375], Loss: 2.1093, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [4/375], Loss: 2.1758, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [5/375], Loss: 2.1927, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [6/375], Loss: 2.2056, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [7/375], Loss: 2.2290, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [8/375], Loss: 2.2700, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [9/375], Loss: 2.2720, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [10/375], Loss: 2.3463, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [11/375], Loss: 2.1549, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [12/375], Loss: 2.2599, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [13/375], Loss: 2.3273, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [14/375], Loss: 2.1290, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [15/375], Loss: 2.2361, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [16/375], Loss: 2.2273, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [17/375], Loss: 2.4550, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [18/375], Loss: 2.3559, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [19/375], Loss: 2.3901, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [20/375], Loss: 2.2259, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [21/375], Loss: 2.3883, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [22/375], Loss: 2.0407, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [23/375], Loss: 2.1221, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [24/375], Loss: 2.2943, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [19/50], Step [25/375], Loss: 2.2270, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [26/375], Loss: 2.1976, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [27/375], Loss: 2.1991, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [28/375], Loss: 2.3299, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [19/50], Step [29/375], Loss: 2.2647, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [30/375], Loss: 2.1178, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [31/375], Loss: 2.2873, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [32/375], Loss: 2.1491, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [33/375], Loss: 2.3256, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [34/375], Loss: 2.1917, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [35/375], Loss: 2.2765, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [36/375], Loss: 2.3063, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [19/50], Step [37/375], Loss: 2.3663, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [38/375], Loss: 2.3948, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [39/375], Loss: 2.2396, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [40/375], Loss: 2.1722, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [19/50], Step [41/375], Loss: 2.2300, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [42/375], Loss: 2.1925, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [43/375], Loss: 2.0851, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [19/50], Step [44/375], Loss: 2.3324, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [19/50], Step [45/375], Loss: 2.1588, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [46/375], Loss: 2.3912, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [47/375], Loss: 2.2493, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [48/375], Loss: 2.0241, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [19/50], Step [49/375], Loss: 2.1324, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [50/375], Loss: 2.2770, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [51/375], Loss: 2.3550, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [52/375], Loss: 2.0907, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [19/50], Step [53/375], Loss: 2.2220, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [54/375], Loss: 2.1007, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [55/375], Loss: 2.2636, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [56/375], Loss: 2.2024, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [57/375], Loss: 2.2286, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [58/375], Loss: 2.1284, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [59/375], Loss: 2.2035, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [60/375], Loss: 2.3107, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [19/50], Step [61/375], Loss: 2.4254, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [62/375], Loss: 2.0913, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [63/375], Loss: 2.0713, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [64/375], Loss: 2.0641, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [65/375], Loss: 2.1407, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [66/375], Loss: 2.3671, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [67/375], Loss: 2.2663, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [68/375], Loss: 2.1807, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [69/375], Loss: 1.9977, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [19/50], Step [70/375], Loss: 2.1160, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [71/375], Loss: 2.1275, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [72/375], Loss: 1.9647, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [19/50], Step [73/375], Loss: 2.2507, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [74/375], Loss: 2.1664, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [75/375], Loss: 2.1334, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [76/375], Loss: 2.2632, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [77/375], Loss: 1.8671, batch time: 0.81, accuracy:  43.75%\n",
      "Epoch [19/50], Step [78/375], Loss: 2.3639, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [79/375], Loss: 2.6211, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [19/50], Step [80/375], Loss: 2.0356, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [19/50], Step [81/375], Loss: 2.1805, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [82/375], Loss: 2.2142, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [83/375], Loss: 2.0172, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [19/50], Step [84/375], Loss: 2.2442, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [85/375], Loss: 2.3324, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [86/375], Loss: 2.3597, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [19/50], Step [87/375], Loss: 2.3322, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [88/375], Loss: 2.3079, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [89/375], Loss: 2.1533, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [90/375], Loss: 2.1647, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [91/375], Loss: 2.4627, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [92/375], Loss: 2.1736, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [93/375], Loss: 2.0110, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [94/375], Loss: 2.2093, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [95/375], Loss: 2.2613, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [96/375], Loss: 2.2997, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [97/375], Loss: 2.1818, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [98/375], Loss: 2.2415, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [99/375], Loss: 2.3736, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [100/375], Loss: 2.0091, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [101/375], Loss: 2.1972, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [102/375], Loss: 2.2850, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [103/375], Loss: 2.2524, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [104/375], Loss: 2.2081, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [105/375], Loss: 2.3536, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [106/375], Loss: 2.4175, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [107/375], Loss: 2.2719, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [108/375], Loss: 2.1251, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [109/375], Loss: 2.2974, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [110/375], Loss: 2.3753, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [111/375], Loss: 2.1797, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [112/375], Loss: 2.3042, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [113/375], Loss: 2.3183, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [114/375], Loss: 2.1302, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [115/375], Loss: 2.4631, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [116/375], Loss: 2.3487, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [117/375], Loss: 2.3737, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [118/375], Loss: 2.2437, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [119/375], Loss: 2.3646, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [120/375], Loss: 2.1906, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [121/375], Loss: 2.2919, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [122/375], Loss: 2.3716, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [123/375], Loss: 2.3047, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [124/375], Loss: 2.1675, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [125/375], Loss: 2.2269, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [126/375], Loss: 2.3827, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [19/50], Step [127/375], Loss: 2.1047, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [128/375], Loss: 2.3796, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [129/375], Loss: 2.3309, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [130/375], Loss: 2.1771, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [131/375], Loss: 2.2176, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [132/375], Loss: 2.1295, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [133/375], Loss: 2.4069, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [134/375], Loss: 2.2891, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [135/375], Loss: 2.2921, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [136/375], Loss: 2.3077, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [137/375], Loss: 2.2329, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [138/375], Loss: 2.2885, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [19/50], Step [139/375], Loss: 2.3087, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [140/375], Loss: 2.2181, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [141/375], Loss: 2.1550, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [142/375], Loss: 2.2046, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [143/375], Loss: 2.0959, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [144/375], Loss: 2.3513, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [145/375], Loss: 2.1355, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [146/375], Loss: 2.1388, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [147/375], Loss: 2.1343, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [148/375], Loss: 2.1583, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [149/375], Loss: 2.2174, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [150/375], Loss: 1.9975, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [19/50], Step [151/375], Loss: 2.2877, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [152/375], Loss: 2.3813, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [153/375], Loss: 2.1854, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [154/375], Loss: 2.2466, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [155/375], Loss: 2.0137, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [156/375], Loss: 2.0865, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [157/375], Loss: 2.1940, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [158/375], Loss: 2.2360, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [159/375], Loss: 2.1837, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [160/375], Loss: 2.1661, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [161/375], Loss: 2.3709, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [162/375], Loss: 2.1911, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [163/375], Loss: 2.2829, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [164/375], Loss: 2.2876, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [165/375], Loss: 2.2372, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [166/375], Loss: 2.1582, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [167/375], Loss: 2.2013, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [168/375], Loss: 2.2406, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [169/375], Loss: 2.2528, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [170/375], Loss: 2.3978, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [171/375], Loss: 2.3757, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [172/375], Loss: 2.1350, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [173/375], Loss: 2.1977, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [174/375], Loss: 2.3473, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [175/375], Loss: 2.2663, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [176/375], Loss: 2.3806, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [177/375], Loss: 2.3879, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [178/375], Loss: 2.3594, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [19/50], Step [179/375], Loss: 2.1980, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [180/375], Loss: 2.3031, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [181/375], Loss: 2.3137, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [182/375], Loss: 2.0593, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [19/50], Step [183/375], Loss: 2.3513, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [184/375], Loss: 2.4639, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [185/375], Loss: 2.1700, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [186/375], Loss: 2.3603, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [187/375], Loss: 2.3883, batch time: 0.99, accuracy:  6.25%\n",
      "Epoch [19/50], Step [188/375], Loss: 2.2191, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [189/375], Loss: 2.2889, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [190/375], Loss: 2.1645, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [19/50], Step [191/375], Loss: 2.4228, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [192/375], Loss: 2.3140, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [193/375], Loss: 2.1681, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [19/50], Step [194/375], Loss: 2.2055, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [195/375], Loss: 2.3012, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [196/375], Loss: 2.2118, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [19/50], Step [197/375], Loss: 2.1641, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [198/375], Loss: 2.4253, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [199/375], Loss: 2.2475, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [200/375], Loss: 2.2745, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [19/50], Step [201/375], Loss: 2.3169, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [202/375], Loss: 2.1709, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [203/375], Loss: 2.3440, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [204/375], Loss: 2.0227, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [19/50], Step [205/375], Loss: 2.2994, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [206/375], Loss: 2.0923, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [207/375], Loss: 2.2484, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [208/375], Loss: 2.1828, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [209/375], Loss: 2.4558, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [210/375], Loss: 2.2772, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [211/375], Loss: 2.3328, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [212/375], Loss: 2.3663, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [19/50], Step [213/375], Loss: 2.1602, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [19/50], Step [214/375], Loss: 2.2504, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [215/375], Loss: 2.2095, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [216/375], Loss: 1.9768, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [19/50], Step [217/375], Loss: 2.3032, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [19/50], Step [218/375], Loss: 2.3939, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [219/375], Loss: 2.3089, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [220/375], Loss: 2.4657, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [19/50], Step [221/375], Loss: 2.1566, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [222/375], Loss: 2.3389, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [223/375], Loss: 2.2942, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [224/375], Loss: 2.1940, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [225/375], Loss: 2.1849, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [226/375], Loss: 2.2659, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [227/375], Loss: 2.3039, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [228/375], Loss: 2.0695, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [19/50], Step [229/375], Loss: 2.2285, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [230/375], Loss: 2.1423, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [231/375], Loss: 2.4292, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [232/375], Loss: 2.1012, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [233/375], Loss: 2.1171, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [234/375], Loss: 2.0920, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [235/375], Loss: 2.2100, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [236/375], Loss: 2.3735, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [237/375], Loss: 2.2450, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [238/375], Loss: 2.3394, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [239/375], Loss: 2.2010, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [240/375], Loss: 2.1047, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [19/50], Step [241/375], Loss: 2.1679, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [242/375], Loss: 2.2624, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [243/375], Loss: 1.9882, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [244/375], Loss: 2.2278, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [245/375], Loss: 2.4051, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [246/375], Loss: 2.1917, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [247/375], Loss: 2.2836, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [248/375], Loss: 2.3605, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [19/50], Step [249/375], Loss: 2.4469, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [250/375], Loss: 2.3525, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [251/375], Loss: 2.2760, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [252/375], Loss: 2.2635, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [19/50], Step [253/375], Loss: 2.1168, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [254/375], Loss: 2.2004, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [255/375], Loss: 2.3420, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [256/375], Loss: 2.1999, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [257/375], Loss: 2.0087, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [258/375], Loss: 2.3799, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [259/375], Loss: 2.2606, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [260/375], Loss: 2.1668, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [261/375], Loss: 2.2100, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [262/375], Loss: 2.2638, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [263/375], Loss: 2.2217, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [264/375], Loss: 2.2248, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [265/375], Loss: 2.3655, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [266/375], Loss: 2.2640, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [267/375], Loss: 2.2121, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [268/375], Loss: 2.1874, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [269/375], Loss: 2.2706, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [270/375], Loss: 2.1417, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [271/375], Loss: 2.1144, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [272/375], Loss: 2.1838, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [273/375], Loss: 2.1581, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [274/375], Loss: 2.2492, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [275/375], Loss: 2.3553, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [276/375], Loss: 2.2451, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [277/375], Loss: 2.3450, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [278/375], Loss: 2.3448, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [279/375], Loss: 2.2268, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [280/375], Loss: 2.1564, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [281/375], Loss: 2.1775, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [282/375], Loss: 2.2317, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [283/375], Loss: 2.4768, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [284/375], Loss: 2.0719, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [19/50], Step [285/375], Loss: 2.1390, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [286/375], Loss: 2.2208, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [287/375], Loss: 2.2921, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [288/375], Loss: 2.1054, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [19/50], Step [289/375], Loss: 2.2723, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [290/375], Loss: 2.2591, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [291/375], Loss: 2.3078, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [292/375], Loss: 2.3448, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [19/50], Step [293/375], Loss: 2.4348, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [294/375], Loss: 2.3748, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [295/375], Loss: 2.1793, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [296/375], Loss: 2.1904, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [19/50], Step [297/375], Loss: 2.4568, batch time: 0.88, accuracy:  6.25%\n",
      "Epoch [19/50], Step [298/375], Loss: 2.2292, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [299/375], Loss: 2.2715, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [300/375], Loss: 2.1500, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [19/50], Step [301/375], Loss: 2.1105, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [302/375], Loss: 2.3713, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [303/375], Loss: 2.1153, batch time: 0.29, accuracy:  37.50%\n",
      "Epoch [19/50], Step [304/375], Loss: 2.4259, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [19/50], Step [305/375], Loss: 2.2909, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [306/375], Loss: 2.3309, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [19/50], Step [307/375], Loss: 1.8870, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [19/50], Step [308/375], Loss: 2.1457, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [19/50], Step [309/375], Loss: 2.2657, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [310/375], Loss: 2.1010, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [19/50], Step [311/375], Loss: 2.3127, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [312/375], Loss: 2.2343, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [313/375], Loss: 2.2879, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [314/375], Loss: 2.1928, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [19/50], Step [315/375], Loss: 2.2585, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [316/375], Loss: 2.4026, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [317/375], Loss: 2.3189, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [318/375], Loss: 2.4173, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [19/50], Step [319/375], Loss: 2.3489, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [320/375], Loss: 2.0145, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [19/50], Step [321/375], Loss: 2.1842, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [322/375], Loss: 2.1603, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [323/375], Loss: 2.4726, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [324/375], Loss: 2.3074, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [325/375], Loss: 2.2593, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [19/50], Step [326/375], Loss: 1.9873, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [19/50], Step [327/375], Loss: 2.2265, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [19/50], Step [328/375], Loss: 2.1896, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [329/375], Loss: 2.3466, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [330/375], Loss: 2.1780, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [331/375], Loss: 2.3254, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [19/50], Step [332/375], Loss: 2.1887, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [333/375], Loss: 2.1130, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [334/375], Loss: 2.1911, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [335/375], Loss: 2.0377, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [336/375], Loss: 2.2662, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [337/375], Loss: 2.2883, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [338/375], Loss: 2.3796, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [19/50], Step [339/375], Loss: 2.4342, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [340/375], Loss: 2.1684, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [341/375], Loss: 2.1457, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [342/375], Loss: 2.1769, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [343/375], Loss: 2.3984, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [344/375], Loss: 2.2421, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [345/375], Loss: 2.1148, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [346/375], Loss: 2.2220, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [347/375], Loss: 2.4436, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [348/375], Loss: 2.0704, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [349/375], Loss: 2.2765, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [350/375], Loss: 2.3336, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [19/50], Step [351/375], Loss: 2.2325, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [352/375], Loss: 2.2353, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [353/375], Loss: 2.2593, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [354/375], Loss: 2.1861, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [355/375], Loss: 2.2307, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [356/375], Loss: 2.1473, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [19/50], Step [357/375], Loss: 2.2098, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [19/50], Step [358/375], Loss: 2.3723, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [359/375], Loss: 2.3836, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [360/375], Loss: 2.0843, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [361/375], Loss: 2.2527, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [362/375], Loss: 2.1458, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [363/375], Loss: 2.1906, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [364/375], Loss: 2.1719, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [19/50], Step [365/375], Loss: 2.2090, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [366/375], Loss: 2.2057, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [19/50], Step [367/375], Loss: 2.2857, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [19/50], Step [368/375], Loss: 2.4752, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [19/50], Step [369/375], Loss: 2.1214, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [370/375], Loss: 2.2188, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [19/50], Step [371/375], Loss: 2.1945, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [19/50], Step [372/375], Loss: 2.3159, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [19/50], Step [373/375], Loss: 2.3451, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [19/50], Step [374/375], Loss: 2.1685, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [19/50], Step [375/375], Loss: 2.0728, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [1/375], Loss: 2.3246, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [2/375], Loss: 2.0846, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [3/375], Loss: 2.4443, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [4/375], Loss: 2.2756, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [5/375], Loss: 2.1803, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [6/375], Loss: 2.0181, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [20/50], Step [7/375], Loss: 2.5041, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [20/50], Step [8/375], Loss: 2.3249, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [9/375], Loss: 2.1695, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [10/375], Loss: 2.1713, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [11/375], Loss: 2.2881, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [12/375], Loss: 2.1886, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [13/375], Loss: 2.4820, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [14/375], Loss: 2.2829, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [15/375], Loss: 2.2123, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [16/375], Loss: 2.2330, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [17/375], Loss: 2.4783, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [18/375], Loss: 2.3746, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [19/375], Loss: 2.2971, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [20/375], Loss: 2.2851, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [21/375], Loss: 2.0287, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [22/375], Loss: 2.2622, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [23/375], Loss: 2.1771, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [24/375], Loss: 2.3871, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [25/375], Loss: 2.3598, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [26/375], Loss: 2.4294, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [27/375], Loss: 2.3000, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [28/375], Loss: 2.1592, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [29/375], Loss: 2.2560, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [30/375], Loss: 2.3684, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [31/375], Loss: 2.2950, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [32/375], Loss: 2.2062, batch time: 0.91, accuracy:  25.00%\n",
      "Epoch [20/50], Step [33/375], Loss: 2.1903, batch time: 0.32, accuracy:  43.75%\n",
      "Epoch [20/50], Step [34/375], Loss: 2.2553, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [20/50], Step [35/375], Loss: 2.2058, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [20/50], Step [36/375], Loss: 2.2445, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [37/375], Loss: 2.2440, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [20/50], Step [38/375], Loss: 2.1814, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [20/50], Step [39/375], Loss: 2.0446, batch time: 0.34, accuracy:  43.75%\n",
      "Epoch [20/50], Step [40/375], Loss: 2.2566, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [20/50], Step [41/375], Loss: 2.2428, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [20/50], Step [42/375], Loss: 2.2183, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [20/50], Step [43/375], Loss: 2.3626, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [44/375], Loss: 2.1570, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [45/375], Loss: 2.1653, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [20/50], Step [46/375], Loss: 2.3513, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [47/375], Loss: 2.2754, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [48/375], Loss: 2.1736, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [20/50], Step [49/375], Loss: 2.4312, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [20/50], Step [50/375], Loss: 2.2336, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [51/375], Loss: 2.3119, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [52/375], Loss: 2.2918, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [53/375], Loss: 2.3759, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [20/50], Step [54/375], Loss: 2.2096, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [55/375], Loss: 2.2568, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [56/375], Loss: 2.1703, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [57/375], Loss: 2.2021, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [58/375], Loss: 2.2621, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [59/375], Loss: 1.9796, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [20/50], Step [60/375], Loss: 1.9922, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [20/50], Step [61/375], Loss: 2.3479, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [62/375], Loss: 2.2528, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [63/375], Loss: 2.2605, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [64/375], Loss: 2.2388, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [65/375], Loss: 2.1965, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [20/50], Step [66/375], Loss: 2.0895, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [20/50], Step [67/375], Loss: 2.2664, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [68/375], Loss: 2.1361, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [69/375], Loss: 2.4698, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [20/50], Step [70/375], Loss: 2.1905, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [71/375], Loss: 2.1444, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [72/375], Loss: 2.2580, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [73/375], Loss: 2.0152, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [20/50], Step [74/375], Loss: 2.1465, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [75/375], Loss: 2.2584, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [76/375], Loss: 2.3265, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [77/375], Loss: 2.2282, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [78/375], Loss: 2.2329, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [79/375], Loss: 2.1769, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [80/375], Loss: 2.2664, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [81/375], Loss: 2.1285, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [82/375], Loss: 2.0063, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [83/375], Loss: 2.0780, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [84/375], Loss: 2.2517, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [85/375], Loss: 1.9949, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [86/375], Loss: 2.3038, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [87/375], Loss: 2.2448, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [88/375], Loss: 2.2232, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [89/375], Loss: 2.2206, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [90/375], Loss: 2.4191, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [91/375], Loss: 2.3310, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [92/375], Loss: 2.3010, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [93/375], Loss: 2.2037, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [94/375], Loss: 2.2535, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [95/375], Loss: 2.4517, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [96/375], Loss: 2.4714, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [97/375], Loss: 2.1806, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [98/375], Loss: 2.3349, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [99/375], Loss: 2.4014, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [100/375], Loss: 2.3199, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [101/375], Loss: 2.3843, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [102/375], Loss: 2.2727, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [103/375], Loss: 2.3492, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [104/375], Loss: 2.1845, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [105/375], Loss: 1.9046, batch time: 0.26, accuracy:  62.50%\n",
      "Epoch [20/50], Step [106/375], Loss: 2.0995, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [107/375], Loss: 2.3182, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [108/375], Loss: 2.3651, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [109/375], Loss: 2.2005, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [110/375], Loss: 2.3990, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [111/375], Loss: 2.2850, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [112/375], Loss: 2.1136, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [113/375], Loss: 2.1965, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [114/375], Loss: 2.2635, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [115/375], Loss: 2.2996, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [116/375], Loss: 2.1656, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [117/375], Loss: 2.2422, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [118/375], Loss: 2.1557, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [119/375], Loss: 2.2121, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [120/375], Loss: 2.2557, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [121/375], Loss: 2.1975, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [122/375], Loss: 2.1657, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [123/375], Loss: 2.2951, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [124/375], Loss: 2.1787, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [125/375], Loss: 2.2192, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [126/375], Loss: 2.4050, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [127/375], Loss: 2.4884, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [128/375], Loss: 2.2609, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [129/375], Loss: 1.9793, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [20/50], Step [130/375], Loss: 2.1638, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [131/375], Loss: 2.2151, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [132/375], Loss: 2.2509, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [133/375], Loss: 2.1616, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [134/375], Loss: 2.0678, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [135/375], Loss: 2.1439, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [136/375], Loss: 2.3051, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [137/375], Loss: 2.2479, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [138/375], Loss: 2.1343, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [139/375], Loss: 2.1278, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [140/375], Loss: 2.1150, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [141/375], Loss: 2.3114, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [142/375], Loss: 2.1511, batch time: 0.92, accuracy:  25.00%\n",
      "Epoch [20/50], Step [143/375], Loss: 2.0769, batch time: 0.34, accuracy:  43.75%\n",
      "Epoch [20/50], Step [144/375], Loss: 2.2852, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [20/50], Step [145/375], Loss: 2.1157, batch time: 0.37, accuracy:  31.25%\n",
      "Epoch [20/50], Step [146/375], Loss: 2.3212, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [20/50], Step [147/375], Loss: 2.5227, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [20/50], Step [148/375], Loss: 2.2424, batch time: 0.38, accuracy:  18.75%\n",
      "Epoch [20/50], Step [149/375], Loss: 2.1597, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [20/50], Step [150/375], Loss: 2.1711, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [151/375], Loss: 2.2687, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [20/50], Step [152/375], Loss: 2.2631, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [153/375], Loss: 2.2782, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [154/375], Loss: 2.1796, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [155/375], Loss: 2.5520, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [20/50], Step [156/375], Loss: 2.1668, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [157/375], Loss: 2.3925, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [20/50], Step [158/375], Loss: 2.3447, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [159/375], Loss: 2.2467, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [20/50], Step [160/375], Loss: 2.3037, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [161/375], Loss: 2.2653, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [162/375], Loss: 2.2476, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [20/50], Step [163/375], Loss: 2.2548, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [20/50], Step [164/375], Loss: 2.2964, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [165/375], Loss: 2.3613, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [166/375], Loss: 2.2136, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [167/375], Loss: 2.1207, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [168/375], Loss: 2.3184, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [169/375], Loss: 2.1787, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [170/375], Loss: 2.3389, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [171/375], Loss: 2.1738, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [20/50], Step [172/375], Loss: 2.1998, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [173/375], Loss: 2.0789, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [174/375], Loss: 2.0469, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [175/375], Loss: 2.2626, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [176/375], Loss: 2.2770, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [177/375], Loss: 2.2353, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [178/375], Loss: 2.2432, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [179/375], Loss: 2.3835, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [20/50], Step [180/375], Loss: 1.9138, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [181/375], Loss: 2.1565, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [182/375], Loss: 2.0399, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [183/375], Loss: 2.3272, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [184/375], Loss: 2.2218, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [185/375], Loss: 2.2089, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [186/375], Loss: 2.1826, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [187/375], Loss: 2.3425, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [188/375], Loss: 2.1060, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [189/375], Loss: 2.2974, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [190/375], Loss: 2.4402, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [191/375], Loss: 2.2851, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [192/375], Loss: 2.2481, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [193/375], Loss: 2.2062, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [194/375], Loss: 2.2409, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [195/375], Loss: 2.1961, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [20/50], Step [196/375], Loss: 2.3102, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [197/375], Loss: 2.1336, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [198/375], Loss: 2.3530, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [199/375], Loss: 2.1800, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [200/375], Loss: 2.5299, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [201/375], Loss: 2.3713, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [202/375], Loss: 2.1466, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [203/375], Loss: 2.2811, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [204/375], Loss: 2.2578, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [205/375], Loss: 2.1451, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [206/375], Loss: 2.2495, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [207/375], Loss: 2.2475, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [20/50], Step [208/375], Loss: 2.2264, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [209/375], Loss: 2.4642, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [210/375], Loss: 2.1177, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [211/375], Loss: 2.1821, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [212/375], Loss: 2.1195, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [213/375], Loss: 2.1956, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [214/375], Loss: 2.2308, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [215/375], Loss: 2.3307, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [216/375], Loss: 2.2024, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [217/375], Loss: 2.3866, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [218/375], Loss: 2.2485, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [219/375], Loss: 2.1346, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [220/375], Loss: 2.2313, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [221/375], Loss: 2.1052, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [222/375], Loss: 2.3241, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [223/375], Loss: 2.4321, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [20/50], Step [224/375], Loss: 2.3741, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [225/375], Loss: 2.1749, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [226/375], Loss: 2.2978, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [227/375], Loss: 2.2421, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [228/375], Loss: 2.3768, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [229/375], Loss: 2.2295, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [230/375], Loss: 2.2010, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [231/375], Loss: 2.3000, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [20/50], Step [232/375], Loss: 2.3878, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [233/375], Loss: 2.2140, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [234/375], Loss: 2.2939, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [235/375], Loss: 2.2770, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [236/375], Loss: 2.1424, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [20/50], Step [237/375], Loss: 2.1319, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [20/50], Step [238/375], Loss: 2.4439, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [239/375], Loss: 2.2611, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [240/375], Loss: 2.3816, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [241/375], Loss: 2.1393, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [242/375], Loss: 2.3520, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [243/375], Loss: 2.1792, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [244/375], Loss: 2.0372, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [245/375], Loss: 2.2625, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [246/375], Loss: 2.0910, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [247/375], Loss: 2.4147, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [248/375], Loss: 2.1684, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [249/375], Loss: 2.0383, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [250/375], Loss: 2.1677, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [251/375], Loss: 2.1567, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [252/375], Loss: 2.3457, batch time: 0.81, accuracy:  18.75%\n",
      "Epoch [20/50], Step [253/375], Loss: 2.2463, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [254/375], Loss: 2.2290, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [255/375], Loss: 2.1583, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [20/50], Step [256/375], Loss: 2.3187, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [257/375], Loss: 2.0742, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [258/375], Loss: 2.2388, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [20/50], Step [259/375], Loss: 2.1701, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [260/375], Loss: 2.0873, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [20/50], Step [261/375], Loss: 2.1459, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [20/50], Step [262/375], Loss: 2.3923, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [263/375], Loss: 2.2942, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [264/375], Loss: 2.1254, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [265/375], Loss: 2.1019, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [20/50], Step [266/375], Loss: 2.3361, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [267/375], Loss: 2.3078, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [268/375], Loss: 2.3118, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [20/50], Step [269/375], Loss: 2.1687, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [20/50], Step [270/375], Loss: 2.2797, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [271/375], Loss: 2.2202, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [272/375], Loss: 2.0729, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [273/375], Loss: 2.1581, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [20/50], Step [274/375], Loss: 1.7979, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [20/50], Step [275/375], Loss: 2.4009, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [276/375], Loss: 2.2264, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [20/50], Step [277/375], Loss: 2.3348, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [278/375], Loss: 2.1521, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [279/375], Loss: 2.2791, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [280/375], Loss: 2.3920, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [281/375], Loss: 2.3335, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [282/375], Loss: 2.3423, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [283/375], Loss: 2.0073, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [284/375], Loss: 2.0984, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [285/375], Loss: 2.1695, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [20/50], Step [286/375], Loss: 2.5679, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [287/375], Loss: 2.2124, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [288/375], Loss: 2.0913, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [289/375], Loss: 2.1523, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [290/375], Loss: 2.3227, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [291/375], Loss: 2.2928, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [292/375], Loss: 2.0633, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [293/375], Loss: 2.2516, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [294/375], Loss: 2.3535, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [295/375], Loss: 2.2056, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [296/375], Loss: 2.1371, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [297/375], Loss: 2.4446, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [298/375], Loss: 2.0604, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [299/375], Loss: 2.3885, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [300/375], Loss: 2.3552, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [301/375], Loss: 2.2029, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [302/375], Loss: 2.2350, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [303/375], Loss: 2.3968, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [304/375], Loss: 2.3264, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [305/375], Loss: 2.0813, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [20/50], Step [306/375], Loss: 2.3118, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [307/375], Loss: 2.1509, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [308/375], Loss: 2.2696, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [309/375], Loss: 2.0739, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [20/50], Step [310/375], Loss: 2.0258, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [311/375], Loss: 2.3681, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [312/375], Loss: 2.3311, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [313/375], Loss: 2.2903, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [20/50], Step [314/375], Loss: 2.2757, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [315/375], Loss: 2.3763, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [316/375], Loss: 2.2075, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [317/375], Loss: 2.1966, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [20/50], Step [318/375], Loss: 2.1790, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [319/375], Loss: 2.1435, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [320/375], Loss: 2.3841, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [321/375], Loss: 2.3731, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [20/50], Step [322/375], Loss: 2.1373, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [323/375], Loss: 2.4098, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [20/50], Step [324/375], Loss: 2.1080, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [325/375], Loss: 2.2520, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [20/50], Step [326/375], Loss: 2.3291, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [327/375], Loss: 2.4895, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [328/375], Loss: 2.2109, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [20/50], Step [329/375], Loss: 2.1697, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [20/50], Step [330/375], Loss: 2.1561, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [331/375], Loss: 2.2401, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [332/375], Loss: 2.0919, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [333/375], Loss: 2.1050, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [20/50], Step [334/375], Loss: 2.2396, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [335/375], Loss: 2.0115, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [20/50], Step [336/375], Loss: 2.4175, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [337/375], Loss: 2.2719, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [20/50], Step [338/375], Loss: 2.1988, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [339/375], Loss: 2.2766, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [340/375], Loss: 2.4204, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [341/375], Loss: 2.1997, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [20/50], Step [342/375], Loss: 2.0060, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [20/50], Step [343/375], Loss: 2.3291, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [344/375], Loss: 2.4628, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [345/375], Loss: 2.2103, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [346/375], Loss: 2.3807, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [347/375], Loss: 2.3958, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [348/375], Loss: 2.3580, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [349/375], Loss: 2.4210, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [20/50], Step [350/375], Loss: 2.1854, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [351/375], Loss: 2.3862, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [20/50], Step [352/375], Loss: 1.9848, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [353/375], Loss: 2.1492, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [20/50], Step [354/375], Loss: 2.3451, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [355/375], Loss: 2.2591, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [356/375], Loss: 2.3113, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [20/50], Step [357/375], Loss: 1.9551, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [20/50], Step [358/375], Loss: 2.0865, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [20/50], Step [359/375], Loss: 2.3036, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [360/375], Loss: 2.4430, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [20/50], Step [361/375], Loss: 2.0669, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [20/50], Step [362/375], Loss: 2.3349, batch time: 0.82, accuracy:  6.25%\n",
      "Epoch [20/50], Step [363/375], Loss: 2.3258, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [364/375], Loss: 2.2544, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [365/375], Loss: 2.1297, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [20/50], Step [366/375], Loss: 2.1300, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [20/50], Step [367/375], Loss: 2.4167, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [368/375], Loss: 2.3177, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [20/50], Step [369/375], Loss: 2.2684, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [370/375], Loss: 2.3303, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [20/50], Step [371/375], Loss: 2.3876, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [20/50], Step [372/375], Loss: 2.2900, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [20/50], Step [373/375], Loss: 2.2598, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [374/375], Loss: 2.2296, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [20/50], Step [375/375], Loss: 2.1588, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [21/50], Step [1/375], Loss: 2.3600, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [2/375], Loss: 2.0089, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [3/375], Loss: 2.2609, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [4/375], Loss: 2.0994, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [21/50], Step [5/375], Loss: 2.4265, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [6/375], Loss: 2.2128, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [7/375], Loss: 2.2560, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [8/375], Loss: 2.2418, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [9/375], Loss: 2.3450, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [10/375], Loss: 2.1577, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [11/375], Loss: 2.2134, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [12/375], Loss: 2.3530, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [21/50], Step [13/375], Loss: 2.2279, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [14/375], Loss: 2.3079, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [15/375], Loss: 2.2998, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [16/375], Loss: 2.3184, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [17/375], Loss: 2.5199, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [18/375], Loss: 2.3043, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [19/375], Loss: 2.0994, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [20/375], Loss: 2.1579, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [21/375], Loss: 2.2267, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [22/375], Loss: 2.2951, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [23/375], Loss: 2.3850, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [24/375], Loss: 2.3355, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [21/50], Step [25/375], Loss: 2.3183, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [26/375], Loss: 2.2299, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [27/375], Loss: 2.2549, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [28/375], Loss: 2.1827, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [29/375], Loss: 2.2018, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [30/375], Loss: 2.2776, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [31/375], Loss: 2.2236, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [32/375], Loss: 2.3391, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [33/375], Loss: 2.3311, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [34/375], Loss: 2.2411, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [35/375], Loss: 2.1423, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [36/375], Loss: 2.3404, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [37/375], Loss: 2.2926, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [38/375], Loss: 2.2912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [39/375], Loss: 2.4426, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [40/375], Loss: 2.1122, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [21/50], Step [41/375], Loss: 2.2560, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [42/375], Loss: 2.2793, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [43/375], Loss: 2.2373, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [44/375], Loss: 2.1828, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [21/50], Step [45/375], Loss: 2.3235, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [21/50], Step [46/375], Loss: 2.2603, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [47/375], Loss: 2.1983, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [48/375], Loss: 2.2701, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [49/375], Loss: 2.3216, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [50/375], Loss: 2.2476, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [51/375], Loss: 2.2380, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [52/375], Loss: 2.1950, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [53/375], Loss: 2.2353, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [54/375], Loss: 2.2112, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [55/375], Loss: 2.2545, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [56/375], Loss: 2.1579, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [57/375], Loss: 2.2530, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [58/375], Loss: 2.2930, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [59/375], Loss: 2.0753, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [21/50], Step [60/375], Loss: 2.1659, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [61/375], Loss: 2.3432, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [62/375], Loss: 2.1065, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [63/375], Loss: 2.4107, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [64/375], Loss: 2.2949, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [65/375], Loss: 2.3250, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [66/375], Loss: 2.0459, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [67/375], Loss: 2.0910, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [68/375], Loss: 2.2121, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [69/375], Loss: 2.2605, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [70/375], Loss: 2.3047, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [71/375], Loss: 2.1806, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [72/375], Loss: 2.2223, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [73/375], Loss: 2.0110, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [74/375], Loss: 2.1359, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [75/375], Loss: 2.3581, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [76/375], Loss: 2.3267, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [77/375], Loss: 2.1524, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [78/375], Loss: 2.1979, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [79/375], Loss: 2.3962, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [80/375], Loss: 2.3315, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [81/375], Loss: 2.2304, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [82/375], Loss: 2.1433, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [83/375], Loss: 2.2540, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [84/375], Loss: 2.3185, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [21/50], Step [85/375], Loss: 2.3878, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [86/375], Loss: 2.0370, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [87/375], Loss: 2.1946, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [88/375], Loss: 2.0125, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [21/50], Step [89/375], Loss: 2.3029, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [90/375], Loss: 2.2923, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [91/375], Loss: 2.0525, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [92/375], Loss: 2.0783, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [93/375], Loss: 2.0704, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [94/375], Loss: 2.2268, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [95/375], Loss: 2.1897, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [96/375], Loss: 2.3380, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [97/375], Loss: 2.1890, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [21/50], Step [98/375], Loss: 2.1334, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [99/375], Loss: 2.2147, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [100/375], Loss: 2.1251, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [21/50], Step [101/375], Loss: 1.9664, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [21/50], Step [102/375], Loss: 2.4823, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [103/375], Loss: 2.3834, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [21/50], Step [104/375], Loss: 2.3253, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [105/375], Loss: 1.9764, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [106/375], Loss: 2.2061, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [21/50], Step [107/375], Loss: 2.3165, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [108/375], Loss: 2.2061, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [109/375], Loss: 2.1920, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [110/375], Loss: 2.2464, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [111/375], Loss: 2.3216, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [112/375], Loss: 2.1703, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [113/375], Loss: 2.0922, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [114/375], Loss: 2.1854, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [115/375], Loss: 2.1404, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [116/375], Loss: 2.1682, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [117/375], Loss: 2.1370, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [118/375], Loss: 2.1044, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [21/50], Step [119/375], Loss: 2.2361, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [120/375], Loss: 2.3693, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [21/50], Step [121/375], Loss: 2.2423, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [122/375], Loss: 2.2892, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [123/375], Loss: 2.3184, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [124/375], Loss: 2.3292, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [125/375], Loss: 2.1190, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [126/375], Loss: 2.4232, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [21/50], Step [127/375], Loss: 2.1449, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [128/375], Loss: 2.2087, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [129/375], Loss: 2.1860, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [130/375], Loss: 2.2722, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [131/375], Loss: 2.3512, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [132/375], Loss: 2.5330, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [21/50], Step [133/375], Loss: 2.2929, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [134/375], Loss: 2.1919, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [135/375], Loss: 2.1365, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [136/375], Loss: 2.3008, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [137/375], Loss: 2.1814, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [138/375], Loss: 2.1399, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [139/375], Loss: 2.2759, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [140/375], Loss: 2.2449, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [141/375], Loss: 2.2701, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [142/375], Loss: 2.1975, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [143/375], Loss: 2.1521, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [144/375], Loss: 2.2449, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [145/375], Loss: 2.1887, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [146/375], Loss: 2.1736, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [147/375], Loss: 2.2000, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [148/375], Loss: 2.3754, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [149/375], Loss: 2.3160, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [150/375], Loss: 2.0872, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [21/50], Step [151/375], Loss: 2.2307, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [152/375], Loss: 2.0906, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [153/375], Loss: 2.1903, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [154/375], Loss: 2.4930, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [155/375], Loss: 2.2832, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [156/375], Loss: 2.1428, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [157/375], Loss: 2.1134, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [158/375], Loss: 2.4114, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [159/375], Loss: 2.2767, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [160/375], Loss: 2.4624, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [161/375], Loss: 2.2047, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [162/375], Loss: 2.2958, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [163/375], Loss: 2.3699, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [164/375], Loss: 2.2159, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [165/375], Loss: 2.2637, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [166/375], Loss: 2.1314, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [21/50], Step [167/375], Loss: 2.1638, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [168/375], Loss: 2.1885, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [169/375], Loss: 2.3183, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [170/375], Loss: 2.0269, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [21/50], Step [171/375], Loss: 2.3976, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [172/375], Loss: 2.2566, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [173/375], Loss: 2.2640, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [174/375], Loss: 2.0618, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [175/375], Loss: 2.2641, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [176/375], Loss: 2.1933, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [177/375], Loss: 2.4305, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [178/375], Loss: 2.4178, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [179/375], Loss: 2.3461, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [180/375], Loss: 2.1854, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [181/375], Loss: 2.2096, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [182/375], Loss: 2.1545, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [21/50], Step [183/375], Loss: 2.2902, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [184/375], Loss: 2.3240, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [185/375], Loss: 2.1342, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [186/375], Loss: 2.1719, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [187/375], Loss: 2.3243, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [188/375], Loss: 2.2034, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [189/375], Loss: 2.2492, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [190/375], Loss: 2.0520, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [21/50], Step [191/375], Loss: 2.2669, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [192/375], Loss: 2.2170, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [193/375], Loss: 2.3552, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [194/375], Loss: 2.0089, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [21/50], Step [195/375], Loss: 2.3119, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [21/50], Step [196/375], Loss: 2.0115, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [21/50], Step [197/375], Loss: 1.9521, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [21/50], Step [198/375], Loss: 2.2618, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [199/375], Loss: 2.3182, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [200/375], Loss: 2.6398, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [21/50], Step [201/375], Loss: 2.3608, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [202/375], Loss: 2.2372, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [203/375], Loss: 2.2852, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [204/375], Loss: 2.2093, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [205/375], Loss: 2.2855, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [206/375], Loss: 2.0766, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [207/375], Loss: 2.3724, batch time: 0.82, accuracy:  18.75%\n",
      "Epoch [21/50], Step [208/375], Loss: 2.3091, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [209/375], Loss: 2.2236, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [210/375], Loss: 2.2696, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [21/50], Step [211/375], Loss: 2.1634, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [212/375], Loss: 2.2823, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [213/375], Loss: 2.3533, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [21/50], Step [214/375], Loss: 2.5319, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [215/375], Loss: 2.3228, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [216/375], Loss: 2.2549, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [21/50], Step [217/375], Loss: 2.2504, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [218/375], Loss: 2.1741, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [219/375], Loss: 2.1082, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [220/375], Loss: 2.0103, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [21/50], Step [221/375], Loss: 2.1742, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [222/375], Loss: 2.2284, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [223/375], Loss: 2.2320, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [224/375], Loss: 2.2975, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [225/375], Loss: 2.3565, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [226/375], Loss: 2.2230, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [227/375], Loss: 2.3072, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [228/375], Loss: 2.2679, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [21/50], Step [229/375], Loss: 2.3193, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [230/375], Loss: 2.0628, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [231/375], Loss: 1.9527, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [21/50], Step [232/375], Loss: 2.3074, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [233/375], Loss: 2.3354, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [234/375], Loss: 2.3057, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [235/375], Loss: 2.3364, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [236/375], Loss: 2.2434, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [237/375], Loss: 2.4503, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [238/375], Loss: 2.3129, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [239/375], Loss: 2.4331, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [240/375], Loss: 2.2598, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [241/375], Loss: 2.3114, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [242/375], Loss: 2.3028, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [243/375], Loss: 2.2182, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [244/375], Loss: 2.0525, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [21/50], Step [245/375], Loss: 2.3029, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [246/375], Loss: 2.2468, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [247/375], Loss: 2.1792, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [248/375], Loss: 2.3567, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [21/50], Step [249/375], Loss: 2.2293, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [250/375], Loss: 2.0696, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [251/375], Loss: 2.2560, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [252/375], Loss: 2.3430, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [253/375], Loss: 2.2075, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [254/375], Loss: 2.2495, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [255/375], Loss: 2.1517, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [21/50], Step [256/375], Loss: 2.0887, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [21/50], Step [257/375], Loss: 2.1038, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [258/375], Loss: 2.1424, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [259/375], Loss: 2.3294, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [260/375], Loss: 2.2903, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [261/375], Loss: 2.2127, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [262/375], Loss: 2.2928, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [263/375], Loss: 2.1725, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [264/375], Loss: 2.0465, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [21/50], Step [265/375], Loss: 2.2602, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [266/375], Loss: 2.2482, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [267/375], Loss: 2.0186, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [21/50], Step [268/375], Loss: 2.1517, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [269/375], Loss: 2.3217, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [270/375], Loss: 2.3306, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [271/375], Loss: 2.1896, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [272/375], Loss: 2.3907, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [273/375], Loss: 2.0938, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [274/375], Loss: 2.2992, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [275/375], Loss: 2.2720, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [276/375], Loss: 2.4329, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [21/50], Step [277/375], Loss: 2.3247, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [278/375], Loss: 2.3499, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [279/375], Loss: 2.3765, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [280/375], Loss: 2.0778, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [21/50], Step [281/375], Loss: 2.1528, batch time: 0.35, accuracy:  31.25%\n",
      "Epoch [21/50], Step [282/375], Loss: 2.2693, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [21/50], Step [283/375], Loss: 2.2540, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [21/50], Step [284/375], Loss: 2.2627, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [21/50], Step [285/375], Loss: 2.2611, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [21/50], Step [286/375], Loss: 2.2173, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [21/50], Step [287/375], Loss: 2.0391, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [21/50], Step [288/375], Loss: 2.1886, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [21/50], Step [289/375], Loss: 2.2596, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [290/375], Loss: 2.0949, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [291/375], Loss: 2.2410, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [292/375], Loss: 2.3541, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [21/50], Step [293/375], Loss: 2.4335, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [21/50], Step [294/375], Loss: 2.2217, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [295/375], Loss: 2.2101, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [296/375], Loss: 2.3785, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [297/375], Loss: 2.2014, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [298/375], Loss: 2.4676, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [21/50], Step [299/375], Loss: 2.3104, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [300/375], Loss: 2.2574, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [301/375], Loss: 2.3585, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [302/375], Loss: 2.4597, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [21/50], Step [303/375], Loss: 2.3033, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [304/375], Loss: 2.2412, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [305/375], Loss: 2.3735, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [306/375], Loss: 2.2565, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [307/375], Loss: 2.1926, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [308/375], Loss: 2.2124, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [309/375], Loss: 2.3522, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [310/375], Loss: 2.1804, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [311/375], Loss: 2.2105, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [21/50], Step [312/375], Loss: 2.1834, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [21/50], Step [313/375], Loss: 2.1361, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [314/375], Loss: 2.2614, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [315/375], Loss: 2.2751, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [316/375], Loss: 2.2878, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [317/375], Loss: 2.2114, batch time: 0.82, accuracy:  18.75%\n",
      "Epoch [21/50], Step [318/375], Loss: 2.2695, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [319/375], Loss: 2.2747, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [320/375], Loss: 2.2702, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [21/50], Step [321/375], Loss: 2.2677, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [322/375], Loss: 2.3043, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [323/375], Loss: 2.2960, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [21/50], Step [324/375], Loss: 2.1489, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [325/375], Loss: 2.2903, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [326/375], Loss: 2.3022, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [21/50], Step [327/375], Loss: 2.2408, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [328/375], Loss: 2.2400, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [329/375], Loss: 2.3447, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [21/50], Step [330/375], Loss: 2.2617, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [21/50], Step [331/375], Loss: 2.0579, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [21/50], Step [332/375], Loss: 2.2023, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [333/375], Loss: 2.0544, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [334/375], Loss: 2.3432, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [21/50], Step [335/375], Loss: 2.0755, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [336/375], Loss: 2.0779, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [337/375], Loss: 2.1789, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [338/375], Loss: 2.4338, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [21/50], Step [339/375], Loss: 2.0420, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [340/375], Loss: 2.2116, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [341/375], Loss: 2.3326, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [342/375], Loss: 2.1679, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [21/50], Step [343/375], Loss: 2.2246, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [344/375], Loss: 2.3260, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [21/50], Step [345/375], Loss: 2.2608, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [346/375], Loss: 2.0291, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [21/50], Step [347/375], Loss: 2.4604, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [348/375], Loss: 2.2881, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [349/375], Loss: 2.2230, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [350/375], Loss: 2.2724, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [351/375], Loss: 2.3650, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [21/50], Step [352/375], Loss: 2.2769, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [353/375], Loss: 1.9620, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [21/50], Step [354/375], Loss: 2.2175, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [21/50], Step [355/375], Loss: 2.2740, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [356/375], Loss: 2.1899, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [21/50], Step [357/375], Loss: 2.2425, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [21/50], Step [358/375], Loss: 2.3023, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [21/50], Step [359/375], Loss: 2.3249, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [21/50], Step [360/375], Loss: 2.0847, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [361/375], Loss: 2.3190, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [362/375], Loss: 2.2056, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [363/375], Loss: 2.1460, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [21/50], Step [364/375], Loss: 2.1707, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [365/375], Loss: 2.0049, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [366/375], Loss: 2.3031, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [21/50], Step [367/375], Loss: 2.2784, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [21/50], Step [368/375], Loss: 2.2965, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [369/375], Loss: 2.1561, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [21/50], Step [370/375], Loss: 2.1666, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [371/375], Loss: 2.0178, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [21/50], Step [372/375], Loss: 2.2768, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [21/50], Step [373/375], Loss: 2.2616, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [21/50], Step [374/375], Loss: 2.1331, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [21/50], Step [375/375], Loss: 2.2735, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [1/375], Loss: 2.1442, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [2/375], Loss: 2.2731, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [3/375], Loss: 2.3063, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [4/375], Loss: 2.4830, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [5/375], Loss: 2.3094, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [6/375], Loss: 2.2128, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [7/375], Loss: 2.4763, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [8/375], Loss: 2.3727, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [9/375], Loss: 2.1832, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [10/375], Loss: 2.1606, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [11/375], Loss: 2.3109, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [12/375], Loss: 2.2810, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [13/375], Loss: 2.2631, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [14/375], Loss: 2.0026, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [15/375], Loss: 2.3055, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [16/375], Loss: 2.1509, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [22/50], Step [17/375], Loss: 2.2013, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [22/50], Step [18/375], Loss: 2.0656, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [22/50], Step [19/375], Loss: 2.4903, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [22/50], Step [20/375], Loss: 2.3569, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [22/50], Step [21/375], Loss: 2.2967, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [22/50], Step [22/375], Loss: 2.3518, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [22/50], Step [23/375], Loss: 2.1504, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [22/50], Step [24/375], Loss: 2.0355, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [22/50], Step [25/375], Loss: 2.2412, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [26/375], Loss: 2.2321, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [27/375], Loss: 2.3274, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [28/375], Loss: 2.3997, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [29/375], Loss: 2.2658, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [30/375], Loss: 2.3156, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [31/375], Loss: 2.3057, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [32/375], Loss: 2.2615, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [33/375], Loss: 2.0622, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [34/375], Loss: 2.3180, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [35/375], Loss: 2.1601, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [36/375], Loss: 2.2939, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [37/375], Loss: 2.1787, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [38/375], Loss: 2.3772, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [39/375], Loss: 2.3640, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [40/375], Loss: 2.5285, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [41/375], Loss: 2.2735, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [42/375], Loss: 2.2332, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [43/375], Loss: 2.4110, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [44/375], Loss: 2.2363, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [45/375], Loss: 1.9961, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [46/375], Loss: 2.2893, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [47/375], Loss: 2.1927, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [48/375], Loss: 2.3535, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [49/375], Loss: 2.2072, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [50/375], Loss: 2.2968, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [51/375], Loss: 2.2386, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [52/375], Loss: 2.0767, batch time: 0.82, accuracy:  31.25%\n",
      "Epoch [22/50], Step [53/375], Loss: 2.2018, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [54/375], Loss: 2.1674, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [55/375], Loss: 2.1812, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [22/50], Step [56/375], Loss: 2.2584, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [57/375], Loss: 2.1369, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [58/375], Loss: 2.2501, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [22/50], Step [59/375], Loss: 2.2733, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [60/375], Loss: 2.2174, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [61/375], Loss: 2.3166, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [22/50], Step [62/375], Loss: 2.2853, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [63/375], Loss: 2.1536, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [64/375], Loss: 2.2355, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [65/375], Loss: 2.1141, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [22/50], Step [66/375], Loss: 2.4425, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [22/50], Step [67/375], Loss: 2.1999, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [68/375], Loss: 2.2545, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [69/375], Loss: 2.2368, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [70/375], Loss: 2.0125, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [71/375], Loss: 2.2591, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [72/375], Loss: 2.2941, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [73/375], Loss: 2.1816, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [74/375], Loss: 2.2593, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [75/375], Loss: 2.0935, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [76/375], Loss: 2.2809, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [77/375], Loss: 2.2195, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [78/375], Loss: 2.3948, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [79/375], Loss: 2.1748, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [80/375], Loss: 2.0611, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [81/375], Loss: 2.4244, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [82/375], Loss: 2.1367, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [83/375], Loss: 2.2178, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [84/375], Loss: 2.1689, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [85/375], Loss: 2.4222, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [86/375], Loss: 2.2407, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [87/375], Loss: 2.0347, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [22/50], Step [88/375], Loss: 2.2169, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [89/375], Loss: 2.4875, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [90/375], Loss: 2.3743, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [91/375], Loss: 2.1584, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [92/375], Loss: 2.1992, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [93/375], Loss: 2.4238, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [94/375], Loss: 2.3737, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [95/375], Loss: 2.2870, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [96/375], Loss: 2.4083, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [97/375], Loss: 2.2625, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [98/375], Loss: 2.4292, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [99/375], Loss: 2.3267, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [100/375], Loss: 2.2607, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [101/375], Loss: 2.3222, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [102/375], Loss: 2.2983, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [103/375], Loss: 2.3398, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [104/375], Loss: 2.2624, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [105/375], Loss: 2.1793, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [106/375], Loss: 2.2540, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [107/375], Loss: 2.2271, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [108/375], Loss: 2.2309, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [109/375], Loss: 2.2735, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [110/375], Loss: 2.3888, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [111/375], Loss: 2.2985, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [112/375], Loss: 2.2193, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [113/375], Loss: 2.4234, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [114/375], Loss: 2.1671, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [115/375], Loss: 2.3261, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [116/375], Loss: 2.2599, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [117/375], Loss: 2.1276, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [118/375], Loss: 2.2075, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [119/375], Loss: 2.0749, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [120/375], Loss: 2.2885, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [121/375], Loss: 2.2902, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [122/375], Loss: 2.3464, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [123/375], Loss: 2.3786, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [124/375], Loss: 2.1800, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [125/375], Loss: 2.3189, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [126/375], Loss: 2.1622, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [127/375], Loss: 2.2988, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [128/375], Loss: 2.3724, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [129/375], Loss: 2.2980, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [130/375], Loss: 2.0515, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [131/375], Loss: 2.2207, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [132/375], Loss: 2.0490, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [22/50], Step [133/375], Loss: 2.1861, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [134/375], Loss: 2.3754, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [135/375], Loss: 2.2684, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [136/375], Loss: 2.2456, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [137/375], Loss: 2.2485, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [138/375], Loss: 2.2913, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [139/375], Loss: 2.2801, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [140/375], Loss: 2.0235, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [22/50], Step [141/375], Loss: 2.1316, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [142/375], Loss: 2.1881, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [143/375], Loss: 2.1864, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [144/375], Loss: 2.1608, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [145/375], Loss: 2.3155, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [146/375], Loss: 2.2889, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [147/375], Loss: 2.0101, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [148/375], Loss: 2.3392, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [149/375], Loss: 2.2588, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [150/375], Loss: 2.1680, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [151/375], Loss: 2.2309, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [152/375], Loss: 2.2556, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [153/375], Loss: 2.2060, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [154/375], Loss: 2.3641, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [155/375], Loss: 2.0584, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [156/375], Loss: 2.0209, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [157/375], Loss: 2.2753, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [158/375], Loss: 2.2719, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [159/375], Loss: 2.2159, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [160/375], Loss: 2.2496, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [161/375], Loss: 2.2600, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [162/375], Loss: 2.2060, batch time: 0.82, accuracy:  25.00%\n",
      "Epoch [22/50], Step [163/375], Loss: 2.3773, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [22/50], Step [164/375], Loss: 1.9053, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [22/50], Step [165/375], Loss: 2.4645, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [22/50], Step [166/375], Loss: 2.0128, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [167/375], Loss: 2.0617, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [22/50], Step [168/375], Loss: 2.2610, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [22/50], Step [169/375], Loss: 2.0421, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [170/375], Loss: 2.3842, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [171/375], Loss: 2.3910, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [22/50], Step [172/375], Loss: 2.1545, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [173/375], Loss: 2.3338, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [174/375], Loss: 2.3953, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [175/375], Loss: 2.2802, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [22/50], Step [176/375], Loss: 2.2628, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [177/375], Loss: 2.4957, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [22/50], Step [178/375], Loss: 2.5429, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [22/50], Step [179/375], Loss: 2.3432, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [180/375], Loss: 2.2408, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [181/375], Loss: 2.3378, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [182/375], Loss: 2.2192, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [183/375], Loss: 2.0921, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [184/375], Loss: 2.3387, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [185/375], Loss: 2.0688, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [22/50], Step [186/375], Loss: 2.2051, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [187/375], Loss: 2.1753, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [188/375], Loss: 2.2118, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [189/375], Loss: 2.2584, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [190/375], Loss: 2.1815, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [191/375], Loss: 2.3769, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [192/375], Loss: 2.1484, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [193/375], Loss: 2.2184, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [194/375], Loss: 2.2105, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [195/375], Loss: 2.3166, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [196/375], Loss: 2.1046, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [22/50], Step [197/375], Loss: 2.2765, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [198/375], Loss: 2.3938, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [199/375], Loss: 2.3028, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [200/375], Loss: 2.2277, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [201/375], Loss: 2.1773, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [202/375], Loss: 2.1893, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [203/375], Loss: 2.1619, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [204/375], Loss: 2.3099, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [22/50], Step [205/375], Loss: 2.2299, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [206/375], Loss: 2.3468, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [207/375], Loss: 2.1864, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [208/375], Loss: 2.1618, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [209/375], Loss: 2.2677, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [210/375], Loss: 2.1635, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [211/375], Loss: 2.2963, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [212/375], Loss: 2.3891, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [213/375], Loss: 2.2227, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [214/375], Loss: 2.2567, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [215/375], Loss: 2.1582, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [216/375], Loss: 2.3214, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [22/50], Step [217/375], Loss: 2.1292, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [218/375], Loss: 2.2058, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [219/375], Loss: 2.3489, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [220/375], Loss: 2.4148, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [221/375], Loss: 1.8936, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [22/50], Step [222/375], Loss: 2.2888, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [223/375], Loss: 2.1272, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [22/50], Step [224/375], Loss: 2.4216, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [225/375], Loss: 2.1396, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [226/375], Loss: 2.4132, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [227/375], Loss: 2.3028, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [228/375], Loss: 2.1350, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [229/375], Loss: 2.3933, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [230/375], Loss: 2.0553, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [231/375], Loss: 2.1796, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [232/375], Loss: 2.3431, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [233/375], Loss: 2.2074, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [234/375], Loss: 2.4829, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [235/375], Loss: 2.0770, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [22/50], Step [236/375], Loss: 2.2873, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [237/375], Loss: 2.2393, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [238/375], Loss: 2.3226, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [239/375], Loss: 2.0935, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [240/375], Loss: 2.1287, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [241/375], Loss: 2.3605, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [242/375], Loss: 2.2377, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [243/375], Loss: 2.2566, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [244/375], Loss: 2.2253, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [245/375], Loss: 2.1839, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [246/375], Loss: 2.1700, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [247/375], Loss: 2.3796, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [248/375], Loss: 2.3769, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [249/375], Loss: 2.3173, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [250/375], Loss: 2.3022, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [251/375], Loss: 2.2875, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [252/375], Loss: 2.2251, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [253/375], Loss: 2.1953, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [254/375], Loss: 2.0784, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [255/375], Loss: 2.3148, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [256/375], Loss: 2.2248, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [257/375], Loss: 2.2428, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [258/375], Loss: 2.2609, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [259/375], Loss: 2.3991, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [260/375], Loss: 2.3216, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [261/375], Loss: 2.2026, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [262/375], Loss: 2.2573, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [263/375], Loss: 2.2163, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [264/375], Loss: 2.3389, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [265/375], Loss: 2.1441, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [266/375], Loss: 2.3345, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [267/375], Loss: 2.3452, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [22/50], Step [268/375], Loss: 2.2479, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [269/375], Loss: 2.1220, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [270/375], Loss: 2.2823, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [271/375], Loss: 2.1397, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [22/50], Step [272/375], Loss: 2.2302, batch time: 0.82, accuracy:  12.50%\n",
      "Epoch [22/50], Step [273/375], Loss: 2.2014, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [274/375], Loss: 2.2330, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [275/375], Loss: 2.2028, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [22/50], Step [276/375], Loss: 2.2065, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [277/375], Loss: 2.1248, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [278/375], Loss: 2.0987, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [22/50], Step [279/375], Loss: 2.2656, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [280/375], Loss: 2.1325, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [22/50], Step [281/375], Loss: 2.2488, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [22/50], Step [282/375], Loss: 2.2255, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [283/375], Loss: 2.3038, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [284/375], Loss: 2.1800, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [285/375], Loss: 2.2051, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [22/50], Step [286/375], Loss: 2.1924, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [287/375], Loss: 2.2406, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [288/375], Loss: 2.3122, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [289/375], Loss: 2.2852, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [290/375], Loss: 2.2117, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [291/375], Loss: 2.1790, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [292/375], Loss: 2.1108, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [293/375], Loss: 2.0725, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [22/50], Step [294/375], Loss: 2.2205, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [295/375], Loss: 2.1872, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [296/375], Loss: 2.2979, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [297/375], Loss: 2.1741, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [22/50], Step [298/375], Loss: 2.3120, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [299/375], Loss: 2.1546, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [300/375], Loss: 2.0536, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [301/375], Loss: 2.3088, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [22/50], Step [302/375], Loss: 2.1312, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [303/375], Loss: 2.1136, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [22/50], Step [304/375], Loss: 2.4576, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [305/375], Loss: 2.2991, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [22/50], Step [306/375], Loss: 2.3046, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [307/375], Loss: 2.0780, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [308/375], Loss: 2.2445, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [309/375], Loss: 2.2681, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [22/50], Step [310/375], Loss: 2.3351, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [311/375], Loss: 2.2252, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [312/375], Loss: 2.4256, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [22/50], Step [313/375], Loss: 2.3565, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [22/50], Step [314/375], Loss: 2.1964, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [315/375], Loss: 2.1097, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [316/375], Loss: 2.2326, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [317/375], Loss: 2.2328, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [318/375], Loss: 2.1632, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [319/375], Loss: 2.1254, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [320/375], Loss: 2.2938, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [321/375], Loss: 2.2325, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [322/375], Loss: 2.4254, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [22/50], Step [323/375], Loss: 2.3460, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [324/375], Loss: 2.3982, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [325/375], Loss: 2.3400, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [326/375], Loss: 2.1150, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [22/50], Step [327/375], Loss: 2.2346, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [328/375], Loss: 2.1840, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [329/375], Loss: 2.1660, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [22/50], Step [330/375], Loss: 2.3110, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [331/375], Loss: 2.1642, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [332/375], Loss: 2.2549, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [333/375], Loss: 2.0501, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [22/50], Step [334/375], Loss: 2.2862, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [335/375], Loss: 2.1436, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [336/375], Loss: 2.1769, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [337/375], Loss: 2.1384, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [338/375], Loss: 2.3970, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [339/375], Loss: 1.9944, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [340/375], Loss: 2.1997, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [341/375], Loss: 2.2287, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [22/50], Step [342/375], Loss: 1.8449, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [22/50], Step [343/375], Loss: 2.3130, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [344/375], Loss: 2.2448, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [345/375], Loss: 2.2093, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [22/50], Step [346/375], Loss: 2.4007, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [347/375], Loss: 2.0908, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [348/375], Loss: 2.4214, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [22/50], Step [349/375], Loss: 2.3338, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [22/50], Step [350/375], Loss: 2.1164, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [351/375], Loss: 2.2997, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [22/50], Step [352/375], Loss: 2.3527, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [353/375], Loss: 2.3619, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [22/50], Step [354/375], Loss: 2.5049, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [22/50], Step [355/375], Loss: 2.2806, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [356/375], Loss: 2.1264, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [357/375], Loss: 2.1232, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [22/50], Step [358/375], Loss: 2.2567, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [22/50], Step [359/375], Loss: 2.2230, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [360/375], Loss: 2.0713, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [22/50], Step [361/375], Loss: 1.9417, batch time: 0.26, accuracy:  50.00%\n",
      "Epoch [22/50], Step [362/375], Loss: 2.1675, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [363/375], Loss: 2.2433, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [22/50], Step [364/375], Loss: 2.1745, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [22/50], Step [365/375], Loss: 2.2733, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [22/50], Step [366/375], Loss: 2.0824, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [22/50], Step [367/375], Loss: 2.1616, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [22/50], Step [368/375], Loss: 2.1504, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [22/50], Step [369/375], Loss: 2.1194, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [22/50], Step [370/375], Loss: 2.1516, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [371/375], Loss: 2.3958, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [372/375], Loss: 2.2303, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [22/50], Step [373/375], Loss: 2.3219, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [22/50], Step [374/375], Loss: 2.1408, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [22/50], Step [375/375], Loss: 2.0991, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [1/375], Loss: 2.0606, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [2/375], Loss: 2.2194, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [3/375], Loss: 2.2611, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [4/375], Loss: 2.3074, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [5/375], Loss: 2.1659, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [6/375], Loss: 2.3411, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [7/375], Loss: 2.0545, batch time: 0.97, accuracy:  37.50%\n",
      "Epoch [23/50], Step [8/375], Loss: 2.2244, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [9/375], Loss: 2.1597, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [10/375], Loss: 1.9997, batch time: 0.30, accuracy:  43.75%\n",
      "Epoch [23/50], Step [11/375], Loss: 2.1592, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [12/375], Loss: 2.2340, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [13/375], Loss: 2.2823, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [23/50], Step [14/375], Loss: 2.0034, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [15/375], Loss: 2.3233, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [16/375], Loss: 2.3610, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [23/50], Step [17/375], Loss: 2.1596, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [18/375], Loss: 2.1457, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [19/375], Loss: 2.3935, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [20/375], Loss: 2.4501, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [21/375], Loss: 2.2610, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [22/375], Loss: 2.4520, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [23/375], Loss: 2.2366, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [24/375], Loss: 2.3906, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [25/375], Loss: 2.4061, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [26/375], Loss: 2.1277, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [27/375], Loss: 2.1888, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [28/375], Loss: 2.1511, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [29/375], Loss: 2.1617, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [30/375], Loss: 2.5529, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [23/50], Step [31/375], Loss: 2.1241, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [32/375], Loss: 2.1327, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [33/375], Loss: 2.3631, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [34/375], Loss: 2.2733, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [35/375], Loss: 2.2074, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [36/375], Loss: 2.3136, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [37/375], Loss: 2.2203, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [38/375], Loss: 2.1781, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [39/375], Loss: 2.2645, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [40/375], Loss: 2.1680, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [41/375], Loss: 2.2910, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [42/375], Loss: 2.2289, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [43/375], Loss: 2.2679, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [44/375], Loss: 2.2629, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [45/375], Loss: 2.2132, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [46/375], Loss: 2.2893, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [47/375], Loss: 2.1581, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [48/375], Loss: 2.1674, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [23/50], Step [49/375], Loss: 2.1934, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [50/375], Loss: 2.2755, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [51/375], Loss: 2.0667, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [23/50], Step [52/375], Loss: 2.3662, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [53/375], Loss: 2.1147, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [54/375], Loss: 2.1427, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [55/375], Loss: 2.2416, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [56/375], Loss: 2.2540, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [57/375], Loss: 2.3084, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [58/375], Loss: 2.2739, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [59/375], Loss: 2.5197, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [60/375], Loss: 2.2603, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [61/375], Loss: 2.1843, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [62/375], Loss: 2.2637, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [63/375], Loss: 2.1995, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [64/375], Loss: 2.2744, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [65/375], Loss: 2.1925, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [66/375], Loss: 2.3384, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [67/375], Loss: 2.3152, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [68/375], Loss: 2.3160, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [69/375], Loss: 2.1510, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [70/375], Loss: 2.1411, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [71/375], Loss: 2.3127, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [72/375], Loss: 2.2905, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [23/50], Step [73/375], Loss: 2.2861, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [74/375], Loss: 2.1292, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [75/375], Loss: 2.1521, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [76/375], Loss: 2.0901, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [77/375], Loss: 2.2989, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [78/375], Loss: 2.0465, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [79/375], Loss: 2.1726, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [80/375], Loss: 2.4336, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [81/375], Loss: 2.0485, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [23/50], Step [82/375], Loss: 2.6997, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [83/375], Loss: 2.3356, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [84/375], Loss: 2.2782, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [85/375], Loss: 2.2396, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [86/375], Loss: 2.4312, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [87/375], Loss: 2.3561, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [88/375], Loss: 2.2348, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [89/375], Loss: 2.3304, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [90/375], Loss: 2.2383, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [91/375], Loss: 2.3265, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [92/375], Loss: 2.4282, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [23/50], Step [93/375], Loss: 2.3082, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [94/375], Loss: 2.1616, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [95/375], Loss: 2.2587, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [96/375], Loss: 2.2208, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [97/375], Loss: 2.2075, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [98/375], Loss: 2.2198, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [99/375], Loss: 2.2501, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [100/375], Loss: 2.3253, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [101/375], Loss: 2.1273, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [23/50], Step [102/375], Loss: 2.2003, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [103/375], Loss: 2.3171, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [104/375], Loss: 2.2256, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [105/375], Loss: 2.2666, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [106/375], Loss: 2.3938, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [107/375], Loss: 2.3074, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [108/375], Loss: 2.1639, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [109/375], Loss: 2.0669, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [110/375], Loss: 2.1998, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [111/375], Loss: 2.3548, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [112/375], Loss: 2.2139, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [113/375], Loss: 2.3354, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [114/375], Loss: 2.1136, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [115/375], Loss: 2.1424, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [116/375], Loss: 2.2975, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [23/50], Step [117/375], Loss: 2.3357, batch time: 0.83, accuracy:  6.25%\n",
      "Epoch [23/50], Step [118/375], Loss: 2.4008, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [119/375], Loss: 2.3482, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [120/375], Loss: 2.0246, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [23/50], Step [121/375], Loss: 2.2499, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [122/375], Loss: 2.1235, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [123/375], Loss: 2.2450, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [23/50], Step [124/375], Loss: 2.2376, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [125/375], Loss: 2.2916, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [126/375], Loss: 2.1520, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [23/50], Step [127/375], Loss: 2.2148, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [128/375], Loss: 2.1735, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [129/375], Loss: 2.2332, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [130/375], Loss: 2.3663, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [23/50], Step [131/375], Loss: 2.1987, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [132/375], Loss: 2.0979, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [133/375], Loss: 2.1932, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [134/375], Loss: 2.3196, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [135/375], Loss: 2.2143, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [136/375], Loss: 2.0829, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [137/375], Loss: 2.3792, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [138/375], Loss: 2.1924, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [139/375], Loss: 2.2578, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [140/375], Loss: 2.2737, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [141/375], Loss: 2.4458, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [142/375], Loss: 2.2077, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [143/375], Loss: 2.1842, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [144/375], Loss: 2.0104, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [145/375], Loss: 2.3047, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [146/375], Loss: 2.1488, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [147/375], Loss: 2.1270, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [148/375], Loss: 2.0282, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [149/375], Loss: 2.3512, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [150/375], Loss: 2.1684, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [151/375], Loss: 2.4079, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [152/375], Loss: 2.4988, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [153/375], Loss: 2.2752, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [154/375], Loss: 2.2186, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [155/375], Loss: 2.1881, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [156/375], Loss: 2.1810, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [157/375], Loss: 2.1728, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [158/375], Loss: 2.1908, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [159/375], Loss: 2.2613, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [160/375], Loss: 2.1270, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [161/375], Loss: 2.1306, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [162/375], Loss: 2.3851, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [23/50], Step [163/375], Loss: 2.2955, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [164/375], Loss: 2.2634, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [165/375], Loss: 2.3461, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [166/375], Loss: 2.2535, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [167/375], Loss: 2.2678, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [168/375], Loss: 2.2950, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [169/375], Loss: 2.2064, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [170/375], Loss: 2.1645, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [171/375], Loss: 2.2989, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [172/375], Loss: 2.1779, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [173/375], Loss: 2.1936, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [174/375], Loss: 2.2333, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [175/375], Loss: 2.2876, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [176/375], Loss: 2.3959, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [177/375], Loss: 2.0989, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [178/375], Loss: 2.2884, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [179/375], Loss: 2.3383, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [180/375], Loss: 2.3988, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [181/375], Loss: 2.3618, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [182/375], Loss: 2.2085, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [183/375], Loss: 2.4194, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [184/375], Loss: 2.3931, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [185/375], Loss: 2.2510, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [186/375], Loss: 2.2387, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [187/375], Loss: 2.3326, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [188/375], Loss: 2.1602, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [189/375], Loss: 2.2748, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [190/375], Loss: 2.1825, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [191/375], Loss: 2.4684, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [192/375], Loss: 2.0761, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [193/375], Loss: 2.1432, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [194/375], Loss: 2.3010, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [195/375], Loss: 2.2109, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [196/375], Loss: 2.2291, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [197/375], Loss: 2.2438, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [198/375], Loss: 2.2378, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [23/50], Step [199/375], Loss: 2.2587, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [200/375], Loss: 2.2760, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [201/375], Loss: 2.2012, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [202/375], Loss: 2.0945, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [23/50], Step [203/375], Loss: 2.1819, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [204/375], Loss: 2.3223, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [205/375], Loss: 2.2605, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [206/375], Loss: 2.1140, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [207/375], Loss: 2.1362, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [23/50], Step [208/375], Loss: 2.2194, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [209/375], Loss: 2.2908, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [210/375], Loss: 2.0784, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [211/375], Loss: 2.2290, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [212/375], Loss: 2.2878, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [213/375], Loss: 2.1238, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [214/375], Loss: 2.1102, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [215/375], Loss: 2.0291, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [216/375], Loss: 2.2073, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [217/375], Loss: 2.0696, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [218/375], Loss: 2.3413, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [23/50], Step [219/375], Loss: 2.2328, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [220/375], Loss: 1.9916, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [221/375], Loss: 2.1296, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [222/375], Loss: 2.1576, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [223/375], Loss: 2.4634, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [224/375], Loss: 2.5587, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [225/375], Loss: 2.1639, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [226/375], Loss: 2.1762, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [227/375], Loss: 2.2411, batch time: 1.00, accuracy:  18.75%\n",
      "Epoch [23/50], Step [228/375], Loss: 2.3270, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [229/375], Loss: 2.1032, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [230/375], Loss: 2.3430, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [23/50], Step [231/375], Loss: 2.3392, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [232/375], Loss: 2.1849, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [233/375], Loss: 2.3009, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [23/50], Step [234/375], Loss: 2.1292, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [235/375], Loss: 2.2114, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [236/375], Loss: 2.2989, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [23/50], Step [237/375], Loss: 2.2059, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [238/375], Loss: 2.0687, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [239/375], Loss: 2.1335, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [240/375], Loss: 2.1615, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [23/50], Step [241/375], Loss: 2.3199, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [242/375], Loss: 2.3782, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [243/375], Loss: 2.2588, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [244/375], Loss: 2.2435, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [245/375], Loss: 2.2036, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [246/375], Loss: 2.4186, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [247/375], Loss: 2.2738, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [248/375], Loss: 2.1181, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [23/50], Step [249/375], Loss: 2.4203, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [23/50], Step [250/375], Loss: 2.2727, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [251/375], Loss: 2.4130, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [252/375], Loss: 1.9742, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [23/50], Step [253/375], Loss: 2.2838, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [254/375], Loss: 2.4040, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [255/375], Loss: 2.1133, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [256/375], Loss: 2.2704, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [23/50], Step [257/375], Loss: 2.2919, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [258/375], Loss: 2.1617, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [259/375], Loss: 2.3498, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [260/375], Loss: 2.2208, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [261/375], Loss: 2.2668, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [262/375], Loss: 2.0011, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [263/375], Loss: 2.2231, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [264/375], Loss: 2.2396, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [265/375], Loss: 2.2333, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [266/375], Loss: 2.3335, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [267/375], Loss: 2.1724, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [268/375], Loss: 2.2317, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [269/375], Loss: 2.1208, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [270/375], Loss: 2.2773, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [271/375], Loss: 2.1459, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [272/375], Loss: 2.4376, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [273/375], Loss: 2.2000, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [274/375], Loss: 2.2181, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [275/375], Loss: 2.1633, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [276/375], Loss: 2.4162, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [23/50], Step [277/375], Loss: 2.3754, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [278/375], Loss: 2.2336, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [279/375], Loss: 2.3253, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [280/375], Loss: 2.2186, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [281/375], Loss: 2.3050, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [282/375], Loss: 2.1146, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [283/375], Loss: 2.2501, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [284/375], Loss: 2.2985, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [285/375], Loss: 2.4040, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [286/375], Loss: 2.1256, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [287/375], Loss: 2.0735, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [288/375], Loss: 2.2570, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [289/375], Loss: 2.3652, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [290/375], Loss: 2.2863, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [291/375], Loss: 2.3290, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [292/375], Loss: 2.1185, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [23/50], Step [293/375], Loss: 2.3194, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [294/375], Loss: 2.1451, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [295/375], Loss: 2.2899, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [296/375], Loss: 2.2862, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [23/50], Step [297/375], Loss: 2.0180, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [298/375], Loss: 2.1874, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [299/375], Loss: 2.1675, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [300/375], Loss: 2.3964, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [301/375], Loss: 2.2167, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [302/375], Loss: 2.0882, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [303/375], Loss: 2.3585, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [23/50], Step [304/375], Loss: 2.3536, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [305/375], Loss: 2.2771, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [306/375], Loss: 2.2199, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [307/375], Loss: 2.3510, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [308/375], Loss: 2.3273, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [309/375], Loss: 2.2424, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [310/375], Loss: 2.2087, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [311/375], Loss: 2.2902, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [312/375], Loss: 2.1977, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [313/375], Loss: 2.1715, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [314/375], Loss: 2.1638, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [315/375], Loss: 2.2291, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [316/375], Loss: 2.0611, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [317/375], Loss: 2.1909, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [318/375], Loss: 2.1835, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [319/375], Loss: 2.3279, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [320/375], Loss: 2.1337, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [321/375], Loss: 2.3571, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [322/375], Loss: 2.1584, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [323/375], Loss: 2.2750, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [324/375], Loss: 2.2049, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [23/50], Step [325/375], Loss: 2.2328, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [326/375], Loss: 2.3367, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [327/375], Loss: 2.2171, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [328/375], Loss: 2.2053, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [329/375], Loss: 2.2568, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [23/50], Step [330/375], Loss: 2.2223, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [331/375], Loss: 2.3201, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [332/375], Loss: 2.1472, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [23/50], Step [333/375], Loss: 2.2316, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [23/50], Step [334/375], Loss: 2.2834, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [23/50], Step [335/375], Loss: 2.0534, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [336/375], Loss: 2.2308, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [337/375], Loss: 1.9733, batch time: 0.85, accuracy:  43.75%\n",
      "Epoch [23/50], Step [338/375], Loss: 2.2976, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [339/375], Loss: 2.3457, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [340/375], Loss: 2.3665, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [23/50], Step [341/375], Loss: 2.0256, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [23/50], Step [342/375], Loss: 2.0718, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [23/50], Step [343/375], Loss: 2.2475, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [23/50], Step [344/375], Loss: 2.4213, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [345/375], Loss: 2.2002, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [346/375], Loss: 2.1081, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [23/50], Step [347/375], Loss: 1.9189, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [348/375], Loss: 2.2156, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [349/375], Loss: 2.1993, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [350/375], Loss: 2.3829, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [23/50], Step [351/375], Loss: 2.3857, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [352/375], Loss: 1.9914, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [353/375], Loss: 2.3635, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [354/375], Loss: 2.2897, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [355/375], Loss: 2.4783, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [356/375], Loss: 2.2310, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [357/375], Loss: 2.0410, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [23/50], Step [358/375], Loss: 2.0734, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [23/50], Step [359/375], Loss: 2.0214, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [23/50], Step [360/375], Loss: 2.1865, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [23/50], Step [361/375], Loss: 2.1774, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [362/375], Loss: 2.2843, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [23/50], Step [363/375], Loss: 2.2881, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [364/375], Loss: 2.3225, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [23/50], Step [365/375], Loss: 2.2376, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [366/375], Loss: 2.2790, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [23/50], Step [367/375], Loss: 2.5345, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [23/50], Step [368/375], Loss: 2.0245, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [23/50], Step [369/375], Loss: 2.3482, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [370/375], Loss: 2.1550, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [23/50], Step [371/375], Loss: 2.2306, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [23/50], Step [372/375], Loss: 2.2350, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [23/50], Step [373/375], Loss: 2.1652, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [23/50], Step [374/375], Loss: 2.2540, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [23/50], Step [375/375], Loss: 2.1535, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [1/375], Loss: 2.0546, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [2/375], Loss: 2.0875, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [3/375], Loss: 2.1182, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [4/375], Loss: 2.0808, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [5/375], Loss: 2.3832, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [24/50], Step [6/375], Loss: 2.1438, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [7/375], Loss: 2.2615, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [8/375], Loss: 2.4644, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [9/375], Loss: 2.3279, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [24/50], Step [10/375], Loss: 2.3290, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [11/375], Loss: 2.3802, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [12/375], Loss: 2.1067, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [13/375], Loss: 2.3692, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [14/375], Loss: 2.0803, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [15/375], Loss: 2.1936, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [16/375], Loss: 1.9748, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [24/50], Step [17/375], Loss: 2.2168, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [18/375], Loss: 2.1501, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [19/375], Loss: 2.1684, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [20/375], Loss: 1.9906, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [21/375], Loss: 2.4436, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [22/375], Loss: 2.3704, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [23/375], Loss: 2.4839, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [24/375], Loss: 2.2357, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [25/375], Loss: 2.0046, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [26/375], Loss: 2.0519, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [27/375], Loss: 2.1883, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [28/375], Loss: 2.3094, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [29/375], Loss: 2.1316, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [30/375], Loss: 2.1574, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [31/375], Loss: 2.1000, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [32/375], Loss: 2.1212, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [33/375], Loss: 2.3490, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [34/375], Loss: 2.2584, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [35/375], Loss: 2.2009, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [36/375], Loss: 2.0397, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [37/375], Loss: 2.4293, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [38/375], Loss: 2.3695, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [39/375], Loss: 2.4070, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [24/50], Step [40/375], Loss: 2.3837, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [41/375], Loss: 2.3524, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [42/375], Loss: 2.2840, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [43/375], Loss: 2.2439, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [44/375], Loss: 2.3210, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [45/375], Loss: 2.3607, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [46/375], Loss: 2.2253, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [47/375], Loss: 2.2764, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [48/375], Loss: 2.0311, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [49/375], Loss: 2.3527, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [50/375], Loss: 2.2566, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [51/375], Loss: 2.2269, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [52/375], Loss: 2.2886, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [53/375], Loss: 2.1508, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [54/375], Loss: 2.3695, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [24/50], Step [55/375], Loss: 2.2224, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [56/375], Loss: 2.3942, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [57/375], Loss: 1.9672, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [58/375], Loss: 2.2523, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [59/375], Loss: 2.2529, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [60/375], Loss: 2.0564, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [61/375], Loss: 2.2365, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [62/375], Loss: 2.1725, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [63/375], Loss: 2.2339, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [64/375], Loss: 2.1888, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [65/375], Loss: 2.2665, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [66/375], Loss: 2.3881, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [67/375], Loss: 2.0993, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [68/375], Loss: 2.4186, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [69/375], Loss: 2.1328, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [70/375], Loss: 2.2900, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [71/375], Loss: 2.3328, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [72/375], Loss: 2.1439, batch time: 1.00, accuracy:  25.00%\n",
      "Epoch [24/50], Step [73/375], Loss: 2.2240, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [74/375], Loss: 2.1269, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [75/375], Loss: 2.0111, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [24/50], Step [76/375], Loss: 2.3628, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [77/375], Loss: 2.1442, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [78/375], Loss: 2.1035, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [24/50], Step [79/375], Loss: 2.2554, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [80/375], Loss: 2.3671, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [81/375], Loss: 2.1266, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [24/50], Step [82/375], Loss: 2.1611, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [83/375], Loss: 2.1265, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [84/375], Loss: 2.2952, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [85/375], Loss: 2.4326, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [86/375], Loss: 2.1513, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [87/375], Loss: 2.1658, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [88/375], Loss: 2.1255, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [89/375], Loss: 2.2516, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [24/50], Step [90/375], Loss: 2.3175, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [91/375], Loss: 1.9774, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [92/375], Loss: 2.3063, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [93/375], Loss: 2.0857, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [94/375], Loss: 2.0695, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [95/375], Loss: 2.1389, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [96/375], Loss: 2.2398, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [97/375], Loss: 2.0825, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [98/375], Loss: 2.1019, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [99/375], Loss: 1.9729, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [24/50], Step [100/375], Loss: 2.5103, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [101/375], Loss: 2.3485, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [102/375], Loss: 2.0399, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [103/375], Loss: 2.3215, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [104/375], Loss: 1.9096, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [105/375], Loss: 2.3101, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [106/375], Loss: 2.3362, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [107/375], Loss: 2.0629, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [108/375], Loss: 2.2415, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [109/375], Loss: 2.0335, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [110/375], Loss: 2.2699, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [111/375], Loss: 2.2524, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [112/375], Loss: 2.1276, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [113/375], Loss: 2.1983, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [114/375], Loss: 2.1992, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [115/375], Loss: 2.3882, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [116/375], Loss: 2.1180, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [117/375], Loss: 2.3501, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [118/375], Loss: 2.2285, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [119/375], Loss: 2.1825, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [120/375], Loss: 2.3773, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [121/375], Loss: 2.3714, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [122/375], Loss: 2.1388, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [123/375], Loss: 2.1660, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [124/375], Loss: 2.1489, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [125/375], Loss: 2.1249, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [24/50], Step [126/375], Loss: 2.4050, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [127/375], Loss: 2.0810, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [128/375], Loss: 2.3250, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [129/375], Loss: 2.2915, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [130/375], Loss: 2.2726, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [131/375], Loss: 2.3759, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [132/375], Loss: 2.0332, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [24/50], Step [133/375], Loss: 2.0855, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [134/375], Loss: 2.4893, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [135/375], Loss: 2.1687, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [136/375], Loss: 2.1434, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [137/375], Loss: 2.4569, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [138/375], Loss: 2.3423, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [139/375], Loss: 2.2100, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [140/375], Loss: 2.2851, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [141/375], Loss: 2.1263, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [24/50], Step [142/375], Loss: 2.3269, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [24/50], Step [143/375], Loss: 2.2650, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [144/375], Loss: 2.2013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [145/375], Loss: 2.2796, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [146/375], Loss: 2.1362, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [147/375], Loss: 2.2683, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [148/375], Loss: 2.3657, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [149/375], Loss: 2.1249, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [150/375], Loss: 2.2536, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [151/375], Loss: 2.2582, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [152/375], Loss: 2.0475, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [153/375], Loss: 2.2905, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [154/375], Loss: 2.1468, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [155/375], Loss: 2.3620, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [156/375], Loss: 2.4503, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [157/375], Loss: 2.2858, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [158/375], Loss: 2.3161, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [159/375], Loss: 2.2577, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [160/375], Loss: 2.3278, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [161/375], Loss: 2.1747, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [162/375], Loss: 2.2706, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [163/375], Loss: 2.2074, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [164/375], Loss: 2.1927, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [165/375], Loss: 2.1321, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [24/50], Step [166/375], Loss: 2.3164, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [167/375], Loss: 2.3156, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [168/375], Loss: 2.1815, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [169/375], Loss: 2.3841, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [170/375], Loss: 2.2447, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [171/375], Loss: 2.3402, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [172/375], Loss: 2.3934, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [24/50], Step [173/375], Loss: 2.1644, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [174/375], Loss: 2.4830, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [175/375], Loss: 2.2393, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [176/375], Loss: 2.2154, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [177/375], Loss: 2.2183, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [178/375], Loss: 2.1712, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [179/375], Loss: 2.1802, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [180/375], Loss: 2.1029, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [181/375], Loss: 2.1773, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [24/50], Step [182/375], Loss: 2.2248, batch time: 0.82, accuracy:  25.00%\n",
      "Epoch [24/50], Step [183/375], Loss: 2.1463, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [184/375], Loss: 2.1934, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [185/375], Loss: 2.2965, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [24/50], Step [186/375], Loss: 2.2013, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [187/375], Loss: 2.2606, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [188/375], Loss: 2.0459, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [24/50], Step [189/375], Loss: 2.2767, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [190/375], Loss: 2.4150, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [191/375], Loss: 2.2376, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [24/50], Step [192/375], Loss: 2.3321, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [193/375], Loss: 2.3309, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [194/375], Loss: 2.2227, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [195/375], Loss: 2.1977, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [24/50], Step [196/375], Loss: 2.2003, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [197/375], Loss: 2.2385, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [198/375], Loss: 2.2437, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [199/375], Loss: 2.2427, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [200/375], Loss: 2.3238, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [201/375], Loss: 2.2604, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [24/50], Step [202/375], Loss: 2.2269, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [203/375], Loss: 2.3305, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [24/50], Step [204/375], Loss: 2.3851, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [205/375], Loss: 2.3805, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [206/375], Loss: 2.2513, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [207/375], Loss: 2.2311, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [208/375], Loss: 2.2646, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [209/375], Loss: 2.2995, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [210/375], Loss: 2.2694, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [211/375], Loss: 2.1143, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [24/50], Step [212/375], Loss: 2.3647, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [213/375], Loss: 2.2372, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [214/375], Loss: 2.2231, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [215/375], Loss: 2.0983, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [216/375], Loss: 2.2667, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [217/375], Loss: 2.3205, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [218/375], Loss: 2.1677, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [24/50], Step [219/375], Loss: 2.2483, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [220/375], Loss: 2.2959, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [221/375], Loss: 2.0347, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [222/375], Loss: 2.2840, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [223/375], Loss: 2.4548, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [224/375], Loss: 2.3395, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [225/375], Loss: 2.2017, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [226/375], Loss: 2.3452, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [227/375], Loss: 2.1290, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [228/375], Loss: 2.3788, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [229/375], Loss: 2.1786, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [230/375], Loss: 2.4576, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [231/375], Loss: 2.2432, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [232/375], Loss: 2.2372, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [233/375], Loss: 2.2824, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [234/375], Loss: 2.3435, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [235/375], Loss: 2.2541, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [236/375], Loss: 2.2440, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [237/375], Loss: 2.2663, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [238/375], Loss: 2.3782, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [24/50], Step [239/375], Loss: 2.0301, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [24/50], Step [240/375], Loss: 2.1657, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [241/375], Loss: 2.2444, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [242/375], Loss: 2.2283, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [243/375], Loss: 2.3587, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [244/375], Loss: 2.2443, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [245/375], Loss: 2.1449, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [246/375], Loss: 2.2054, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [247/375], Loss: 2.2302, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [248/375], Loss: 2.1964, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [249/375], Loss: 2.0986, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [250/375], Loss: 2.0426, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [251/375], Loss: 2.3190, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [252/375], Loss: 2.2407, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [253/375], Loss: 2.2194, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [254/375], Loss: 2.3006, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [255/375], Loss: 2.2723, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [256/375], Loss: 2.4143, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [257/375], Loss: 2.3263, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [258/375], Loss: 2.2337, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [259/375], Loss: 2.1377, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [24/50], Step [260/375], Loss: 2.0787, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [261/375], Loss: 2.1630, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [262/375], Loss: 2.0701, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [263/375], Loss: 2.3376, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [264/375], Loss: 2.1033, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [265/375], Loss: 2.2797, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [266/375], Loss: 2.3778, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [24/50], Step [267/375], Loss: 2.3221, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [268/375], Loss: 2.3300, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [269/375], Loss: 2.1440, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [270/375], Loss: 2.3442, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [271/375], Loss: 2.3258, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [272/375], Loss: 2.1247, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [273/375], Loss: 2.0097, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [24/50], Step [274/375], Loss: 2.1792, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [275/375], Loss: 2.3634, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [24/50], Step [276/375], Loss: 2.0577, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [277/375], Loss: 2.2094, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [278/375], Loss: 2.2038, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [279/375], Loss: 2.2805, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [24/50], Step [280/375], Loss: 2.3290, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [24/50], Step [281/375], Loss: 2.2091, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [282/375], Loss: 2.3077, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [283/375], Loss: 2.2595, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [284/375], Loss: 2.5358, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [285/375], Loss: 2.2020, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [286/375], Loss: 2.2112, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [287/375], Loss: 2.1656, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [288/375], Loss: 2.2865, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [289/375], Loss: 2.2488, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [290/375], Loss: 2.0059, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [291/375], Loss: 2.1876, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [24/50], Step [292/375], Loss: 2.2467, batch time: 0.82, accuracy:  25.00%\n",
      "Epoch [24/50], Step [293/375], Loss: 2.1953, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [294/375], Loss: 2.2857, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [295/375], Loss: 2.0464, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [24/50], Step [296/375], Loss: 2.3176, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [297/375], Loss: 2.0997, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [298/375], Loss: 2.1829, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [24/50], Step [299/375], Loss: 2.1589, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [300/375], Loss: 2.3085, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [301/375], Loss: 2.4046, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [24/50], Step [302/375], Loss: 2.2762, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [303/375], Loss: 2.2390, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [304/375], Loss: 2.2454, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [305/375], Loss: 2.0904, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [306/375], Loss: 2.1843, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [307/375], Loss: 2.2603, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [308/375], Loss: 2.2763, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [309/375], Loss: 2.5395, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [24/50], Step [310/375], Loss: 2.2937, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [311/375], Loss: 2.4033, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [24/50], Step [312/375], Loss: 2.2068, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [313/375], Loss: 2.2453, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [314/375], Loss: 2.3084, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [315/375], Loss: 2.3849, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [316/375], Loss: 2.3427, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [317/375], Loss: 2.3406, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [318/375], Loss: 2.4443, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [24/50], Step [319/375], Loss: 2.2734, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [320/375], Loss: 2.2186, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [321/375], Loss: 1.9891, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [24/50], Step [322/375], Loss: 2.1381, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [323/375], Loss: 2.3287, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [324/375], Loss: 2.2402, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [325/375], Loss: 2.2200, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [326/375], Loss: 2.1429, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [327/375], Loss: 2.1876, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [328/375], Loss: 2.3279, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [329/375], Loss: 2.3543, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [330/375], Loss: 2.2359, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [331/375], Loss: 2.1846, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [332/375], Loss: 2.0603, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [333/375], Loss: 2.1424, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [24/50], Step [334/375], Loss: 2.2834, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [335/375], Loss: 2.2587, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [336/375], Loss: 2.2757, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [337/375], Loss: 2.3164, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [338/375], Loss: 2.2553, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [339/375], Loss: 2.1205, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [24/50], Step [340/375], Loss: 2.2846, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [341/375], Loss: 2.3382, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [24/50], Step [342/375], Loss: 2.1558, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [343/375], Loss: 2.2017, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [24/50], Step [344/375], Loss: 2.4144, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [345/375], Loss: 2.1324, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [346/375], Loss: 2.2052, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [347/375], Loss: 2.2177, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [348/375], Loss: 2.1786, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [24/50], Step [349/375], Loss: 2.2583, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [350/375], Loss: 2.1534, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [351/375], Loss: 2.1705, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [352/375], Loss: 2.3595, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [353/375], Loss: 2.2974, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [354/375], Loss: 2.1555, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [355/375], Loss: 2.3871, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [356/375], Loss: 2.3579, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [357/375], Loss: 1.9762, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [358/375], Loss: 2.1629, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [359/375], Loss: 2.3987, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [24/50], Step [360/375], Loss: 2.0567, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [24/50], Step [361/375], Loss: 2.2381, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [24/50], Step [362/375], Loss: 2.1438, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [24/50], Step [363/375], Loss: 2.2494, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [364/375], Loss: 2.3737, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [365/375], Loss: 2.2390, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [24/50], Step [366/375], Loss: 2.3450, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [367/375], Loss: 2.3032, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [24/50], Step [368/375], Loss: 2.2263, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [24/50], Step [369/375], Loss: 2.0990, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [24/50], Step [370/375], Loss: 2.3123, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [24/50], Step [371/375], Loss: 2.2665, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [24/50], Step [372/375], Loss: 2.4343, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [24/50], Step [373/375], Loss: 2.2376, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [24/50], Step [374/375], Loss: 2.1985, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [24/50], Step [375/375], Loss: 2.2861, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [1/375], Loss: 2.1127, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [2/375], Loss: 2.2230, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [3/375], Loss: 2.1836, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [4/375], Loss: 2.1098, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [5/375], Loss: 2.2458, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [6/375], Loss: 2.2081, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [7/375], Loss: 2.3851, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [8/375], Loss: 2.3110, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [9/375], Loss: 2.1301, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [10/375], Loss: 2.1522, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [11/375], Loss: 2.3644, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [12/375], Loss: 2.1334, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [13/375], Loss: 2.1890, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [14/375], Loss: 2.1043, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [15/375], Loss: 2.1638, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [16/375], Loss: 2.1829, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [17/375], Loss: 2.2629, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [18/375], Loss: 2.2606, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [25/50], Step [19/375], Loss: 2.2603, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [20/375], Loss: 2.3202, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [21/375], Loss: 2.0349, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [22/375], Loss: 2.3334, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [23/375], Loss: 2.2558, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [24/375], Loss: 2.1946, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [25/375], Loss: 2.1871, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [26/375], Loss: 2.0858, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [27/375], Loss: 2.2427, batch time: 1.01, accuracy:  18.75%\n",
      "Epoch [25/50], Step [28/375], Loss: 2.5069, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [29/375], Loss: 2.3393, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [30/375], Loss: 2.1151, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [25/50], Step [31/375], Loss: 2.2622, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [32/375], Loss: 2.3805, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [33/375], Loss: 2.4044, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [25/50], Step [34/375], Loss: 2.3014, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [35/375], Loss: 2.2958, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [36/375], Loss: 2.1408, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [25/50], Step [37/375], Loss: 2.2084, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [38/375], Loss: 2.2618, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [39/375], Loss: 2.1290, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [40/375], Loss: 2.0715, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [25/50], Step [41/375], Loss: 2.2831, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [42/375], Loss: 2.2055, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [43/375], Loss: 2.3390, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [44/375], Loss: 2.3261, batch time: 0.28, accuracy:  0.00%\n",
      "Epoch [25/50], Step [45/375], Loss: 2.1996, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [46/375], Loss: 2.3512, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [47/375], Loss: 2.0988, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [48/375], Loss: 2.2992, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [25/50], Step [49/375], Loss: 2.0879, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [50/375], Loss: 2.2977, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [51/375], Loss: 2.4961, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [52/375], Loss: 2.1993, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [53/375], Loss: 2.4122, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [25/50], Step [54/375], Loss: 2.1732, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [55/375], Loss: 2.1602, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [56/375], Loss: 2.4161, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [25/50], Step [57/375], Loss: 2.1588, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [58/375], Loss: 2.1281, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [59/375], Loss: 2.2751, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [60/375], Loss: 2.3307, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [25/50], Step [61/375], Loss: 1.9972, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [25/50], Step [62/375], Loss: 2.1440, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [63/375], Loss: 2.2919, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [64/375], Loss: 2.3442, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [65/375], Loss: 2.2614, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [66/375], Loss: 2.0918, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [67/375], Loss: 2.1316, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [68/375], Loss: 2.0559, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [69/375], Loss: 2.3974, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [70/375], Loss: 2.0885, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [71/375], Loss: 2.1628, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [72/375], Loss: 2.2808, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [73/375], Loss: 2.2852, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [74/375], Loss: 2.3359, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [75/375], Loss: 2.3220, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [76/375], Loss: 2.1362, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [77/375], Loss: 2.2184, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [78/375], Loss: 2.3891, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [79/375], Loss: 2.1794, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [80/375], Loss: 2.3548, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [25/50], Step [81/375], Loss: 2.4314, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [25/50], Step [82/375], Loss: 2.3582, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [83/375], Loss: 2.0804, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [84/375], Loss: 2.1784, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [85/375], Loss: 2.2413, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [86/375], Loss: 2.2981, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [87/375], Loss: 2.2382, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [88/375], Loss: 2.2958, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [89/375], Loss: 2.2878, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [90/375], Loss: 2.1055, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [91/375], Loss: 2.0090, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [25/50], Step [92/375], Loss: 2.1648, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [93/375], Loss: 2.0872, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [94/375], Loss: 2.3701, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [95/375], Loss: 2.0171, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [96/375], Loss: 2.1127, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [97/375], Loss: 2.2443, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [25/50], Step [98/375], Loss: 2.3684, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [99/375], Loss: 2.2162, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [100/375], Loss: 2.2443, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [101/375], Loss: 2.2018, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [102/375], Loss: 2.2037, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [103/375], Loss: 2.3082, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [104/375], Loss: 2.2274, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [105/375], Loss: 2.3194, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [25/50], Step [106/375], Loss: 2.2398, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [107/375], Loss: 2.4249, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [108/375], Loss: 2.2448, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [109/375], Loss: 2.2528, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [110/375], Loss: 2.2793, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [111/375], Loss: 2.3407, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [112/375], Loss: 2.3770, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [113/375], Loss: 2.3905, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [114/375], Loss: 2.3740, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [115/375], Loss: 2.2913, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [116/375], Loss: 2.2729, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [117/375], Loss: 2.2497, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [118/375], Loss: 2.2586, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [119/375], Loss: 2.0210, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [25/50], Step [120/375], Loss: 2.2880, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [121/375], Loss: 2.3134, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [122/375], Loss: 2.2163, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [123/375], Loss: 2.1188, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [124/375], Loss: 2.2703, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [125/375], Loss: 2.2083, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [126/375], Loss: 2.3475, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [127/375], Loss: 2.4208, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [128/375], Loss: 2.3171, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [129/375], Loss: 2.2172, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [130/375], Loss: 2.2316, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [131/375], Loss: 2.1264, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [132/375], Loss: 2.1984, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [133/375], Loss: 2.3500, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [134/375], Loss: 2.1071, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [135/375], Loss: 2.2381, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [136/375], Loss: 2.2824, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [137/375], Loss: 2.2115, batch time: 0.83, accuracy:  18.75%\n",
      "Epoch [25/50], Step [138/375], Loss: 2.3296, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [139/375], Loss: 2.4398, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [140/375], Loss: 2.1954, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [25/50], Step [141/375], Loss: 2.1936, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [142/375], Loss: 2.2397, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [143/375], Loss: 2.2595, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [25/50], Step [144/375], Loss: 2.2260, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [145/375], Loss: 2.2666, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [146/375], Loss: 2.4145, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [25/50], Step [147/375], Loss: 2.1161, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [148/375], Loss: 2.0115, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [149/375], Loss: 2.2472, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [150/375], Loss: 2.1960, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [25/50], Step [151/375], Loss: 2.4034, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [152/375], Loss: 2.1661, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [153/375], Loss: 2.1377, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [154/375], Loss: 2.1278, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [155/375], Loss: 2.2074, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [156/375], Loss: 2.3018, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [25/50], Step [157/375], Loss: 2.2126, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [158/375], Loss: 2.1600, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [25/50], Step [159/375], Loss: 2.3008, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [160/375], Loss: 2.3310, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [161/375], Loss: 2.2428, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [162/375], Loss: 2.2360, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [163/375], Loss: 2.3155, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [164/375], Loss: 2.1564, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [165/375], Loss: 2.1745, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [166/375], Loss: 2.1801, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [25/50], Step [167/375], Loss: 2.1341, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [168/375], Loss: 2.1652, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [169/375], Loss: 2.5646, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [25/50], Step [170/375], Loss: 2.0571, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [171/375], Loss: 2.1075, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [172/375], Loss: 2.0930, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [173/375], Loss: 2.4372, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [174/375], Loss: 2.2780, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [175/375], Loss: 2.2930, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [176/375], Loss: 1.9860, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [177/375], Loss: 2.1922, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [178/375], Loss: 2.2413, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [179/375], Loss: 2.1677, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [180/375], Loss: 2.3576, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [181/375], Loss: 2.1994, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [182/375], Loss: 2.2038, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [25/50], Step [183/375], Loss: 2.0536, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [184/375], Loss: 2.2603, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [185/375], Loss: 2.1579, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [186/375], Loss: 2.2385, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [187/375], Loss: 2.2151, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [25/50], Step [188/375], Loss: 2.1301, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [189/375], Loss: 2.4915, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [25/50], Step [190/375], Loss: 2.3093, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [25/50], Step [191/375], Loss: 2.1660, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [192/375], Loss: 2.1244, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [193/375], Loss: 2.3633, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [194/375], Loss: 2.1964, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [195/375], Loss: 2.2168, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [196/375], Loss: 2.1349, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [197/375], Loss: 2.2589, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [198/375], Loss: 2.1903, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [199/375], Loss: 2.4402, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [25/50], Step [200/375], Loss: 2.2154, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [201/375], Loss: 2.2355, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [202/375], Loss: 2.3459, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [203/375], Loss: 2.1944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [204/375], Loss: 2.4657, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [205/375], Loss: 2.3066, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [206/375], Loss: 2.3027, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [207/375], Loss: 2.1659, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [208/375], Loss: 2.2594, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [209/375], Loss: 2.1598, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [210/375], Loss: 2.2892, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [211/375], Loss: 2.4826, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [212/375], Loss: 2.1662, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [213/375], Loss: 1.9029, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [25/50], Step [214/375], Loss: 2.2864, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [215/375], Loss: 2.1612, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [216/375], Loss: 2.3224, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [217/375], Loss: 2.2589, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [218/375], Loss: 2.0477, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [219/375], Loss: 2.1743, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [220/375], Loss: 2.2491, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [221/375], Loss: 2.0691, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [222/375], Loss: 2.3081, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [223/375], Loss: 2.5039, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [25/50], Step [224/375], Loss: 2.2861, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [225/375], Loss: 2.2819, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [226/375], Loss: 2.3243, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [227/375], Loss: 2.2144, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [228/375], Loss: 2.2646, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [229/375], Loss: 2.0280, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [25/50], Step [230/375], Loss: 2.0821, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [231/375], Loss: 2.4877, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [232/375], Loss: 2.1929, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [233/375], Loss: 2.2228, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [234/375], Loss: 2.3779, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [235/375], Loss: 2.3721, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [236/375], Loss: 2.2721, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [237/375], Loss: 2.1958, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [238/375], Loss: 2.1834, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [25/50], Step [239/375], Loss: 2.0322, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [240/375], Loss: 2.3590, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [241/375], Loss: 2.3163, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [242/375], Loss: 2.1986, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [243/375], Loss: 2.2200, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [244/375], Loss: 2.2846, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [245/375], Loss: 2.3106, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [246/375], Loss: 2.2943, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [247/375], Loss: 2.0374, batch time: 0.86, accuracy:  43.75%\n",
      "Epoch [25/50], Step [248/375], Loss: 2.2251, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [249/375], Loss: 2.1051, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [250/375], Loss: 2.2708, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [25/50], Step [251/375], Loss: 2.3713, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [252/375], Loss: 2.4294, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [253/375], Loss: 2.2937, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [25/50], Step [254/375], Loss: 2.3261, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [255/375], Loss: 2.1797, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [256/375], Loss: 2.2475, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [25/50], Step [257/375], Loss: 2.2984, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [258/375], Loss: 2.1267, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [259/375], Loss: 2.3114, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [260/375], Loss: 2.3679, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [25/50], Step [261/375], Loss: 2.2383, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [262/375], Loss: 2.1860, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [263/375], Loss: 2.2895, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [264/375], Loss: 2.2924, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [265/375], Loss: 1.9395, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [25/50], Step [266/375], Loss: 2.2932, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [267/375], Loss: 2.2622, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [268/375], Loss: 2.1520, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [269/375], Loss: 2.2398, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [270/375], Loss: 2.0873, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [271/375], Loss: 2.1070, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [272/375], Loss: 2.0967, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [273/375], Loss: 2.0542, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [274/375], Loss: 2.2304, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [275/375], Loss: 2.3796, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [276/375], Loss: 2.3310, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [277/375], Loss: 2.2971, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [278/375], Loss: 2.2060, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [279/375], Loss: 2.1396, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [280/375], Loss: 2.3102, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [281/375], Loss: 2.2270, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [282/375], Loss: 2.0919, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [283/375], Loss: 2.4343, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [284/375], Loss: 2.1530, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [285/375], Loss: 2.2458, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [286/375], Loss: 2.2401, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [287/375], Loss: 2.1060, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [288/375], Loss: 2.0309, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [25/50], Step [289/375], Loss: 1.9507, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [25/50], Step [290/375], Loss: 2.0260, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [291/375], Loss: 2.3795, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [292/375], Loss: 2.3050, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [293/375], Loss: 2.4039, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [294/375], Loss: 2.1687, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [295/375], Loss: 2.2374, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [296/375], Loss: 2.1932, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [297/375], Loss: 2.2347, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [298/375], Loss: 2.5617, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [299/375], Loss: 2.4433, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [25/50], Step [300/375], Loss: 2.0543, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [301/375], Loss: 2.0580, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [302/375], Loss: 2.1822, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [303/375], Loss: 2.3496, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [304/375], Loss: 2.2423, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [305/375], Loss: 2.2272, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [306/375], Loss: 2.3443, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [307/375], Loss: 2.3534, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [25/50], Step [308/375], Loss: 2.2342, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [25/50], Step [309/375], Loss: 2.3358, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [310/375], Loss: 2.2766, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [311/375], Loss: 2.0196, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [312/375], Loss: 2.3989, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [313/375], Loss: 2.1857, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [314/375], Loss: 2.2538, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [315/375], Loss: 2.4669, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [316/375], Loss: 2.2736, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [317/375], Loss: 2.3097, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [318/375], Loss: 1.9825, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [25/50], Step [319/375], Loss: 2.0810, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [25/50], Step [320/375], Loss: 2.2569, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [321/375], Loss: 2.1708, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [322/375], Loss: 2.2460, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [323/375], Loss: 2.4006, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [324/375], Loss: 2.3493, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [325/375], Loss: 2.2041, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [326/375], Loss: 2.2462, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [327/375], Loss: 2.3479, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [328/375], Loss: 2.4112, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [25/50], Step [329/375], Loss: 2.2400, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [330/375], Loss: 2.2652, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [331/375], Loss: 2.1918, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [332/375], Loss: 2.3314, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [333/375], Loss: 2.2983, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [334/375], Loss: 2.2399, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [335/375], Loss: 2.2386, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [336/375], Loss: 2.1555, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [25/50], Step [337/375], Loss: 2.1029, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [25/50], Step [338/375], Loss: 2.2707, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [339/375], Loss: 2.2985, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [340/375], Loss: 2.2434, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [25/50], Step [341/375], Loss: 2.1372, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [342/375], Loss: 2.1243, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [343/375], Loss: 2.1765, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [344/375], Loss: 2.3234, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [25/50], Step [345/375], Loss: 2.3081, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [346/375], Loss: 2.2376, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [25/50], Step [347/375], Loss: 2.3576, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [348/375], Loss: 2.2445, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [349/375], Loss: 2.2655, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [350/375], Loss: 2.1661, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [25/50], Step [351/375], Loss: 2.3514, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [352/375], Loss: 2.0580, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [25/50], Step [353/375], Loss: 2.0342, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [25/50], Step [354/375], Loss: 2.3797, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [25/50], Step [355/375], Loss: 2.2626, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [356/375], Loss: 2.1696, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [25/50], Step [357/375], Loss: 2.2349, batch time: 0.84, accuracy:  31.25%\n",
      "Epoch [25/50], Step [358/375], Loss: 2.4965, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [359/375], Loss: 2.1812, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [25/50], Step [360/375], Loss: 2.3666, batch time: 0.29, accuracy:  0.00%\n",
      "Epoch [25/50], Step [361/375], Loss: 2.3252, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [362/375], Loss: 2.1804, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [363/375], Loss: 2.4011, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [25/50], Step [364/375], Loss: 2.2382, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [365/375], Loss: 2.3283, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [25/50], Step [366/375], Loss: 2.4274, batch time: 0.30, accuracy:  0.00%\n",
      "Epoch [25/50], Step [367/375], Loss: 2.1770, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [25/50], Step [368/375], Loss: 2.2504, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [369/375], Loss: 2.1433, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [25/50], Step [370/375], Loss: 2.2770, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [25/50], Step [371/375], Loss: 2.0793, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [372/375], Loss: 2.2657, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [25/50], Step [373/375], Loss: 2.2447, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [25/50], Step [374/375], Loss: 2.3493, batch time: 0.28, accuracy:  0.00%\n",
      "Epoch [25/50], Step [375/375], Loss: 2.0307, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [26/50], Step [1/375], Loss: 2.1385, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [2/375], Loss: 2.3107, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [3/375], Loss: 2.1678, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [4/375], Loss: 2.0846, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [5/375], Loss: 2.2754, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [6/375], Loss: 2.1872, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [7/375], Loss: 2.0308, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [26/50], Step [8/375], Loss: 2.3188, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [9/375], Loss: 2.3066, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [10/375], Loss: 2.1718, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [11/375], Loss: 2.2936, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [12/375], Loss: 2.1205, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [13/375], Loss: 1.9473, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [26/50], Step [14/375], Loss: 2.1954, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [15/375], Loss: 2.1243, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [26/50], Step [16/375], Loss: 2.0608, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [17/375], Loss: 2.5297, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [18/375], Loss: 2.2326, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [19/375], Loss: 2.3825, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [26/50], Step [20/375], Loss: 2.4075, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [21/375], Loss: 2.4490, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [22/375], Loss: 2.0886, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [23/375], Loss: 2.3317, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [24/375], Loss: 2.3031, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [25/375], Loss: 2.0998, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [26/375], Loss: 2.2572, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [27/375], Loss: 2.2686, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [28/375], Loss: 2.2346, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [29/375], Loss: 2.4053, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [30/375], Loss: 2.1567, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [31/375], Loss: 2.2150, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [32/375], Loss: 2.3225, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [33/375], Loss: 2.2268, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [34/375], Loss: 2.4976, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [35/375], Loss: 2.4443, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [36/375], Loss: 2.1802, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [37/375], Loss: 2.3650, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [38/375], Loss: 1.9601, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [39/375], Loss: 2.3813, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [26/50], Step [40/375], Loss: 2.2591, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [41/375], Loss: 2.2708, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [42/375], Loss: 2.5361, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [26/50], Step [43/375], Loss: 2.0229, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [26/50], Step [44/375], Loss: 2.2784, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [45/375], Loss: 2.4172, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [46/375], Loss: 2.3319, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [47/375], Loss: 2.3443, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [48/375], Loss: 2.3853, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [49/375], Loss: 2.2263, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [50/375], Loss: 2.3438, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [51/375], Loss: 2.1413, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [52/375], Loss: 2.2120, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [53/375], Loss: 2.2260, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [54/375], Loss: 2.3071, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [55/375], Loss: 2.2972, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [56/375], Loss: 2.1515, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [57/375], Loss: 2.2392, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [58/375], Loss: 2.3269, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [59/375], Loss: 2.2550, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [60/375], Loss: 2.1387, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [61/375], Loss: 2.2544, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [62/375], Loss: 2.2490, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [63/375], Loss: 2.1785, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [64/375], Loss: 2.1138, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [65/375], Loss: 2.1532, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [66/375], Loss: 2.3627, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [67/375], Loss: 2.2546, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [68/375], Loss: 2.3778, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [26/50], Step [69/375], Loss: 2.2412, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [70/375], Loss: 2.3494, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [71/375], Loss: 2.3968, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [72/375], Loss: 2.1761, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [73/375], Loss: 2.2762, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [74/375], Loss: 2.2225, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [75/375], Loss: 2.1394, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [26/50], Step [76/375], Loss: 2.1149, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [77/375], Loss: 2.2922, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [78/375], Loss: 2.3050, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [79/375], Loss: 2.2232, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [80/375], Loss: 2.3235, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [81/375], Loss: 2.0679, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [82/375], Loss: 2.3276, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [83/375], Loss: 2.2452, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [84/375], Loss: 2.2578, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [85/375], Loss: 2.2767, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [86/375], Loss: 2.2185, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [87/375], Loss: 2.1916, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [88/375], Loss: 2.2396, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [89/375], Loss: 2.2170, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [90/375], Loss: 2.2243, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [91/375], Loss: 2.1886, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [92/375], Loss: 2.3030, batch time: 0.86, accuracy:  25.00%\n",
      "Epoch [26/50], Step [93/375], Loss: 2.1981, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [94/375], Loss: 2.1847, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [95/375], Loss: 2.1211, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [26/50], Step [96/375], Loss: 2.2215, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [97/375], Loss: 2.2087, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [98/375], Loss: 2.0332, batch time: 0.30, accuracy:  37.50%\n",
      "Epoch [26/50], Step [99/375], Loss: 2.3382, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [100/375], Loss: 2.2106, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [101/375], Loss: 2.3279, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [26/50], Step [102/375], Loss: 2.3447, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [103/375], Loss: 2.3895, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [104/375], Loss: 2.1919, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [105/375], Loss: 2.1943, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [26/50], Step [106/375], Loss: 2.1782, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [107/375], Loss: 2.3698, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [108/375], Loss: 2.1378, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [109/375], Loss: 2.0744, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [26/50], Step [110/375], Loss: 2.2471, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [111/375], Loss: 2.0866, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [112/375], Loss: 2.2021, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [113/375], Loss: 2.2631, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [114/375], Loss: 2.2852, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [115/375], Loss: 1.9763, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [116/375], Loss: 2.4012, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [117/375], Loss: 2.3471, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [26/50], Step [118/375], Loss: 2.2884, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [119/375], Loss: 2.2981, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [120/375], Loss: 2.1843, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [121/375], Loss: 2.1326, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [122/375], Loss: 2.3741, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [26/50], Step [123/375], Loss: 2.1386, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [124/375], Loss: 2.0563, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [125/375], Loss: 2.3206, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [126/375], Loss: 2.2370, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [127/375], Loss: 2.4097, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [128/375], Loss: 2.5541, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [129/375], Loss: 2.3393, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [26/50], Step [130/375], Loss: 2.1515, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [131/375], Loss: 2.2715, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [132/375], Loss: 2.3124, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [133/375], Loss: 2.0613, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [26/50], Step [134/375], Loss: 2.1431, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [135/375], Loss: 2.2656, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [136/375], Loss: 2.1727, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [137/375], Loss: 2.3216, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [26/50], Step [138/375], Loss: 2.0986, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [139/375], Loss: 2.1798, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [140/375], Loss: 2.1746, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [141/375], Loss: 2.2064, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [142/375], Loss: 2.2956, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [143/375], Loss: 2.2267, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [144/375], Loss: 2.2646, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [145/375], Loss: 1.8886, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [26/50], Step [146/375], Loss: 2.3408, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [147/375], Loss: 2.0692, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [148/375], Loss: 2.3617, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [149/375], Loss: 2.1900, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [150/375], Loss: 2.3864, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [151/375], Loss: 2.1280, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [152/375], Loss: 2.1778, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [153/375], Loss: 2.2041, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [154/375], Loss: 2.1029, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [155/375], Loss: 2.0890, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [156/375], Loss: 2.2761, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [157/375], Loss: 2.4273, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [158/375], Loss: 2.3348, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [159/375], Loss: 2.1143, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [160/375], Loss: 2.2912, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [161/375], Loss: 2.0386, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [26/50], Step [162/375], Loss: 2.0781, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [163/375], Loss: 2.1026, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [164/375], Loss: 2.3185, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [165/375], Loss: 2.2719, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [166/375], Loss: 2.4945, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [167/375], Loss: 2.2168, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [168/375], Loss: 2.3268, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [169/375], Loss: 2.2979, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [170/375], Loss: 2.1866, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [171/375], Loss: 2.1095, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [172/375], Loss: 1.9051, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [173/375], Loss: 2.2645, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [174/375], Loss: 2.3403, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [175/375], Loss: 2.2111, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [176/375], Loss: 2.2546, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [177/375], Loss: 2.2897, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [178/375], Loss: 1.9690, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [179/375], Loss: 2.2993, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [180/375], Loss: 2.1946, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [181/375], Loss: 2.1277, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [26/50], Step [182/375], Loss: 2.0813, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [183/375], Loss: 2.0246, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [26/50], Step [184/375], Loss: 2.4017, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [185/375], Loss: 2.3498, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [186/375], Loss: 1.9670, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [26/50], Step [187/375], Loss: 2.2227, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [188/375], Loss: 2.2102, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [189/375], Loss: 2.3313, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [190/375], Loss: 2.1851, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [191/375], Loss: 2.2646, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [192/375], Loss: 2.2966, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [193/375], Loss: 2.2666, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [194/375], Loss: 2.2985, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [195/375], Loss: 2.2229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [196/375], Loss: 2.1455, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [197/375], Loss: 2.3131, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [198/375], Loss: 2.0467, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [199/375], Loss: 2.3466, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [200/375], Loss: 2.3522, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [201/375], Loss: 2.2921, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [26/50], Step [202/375], Loss: 2.3277, batch time: 0.83, accuracy:  12.50%\n",
      "Epoch [26/50], Step [203/375], Loss: 2.1179, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [204/375], Loss: 2.2981, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [205/375], Loss: 2.2706, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [26/50], Step [206/375], Loss: 2.2485, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [207/375], Loss: 2.3768, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [208/375], Loss: 2.1808, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [26/50], Step [209/375], Loss: 2.0835, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [210/375], Loss: 2.2051, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [211/375], Loss: 2.0941, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [26/50], Step [212/375], Loss: 2.2158, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [213/375], Loss: 2.2281, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [214/375], Loss: 2.2931, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [215/375], Loss: 2.2537, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [26/50], Step [216/375], Loss: 2.2417, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [217/375], Loss: 2.4148, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [218/375], Loss: 2.2196, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [219/375], Loss: 2.3697, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [220/375], Loss: 2.2064, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [221/375], Loss: 2.3621, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [222/375], Loss: 2.1665, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [223/375], Loss: 2.3318, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [224/375], Loss: 2.3171, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [225/375], Loss: 2.2890, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [226/375], Loss: 2.2736, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [227/375], Loss: 2.1254, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [26/50], Step [228/375], Loss: 2.3033, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [229/375], Loss: 2.2693, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [230/375], Loss: 2.0619, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [231/375], Loss: 2.1397, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [232/375], Loss: 2.3199, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [233/375], Loss: 2.3002, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [234/375], Loss: 2.2368, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [235/375], Loss: 2.3564, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [236/375], Loss: 2.3486, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [237/375], Loss: 2.1827, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [26/50], Step [238/375], Loss: 2.3221, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [239/375], Loss: 2.1246, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [240/375], Loss: 2.2349, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [241/375], Loss: 2.1234, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [242/375], Loss: 2.3979, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [26/50], Step [243/375], Loss: 2.0846, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [26/50], Step [244/375], Loss: 2.3132, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [245/375], Loss: 2.2444, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [246/375], Loss: 2.4109, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [247/375], Loss: 2.1468, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [26/50], Step [248/375], Loss: 2.2527, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [249/375], Loss: 2.3314, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [250/375], Loss: 2.0249, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [251/375], Loss: 2.2994, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [252/375], Loss: 2.2365, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [253/375], Loss: 2.1838, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [254/375], Loss: 2.2851, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [255/375], Loss: 2.2294, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [256/375], Loss: 2.1613, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [257/375], Loss: 2.3272, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [258/375], Loss: 2.2588, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [259/375], Loss: 2.0475, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [26/50], Step [260/375], Loss: 2.0424, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [261/375], Loss: 2.2593, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [262/375], Loss: 2.2136, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [263/375], Loss: 2.3666, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [264/375], Loss: 2.1290, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [265/375], Loss: 2.1633, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [266/375], Loss: 2.0886, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [267/375], Loss: 2.1429, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [26/50], Step [268/375], Loss: 2.1508, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [269/375], Loss: 2.1056, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [270/375], Loss: 2.4410, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [271/375], Loss: 2.1436, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [26/50], Step [272/375], Loss: 2.0891, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [273/375], Loss: 2.2208, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [274/375], Loss: 2.1610, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [275/375], Loss: 2.3350, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [26/50], Step [276/375], Loss: 2.1056, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [277/375], Loss: 2.0348, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [26/50], Step [278/375], Loss: 2.2093, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [279/375], Loss: 2.1286, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [280/375], Loss: 2.2823, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [281/375], Loss: 2.1300, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [282/375], Loss: 2.1075, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [283/375], Loss: 2.2671, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [284/375], Loss: 2.2626, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [285/375], Loss: 2.4725, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [286/375], Loss: 2.1792, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [287/375], Loss: 2.2127, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [288/375], Loss: 2.1814, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [289/375], Loss: 2.1622, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [290/375], Loss: 2.2425, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [291/375], Loss: 2.2594, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [292/375], Loss: 2.0117, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [293/375], Loss: 2.3563, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [294/375], Loss: 2.1832, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [295/375], Loss: 2.1516, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [296/375], Loss: 2.1021, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [297/375], Loss: 2.0029, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [298/375], Loss: 2.0764, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [299/375], Loss: 2.1011, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [300/375], Loss: 2.0172, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [26/50], Step [301/375], Loss: 2.2400, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [302/375], Loss: 2.3596, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [26/50], Step [303/375], Loss: 2.2505, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [304/375], Loss: 2.2317, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [305/375], Loss: 2.2730, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [306/375], Loss: 2.2615, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [307/375], Loss: 2.2444, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [308/375], Loss: 2.3588, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [309/375], Loss: 2.2706, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [310/375], Loss: 2.2128, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [311/375], Loss: 1.9305, batch time: 0.26, accuracy:  50.00%\n",
      "Epoch [26/50], Step [312/375], Loss: 2.1833, batch time: 0.83, accuracy:  25.00%\n",
      "Epoch [26/50], Step [313/375], Loss: 2.3730, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [314/375], Loss: 2.1475, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [315/375], Loss: 2.2750, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [26/50], Step [316/375], Loss: 2.2054, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [317/375], Loss: 2.3169, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [318/375], Loss: 2.3385, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [26/50], Step [319/375], Loss: 2.0642, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [320/375], Loss: 1.9548, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [26/50], Step [321/375], Loss: 2.4988, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [26/50], Step [322/375], Loss: 2.1039, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [323/375], Loss: 2.3468, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [324/375], Loss: 2.2494, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [325/375], Loss: 2.3609, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [326/375], Loss: 2.4409, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [327/375], Loss: 2.0469, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [26/50], Step [328/375], Loss: 2.2380, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [329/375], Loss: 2.2161, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [330/375], Loss: 2.2462, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [331/375], Loss: 1.9993, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [26/50], Step [332/375], Loss: 2.5294, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [333/375], Loss: 2.2710, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [26/50], Step [334/375], Loss: 2.1474, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [26/50], Step [335/375], Loss: 2.4317, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [336/375], Loss: 2.2714, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [337/375], Loss: 2.3227, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [338/375], Loss: 2.0369, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [339/375], Loss: 2.4117, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [340/375], Loss: 2.2649, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [341/375], Loss: 2.3979, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [342/375], Loss: 2.4541, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [343/375], Loss: 2.3323, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [344/375], Loss: 2.3546, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [345/375], Loss: 2.2702, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [346/375], Loss: 2.3108, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [347/375], Loss: 2.1002, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [348/375], Loss: 2.3580, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [26/50], Step [349/375], Loss: 2.4273, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [26/50], Step [350/375], Loss: 2.4085, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [351/375], Loss: 2.2101, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [352/375], Loss: 2.3418, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [353/375], Loss: 2.2104, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [26/50], Step [354/375], Loss: 2.2934, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [26/50], Step [355/375], Loss: 2.2344, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [356/375], Loss: 2.1279, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [26/50], Step [357/375], Loss: 2.2180, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [26/50], Step [358/375], Loss: 2.3974, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [359/375], Loss: 2.2241, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [26/50], Step [360/375], Loss: 2.2042, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [361/375], Loss: 2.2688, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [362/375], Loss: 2.1558, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [363/375], Loss: 2.3160, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [364/375], Loss: 2.2677, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [26/50], Step [365/375], Loss: 2.3306, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [26/50], Step [366/375], Loss: 2.2477, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [367/375], Loss: 2.3185, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [26/50], Step [368/375], Loss: 2.2724, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [26/50], Step [369/375], Loss: 2.3273, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [26/50], Step [370/375], Loss: 2.3141, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [26/50], Step [371/375], Loss: 2.1799, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [26/50], Step [372/375], Loss: 2.1930, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [26/50], Step [373/375], Loss: 2.3809, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [26/50], Step [374/375], Loss: 2.3022, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [26/50], Step [375/375], Loss: 2.2904, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [1/375], Loss: 2.1821, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [2/375], Loss: 2.2505, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [27/50], Step [3/375], Loss: 2.1198, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [4/375], Loss: 2.2985, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [5/375], Loss: 2.0215, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [6/375], Loss: 2.1402, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [27/50], Step [7/375], Loss: 2.0953, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [27/50], Step [8/375], Loss: 2.2358, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [9/375], Loss: 2.2841, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [10/375], Loss: 1.9764, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [27/50], Step [11/375], Loss: 2.2480, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [12/375], Loss: 2.1664, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [13/375], Loss: 2.1786, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [14/375], Loss: 2.2238, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [15/375], Loss: 2.2555, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [16/375], Loss: 2.2863, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [17/375], Loss: 2.1628, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [18/375], Loss: 2.3195, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [19/375], Loss: 2.1212, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [20/375], Loss: 2.4775, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [21/375], Loss: 2.2276, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [22/375], Loss: 2.0954, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [23/375], Loss: 2.2029, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [24/375], Loss: 2.1527, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [25/375], Loss: 2.1994, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [26/375], Loss: 2.3177, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [27/375], Loss: 2.3609, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [28/375], Loss: 2.0955, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [29/375], Loss: 2.3042, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [30/375], Loss: 2.2266, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [31/375], Loss: 2.2070, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [32/375], Loss: 2.1910, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [33/375], Loss: 2.2719, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [34/375], Loss: 2.1881, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [27/50], Step [35/375], Loss: 2.4605, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [36/375], Loss: 2.1354, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [37/375], Loss: 2.1834, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [38/375], Loss: 2.3620, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [39/375], Loss: 2.1703, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [40/375], Loss: 2.2173, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [41/375], Loss: 2.2449, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [42/375], Loss: 2.3859, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [43/375], Loss: 2.1228, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [44/375], Loss: 2.1997, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [45/375], Loss: 2.3875, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [46/375], Loss: 2.3551, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [47/375], Loss: 2.1904, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [27/50], Step [48/375], Loss: 2.3806, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [49/375], Loss: 2.1837, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [50/375], Loss: 2.2784, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [27/50], Step [51/375], Loss: 2.1232, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [52/375], Loss: 2.0284, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [53/375], Loss: 2.2451, batch time: 0.29, accuracy:  31.25%\n",
      "Epoch [27/50], Step [54/375], Loss: 2.1616, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [55/375], Loss: 2.1047, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [56/375], Loss: 2.3521, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [27/50], Step [57/375], Loss: 2.2866, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [58/375], Loss: 2.3792, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [59/375], Loss: 1.8998, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [27/50], Step [60/375], Loss: 2.2711, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [27/50], Step [61/375], Loss: 2.3904, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [27/50], Step [62/375], Loss: 2.2633, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [63/375], Loss: 2.1184, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [64/375], Loss: 2.2624, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [65/375], Loss: 2.2103, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [66/375], Loss: 2.2178, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [67/375], Loss: 2.4012, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [68/375], Loss: 2.4108, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [27/50], Step [69/375], Loss: 2.1735, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [70/375], Loss: 2.1602, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [27/50], Step [71/375], Loss: 2.1749, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [72/375], Loss: 2.2662, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [73/375], Loss: 2.3138, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [74/375], Loss: 2.2523, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [75/375], Loss: 2.2053, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [76/375], Loss: 2.3356, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [77/375], Loss: 2.2306, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [78/375], Loss: 2.2338, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [79/375], Loss: 2.2004, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [80/375], Loss: 2.0535, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [27/50], Step [81/375], Loss: 2.1508, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [82/375], Loss: 2.2221, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [83/375], Loss: 2.3123, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [84/375], Loss: 2.4229, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [85/375], Loss: 2.3648, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [86/375], Loss: 2.2449, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [87/375], Loss: 2.0212, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [27/50], Step [88/375], Loss: 2.2659, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [89/375], Loss: 2.2236, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [90/375], Loss: 2.4286, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [91/375], Loss: 2.2158, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [92/375], Loss: 2.1321, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [93/375], Loss: 2.2049, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [94/375], Loss: 2.2554, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [95/375], Loss: 2.1994, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [96/375], Loss: 2.2744, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [97/375], Loss: 2.2807, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [98/375], Loss: 2.1629, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [99/375], Loss: 2.1749, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [100/375], Loss: 2.2985, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [101/375], Loss: 2.2360, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [27/50], Step [102/375], Loss: 2.1775, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [103/375], Loss: 2.1903, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [104/375], Loss: 2.1849, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [105/375], Loss: 2.2700, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [106/375], Loss: 2.2448, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [107/375], Loss: 2.0712, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [27/50], Step [108/375], Loss: 2.4268, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [109/375], Loss: 2.4843, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [110/375], Loss: 2.1758, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [111/375], Loss: 2.3123, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [112/375], Loss: 2.3071, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [113/375], Loss: 2.3277, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [114/375], Loss: 2.3433, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [115/375], Loss: 2.0997, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [116/375], Loss: 2.3949, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [117/375], Loss: 2.2704, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [118/375], Loss: 2.2412, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [119/375], Loss: 2.2026, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [120/375], Loss: 2.4708, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [121/375], Loss: 2.3091, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [122/375], Loss: 2.2073, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [123/375], Loss: 1.9206, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [27/50], Step [124/375], Loss: 2.0256, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [125/375], Loss: 2.3690, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [126/375], Loss: 2.2104, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [127/375], Loss: 2.3268, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [128/375], Loss: 2.2180, batch time: 0.37, accuracy:  18.75%\n",
      "Epoch [27/50], Step [129/375], Loss: 2.1681, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [27/50], Step [130/375], Loss: 2.3618, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [131/375], Loss: 2.2755, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [27/50], Step [132/375], Loss: 2.2581, batch time: 0.36, accuracy:  37.50%\n",
      "Epoch [27/50], Step [133/375], Loss: 2.2448, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [134/375], Loss: 2.2500, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [135/375], Loss: 2.2132, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [136/375], Loss: 2.4067, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [137/375], Loss: 2.3478, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [138/375], Loss: 2.1837, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [139/375], Loss: 2.1390, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [140/375], Loss: 2.1795, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [141/375], Loss: 2.1025, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [142/375], Loss: 2.3566, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [143/375], Loss: 2.2132, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [144/375], Loss: 2.3895, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [145/375], Loss: 2.3235, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [146/375], Loss: 2.0772, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [147/375], Loss: 2.2111, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [148/375], Loss: 2.3405, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [27/50], Step [149/375], Loss: 2.1518, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [150/375], Loss: 2.3553, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [27/50], Step [151/375], Loss: 2.3215, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [152/375], Loss: 2.2727, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [153/375], Loss: 2.2575, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [154/375], Loss: 2.1609, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [155/375], Loss: 2.0945, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [27/50], Step [156/375], Loss: 2.1426, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [157/375], Loss: 2.3649, batch time: 0.83, accuracy:  18.75%\n",
      "Epoch [27/50], Step [158/375], Loss: 2.1715, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [27/50], Step [159/375], Loss: 2.2381, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [160/375], Loss: 2.1037, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [27/50], Step [161/375], Loss: 2.1562, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [162/375], Loss: 2.1013, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [163/375], Loss: 2.2841, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [27/50], Step [164/375], Loss: 2.3092, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [165/375], Loss: 2.2631, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [166/375], Loss: 2.1785, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [27/50], Step [167/375], Loss: 2.2010, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [168/375], Loss: 2.3156, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [169/375], Loss: 2.1648, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [170/375], Loss: 2.2948, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [27/50], Step [171/375], Loss: 2.1686, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [172/375], Loss: 2.0474, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [27/50], Step [173/375], Loss: 2.2137, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [174/375], Loss: 2.3683, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [27/50], Step [175/375], Loss: 2.1650, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [176/375], Loss: 2.2916, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [177/375], Loss: 2.3472, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [178/375], Loss: 2.4049, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [27/50], Step [179/375], Loss: 2.3895, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [180/375], Loss: 1.9546, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [27/50], Step [181/375], Loss: 2.2625, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [182/375], Loss: 2.1773, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [183/375], Loss: 2.2517, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [184/375], Loss: 2.1943, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [185/375], Loss: 2.3130, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [186/375], Loss: 2.2283, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [187/375], Loss: 2.1376, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [188/375], Loss: 2.3230, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [27/50], Step [189/375], Loss: 2.0588, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [190/375], Loss: 2.3406, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [191/375], Loss: 2.1338, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [192/375], Loss: 1.9879, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [193/375], Loss: 2.3707, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [194/375], Loss: 2.2413, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [195/375], Loss: 2.3685, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [196/375], Loss: 2.4084, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [197/375], Loss: 2.1625, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [198/375], Loss: 2.1916, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [27/50], Step [199/375], Loss: 2.4486, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [27/50], Step [200/375], Loss: 2.4550, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [201/375], Loss: 2.1336, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [27/50], Step [202/375], Loss: 2.2091, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [27/50], Step [203/375], Loss: 2.4647, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [204/375], Loss: 2.1353, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [205/375], Loss: 2.0490, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [206/375], Loss: 2.2197, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [27/50], Step [207/375], Loss: 2.1292, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [208/375], Loss: 2.1815, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [209/375], Loss: 2.1933, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [210/375], Loss: 2.3527, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [27/50], Step [211/375], Loss: 2.1049, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [212/375], Loss: 2.1846, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [213/375], Loss: 2.2071, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [214/375], Loss: 2.1112, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [215/375], Loss: 2.2020, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [216/375], Loss: 2.3034, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [217/375], Loss: 2.2665, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [218/375], Loss: 2.4203, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [219/375], Loss: 2.2819, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [220/375], Loss: 2.0838, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [221/375], Loss: 2.2148, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [222/375], Loss: 2.1177, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [27/50], Step [223/375], Loss: 2.2057, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [224/375], Loss: 2.1704, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [225/375], Loss: 2.0969, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [226/375], Loss: 2.2149, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [227/375], Loss: 2.1577, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [228/375], Loss: 2.4342, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [229/375], Loss: 2.2884, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [230/375], Loss: 2.2546, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [231/375], Loss: 2.4772, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [232/375], Loss: 2.2564, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [233/375], Loss: 2.1146, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [234/375], Loss: 2.1424, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [27/50], Step [235/375], Loss: 2.2559, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [236/375], Loss: 2.2140, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [237/375], Loss: 2.1777, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [238/375], Loss: 2.3670, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [27/50], Step [239/375], Loss: 2.1243, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [240/375], Loss: 2.4809, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [27/50], Step [241/375], Loss: 2.2505, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [242/375], Loss: 2.2022, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [243/375], Loss: 2.2367, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [244/375], Loss: 2.2752, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [245/375], Loss: 2.2807, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [246/375], Loss: 2.3035, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [27/50], Step [247/375], Loss: 2.2938, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [27/50], Step [248/375], Loss: 2.2888, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [249/375], Loss: 2.3401, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [27/50], Step [250/375], Loss: 2.3941, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [27/50], Step [251/375], Loss: 2.2885, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [27/50], Step [252/375], Loss: 2.1297, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [27/50], Step [253/375], Loss: 2.2591, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [27/50], Step [254/375], Loss: 2.1771, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [27/50], Step [255/375], Loss: 2.2257, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [27/50], Step [256/375], Loss: 2.0652, batch time: 0.33, accuracy:  50.00%\n",
      "Epoch [27/50], Step [257/375], Loss: 2.2833, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [27/50], Step [258/375], Loss: 2.2727, batch time: 0.34, accuracy:  25.00%\n",
      "Epoch [27/50], Step [259/375], Loss: 2.2262, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [260/375], Loss: 2.1108, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [27/50], Step [261/375], Loss: 2.3056, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [27/50], Step [262/375], Loss: 2.4950, batch time: 0.36, accuracy:  0.00%\n",
      "Epoch [27/50], Step [263/375], Loss: 2.2956, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [264/375], Loss: 2.2238, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [27/50], Step [265/375], Loss: 2.0808, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [27/50], Step [266/375], Loss: 2.2767, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [27/50], Step [267/375], Loss: 2.1648, batch time: 1.01, accuracy:  25.00%\n",
      "Epoch [27/50], Step [268/375], Loss: 2.2243, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [27/50], Step [269/375], Loss: 2.2030, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [27/50], Step [270/375], Loss: 2.3307, batch time: 0.38, accuracy:  25.00%\n",
      "Epoch [27/50], Step [271/375], Loss: 2.2997, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [27/50], Step [272/375], Loss: 2.3770, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [27/50], Step [273/375], Loss: 2.2811, batch time: 0.37, accuracy:  12.50%\n",
      "Epoch [27/50], Step [274/375], Loss: 2.2149, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [27/50], Step [275/375], Loss: 2.3232, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [27/50], Step [276/375], Loss: 2.1740, batch time: 0.37, accuracy:  25.00%\n",
      "Epoch [27/50], Step [277/375], Loss: 2.2202, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [27/50], Step [278/375], Loss: 2.1968, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [27/50], Step [279/375], Loss: 2.2743, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [27/50], Step [280/375], Loss: 2.1452, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [281/375], Loss: 2.3876, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [282/375], Loss: 2.2191, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [283/375], Loss: 2.2956, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [284/375], Loss: 2.2685, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [27/50], Step [285/375], Loss: 2.3599, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [286/375], Loss: 2.2269, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [287/375], Loss: 2.2557, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [288/375], Loss: 2.0439, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [27/50], Step [289/375], Loss: 2.2614, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [290/375], Loss: 2.1526, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [291/375], Loss: 2.1784, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [292/375], Loss: 2.1432, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [293/375], Loss: 2.1107, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [294/375], Loss: 2.2577, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [295/375], Loss: 2.0747, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [296/375], Loss: 2.2188, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [297/375], Loss: 2.1854, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [298/375], Loss: 2.3340, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [299/375], Loss: 2.2340, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [300/375], Loss: 2.0771, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [27/50], Step [301/375], Loss: 2.0758, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [302/375], Loss: 2.1779, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [303/375], Loss: 2.3104, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [304/375], Loss: 2.3021, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [305/375], Loss: 2.2365, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [306/375], Loss: 2.1265, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [307/375], Loss: 2.3282, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [308/375], Loss: 2.3583, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [27/50], Step [309/375], Loss: 2.1359, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [310/375], Loss: 2.3900, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [311/375], Loss: 2.3100, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [312/375], Loss: 2.4968, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [27/50], Step [313/375], Loss: 2.2555, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [314/375], Loss: 2.2216, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [315/375], Loss: 2.2205, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [316/375], Loss: 2.3026, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [317/375], Loss: 2.3913, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [318/375], Loss: 2.0572, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [27/50], Step [319/375], Loss: 2.2697, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [320/375], Loss: 2.3849, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [27/50], Step [321/375], Loss: 2.3306, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [322/375], Loss: 2.1081, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [323/375], Loss: 2.2698, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [324/375], Loss: 2.2345, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [27/50], Step [325/375], Loss: 2.4008, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [27/50], Step [326/375], Loss: 2.0953, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [327/375], Loss: 2.0966, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [328/375], Loss: 2.3062, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [329/375], Loss: 2.1170, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [330/375], Loss: 2.1310, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [331/375], Loss: 2.3451, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [332/375], Loss: 2.1387, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [27/50], Step [333/375], Loss: 2.2235, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [334/375], Loss: 2.3337, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [335/375], Loss: 2.1338, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [336/375], Loss: 2.2845, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [337/375], Loss: 2.3054, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [338/375], Loss: 2.2881, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [339/375], Loss: 2.1970, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [340/375], Loss: 2.1604, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [341/375], Loss: 2.0775, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [342/375], Loss: 2.0672, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [343/375], Loss: 2.3706, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [344/375], Loss: 2.2634, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [27/50], Step [345/375], Loss: 2.0993, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [346/375], Loss: 2.2342, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [347/375], Loss: 2.1976, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [27/50], Step [348/375], Loss: 2.2797, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [349/375], Loss: 2.3951, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [350/375], Loss: 2.1797, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [351/375], Loss: 2.1524, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [352/375], Loss: 2.4175, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [353/375], Loss: 2.3446, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [354/375], Loss: 2.3283, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [355/375], Loss: 2.2574, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [356/375], Loss: 2.4066, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [357/375], Loss: 2.0516, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [358/375], Loss: 2.1767, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [359/375], Loss: 2.2023, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [360/375], Loss: 2.3597, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [27/50], Step [361/375], Loss: 2.2016, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [27/50], Step [362/375], Loss: 2.3262, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [27/50], Step [363/375], Loss: 2.3324, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [27/50], Step [364/375], Loss: 2.3915, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [27/50], Step [365/375], Loss: 1.9840, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [366/375], Loss: 2.0348, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [27/50], Step [367/375], Loss: 2.2626, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [27/50], Step [368/375], Loss: 2.2561, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [27/50], Step [369/375], Loss: 2.2545, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [27/50], Step [370/375], Loss: 2.1912, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [27/50], Step [371/375], Loss: 2.4291, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [372/375], Loss: 2.2582, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [27/50], Step [373/375], Loss: 1.8643, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [27/50], Step [374/375], Loss: 2.2595, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [27/50], Step [375/375], Loss: 2.2022, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [1/375], Loss: 2.2806, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [2/375], Loss: 2.2195, batch time: 0.84, accuracy:  12.50%\n",
      "Epoch [28/50], Step [3/375], Loss: 2.4299, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [4/375], Loss: 2.2764, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [5/375], Loss: 2.2430, batch time: 0.29, accuracy:  25.00%\n",
      "Epoch [28/50], Step [6/375], Loss: 2.4241, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [7/375], Loss: 2.3281, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [8/375], Loss: 2.3510, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [28/50], Step [9/375], Loss: 2.3413, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [10/375], Loss: 2.2631, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [11/375], Loss: 2.5058, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [28/50], Step [12/375], Loss: 2.3132, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [13/375], Loss: 2.2364, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [14/375], Loss: 2.4937, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [28/50], Step [15/375], Loss: 2.2426, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [16/375], Loss: 2.2767, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [17/375], Loss: 2.2160, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [18/375], Loss: 2.2327, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [19/375], Loss: 2.1158, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [28/50], Step [20/375], Loss: 2.1773, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [21/375], Loss: 2.1832, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [22/375], Loss: 2.2781, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [23/375], Loss: 2.2494, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [28/50], Step [24/375], Loss: 2.1816, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [28/50], Step [25/375], Loss: 2.2916, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [26/375], Loss: 2.3214, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [27/375], Loss: 2.0406, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [28/50], Step [28/375], Loss: 2.2217, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [29/375], Loss: 2.2125, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [30/375], Loss: 2.2857, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [31/375], Loss: 2.2050, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [32/375], Loss: 2.4283, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [28/50], Step [33/375], Loss: 2.2583, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [34/375], Loss: 2.0959, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [35/375], Loss: 2.3532, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [36/375], Loss: 2.1001, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [37/375], Loss: 2.2556, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [38/375], Loss: 2.1058, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [28/50], Step [39/375], Loss: 2.5371, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [28/50], Step [40/375], Loss: 2.1564, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [41/375], Loss: 2.4630, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [42/375], Loss: 2.2895, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [43/375], Loss: 2.1774, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [44/375], Loss: 2.3633, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [45/375], Loss: 2.3736, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [46/375], Loss: 2.3132, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [47/375], Loss: 2.2522, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [48/375], Loss: 2.2656, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [49/375], Loss: 2.2238, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [50/375], Loss: 2.2363, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [51/375], Loss: 2.1084, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [28/50], Step [52/375], Loss: 2.2603, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [53/375], Loss: 2.2590, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [54/375], Loss: 2.1844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [55/375], Loss: 2.3716, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [56/375], Loss: 2.1416, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [57/375], Loss: 2.4128, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [58/375], Loss: 2.2263, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [59/375], Loss: 2.2932, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [60/375], Loss: 2.2131, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [61/375], Loss: 2.2071, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [62/375], Loss: 2.1757, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [63/375], Loss: 2.3262, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [64/375], Loss: 2.2681, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [65/375], Loss: 2.2796, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [66/375], Loss: 2.2513, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [67/375], Loss: 2.2756, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [68/375], Loss: 2.2603, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [69/375], Loss: 2.3206, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [70/375], Loss: 2.2261, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [71/375], Loss: 2.1051, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [72/375], Loss: 2.1395, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [73/375], Loss: 2.2474, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [74/375], Loss: 2.1497, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [75/375], Loss: 2.1358, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [28/50], Step [76/375], Loss: 2.1243, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [77/375], Loss: 2.1737, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [28/50], Step [78/375], Loss: 2.0218, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [79/375], Loss: 2.1393, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [80/375], Loss: 2.1318, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [81/375], Loss: 2.0128, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [82/375], Loss: 2.2951, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [83/375], Loss: 2.2153, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [84/375], Loss: 2.0732, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [85/375], Loss: 2.2670, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [86/375], Loss: 2.2473, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [87/375], Loss: 2.2104, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [88/375], Loss: 2.3513, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [89/375], Loss: 2.1086, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [90/375], Loss: 2.2771, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [91/375], Loss: 2.2350, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [92/375], Loss: 2.3511, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [93/375], Loss: 2.2634, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [94/375], Loss: 2.2045, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [95/375], Loss: 2.4084, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [28/50], Step [96/375], Loss: 2.3177, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [97/375], Loss: 2.3070, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [98/375], Loss: 2.2232, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [99/375], Loss: 2.0812, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [28/50], Step [100/375], Loss: 2.0699, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [101/375], Loss: 2.2637, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [102/375], Loss: 1.9026, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [28/50], Step [103/375], Loss: 2.2598, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [104/375], Loss: 2.1799, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [105/375], Loss: 2.2108, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [106/375], Loss: 2.1435, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [107/375], Loss: 2.3830, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [28/50], Step [108/375], Loss: 2.5598, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [109/375], Loss: 2.3615, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [28/50], Step [110/375], Loss: 2.3388, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [111/375], Loss: 2.2434, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [112/375], Loss: 2.1879, batch time: 0.96, accuracy:  18.75%\n",
      "Epoch [28/50], Step [113/375], Loss: 2.0913, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [28/50], Step [114/375], Loss: 2.3103, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [115/375], Loss: 2.1220, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [28/50], Step [116/375], Loss: 2.0495, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [28/50], Step [117/375], Loss: 2.0543, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [118/375], Loss: 2.1235, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [28/50], Step [119/375], Loss: 2.0660, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [120/375], Loss: 2.3017, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [121/375], Loss: 2.1593, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [28/50], Step [122/375], Loss: 2.2396, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [123/375], Loss: 2.4534, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [124/375], Loss: 2.3180, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [125/375], Loss: 2.2721, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [126/375], Loss: 2.1182, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [127/375], Loss: 2.2827, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [128/375], Loss: 1.9792, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [129/375], Loss: 2.3257, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [130/375], Loss: 2.2045, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [131/375], Loss: 2.2457, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [132/375], Loss: 2.1100, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [133/375], Loss: 2.1698, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [134/375], Loss: 2.3247, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [135/375], Loss: 2.2463, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [136/375], Loss: 2.1703, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [137/375], Loss: 2.2628, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [138/375], Loss: 2.2902, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [139/375], Loss: 2.0089, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [140/375], Loss: 2.2393, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [141/375], Loss: 2.3218, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [28/50], Step [142/375], Loss: 2.3627, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [143/375], Loss: 2.0968, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [144/375], Loss: 2.0926, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [145/375], Loss: 2.0913, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [28/50], Step [146/375], Loss: 2.1312, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [147/375], Loss: 2.2221, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [148/375], Loss: 2.1811, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [149/375], Loss: 2.2759, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [150/375], Loss: 2.2113, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [151/375], Loss: 2.2765, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [152/375], Loss: 2.1857, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [153/375], Loss: 2.2328, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [154/375], Loss: 2.4951, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [155/375], Loss: 2.2593, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [156/375], Loss: 2.2024, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [157/375], Loss: 2.5192, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [28/50], Step [158/375], Loss: 2.2462, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [159/375], Loss: 2.2500, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [160/375], Loss: 2.0272, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [161/375], Loss: 2.3455, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [162/375], Loss: 2.1673, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [163/375], Loss: 2.2308, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [164/375], Loss: 2.2055, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [165/375], Loss: 2.1925, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [166/375], Loss: 2.4625, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [167/375], Loss: 2.3110, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [168/375], Loss: 2.1919, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [169/375], Loss: 2.2501, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [170/375], Loss: 2.5589, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [171/375], Loss: 2.0900, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [172/375], Loss: 2.4158, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [173/375], Loss: 2.0142, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [174/375], Loss: 2.1527, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [175/375], Loss: 2.2959, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [176/375], Loss: 2.1567, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [177/375], Loss: 2.3041, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [178/375], Loss: 2.1197, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [179/375], Loss: 2.3366, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [180/375], Loss: 2.2408, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [181/375], Loss: 2.3134, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [28/50], Step [182/375], Loss: 2.4160, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [183/375], Loss: 2.4275, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [184/375], Loss: 2.2468, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [185/375], Loss: 2.3450, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [186/375], Loss: 2.2026, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [187/375], Loss: 2.3262, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [188/375], Loss: 2.1666, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [189/375], Loss: 2.2524, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [190/375], Loss: 2.2697, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [191/375], Loss: 2.2630, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [192/375], Loss: 2.2931, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [193/375], Loss: 2.1923, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [28/50], Step [194/375], Loss: 2.2537, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [195/375], Loss: 2.3632, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [196/375], Loss: 2.0873, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [197/375], Loss: 2.2584, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [28/50], Step [198/375], Loss: 2.3843, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [28/50], Step [199/375], Loss: 2.2251, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [200/375], Loss: 2.1152, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [201/375], Loss: 2.2605, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [202/375], Loss: 2.2695, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [203/375], Loss: 2.4438, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [204/375], Loss: 2.2243, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [205/375], Loss: 2.0482, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [28/50], Step [206/375], Loss: 2.2354, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [207/375], Loss: 2.1265, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [208/375], Loss: 2.2836, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [209/375], Loss: 2.2331, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [210/375], Loss: 2.2624, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [211/375], Loss: 2.2271, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [212/375], Loss: 2.2649, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [213/375], Loss: 2.2067, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [214/375], Loss: 2.2936, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [215/375], Loss: 2.1912, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [216/375], Loss: 2.2034, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [217/375], Loss: 2.1665, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [28/50], Step [218/375], Loss: 2.2854, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [219/375], Loss: 2.1749, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [220/375], Loss: 2.2566, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [221/375], Loss: 2.2132, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [222/375], Loss: 2.1112, batch time: 0.83, accuracy:  31.25%\n",
      "Epoch [28/50], Step [223/375], Loss: 2.2845, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [224/375], Loss: 2.1904, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [225/375], Loss: 2.2217, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [28/50], Step [226/375], Loss: 2.2285, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [227/375], Loss: 2.3062, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [228/375], Loss: 2.4489, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [28/50], Step [229/375], Loss: 2.2300, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [230/375], Loss: 2.3668, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [231/375], Loss: 2.2113, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [28/50], Step [232/375], Loss: 2.3782, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [233/375], Loss: 2.4490, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [234/375], Loss: 1.8939, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [28/50], Step [235/375], Loss: 2.2962, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [28/50], Step [236/375], Loss: 2.2938, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [237/375], Loss: 2.2652, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [238/375], Loss: 2.1900, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [239/375], Loss: 2.3618, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [28/50], Step [240/375], Loss: 2.2759, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [241/375], Loss: 2.2853, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [242/375], Loss: 2.4883, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [243/375], Loss: 2.1957, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [244/375], Loss: 2.2030, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [245/375], Loss: 2.1537, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [246/375], Loss: 2.0532, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [247/375], Loss: 2.2594, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [248/375], Loss: 2.2336, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [249/375], Loss: 2.1376, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [28/50], Step [250/375], Loss: 2.2591, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [251/375], Loss: 2.2394, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [252/375], Loss: 2.3262, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [253/375], Loss: 2.3663, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [254/375], Loss: 2.2970, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [255/375], Loss: 2.0372, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [28/50], Step [256/375], Loss: 2.3751, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [257/375], Loss: 2.2013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [258/375], Loss: 2.2344, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [28/50], Step [259/375], Loss: 2.1659, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [28/50], Step [260/375], Loss: 2.2147, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [261/375], Loss: 2.3686, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [28/50], Step [262/375], Loss: 2.2110, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [263/375], Loss: 2.3671, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [264/375], Loss: 2.2518, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [265/375], Loss: 2.1727, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [266/375], Loss: 2.2243, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [267/375], Loss: 2.3228, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [28/50], Step [268/375], Loss: 2.2696, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [269/375], Loss: 2.2315, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [270/375], Loss: 2.2963, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [271/375], Loss: 2.0027, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [28/50], Step [272/375], Loss: 2.1234, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [273/375], Loss: 2.2252, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [274/375], Loss: 2.2083, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [275/375], Loss: 2.2000, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [276/375], Loss: 2.1641, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [277/375], Loss: 2.2491, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [278/375], Loss: 2.2075, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [279/375], Loss: 2.1324, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [28/50], Step [280/375], Loss: 2.3147, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [28/50], Step [281/375], Loss: 2.2054, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [282/375], Loss: 2.1375, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [283/375], Loss: 2.1622, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [284/375], Loss: 2.0680, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [285/375], Loss: 2.2628, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [286/375], Loss: 2.2198, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [287/375], Loss: 2.3177, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [288/375], Loss: 2.1359, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [289/375], Loss: 2.1434, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [290/375], Loss: 2.1912, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [291/375], Loss: 2.3260, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [292/375], Loss: 2.2842, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [293/375], Loss: 2.3400, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [294/375], Loss: 2.2746, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [295/375], Loss: 2.0729, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [296/375], Loss: 2.3023, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [297/375], Loss: 2.1352, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [298/375], Loss: 2.3165, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [299/375], Loss: 2.1202, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [300/375], Loss: 2.1885, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [301/375], Loss: 2.1524, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [302/375], Loss: 2.2959, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [303/375], Loss: 2.2575, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [304/375], Loss: 2.3736, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [305/375], Loss: 2.1099, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [306/375], Loss: 2.2940, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [307/375], Loss: 2.2914, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [308/375], Loss: 2.2452, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [309/375], Loss: 2.3313, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [310/375], Loss: 2.1706, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [311/375], Loss: 2.3320, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [28/50], Step [312/375], Loss: 2.3427, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [313/375], Loss: 2.3013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [314/375], Loss: 2.1855, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [315/375], Loss: 2.2489, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [316/375], Loss: 2.2943, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [317/375], Loss: 2.1609, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [318/375], Loss: 2.2013, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [319/375], Loss: 2.3681, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [320/375], Loss: 2.1768, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [321/375], Loss: 2.2504, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [322/375], Loss: 2.0592, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [28/50], Step [323/375], Loss: 2.3747, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [28/50], Step [324/375], Loss: 2.2504, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [325/375], Loss: 2.3767, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [28/50], Step [326/375], Loss: 2.3175, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [28/50], Step [327/375], Loss: 2.1337, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [28/50], Step [328/375], Loss: 2.1369, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [329/375], Loss: 2.3439, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [330/375], Loss: 2.2150, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [331/375], Loss: 2.2106, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [332/375], Loss: 2.4932, batch time: 0.84, accuracy:  12.50%\n",
      "Epoch [28/50], Step [333/375], Loss: 2.0214, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [28/50], Step [334/375], Loss: 2.1252, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [335/375], Loss: 2.1946, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [28/50], Step [336/375], Loss: 2.3370, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [337/375], Loss: 2.1983, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [338/375], Loss: 2.2679, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [28/50], Step [339/375], Loss: 2.2010, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [340/375], Loss: 2.3721, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [341/375], Loss: 2.0722, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [28/50], Step [342/375], Loss: 2.2848, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [343/375], Loss: 2.1438, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [344/375], Loss: 2.0869, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [345/375], Loss: 2.2876, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [346/375], Loss: 2.1999, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [28/50], Step [347/375], Loss: 2.2665, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [348/375], Loss: 2.1070, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [349/375], Loss: 2.1092, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [28/50], Step [350/375], Loss: 2.1734, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [351/375], Loss: 2.3021, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [352/375], Loss: 2.5006, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [28/50], Step [353/375], Loss: 2.0968, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [28/50], Step [354/375], Loss: 2.1259, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [28/50], Step [355/375], Loss: 2.1418, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [356/375], Loss: 2.3446, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [357/375], Loss: 2.3095, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [28/50], Step [358/375], Loss: 2.2562, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [359/375], Loss: 2.2006, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [360/375], Loss: 2.3886, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [361/375], Loss: 2.1639, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [28/50], Step [362/375], Loss: 2.1671, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [363/375], Loss: 1.9823, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [364/375], Loss: 2.3075, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [28/50], Step [365/375], Loss: 2.1650, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [28/50], Step [366/375], Loss: 2.1913, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [28/50], Step [367/375], Loss: 2.1547, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [368/375], Loss: 2.0688, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [28/50], Step [369/375], Loss: 2.3942, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [28/50], Step [370/375], Loss: 2.1647, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [371/375], Loss: 2.4393, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [28/50], Step [372/375], Loss: 2.1900, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [28/50], Step [373/375], Loss: 2.0793, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [28/50], Step [374/375], Loss: 2.0374, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [28/50], Step [375/375], Loss: 2.0311, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [1/375], Loss: 2.3881, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [2/375], Loss: 2.1774, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [3/375], Loss: 2.1735, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [4/375], Loss: 2.1780, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [5/375], Loss: 2.0054, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [6/375], Loss: 2.2435, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [7/375], Loss: 2.3638, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [8/375], Loss: 2.2448, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [9/375], Loss: 2.2653, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [10/375], Loss: 2.1827, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [11/375], Loss: 2.2857, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [29/50], Step [12/375], Loss: 2.4517, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [13/375], Loss: 2.2602, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [14/375], Loss: 2.3164, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [29/50], Step [15/375], Loss: 2.3376, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [16/375], Loss: 2.3759, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [17/375], Loss: 2.3813, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [18/375], Loss: 2.1838, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [19/375], Loss: 2.2666, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [20/375], Loss: 2.2156, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [21/375], Loss: 2.0356, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [22/375], Loss: 2.2969, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [23/375], Loss: 2.4297, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [24/375], Loss: 2.3173, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [25/375], Loss: 2.2724, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [26/375], Loss: 2.2485, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [27/375], Loss: 2.2769, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [28/375], Loss: 2.1143, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [29/375], Loss: 2.3849, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [30/375], Loss: 2.3850, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [31/375], Loss: 2.3309, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [32/375], Loss: 2.2414, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [33/375], Loss: 2.0045, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [29/50], Step [34/375], Loss: 2.3054, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [35/375], Loss: 2.1739, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [36/375], Loss: 2.1565, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [37/375], Loss: 2.3501, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [38/375], Loss: 2.1455, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [39/375], Loss: 2.3665, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [29/50], Step [40/375], Loss: 2.3898, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [41/375], Loss: 2.3152, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [42/375], Loss: 2.3262, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [43/375], Loss: 2.2388, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [44/375], Loss: 2.3224, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [45/375], Loss: 2.2789, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [46/375], Loss: 2.2510, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [29/50], Step [47/375], Loss: 2.3011, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [48/375], Loss: 2.1745, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [49/375], Loss: 2.2969, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [50/375], Loss: 2.1577, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [29/50], Step [51/375], Loss: 2.1339, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [52/375], Loss: 2.2740, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [53/375], Loss: 2.2718, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [54/375], Loss: 2.3981, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [55/375], Loss: 2.1684, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [56/375], Loss: 2.3056, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [57/375], Loss: 2.3158, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [58/375], Loss: 2.3002, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [29/50], Step [59/375], Loss: 2.2434, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [60/375], Loss: 2.2224, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [61/375], Loss: 2.1455, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [62/375], Loss: 2.2561, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [63/375], Loss: 2.3710, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [64/375], Loss: 1.9963, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [65/375], Loss: 2.2573, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [66/375], Loss: 2.3503, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [67/375], Loss: 2.1348, batch time: 0.92, accuracy:  25.00%\n",
      "Epoch [29/50], Step [68/375], Loss: 2.0226, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [69/375], Loss: 2.2128, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [70/375], Loss: 2.3056, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [29/50], Step [71/375], Loss: 2.2296, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [72/375], Loss: 2.1665, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [73/375], Loss: 2.1802, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [29/50], Step [74/375], Loss: 2.2467, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [75/375], Loss: 2.2897, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [76/375], Loss: 2.0716, batch time: 0.29, accuracy:  50.00%\n",
      "Epoch [29/50], Step [77/375], Loss: 2.4092, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [78/375], Loss: 2.3034, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [79/375], Loss: 2.2522, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [80/375], Loss: 2.3906, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [29/50], Step [81/375], Loss: 2.1637, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [82/375], Loss: 2.0258, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [29/50], Step [83/375], Loss: 2.0287, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [84/375], Loss: 2.1021, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [29/50], Step [85/375], Loss: 2.1336, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [86/375], Loss: 2.3139, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [87/375], Loss: 2.1970, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [88/375], Loss: 2.3294, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [89/375], Loss: 2.3785, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [90/375], Loss: 2.2277, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [91/375], Loss: 2.1743, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [92/375], Loss: 2.2190, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [93/375], Loss: 2.4851, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [94/375], Loss: 2.2731, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [95/375], Loss: 2.1220, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [96/375], Loss: 2.1578, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [97/375], Loss: 2.2124, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [98/375], Loss: 2.1792, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [99/375], Loss: 2.1731, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [100/375], Loss: 2.2335, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [101/375], Loss: 2.3531, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [102/375], Loss: 2.2940, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [103/375], Loss: 2.1402, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [29/50], Step [104/375], Loss: 2.2531, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [105/375], Loss: 2.2572, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [106/375], Loss: 2.1973, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [107/375], Loss: 2.2061, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [108/375], Loss: 2.2054, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [29/50], Step [109/375], Loss: 2.1889, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [110/375], Loss: 2.0673, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [111/375], Loss: 2.3160, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [112/375], Loss: 2.1247, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [113/375], Loss: 2.1289, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [114/375], Loss: 2.4175, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [29/50], Step [115/375], Loss: 2.2012, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [116/375], Loss: 2.2634, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [29/50], Step [117/375], Loss: 2.1078, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [118/375], Loss: 1.8909, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [29/50], Step [119/375], Loss: 2.2951, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [120/375], Loss: 2.1650, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [29/50], Step [121/375], Loss: 2.1128, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [122/375], Loss: 2.1486, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [123/375], Loss: 2.1289, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [124/375], Loss: 2.0847, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [125/375], Loss: 2.2289, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [126/375], Loss: 2.1858, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [127/375], Loss: 2.3294, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [128/375], Loss: 2.4941, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [29/50], Step [129/375], Loss: 2.2449, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [130/375], Loss: 2.2104, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [131/375], Loss: 2.1045, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [132/375], Loss: 1.9633, batch time: 0.27, accuracy:  56.25%\n",
      "Epoch [29/50], Step [133/375], Loss: 2.2128, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [134/375], Loss: 2.3311, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [135/375], Loss: 2.3619, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [136/375], Loss: 1.9676, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [137/375], Loss: 2.0262, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [138/375], Loss: 2.2957, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [139/375], Loss: 2.2441, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [140/375], Loss: 2.2525, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [141/375], Loss: 2.3186, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [142/375], Loss: 2.0678, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [143/375], Loss: 2.4415, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [144/375], Loss: 2.1560, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [145/375], Loss: 2.2558, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [146/375], Loss: 2.3648, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [147/375], Loss: 2.3889, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [29/50], Step [148/375], Loss: 2.2943, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [149/375], Loss: 2.0921, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [150/375], Loss: 2.1967, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [151/375], Loss: 2.3636, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [152/375], Loss: 2.4896, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [153/375], Loss: 2.1355, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [154/375], Loss: 2.2905, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [155/375], Loss: 2.3905, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [156/375], Loss: 2.2947, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [157/375], Loss: 2.2089, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [158/375], Loss: 2.2665, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [159/375], Loss: 2.2176, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [160/375], Loss: 2.1823, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [161/375], Loss: 2.2068, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [162/375], Loss: 2.2667, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [163/375], Loss: 2.2954, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [164/375], Loss: 2.2865, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [165/375], Loss: 2.3120, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [166/375], Loss: 2.3156, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [167/375], Loss: 2.3767, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [168/375], Loss: 2.1102, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [169/375], Loss: 2.3482, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [170/375], Loss: 2.1507, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [171/375], Loss: 2.1733, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [172/375], Loss: 2.2424, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [173/375], Loss: 2.0185, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [29/50], Step [174/375], Loss: 2.1478, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [175/375], Loss: 2.1550, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [176/375], Loss: 2.2640, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [177/375], Loss: 2.3198, batch time: 1.02, accuracy:  25.00%\n",
      "Epoch [29/50], Step [178/375], Loss: 2.2424, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [179/375], Loss: 2.4127, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [180/375], Loss: 2.2561, batch time: 0.29, accuracy:  37.50%\n",
      "Epoch [29/50], Step [181/375], Loss: 2.1441, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [182/375], Loss: 2.1103, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [183/375], Loss: 2.0584, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [29/50], Step [184/375], Loss: 2.2388, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [185/375], Loss: 2.4279, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [186/375], Loss: 2.2936, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [29/50], Step [187/375], Loss: 2.0310, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [188/375], Loss: 2.2227, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [189/375], Loss: 2.2406, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [190/375], Loss: 2.1052, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [191/375], Loss: 2.0507, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [192/375], Loss: 2.3366, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [193/375], Loss: 2.2916, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [194/375], Loss: 2.1509, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [195/375], Loss: 2.0762, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [196/375], Loss: 2.3869, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [197/375], Loss: 2.3498, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [198/375], Loss: 2.2356, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [199/375], Loss: 2.1882, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [200/375], Loss: 2.3604, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [201/375], Loss: 2.4154, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [202/375], Loss: 2.2486, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [203/375], Loss: 2.2244, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [204/375], Loss: 2.2911, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [205/375], Loss: 2.2427, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [206/375], Loss: 2.1409, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [207/375], Loss: 2.3835, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [208/375], Loss: 2.3246, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [209/375], Loss: 2.0974, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [210/375], Loss: 2.2304, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [211/375], Loss: 2.1169, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [212/375], Loss: 2.1835, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [213/375], Loss: 2.1975, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [214/375], Loss: 2.2078, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [215/375], Loss: 2.4469, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [216/375], Loss: 2.4888, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [29/50], Step [217/375], Loss: 2.4044, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [218/375], Loss: 2.0954, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [219/375], Loss: 2.3592, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [220/375], Loss: 2.2274, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [221/375], Loss: 2.4407, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [222/375], Loss: 2.1480, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [223/375], Loss: 2.2893, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [224/375], Loss: 2.2178, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [225/375], Loss: 2.0995, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [226/375], Loss: 2.2920, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [29/50], Step [227/375], Loss: 1.8482, batch time: 0.25, accuracy:  62.50%\n",
      "Epoch [29/50], Step [228/375], Loss: 2.2527, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [229/375], Loss: 2.3462, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [230/375], Loss: 2.2060, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [231/375], Loss: 2.4847, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [232/375], Loss: 2.3371, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [233/375], Loss: 2.2708, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [234/375], Loss: 2.0945, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [235/375], Loss: 2.2838, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [236/375], Loss: 2.2762, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [29/50], Step [237/375], Loss: 2.3746, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [238/375], Loss: 2.3077, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [29/50], Step [239/375], Loss: 2.3604, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [240/375], Loss: 2.2181, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [241/375], Loss: 2.0342, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [29/50], Step [242/375], Loss: 2.0301, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [243/375], Loss: 2.2165, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [244/375], Loss: 2.2230, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [245/375], Loss: 2.4087, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [246/375], Loss: 2.1603, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [29/50], Step [247/375], Loss: 2.2102, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [248/375], Loss: 2.3599, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [249/375], Loss: 2.3456, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [29/50], Step [250/375], Loss: 2.1726, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [29/50], Step [251/375], Loss: 2.1624, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [252/375], Loss: 2.2944, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [253/375], Loss: 2.1863, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [254/375], Loss: 2.2416, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [255/375], Loss: 2.0642, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [256/375], Loss: 2.2472, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [257/375], Loss: 2.2215, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [258/375], Loss: 2.1655, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [29/50], Step [259/375], Loss: 2.2304, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [260/375], Loss: 2.0232, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [261/375], Loss: 2.4128, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [29/50], Step [262/375], Loss: 2.0972, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [263/375], Loss: 2.1358, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [264/375], Loss: 2.3325, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [265/375], Loss: 2.4917, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [266/375], Loss: 2.2124, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [267/375], Loss: 2.4191, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [268/375], Loss: 2.2048, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [269/375], Loss: 2.0951, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [29/50], Step [270/375], Loss: 2.2768, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [271/375], Loss: 2.4732, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [272/375], Loss: 2.1864, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [273/375], Loss: 2.1180, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [274/375], Loss: 2.1626, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [275/375], Loss: 2.3474, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [276/375], Loss: 2.2513, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [277/375], Loss: 2.1403, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [29/50], Step [278/375], Loss: 2.3155, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [279/375], Loss: 2.1566, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [280/375], Loss: 2.2492, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [281/375], Loss: 2.2977, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [282/375], Loss: 2.2854, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [283/375], Loss: 2.0970, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [284/375], Loss: 2.4275, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [285/375], Loss: 2.2962, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [286/375], Loss: 2.1249, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [287/375], Loss: 2.2608, batch time: 0.89, accuracy:  18.75%\n",
      "Epoch [29/50], Step [288/375], Loss: 2.1846, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [289/375], Loss: 2.1765, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [290/375], Loss: 2.2854, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [29/50], Step [291/375], Loss: 2.2063, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [292/375], Loss: 2.1467, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [293/375], Loss: 2.0910, batch time: 0.30, accuracy:  37.50%\n",
      "Epoch [29/50], Step [294/375], Loss: 2.4026, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [295/375], Loss: 2.3420, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [296/375], Loss: 2.2633, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [29/50], Step [297/375], Loss: 2.0009, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [298/375], Loss: 2.3235, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [299/375], Loss: 2.3616, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [29/50], Step [300/375], Loss: 2.1308, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [29/50], Step [301/375], Loss: 2.1072, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [302/375], Loss: 2.1108, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [303/375], Loss: 2.4371, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [304/375], Loss: 2.2655, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [29/50], Step [305/375], Loss: 2.4120, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [29/50], Step [306/375], Loss: 2.0791, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [29/50], Step [307/375], Loss: 2.2272, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [308/375], Loss: 2.0854, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [29/50], Step [309/375], Loss: 2.2831, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [310/375], Loss: 2.3216, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [311/375], Loss: 2.3129, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [312/375], Loss: 2.0904, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [29/50], Step [313/375], Loss: 2.1862, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [314/375], Loss: 1.8512, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [29/50], Step [315/375], Loss: 2.2402, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [316/375], Loss: 2.2667, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [317/375], Loss: 2.1887, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [318/375], Loss: 2.3832, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [319/375], Loss: 2.1582, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [320/375], Loss: 2.3074, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [321/375], Loss: 2.2233, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [322/375], Loss: 2.3079, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [323/375], Loss: 2.0303, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [29/50], Step [324/375], Loss: 2.3617, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [29/50], Step [325/375], Loss: 2.2982, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [29/50], Step [326/375], Loss: 2.2442, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [327/375], Loss: 2.1056, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [328/375], Loss: 2.3177, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [329/375], Loss: 2.5390, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [29/50], Step [330/375], Loss: 2.3006, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [331/375], Loss: 2.2012, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [332/375], Loss: 2.1817, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [333/375], Loss: 2.0984, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [334/375], Loss: 2.2143, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [335/375], Loss: 2.1253, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [336/375], Loss: 2.1657, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [337/375], Loss: 2.1834, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [338/375], Loss: 2.2857, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [339/375], Loss: 2.1782, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [29/50], Step [340/375], Loss: 2.1652, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [29/50], Step [341/375], Loss: 2.3881, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [342/375], Loss: 2.1741, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [343/375], Loss: 2.2000, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [344/375], Loss: 2.3232, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [29/50], Step [345/375], Loss: 2.3319, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [346/375], Loss: 2.1010, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [347/375], Loss: 2.1238, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [348/375], Loss: 2.1473, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [349/375], Loss: 2.2934, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [29/50], Step [350/375], Loss: 2.2080, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [29/50], Step [351/375], Loss: 2.2486, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [352/375], Loss: 2.1913, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [353/375], Loss: 2.1400, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [354/375], Loss: 2.1781, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [355/375], Loss: 2.2737, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [356/375], Loss: 2.2431, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [357/375], Loss: 2.2003, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [29/50], Step [358/375], Loss: 2.3606, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [359/375], Loss: 2.2327, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [360/375], Loss: 2.2915, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [361/375], Loss: 2.0087, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [29/50], Step [362/375], Loss: 2.2672, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [363/375], Loss: 2.1211, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [364/375], Loss: 2.3388, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [29/50], Step [365/375], Loss: 2.3113, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [29/50], Step [366/375], Loss: 2.2952, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [367/375], Loss: 2.2906, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [368/375], Loss: 2.1782, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [29/50], Step [369/375], Loss: 2.1719, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [29/50], Step [370/375], Loss: 2.1910, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [29/50], Step [371/375], Loss: 2.0955, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [372/375], Loss: 2.3678, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [29/50], Step [373/375], Loss: 2.2570, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [374/375], Loss: 2.3439, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [29/50], Step [375/375], Loss: 2.2435, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [1/375], Loss: 2.2150, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [2/375], Loss: 2.1820, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [3/375], Loss: 2.2291, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [4/375], Loss: 2.2874, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [5/375], Loss: 2.2825, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [6/375], Loss: 2.1864, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [7/375], Loss: 2.1407, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [8/375], Loss: 2.2910, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [9/375], Loss: 2.2307, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [10/375], Loss: 2.2688, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [11/375], Loss: 2.2150, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [12/375], Loss: 2.3909, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [13/375], Loss: 2.0438, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [30/50], Step [14/375], Loss: 2.1807, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [15/375], Loss: 2.3220, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [16/375], Loss: 2.1845, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [17/375], Loss: 2.1820, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [18/375], Loss: 2.3339, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [19/375], Loss: 2.2263, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [20/375], Loss: 2.2080, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [21/375], Loss: 2.1353, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [30/50], Step [22/375], Loss: 2.2218, batch time: 0.84, accuracy:  18.75%\n",
      "Epoch [30/50], Step [23/375], Loss: 2.1319, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [24/375], Loss: 2.2243, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [25/375], Loss: 2.2855, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [30/50], Step [26/375], Loss: 2.2116, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [27/375], Loss: 2.3869, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [28/375], Loss: 2.2946, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [30/50], Step [29/375], Loss: 2.0702, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [30/375], Loss: 2.2590, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [31/375], Loss: 2.3441, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [30/50], Step [32/375], Loss: 2.3381, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [33/375], Loss: 2.2893, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [34/375], Loss: 2.2657, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [35/375], Loss: 2.2029, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [30/50], Step [36/375], Loss: 2.3475, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [37/375], Loss: 2.1779, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [38/375], Loss: 2.1940, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [39/375], Loss: 2.1819, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [40/375], Loss: 2.1938, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [41/375], Loss: 2.2483, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [42/375], Loss: 2.1818, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [43/375], Loss: 2.2691, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [44/375], Loss: 2.3086, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [45/375], Loss: 2.1132, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [46/375], Loss: 2.3961, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [47/375], Loss: 2.3386, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [30/50], Step [48/375], Loss: 2.1677, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [49/375], Loss: 2.3509, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [50/375], Loss: 2.3266, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [51/375], Loss: 2.2941, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [52/375], Loss: 2.1686, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [53/375], Loss: 2.0781, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [54/375], Loss: 2.2058, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [55/375], Loss: 2.2928, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [56/375], Loss: 2.2623, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [57/375], Loss: 2.1919, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [58/375], Loss: 2.2065, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [59/375], Loss: 2.3045, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [60/375], Loss: 2.3834, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [61/375], Loss: 2.3728, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [62/375], Loss: 2.1284, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [63/375], Loss: 2.2943, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [64/375], Loss: 2.2256, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [65/375], Loss: 2.0881, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [66/375], Loss: 2.2760, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [67/375], Loss: 2.2460, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [68/375], Loss: 2.2126, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [69/375], Loss: 2.3076, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [70/375], Loss: 2.3862, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [71/375], Loss: 2.3902, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [30/50], Step [72/375], Loss: 2.3172, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [73/375], Loss: 2.1746, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [74/375], Loss: 2.1596, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [75/375], Loss: 2.3290, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [76/375], Loss: 2.3918, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [77/375], Loss: 2.4157, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [78/375], Loss: 2.2861, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [79/375], Loss: 2.3665, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [80/375], Loss: 2.1007, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [81/375], Loss: 2.3078, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [82/375], Loss: 2.1038, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [83/375], Loss: 2.3783, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [30/50], Step [84/375], Loss: 2.3122, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [85/375], Loss: 2.1916, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [86/375], Loss: 2.1971, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [87/375], Loss: 2.2667, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [88/375], Loss: 2.2294, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [89/375], Loss: 2.3536, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [30/50], Step [90/375], Loss: 2.3242, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [91/375], Loss: 2.3277, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [92/375], Loss: 2.2640, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [93/375], Loss: 2.2238, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [94/375], Loss: 2.2171, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [95/375], Loss: 2.2049, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [96/375], Loss: 2.1878, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [97/375], Loss: 2.2673, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [98/375], Loss: 2.0388, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [99/375], Loss: 2.1659, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [100/375], Loss: 2.2855, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [101/375], Loss: 2.2541, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [102/375], Loss: 2.3010, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [103/375], Loss: 2.1889, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [104/375], Loss: 2.0674, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [105/375], Loss: 2.1655, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [106/375], Loss: 2.2302, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [107/375], Loss: 2.2627, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [108/375], Loss: 2.1852, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [109/375], Loss: 2.2676, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [110/375], Loss: 2.4006, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [111/375], Loss: 2.3386, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [112/375], Loss: 2.1991, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [113/375], Loss: 1.9628, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [114/375], Loss: 2.1371, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [115/375], Loss: 1.9869, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [116/375], Loss: 2.3360, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [117/375], Loss: 2.2103, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [118/375], Loss: 2.0412, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [119/375], Loss: 2.2109, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [120/375], Loss: 2.3563, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [121/375], Loss: 2.2882, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [122/375], Loss: 2.2423, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [123/375], Loss: 1.9890, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [124/375], Loss: 2.3854, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [125/375], Loss: 2.2036, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [126/375], Loss: 2.3196, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [127/375], Loss: 2.0404, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [128/375], Loss: 2.3194, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [129/375], Loss: 2.0691, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [130/375], Loss: 2.0055, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [131/375], Loss: 2.3452, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [132/375], Loss: 2.3913, batch time: 0.84, accuracy:  6.25%\n",
      "Epoch [30/50], Step [133/375], Loss: 2.2668, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [134/375], Loss: 2.3094, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [135/375], Loss: 2.2437, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [30/50], Step [136/375], Loss: 2.3070, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [137/375], Loss: 1.9727, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [30/50], Step [138/375], Loss: 2.3030, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [30/50], Step [139/375], Loss: 2.1374, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [140/375], Loss: 2.3103, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [141/375], Loss: 2.3009, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [30/50], Step [142/375], Loss: 2.0365, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [143/375], Loss: 2.2853, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [144/375], Loss: 2.2693, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [145/375], Loss: 2.3916, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [146/375], Loss: 2.2125, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [147/375], Loss: 2.0700, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [148/375], Loss: 2.0958, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [149/375], Loss: 2.1817, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [150/375], Loss: 1.9136, batch time: 0.24, accuracy:  62.50%\n",
      "Epoch [30/50], Step [151/375], Loss: 2.2848, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [152/375], Loss: 2.1896, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [153/375], Loss: 2.4725, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [154/375], Loss: 2.3415, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [155/375], Loss: 2.0645, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [156/375], Loss: 2.0111, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [157/375], Loss: 2.4406, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [158/375], Loss: 2.1579, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [159/375], Loss: 2.2191, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [160/375], Loss: 2.1831, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [161/375], Loss: 2.3514, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [30/50], Step [162/375], Loss: 2.1235, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [163/375], Loss: 2.2988, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [164/375], Loss: 2.1163, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [165/375], Loss: 2.2125, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [166/375], Loss: 2.3521, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [167/375], Loss: 2.2560, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [168/375], Loss: 2.2584, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [169/375], Loss: 2.2443, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [170/375], Loss: 2.3188, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [171/375], Loss: 2.2773, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [172/375], Loss: 2.2149, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [173/375], Loss: 2.0912, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [174/375], Loss: 2.1206, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [175/375], Loss: 2.2986, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [176/375], Loss: 2.1230, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [177/375], Loss: 2.1941, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [178/375], Loss: 2.1984, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [179/375], Loss: 2.1604, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [180/375], Loss: 2.2521, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [181/375], Loss: 2.4024, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [30/50], Step [182/375], Loss: 1.9881, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [30/50], Step [183/375], Loss: 2.2865, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [184/375], Loss: 2.4040, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [185/375], Loss: 2.2404, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [186/375], Loss: 2.1656, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [187/375], Loss: 2.2826, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [188/375], Loss: 2.3831, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [189/375], Loss: 2.2422, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [190/375], Loss: 2.1103, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [191/375], Loss: 2.2022, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [192/375], Loss: 2.2086, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [193/375], Loss: 2.2239, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [194/375], Loss: 2.2113, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [195/375], Loss: 2.1494, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [196/375], Loss: 2.2625, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [197/375], Loss: 2.2127, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [198/375], Loss: 2.2398, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [199/375], Loss: 2.4293, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [200/375], Loss: 2.2195, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [201/375], Loss: 2.1127, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [202/375], Loss: 2.2541, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [203/375], Loss: 2.3841, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [204/375], Loss: 2.2732, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [205/375], Loss: 2.2046, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [206/375], Loss: 2.1510, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [207/375], Loss: 2.2411, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [208/375], Loss: 2.1634, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [209/375], Loss: 2.2679, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [210/375], Loss: 1.9210, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [30/50], Step [211/375], Loss: 2.1815, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [212/375], Loss: 1.9984, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [30/50], Step [213/375], Loss: 2.0830, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [214/375], Loss: 2.3886, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [215/375], Loss: 2.3777, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [216/375], Loss: 2.1551, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [217/375], Loss: 2.3561, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [218/375], Loss: 2.3569, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [219/375], Loss: 2.2838, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [220/375], Loss: 2.3474, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [221/375], Loss: 2.3512, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [30/50], Step [222/375], Loss: 2.2530, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [223/375], Loss: 2.2746, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [224/375], Loss: 2.3560, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [225/375], Loss: 2.1999, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [226/375], Loss: 2.3485, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [227/375], Loss: 2.2209, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [228/375], Loss: 2.3122, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [229/375], Loss: 2.1741, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [30/50], Step [230/375], Loss: 2.4050, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [231/375], Loss: 2.2544, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [232/375], Loss: 1.9616, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [233/375], Loss: 2.2529, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [30/50], Step [234/375], Loss: 2.1954, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [235/375], Loss: 2.2191, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [236/375], Loss: 2.2077, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [237/375], Loss: 2.1823, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [238/375], Loss: 2.3807, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [30/50], Step [239/375], Loss: 2.4632, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [240/375], Loss: 2.4671, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [30/50], Step [241/375], Loss: 2.2515, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [30/50], Step [242/375], Loss: 2.4493, batch time: 0.92, accuracy:  12.50%\n",
      "Epoch [30/50], Step [243/375], Loss: 2.1666, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [30/50], Step [244/375], Loss: 2.3083, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [245/375], Loss: 2.1884, batch time: 0.30, accuracy:  37.50%\n",
      "Epoch [30/50], Step [246/375], Loss: 2.1313, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [247/375], Loss: 2.3505, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [248/375], Loss: 2.1977, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [30/50], Step [249/375], Loss: 2.1714, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [250/375], Loss: 2.2658, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [251/375], Loss: 2.4939, batch time: 0.30, accuracy:  0.00%\n",
      "Epoch [30/50], Step [252/375], Loss: 2.0703, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [30/50], Step [253/375], Loss: 2.3247, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [254/375], Loss: 2.1767, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [255/375], Loss: 2.2084, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [30/50], Step [256/375], Loss: 2.2312, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [257/375], Loss: 2.2383, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [258/375], Loss: 2.0485, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [259/375], Loss: 2.3222, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [260/375], Loss: 2.3116, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [261/375], Loss: 2.2059, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [262/375], Loss: 2.2968, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [263/375], Loss: 2.2950, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [30/50], Step [264/375], Loss: 2.2792, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [265/375], Loss: 2.1003, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [30/50], Step [266/375], Loss: 2.1958, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [267/375], Loss: 2.3972, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [268/375], Loss: 2.3659, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [30/50], Step [269/375], Loss: 2.0131, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [270/375], Loss: 2.2664, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [271/375], Loss: 2.2908, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [30/50], Step [272/375], Loss: 2.2833, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [273/375], Loss: 2.2401, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [274/375], Loss: 2.0141, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [275/375], Loss: 2.0675, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [276/375], Loss: 2.3151, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [277/375], Loss: 2.0772, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [30/50], Step [278/375], Loss: 2.2679, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [279/375], Loss: 2.2271, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [30/50], Step [280/375], Loss: 2.3813, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [281/375], Loss: 2.0630, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [282/375], Loss: 2.0922, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [283/375], Loss: 2.3024, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [284/375], Loss: 2.0571, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [285/375], Loss: 2.3518, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [286/375], Loss: 2.2097, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [287/375], Loss: 2.1889, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [288/375], Loss: 1.8369, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [30/50], Step [289/375], Loss: 2.2533, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [290/375], Loss: 2.5276, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [291/375], Loss: 2.2399, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [292/375], Loss: 2.2431, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [293/375], Loss: 2.1208, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [294/375], Loss: 2.0979, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [295/375], Loss: 2.3842, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [30/50], Step [296/375], Loss: 2.1779, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [297/375], Loss: 2.3643, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [298/375], Loss: 2.2648, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [299/375], Loss: 2.3288, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [300/375], Loss: 2.4128, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [301/375], Loss: 2.1975, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [30/50], Step [302/375], Loss: 2.1606, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [303/375], Loss: 2.2280, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [304/375], Loss: 2.1416, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [305/375], Loss: 2.2188, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [306/375], Loss: 2.4560, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [30/50], Step [307/375], Loss: 2.0771, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [30/50], Step [308/375], Loss: 2.1652, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [309/375], Loss: 2.2614, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [310/375], Loss: 2.1942, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [311/375], Loss: 2.3753, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [312/375], Loss: 2.0954, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [313/375], Loss: 1.8067, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [30/50], Step [314/375], Loss: 2.4064, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [315/375], Loss: 2.2483, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [316/375], Loss: 2.2374, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [317/375], Loss: 2.1655, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [318/375], Loss: 2.3344, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [319/375], Loss: 2.2480, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [30/50], Step [320/375], Loss: 2.2357, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [30/50], Step [321/375], Loss: 2.3995, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [322/375], Loss: 2.2495, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [323/375], Loss: 2.2773, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [324/375], Loss: 2.0880, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [325/375], Loss: 2.3928, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [326/375], Loss: 2.2725, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [327/375], Loss: 2.1065, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [30/50], Step [328/375], Loss: 2.2191, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [329/375], Loss: 2.3321, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [330/375], Loss: 2.2442, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [331/375], Loss: 2.1839, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [30/50], Step [332/375], Loss: 2.2529, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [30/50], Step [333/375], Loss: 2.2902, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [334/375], Loss: 2.0990, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [30/50], Step [335/375], Loss: 2.2377, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [30/50], Step [336/375], Loss: 2.2474, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [337/375], Loss: 2.3188, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [338/375], Loss: 2.0770, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [339/375], Loss: 2.4231, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [30/50], Step [340/375], Loss: 2.3244, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [341/375], Loss: 2.3371, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [342/375], Loss: 2.2221, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [343/375], Loss: 2.3343, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [30/50], Step [344/375], Loss: 2.3165, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [345/375], Loss: 2.3189, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [346/375], Loss: 2.3863, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [347/375], Loss: 2.4045, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [30/50], Step [348/375], Loss: 2.4302, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [349/375], Loss: 2.3343, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [30/50], Step [350/375], Loss: 2.1764, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [351/375], Loss: 2.3242, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [30/50], Step [352/375], Loss: 2.1342, batch time: 0.91, accuracy:  25.00%\n",
      "Epoch [30/50], Step [353/375], Loss: 2.2938, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [354/375], Loss: 2.1866, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [355/375], Loss: 2.1615, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [30/50], Step [356/375], Loss: 2.1503, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [357/375], Loss: 2.2829, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [358/375], Loss: 2.1459, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [30/50], Step [359/375], Loss: 2.4019, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [30/50], Step [360/375], Loss: 2.1071, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [361/375], Loss: 2.2093, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [30/50], Step [362/375], Loss: 2.1884, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [363/375], Loss: 2.0831, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [30/50], Step [364/375], Loss: 2.3005, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [30/50], Step [365/375], Loss: 2.2540, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [30/50], Step [366/375], Loss: 2.2769, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [30/50], Step [367/375], Loss: 2.1311, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [30/50], Step [368/375], Loss: 2.3859, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [30/50], Step [369/375], Loss: 2.0853, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [30/50], Step [370/375], Loss: 2.2454, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [371/375], Loss: 2.2157, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [372/375], Loss: 2.1083, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [30/50], Step [373/375], Loss: 2.2896, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [30/50], Step [374/375], Loss: 2.2812, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [30/50], Step [375/375], Loss: 2.1457, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [1/375], Loss: 2.3109, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [2/375], Loss: 2.1798, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [3/375], Loss: 2.1865, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [4/375], Loss: 2.2784, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [5/375], Loss: 2.3870, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [31/50], Step [6/375], Loss: 2.2801, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [31/50], Step [7/375], Loss: 2.2837, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [8/375], Loss: 2.3264, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [9/375], Loss: 2.0773, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [10/375], Loss: 2.3540, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [11/375], Loss: 2.3641, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [12/375], Loss: 2.2991, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [13/375], Loss: 2.1062, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [14/375], Loss: 2.1408, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [15/375], Loss: 2.1354, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [16/375], Loss: 2.4121, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [17/375], Loss: 2.1787, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [18/375], Loss: 2.1416, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [19/375], Loss: 2.1797, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [20/375], Loss: 2.1733, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [21/375], Loss: 2.3445, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [22/375], Loss: 2.2230, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [23/375], Loss: 2.4245, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [24/375], Loss: 2.0746, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [25/375], Loss: 2.2598, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [26/375], Loss: 2.1123, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [27/375], Loss: 2.1623, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [28/375], Loss: 2.4713, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [29/375], Loss: 2.0228, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [30/375], Loss: 2.2613, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [31/375], Loss: 2.3051, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [32/375], Loss: 2.1424, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [33/375], Loss: 2.2508, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [34/375], Loss: 2.2755, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [35/375], Loss: 2.4468, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [36/375], Loss: 2.4759, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [37/375], Loss: 2.3005, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [38/375], Loss: 2.1106, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [39/375], Loss: 2.1842, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [40/375], Loss: 2.1421, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [41/375], Loss: 2.2233, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [42/375], Loss: 2.2847, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [43/375], Loss: 2.2455, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [44/375], Loss: 2.2926, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [45/375], Loss: 2.0345, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [31/50], Step [46/375], Loss: 2.2084, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [47/375], Loss: 2.3050, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [48/375], Loss: 2.2108, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [49/375], Loss: 2.2063, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [50/375], Loss: 2.1959, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [51/375], Loss: 2.2316, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [52/375], Loss: 2.1326, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [53/375], Loss: 2.1475, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [54/375], Loss: 2.2210, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [55/375], Loss: 2.0483, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [56/375], Loss: 2.2995, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [57/375], Loss: 2.4077, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [58/375], Loss: 2.2843, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [59/375], Loss: 2.2292, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [60/375], Loss: 2.0551, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [61/375], Loss: 2.0871, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [62/375], Loss: 2.3969, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [63/375], Loss: 2.2872, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [64/375], Loss: 2.1925, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [65/375], Loss: 2.2993, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [66/375], Loss: 2.1072, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [67/375], Loss: 2.2298, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [68/375], Loss: 2.1270, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [69/375], Loss: 2.2147, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [70/375], Loss: 2.2123, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [71/375], Loss: 2.0834, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [72/375], Loss: 2.0514, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [73/375], Loss: 2.1282, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [74/375], Loss: 2.3981, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [75/375], Loss: 2.1071, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [76/375], Loss: 2.2190, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [77/375], Loss: 2.1777, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [78/375], Loss: 2.1481, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [79/375], Loss: 2.3026, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [80/375], Loss: 2.2293, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [81/375], Loss: 2.3639, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [82/375], Loss: 2.2671, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [83/375], Loss: 2.3299, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [84/375], Loss: 2.3211, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [85/375], Loss: 2.1191, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [86/375], Loss: 2.2113, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [87/375], Loss: 2.2196, batch time: 0.99, accuracy:  12.50%\n",
      "Epoch [31/50], Step [88/375], Loss: 1.9774, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [89/375], Loss: 2.2580, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [90/375], Loss: 2.3798, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [31/50], Step [91/375], Loss: 2.2646, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [92/375], Loss: 2.3852, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [93/375], Loss: 2.2910, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [31/50], Step [94/375], Loss: 2.1861, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [95/375], Loss: 1.8885, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [31/50], Step [96/375], Loss: 2.1723, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [31/50], Step [97/375], Loss: 2.1480, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [98/375], Loss: 2.1026, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [99/375], Loss: 2.3457, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [100/375], Loss: 2.1668, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [31/50], Step [101/375], Loss: 2.3195, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [102/375], Loss: 2.0887, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [103/375], Loss: 2.2383, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [104/375], Loss: 2.2278, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [31/50], Step [105/375], Loss: 2.2375, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [106/375], Loss: 2.2031, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [107/375], Loss: 2.1884, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [108/375], Loss: 2.4561, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [109/375], Loss: 2.0586, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [110/375], Loss: 2.2035, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [111/375], Loss: 2.2185, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [112/375], Loss: 2.2153, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [113/375], Loss: 2.3665, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [114/375], Loss: 2.3658, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [115/375], Loss: 2.0839, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [116/375], Loss: 2.2924, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [117/375], Loss: 1.8758, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [118/375], Loss: 2.2500, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [119/375], Loss: 2.4101, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [31/50], Step [120/375], Loss: 2.1414, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [121/375], Loss: 2.1375, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [122/375], Loss: 2.0878, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [123/375], Loss: 2.5408, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [124/375], Loss: 2.2585, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [125/375], Loss: 2.3113, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [126/375], Loss: 2.0717, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [127/375], Loss: 2.3850, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [128/375], Loss: 2.4300, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [129/375], Loss: 2.2206, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [130/375], Loss: 2.2793, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [131/375], Loss: 2.0889, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [132/375], Loss: 2.2659, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [31/50], Step [133/375], Loss: 2.2476, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [134/375], Loss: 2.1663, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [135/375], Loss: 2.1495, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [136/375], Loss: 2.4082, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [31/50], Step [137/375], Loss: 2.1666, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [138/375], Loss: 2.2371, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [139/375], Loss: 2.3783, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [140/375], Loss: 2.4347, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [31/50], Step [141/375], Loss: 2.0908, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [142/375], Loss: 2.3560, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [143/375], Loss: 2.2051, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [144/375], Loss: 2.3993, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [145/375], Loss: 2.1593, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [146/375], Loss: 2.2363, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [147/375], Loss: 2.3721, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [148/375], Loss: 2.4569, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [31/50], Step [149/375], Loss: 2.2275, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [150/375], Loss: 2.0707, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [151/375], Loss: 2.1374, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [152/375], Loss: 2.2392, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [153/375], Loss: 2.2767, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [154/375], Loss: 2.1311, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [155/375], Loss: 2.2458, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [156/375], Loss: 2.2742, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [157/375], Loss: 2.2580, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [158/375], Loss: 2.0963, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [159/375], Loss: 2.1390, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [160/375], Loss: 2.3520, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [161/375], Loss: 2.1201, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [162/375], Loss: 2.2547, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [163/375], Loss: 2.2224, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [164/375], Loss: 2.2131, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [165/375], Loss: 2.3265, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [166/375], Loss: 2.2786, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [167/375], Loss: 1.9307, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [31/50], Step [168/375], Loss: 2.2789, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [169/375], Loss: 2.1246, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [170/375], Loss: 2.2844, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [171/375], Loss: 2.0028, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [31/50], Step [172/375], Loss: 2.3378, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [173/375], Loss: 2.2747, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [174/375], Loss: 2.2933, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [175/375], Loss: 2.2227, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [176/375], Loss: 2.3400, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [177/375], Loss: 2.2521, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [178/375], Loss: 2.2453, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [179/375], Loss: 2.2966, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [180/375], Loss: 2.1054, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [181/375], Loss: 2.2766, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [182/375], Loss: 2.0888, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [183/375], Loss: 2.3721, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [184/375], Loss: 2.2282, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [185/375], Loss: 2.1746, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [186/375], Loss: 2.3948, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [187/375], Loss: 2.4007, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [188/375], Loss: 2.4312, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [189/375], Loss: 2.4322, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [190/375], Loss: 2.3350, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [191/375], Loss: 2.2286, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [192/375], Loss: 2.2138, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [193/375], Loss: 2.2222, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [194/375], Loss: 2.3495, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [195/375], Loss: 2.1515, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [196/375], Loss: 2.1973, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [197/375], Loss: 2.2447, batch time: 1.03, accuracy:  25.00%\n",
      "Epoch [31/50], Step [198/375], Loss: 2.2163, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [199/375], Loss: 2.3930, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [200/375], Loss: 2.0962, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [31/50], Step [201/375], Loss: 2.1104, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [202/375], Loss: 2.4678, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [203/375], Loss: 2.1982, batch time: 0.29, accuracy:  18.75%\n",
      "Epoch [31/50], Step [204/375], Loss: 2.1314, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [205/375], Loss: 2.2393, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [206/375], Loss: 2.2958, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [31/50], Step [207/375], Loss: 2.3516, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [208/375], Loss: 2.0222, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [209/375], Loss: 2.1310, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [210/375], Loss: 2.2716, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [211/375], Loss: 2.3060, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [212/375], Loss: 2.2835, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [213/375], Loss: 2.2464, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [214/375], Loss: 2.1948, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [31/50], Step [215/375], Loss: 2.1449, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [216/375], Loss: 2.2553, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [217/375], Loss: 2.2586, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [218/375], Loss: 2.1753, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [219/375], Loss: 2.0231, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [220/375], Loss: 2.1599, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [221/375], Loss: 2.0468, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [222/375], Loss: 2.2278, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [223/375], Loss: 2.4688, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [224/375], Loss: 2.1520, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [225/375], Loss: 2.1078, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [226/375], Loss: 2.3383, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [227/375], Loss: 2.1838, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [228/375], Loss: 2.2051, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [229/375], Loss: 2.3018, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [230/375], Loss: 2.2231, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [31/50], Step [231/375], Loss: 2.3717, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [232/375], Loss: 2.1431, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [233/375], Loss: 2.3888, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [234/375], Loss: 2.3371, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [31/50], Step [235/375], Loss: 2.2357, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [236/375], Loss: 2.4186, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [237/375], Loss: 2.4487, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [238/375], Loss: 2.1547, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [239/375], Loss: 2.2969, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [240/375], Loss: 2.3094, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [241/375], Loss: 2.1493, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [242/375], Loss: 2.3310, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [243/375], Loss: 1.9634, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [31/50], Step [244/375], Loss: 2.0644, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [245/375], Loss: 2.2040, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [246/375], Loss: 2.3411, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [247/375], Loss: 2.2540, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [248/375], Loss: 2.5010, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [249/375], Loss: 2.4025, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [250/375], Loss: 2.3055, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [251/375], Loss: 2.1037, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [31/50], Step [252/375], Loss: 2.2129, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [253/375], Loss: 2.1189, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [254/375], Loss: 2.3399, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [255/375], Loss: 1.9560, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [256/375], Loss: 2.2596, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [257/375], Loss: 2.3368, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [258/375], Loss: 2.2729, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [259/375], Loss: 2.1451, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [260/375], Loss: 2.2882, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [261/375], Loss: 2.1844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [262/375], Loss: 2.2502, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [31/50], Step [263/375], Loss: 2.3884, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [264/375], Loss: 2.1875, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [265/375], Loss: 2.3317, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [266/375], Loss: 2.3565, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [31/50], Step [267/375], Loss: 2.1651, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [268/375], Loss: 2.3057, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [269/375], Loss: 2.1326, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [270/375], Loss: 2.2316, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [271/375], Loss: 2.3347, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [272/375], Loss: 2.3986, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [31/50], Step [273/375], Loss: 2.3275, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [274/375], Loss: 2.0989, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [31/50], Step [275/375], Loss: 2.4282, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [276/375], Loss: 2.3289, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [31/50], Step [277/375], Loss: 2.3605, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [278/375], Loss: 2.1597, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [31/50], Step [279/375], Loss: 2.1584, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [280/375], Loss: 2.1764, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [281/375], Loss: 2.1258, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [282/375], Loss: 2.2331, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [31/50], Step [283/375], Loss: 2.2557, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [284/375], Loss: 2.2823, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [285/375], Loss: 2.2378, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [286/375], Loss: 2.1796, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [31/50], Step [287/375], Loss: 2.3754, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [288/375], Loss: 2.1779, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [289/375], Loss: 2.2754, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [290/375], Loss: 2.1502, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [31/50], Step [291/375], Loss: 2.1883, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [292/375], Loss: 2.1890, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [293/375], Loss: 2.1182, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [294/375], Loss: 2.1340, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [31/50], Step [295/375], Loss: 2.4594, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [296/375], Loss: 2.2139, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [297/375], Loss: 2.3932, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [298/375], Loss: 2.4042, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [31/50], Step [299/375], Loss: 2.2781, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [300/375], Loss: 2.2588, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [301/375], Loss: 2.3570, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [302/375], Loss: 2.2886, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [31/50], Step [303/375], Loss: 2.3916, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [31/50], Step [304/375], Loss: 2.1569, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [305/375], Loss: 2.2572, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [306/375], Loss: 2.2450, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [31/50], Step [307/375], Loss: 2.3004, batch time: 1.00, accuracy:  6.25%\n",
      "Epoch [31/50], Step [308/375], Loss: 2.1178, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [309/375], Loss: 2.2546, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [310/375], Loss: 2.1162, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [31/50], Step [311/375], Loss: 2.4491, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [31/50], Step [312/375], Loss: 2.2938, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [313/375], Loss: 2.2391, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [31/50], Step [314/375], Loss: 2.2095, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [315/375], Loss: 2.2104, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [316/375], Loss: 2.2518, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [31/50], Step [317/375], Loss: 2.1669, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [318/375], Loss: 2.2019, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [319/375], Loss: 2.2915, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [320/375], Loss: 2.1200, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [31/50], Step [321/375], Loss: 2.3164, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [322/375], Loss: 2.2232, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [323/375], Loss: 2.3005, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [324/375], Loss: 2.2927, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [31/50], Step [325/375], Loss: 2.2346, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [326/375], Loss: 2.3438, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [327/375], Loss: 2.2230, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [328/375], Loss: 2.3620, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [329/375], Loss: 2.1716, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [330/375], Loss: 2.2192, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [331/375], Loss: 2.2641, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [332/375], Loss: 2.2869, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [31/50], Step [333/375], Loss: 2.1126, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [334/375], Loss: 2.3085, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [335/375], Loss: 2.0074, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [336/375], Loss: 2.2486, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [31/50], Step [337/375], Loss: 2.0048, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [31/50], Step [338/375], Loss: 2.4445, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [339/375], Loss: 2.2871, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [340/375], Loss: 2.4488, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [31/50], Step [341/375], Loss: 2.2956, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [342/375], Loss: 2.1984, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [343/375], Loss: 2.2135, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [344/375], Loss: 2.1240, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [31/50], Step [345/375], Loss: 2.2321, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [346/375], Loss: 2.1661, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [347/375], Loss: 2.1492, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [348/375], Loss: 2.2979, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [31/50], Step [349/375], Loss: 2.0276, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [350/375], Loss: 2.2334, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [351/375], Loss: 2.1345, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [352/375], Loss: 2.3241, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [31/50], Step [353/375], Loss: 2.0069, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [31/50], Step [354/375], Loss: 2.1647, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [355/375], Loss: 2.2749, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [31/50], Step [356/375], Loss: 2.2816, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [31/50], Step [357/375], Loss: 2.1921, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [358/375], Loss: 2.0964, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [31/50], Step [359/375], Loss: 2.2570, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [31/50], Step [360/375], Loss: 2.3743, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [31/50], Step [361/375], Loss: 2.2239, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [31/50], Step [362/375], Loss: 2.3808, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [363/375], Loss: 2.2422, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [364/375], Loss: 2.2322, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [31/50], Step [365/375], Loss: 2.1934, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [31/50], Step [366/375], Loss: 2.2127, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [31/50], Step [367/375], Loss: 2.3940, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [368/375], Loss: 2.1856, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [369/375], Loss: 2.2116, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [370/375], Loss: 2.4191, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [31/50], Step [371/375], Loss: 2.2849, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [31/50], Step [372/375], Loss: 2.0956, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [31/50], Step [373/375], Loss: 2.1566, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [31/50], Step [374/375], Loss: 2.1501, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [31/50], Step [375/375], Loss: 2.2144, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [1/375], Loss: 2.1396, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [2/375], Loss: 2.1483, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [3/375], Loss: 2.2821, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [4/375], Loss: 2.1868, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [5/375], Loss: 2.3041, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [6/375], Loss: 2.1557, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [7/375], Loss: 2.3661, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [8/375], Loss: 2.1004, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [9/375], Loss: 2.2223, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [10/375], Loss: 2.2887, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [11/375], Loss: 2.2400, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [12/375], Loss: 2.3681, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [13/375], Loss: 2.3252, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [14/375], Loss: 2.4133, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [15/375], Loss: 2.3241, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [16/375], Loss: 2.2555, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [17/375], Loss: 2.2078, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [18/375], Loss: 2.2233, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [19/375], Loss: 2.2272, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [20/375], Loss: 2.1747, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [21/375], Loss: 2.5227, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [32/50], Step [22/375], Loss: 2.2750, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [23/375], Loss: 2.3899, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [24/375], Loss: 2.2043, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [25/375], Loss: 2.2262, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [26/375], Loss: 2.0585, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [27/375], Loss: 2.0977, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [28/375], Loss: 2.0985, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [29/375], Loss: 2.2283, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [30/375], Loss: 2.2920, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [31/375], Loss: 2.1773, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [32/375], Loss: 2.2720, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [33/375], Loss: 2.1041, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [34/375], Loss: 2.0937, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [35/375], Loss: 2.1727, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [36/375], Loss: 2.2582, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [37/375], Loss: 2.2281, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [38/375], Loss: 2.3369, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [39/375], Loss: 2.0350, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [40/375], Loss: 2.2677, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [41/375], Loss: 2.4240, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [32/50], Step [42/375], Loss: 2.5513, batch time: 1.01, accuracy:  0.00%\n",
      "Epoch [32/50], Step [43/375], Loss: 2.1693, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [44/375], Loss: 2.1004, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [45/375], Loss: 2.3409, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [32/50], Step [46/375], Loss: 2.2073, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [47/375], Loss: 2.2980, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [48/375], Loss: 2.1799, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [32/50], Step [49/375], Loss: 2.1696, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [50/375], Loss: 2.3072, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [51/375], Loss: 2.1112, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [32/50], Step [52/375], Loss: 2.2615, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [53/375], Loss: 2.1905, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [54/375], Loss: 2.2761, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [55/375], Loss: 2.3320, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [56/375], Loss: 2.1626, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [57/375], Loss: 2.2866, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [58/375], Loss: 1.9883, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [32/50], Step [59/375], Loss: 2.1779, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [60/375], Loss: 2.2769, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [61/375], Loss: 2.4797, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [62/375], Loss: 2.2015, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [63/375], Loss: 2.2088, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [64/375], Loss: 2.2940, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [65/375], Loss: 2.3581, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [66/375], Loss: 2.1077, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [67/375], Loss: 2.2717, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [68/375], Loss: 2.3971, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [69/375], Loss: 2.2394, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [70/375], Loss: 2.3570, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [71/375], Loss: 2.2472, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [72/375], Loss: 2.1392, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [73/375], Loss: 2.2339, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [74/375], Loss: 2.2096, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [75/375], Loss: 2.3047, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [76/375], Loss: 2.2259, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [77/375], Loss: 2.2695, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [78/375], Loss: 2.3616, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [79/375], Loss: 2.1166, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [80/375], Loss: 2.0542, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [32/50], Step [81/375], Loss: 2.1635, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [82/375], Loss: 2.2656, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [83/375], Loss: 2.3066, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [84/375], Loss: 2.2557, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [85/375], Loss: 2.2165, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [32/50], Step [86/375], Loss: 2.3071, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [87/375], Loss: 2.2474, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [88/375], Loss: 2.1584, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [89/375], Loss: 2.1693, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [90/375], Loss: 2.4754, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [32/50], Step [91/375], Loss: 2.2589, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [92/375], Loss: 2.3311, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [32/50], Step [93/375], Loss: 2.2145, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [94/375], Loss: 2.2752, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [95/375], Loss: 2.2614, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [96/375], Loss: 2.3076, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [97/375], Loss: 2.1091, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [98/375], Loss: 2.2749, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [99/375], Loss: 2.1263, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [100/375], Loss: 2.3122, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [101/375], Loss: 1.9685, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [32/50], Step [102/375], Loss: 2.2760, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [103/375], Loss: 2.3951, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [32/50], Step [104/375], Loss: 2.4187, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [105/375], Loss: 2.2327, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [106/375], Loss: 2.2733, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [107/375], Loss: 2.2036, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [108/375], Loss: 2.2988, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [109/375], Loss: 2.1533, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [110/375], Loss: 2.3795, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [111/375], Loss: 2.3141, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [112/375], Loss: 2.2761, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [113/375], Loss: 2.2926, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [114/375], Loss: 2.2465, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [115/375], Loss: 2.3537, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [116/375], Loss: 2.2189, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [117/375], Loss: 1.9725, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [32/50], Step [118/375], Loss: 2.2336, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [119/375], Loss: 2.3349, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [120/375], Loss: 2.2126, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [121/375], Loss: 2.3342, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [122/375], Loss: 2.2144, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [123/375], Loss: 1.9617, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [32/50], Step [124/375], Loss: 2.2473, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [125/375], Loss: 2.1229, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [126/375], Loss: 2.3117, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [127/375], Loss: 2.3355, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [128/375], Loss: 2.2498, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [129/375], Loss: 2.2130, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [130/375], Loss: 2.3381, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [131/375], Loss: 2.1589, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [132/375], Loss: 2.1981, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [133/375], Loss: 2.2431, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [134/375], Loss: 2.4077, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [135/375], Loss: 2.2913, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [136/375], Loss: 2.2993, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [137/375], Loss: 2.2268, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [138/375], Loss: 2.1264, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [139/375], Loss: 2.2312, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [32/50], Step [140/375], Loss: 2.0709, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [141/375], Loss: 2.5666, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [142/375], Loss: 2.2002, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [143/375], Loss: 2.1519, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [144/375], Loss: 2.2435, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [145/375], Loss: 2.2851, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [146/375], Loss: 2.1941, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [147/375], Loss: 2.3986, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [148/375], Loss: 2.2979, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [149/375], Loss: 2.2730, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [150/375], Loss: 2.1529, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [151/375], Loss: 2.0570, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [152/375], Loss: 2.1921, batch time: 1.01, accuracy:  31.25%\n",
      "Epoch [32/50], Step [153/375], Loss: 2.3881, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [32/50], Step [154/375], Loss: 2.2996, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [155/375], Loss: 2.2564, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [32/50], Step [156/375], Loss: 2.0805, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [157/375], Loss: 2.2075, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [158/375], Loss: 2.3735, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [32/50], Step [159/375], Loss: 2.3008, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [160/375], Loss: 2.0777, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [32/50], Step [161/375], Loss: 2.1142, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [32/50], Step [162/375], Loss: 2.1797, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [163/375], Loss: 2.3601, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [164/375], Loss: 2.3082, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [165/375], Loss: 2.4205, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [166/375], Loss: 2.3544, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [167/375], Loss: 2.1172, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [168/375], Loss: 2.2131, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [169/375], Loss: 2.1152, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [32/50], Step [170/375], Loss: 2.2196, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [171/375], Loss: 2.3108, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [172/375], Loss: 2.3357, batch time: 0.35, accuracy:  12.50%\n",
      "Epoch [32/50], Step [173/375], Loss: 2.0794, batch time: 0.34, accuracy:  37.50%\n",
      "Epoch [32/50], Step [174/375], Loss: 2.2167, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [32/50], Step [175/375], Loss: 2.3045, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [176/375], Loss: 2.1373, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [177/375], Loss: 2.1851, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [32/50], Step [178/375], Loss: 2.1145, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [32/50], Step [179/375], Loss: 2.1581, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [32/50], Step [180/375], Loss: 2.1413, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [181/375], Loss: 2.1504, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [32/50], Step [182/375], Loss: 2.2059, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [183/375], Loss: 2.3395, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [32/50], Step [184/375], Loss: 2.1627, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [32/50], Step [185/375], Loss: 2.1760, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [186/375], Loss: 2.2726, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [32/50], Step [187/375], Loss: 2.2357, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [32/50], Step [188/375], Loss: 2.0888, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [32/50], Step [189/375], Loss: 2.2450, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [190/375], Loss: 2.1988, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [32/50], Step [191/375], Loss: 2.1313, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [32/50], Step [192/375], Loss: 2.2267, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [193/375], Loss: 2.3780, batch time: 0.35, accuracy:  6.25%\n",
      "Epoch [32/50], Step [194/375], Loss: 2.2195, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [32/50], Step [195/375], Loss: 2.3486, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [196/375], Loss: 2.1479, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [197/375], Loss: 2.3113, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [32/50], Step [198/375], Loss: 2.0503, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [199/375], Loss: 2.2588, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [32/50], Step [200/375], Loss: 2.2419, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [201/375], Loss: 2.3336, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [32/50], Step [202/375], Loss: 2.1993, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [203/375], Loss: 2.2478, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [32/50], Step [204/375], Loss: 2.2471, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [32/50], Step [205/375], Loss: 2.2773, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [32/50], Step [206/375], Loss: 2.2826, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [32/50], Step [207/375], Loss: 2.1744, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [32/50], Step [208/375], Loss: 1.9676, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [32/50], Step [209/375], Loss: 2.3460, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [32/50], Step [210/375], Loss: 2.2588, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [32/50], Step [211/375], Loss: 2.2313, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [32/50], Step [212/375], Loss: 2.0805, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [213/375], Loss: 2.3745, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [32/50], Step [214/375], Loss: 2.3581, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [215/375], Loss: 2.1662, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [216/375], Loss: 2.0723, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [217/375], Loss: 2.3358, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [218/375], Loss: 2.2401, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [219/375], Loss: 2.2585, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [220/375], Loss: 2.3767, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [221/375], Loss: 2.4205, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [32/50], Step [222/375], Loss: 2.1885, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [223/375], Loss: 2.0384, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [224/375], Loss: 2.2683, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [225/375], Loss: 2.2819, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [226/375], Loss: 2.3397, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [227/375], Loss: 2.1077, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [228/375], Loss: 2.1552, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [229/375], Loss: 2.0781, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [32/50], Step [230/375], Loss: 2.4381, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [231/375], Loss: 2.2869, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [232/375], Loss: 2.1853, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [233/375], Loss: 2.3081, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [234/375], Loss: 2.0677, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [235/375], Loss: 2.3291, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [236/375], Loss: 2.1597, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [32/50], Step [237/375], Loss: 2.2806, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [238/375], Loss: 2.0524, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [239/375], Loss: 2.2774, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [240/375], Loss: 2.0714, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [241/375], Loss: 2.1342, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [242/375], Loss: 2.0474, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [243/375], Loss: 2.3284, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [244/375], Loss: 2.2301, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [245/375], Loss: 2.4641, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [32/50], Step [246/375], Loss: 2.3746, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [247/375], Loss: 2.0990, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [248/375], Loss: 2.3730, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [249/375], Loss: 2.4720, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [32/50], Step [250/375], Loss: 2.2525, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [251/375], Loss: 2.4465, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [252/375], Loss: 2.2639, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [253/375], Loss: 2.2773, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [254/375], Loss: 2.1143, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [255/375], Loss: 2.1594, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [256/375], Loss: 2.1871, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [257/375], Loss: 2.2541, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [258/375], Loss: 2.2847, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [259/375], Loss: 2.1931, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [260/375], Loss: 2.1246, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [261/375], Loss: 2.1498, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [262/375], Loss: 2.3645, batch time: 0.85, accuracy:  6.25%\n",
      "Epoch [32/50], Step [263/375], Loss: 2.2571, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [264/375], Loss: 2.1975, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [265/375], Loss: 2.2004, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [32/50], Step [266/375], Loss: 2.3072, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [267/375], Loss: 2.1707, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [268/375], Loss: 2.3637, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [32/50], Step [269/375], Loss: 2.3861, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [270/375], Loss: 2.0919, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [32/50], Step [271/375], Loss: 2.2046, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [32/50], Step [272/375], Loss: 2.1259, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [273/375], Loss: 2.2441, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [274/375], Loss: 2.2068, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [275/375], Loss: 2.1674, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [32/50], Step [276/375], Loss: 2.1438, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [277/375], Loss: 2.2806, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [278/375], Loss: 2.3169, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [279/375], Loss: 2.3721, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [32/50], Step [280/375], Loss: 2.2886, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [281/375], Loss: 2.4162, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [282/375], Loss: 2.3664, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [283/375], Loss: 2.2889, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [32/50], Step [284/375], Loss: 2.2896, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [285/375], Loss: 2.1012, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [286/375], Loss: 2.1927, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [287/375], Loss: 2.2812, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [288/375], Loss: 2.2483, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [289/375], Loss: 2.1602, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [290/375], Loss: 2.3182, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [291/375], Loss: 2.4173, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [32/50], Step [292/375], Loss: 1.9748, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [32/50], Step [293/375], Loss: 2.0977, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [32/50], Step [294/375], Loss: 2.1486, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [295/375], Loss: 2.2431, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [296/375], Loss: 2.0978, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [297/375], Loss: 2.3703, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [298/375], Loss: 2.3476, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [32/50], Step [299/375], Loss: 2.2085, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [300/375], Loss: 2.1994, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [301/375], Loss: 2.1014, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [302/375], Loss: 2.1358, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [303/375], Loss: 2.1942, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [304/375], Loss: 2.0588, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [305/375], Loss: 2.1222, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [306/375], Loss: 2.1325, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [307/375], Loss: 2.0383, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [32/50], Step [308/375], Loss: 2.1724, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [309/375], Loss: 2.2121, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [310/375], Loss: 2.3570, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [311/375], Loss: 2.2808, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [32/50], Step [312/375], Loss: 2.4449, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [32/50], Step [313/375], Loss: 2.2236, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [314/375], Loss: 1.8244, batch time: 0.25, accuracy:  56.25%\n",
      "Epoch [32/50], Step [315/375], Loss: 2.2640, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [316/375], Loss: 2.2298, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [317/375], Loss: 2.1242, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [32/50], Step [318/375], Loss: 2.2967, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [319/375], Loss: 2.2511, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [320/375], Loss: 2.2073, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [321/375], Loss: 2.2565, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [322/375], Loss: 2.1034, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [323/375], Loss: 2.1795, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [324/375], Loss: 2.4119, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [325/375], Loss: 2.4538, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [326/375], Loss: 2.3382, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [327/375], Loss: 2.2653, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [328/375], Loss: 2.4589, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [329/375], Loss: 2.2389, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [32/50], Step [330/375], Loss: 2.2518, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [331/375], Loss: 2.3339, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [32/50], Step [332/375], Loss: 2.2342, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [333/375], Loss: 2.3405, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [334/375], Loss: 2.3235, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [335/375], Loss: 2.2001, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [32/50], Step [336/375], Loss: 2.2895, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [337/375], Loss: 2.1534, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [338/375], Loss: 2.1786, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [339/375], Loss: 2.1518, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [340/375], Loss: 2.2431, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [341/375], Loss: 2.2211, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [342/375], Loss: 1.9869, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [32/50], Step [343/375], Loss: 2.3178, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [32/50], Step [344/375], Loss: 2.0791, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [345/375], Loss: 2.3173, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [346/375], Loss: 2.3545, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [347/375], Loss: 2.2454, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [32/50], Step [348/375], Loss: 2.1653, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [349/375], Loss: 2.2155, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [350/375], Loss: 2.3840, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [32/50], Step [351/375], Loss: 2.1763, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [352/375], Loss: 2.1951, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [353/375], Loss: 2.2516, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [32/50], Step [354/375], Loss: 2.0693, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [32/50], Step [355/375], Loss: 2.3485, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [356/375], Loss: 2.0605, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [32/50], Step [357/375], Loss: 2.1787, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [358/375], Loss: 2.0074, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [32/50], Step [359/375], Loss: 2.2369, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [32/50], Step [360/375], Loss: 2.2465, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [361/375], Loss: 2.2133, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [32/50], Step [362/375], Loss: 2.1724, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [363/375], Loss: 2.3236, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [364/375], Loss: 2.2913, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [365/375], Loss: 2.3072, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [366/375], Loss: 2.2225, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [367/375], Loss: 2.2898, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [32/50], Step [368/375], Loss: 2.2688, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [369/375], Loss: 2.2575, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [32/50], Step [370/375], Loss: 2.3971, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [32/50], Step [371/375], Loss: 2.1833, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [32/50], Step [372/375], Loss: 2.4127, batch time: 0.85, accuracy:  6.25%\n",
      "Epoch [32/50], Step [373/375], Loss: 2.2200, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [32/50], Step [374/375], Loss: 2.3086, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [32/50], Step [375/375], Loss: 1.9995, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [33/50], Step [1/375], Loss: 2.2875, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [2/375], Loss: 2.0419, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [3/375], Loss: 2.2267, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [33/50], Step [4/375], Loss: 2.4313, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [5/375], Loss: 2.3161, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [6/375], Loss: 2.2763, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [33/50], Step [7/375], Loss: 2.1828, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [8/375], Loss: 2.2021, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [9/375], Loss: 2.2645, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [10/375], Loss: 2.1251, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [33/50], Step [11/375], Loss: 2.1587, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [12/375], Loss: 2.3148, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [13/375], Loss: 2.1940, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [14/375], Loss: 2.3182, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [15/375], Loss: 2.2150, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [16/375], Loss: 2.1503, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [33/50], Step [17/375], Loss: 2.3707, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [18/375], Loss: 2.3319, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [33/50], Step [19/375], Loss: 2.2976, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [20/375], Loss: 2.2927, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [21/375], Loss: 2.0839, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [22/375], Loss: 2.1666, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [23/375], Loss: 2.3249, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [24/375], Loss: 2.2547, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [25/375], Loss: 2.2995, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [26/375], Loss: 2.3535, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [27/375], Loss: 2.1861, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [28/375], Loss: 2.3038, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [29/375], Loss: 2.2646, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [30/375], Loss: 2.2136, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [31/375], Loss: 2.3923, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [32/375], Loss: 2.0882, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [33/375], Loss: 2.4219, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [34/375], Loss: 2.2319, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [35/375], Loss: 2.1820, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [36/375], Loss: 2.2339, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [37/375], Loss: 2.2434, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [38/375], Loss: 2.1759, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [39/375], Loss: 2.1808, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [40/375], Loss: 2.2455, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [41/375], Loss: 2.1409, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [42/375], Loss: 2.2269, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [43/375], Loss: 2.0264, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [33/50], Step [44/375], Loss: 2.1093, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [45/375], Loss: 2.1125, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [46/375], Loss: 2.0658, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [33/50], Step [47/375], Loss: 2.3989, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [48/375], Loss: 2.2492, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [49/375], Loss: 2.1238, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [50/375], Loss: 2.2495, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [51/375], Loss: 2.3375, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [52/375], Loss: 2.4249, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [53/375], Loss: 2.2821, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [54/375], Loss: 2.1388, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [33/50], Step [55/375], Loss: 2.0591, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [56/375], Loss: 2.3499, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [33/50], Step [57/375], Loss: 2.0561, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [33/50], Step [58/375], Loss: 2.1036, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [33/50], Step [59/375], Loss: 2.1531, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [60/375], Loss: 2.3521, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [61/375], Loss: 2.1685, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [62/375], Loss: 2.3958, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [63/375], Loss: 2.3832, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [33/50], Step [64/375], Loss: 2.0848, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [65/375], Loss: 2.2328, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [66/375], Loss: 2.3519, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [67/375], Loss: 2.1672, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [68/375], Loss: 2.0033, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [69/375], Loss: 2.4635, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [70/375], Loss: 2.3629, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [71/375], Loss: 2.3688, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [72/375], Loss: 2.2911, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [73/375], Loss: 2.2290, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [74/375], Loss: 2.2877, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [75/375], Loss: 2.2238, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [76/375], Loss: 2.3511, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [77/375], Loss: 2.0922, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [78/375], Loss: 2.2258, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [79/375], Loss: 2.0692, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [80/375], Loss: 2.0134, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [81/375], Loss: 2.2508, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [82/375], Loss: 2.2814, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [83/375], Loss: 2.2927, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [84/375], Loss: 2.1480, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [85/375], Loss: 2.0821, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [86/375], Loss: 2.1441, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [87/375], Loss: 2.1238, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [88/375], Loss: 2.3404, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [89/375], Loss: 2.1566, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [90/375], Loss: 2.3937, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [33/50], Step [91/375], Loss: 2.3015, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [92/375], Loss: 2.4554, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [33/50], Step [93/375], Loss: 2.2940, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [94/375], Loss: 2.1496, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [95/375], Loss: 2.3680, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [96/375], Loss: 2.1264, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [33/50], Step [97/375], Loss: 2.1601, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [98/375], Loss: 2.2449, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [33/50], Step [99/375], Loss: 1.8887, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [33/50], Step [100/375], Loss: 2.0346, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [33/50], Step [101/375], Loss: 2.1499, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [102/375], Loss: 2.2405, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [103/375], Loss: 2.4136, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [104/375], Loss: 1.9848, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [33/50], Step [105/375], Loss: 2.2605, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [106/375], Loss: 2.3265, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [107/375], Loss: 2.1694, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [33/50], Step [108/375], Loss: 2.0960, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [109/375], Loss: 2.4445, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [110/375], Loss: 1.9696, batch time: 0.29, accuracy:  43.75%\n",
      "Epoch [33/50], Step [111/375], Loss: 2.1951, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [112/375], Loss: 1.8630, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [33/50], Step [113/375], Loss: 2.2774, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [33/50], Step [114/375], Loss: 2.3746, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [115/375], Loss: 2.2778, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [116/375], Loss: 2.2579, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [33/50], Step [117/375], Loss: 2.1227, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [118/375], Loss: 2.2398, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [119/375], Loss: 2.2776, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [120/375], Loss: 2.4644, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [33/50], Step [121/375], Loss: 2.3453, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [122/375], Loss: 2.1553, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [123/375], Loss: 2.2649, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [124/375], Loss: 2.0399, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [125/375], Loss: 2.2711, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [126/375], Loss: 2.3636, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [127/375], Loss: 2.2657, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [128/375], Loss: 2.2107, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [33/50], Step [129/375], Loss: 2.0762, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [130/375], Loss: 2.2801, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [131/375], Loss: 2.3078, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [132/375], Loss: 2.3490, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [33/50], Step [133/375], Loss: 2.2961, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [134/375], Loss: 2.1994, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [135/375], Loss: 2.3693, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [136/375], Loss: 1.8590, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [33/50], Step [137/375], Loss: 2.3722, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [138/375], Loss: 2.2802, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [139/375], Loss: 2.1699, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [140/375], Loss: 2.3467, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [33/50], Step [141/375], Loss: 2.2438, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [142/375], Loss: 2.2265, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [143/375], Loss: 2.2848, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [144/375], Loss: 1.9147, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [33/50], Step [145/375], Loss: 2.3914, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [146/375], Loss: 2.1510, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [147/375], Loss: 2.3529, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [148/375], Loss: 2.3555, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [33/50], Step [149/375], Loss: 2.4060, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [33/50], Step [150/375], Loss: 2.1292, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [151/375], Loss: 2.0951, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [152/375], Loss: 2.2434, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [33/50], Step [153/375], Loss: 2.4289, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [33/50], Step [154/375], Loss: 2.3569, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [155/375], Loss: 2.3447, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [156/375], Loss: 2.2082, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [33/50], Step [157/375], Loss: 2.1692, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [158/375], Loss: 2.4110, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [159/375], Loss: 2.1696, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [160/375], Loss: 2.2715, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [161/375], Loss: 2.1630, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [162/375], Loss: 2.2711, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [163/375], Loss: 2.3487, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [164/375], Loss: 2.1827, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [165/375], Loss: 2.2035, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [166/375], Loss: 2.2614, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [167/375], Loss: 2.3437, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [168/375], Loss: 2.1716, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [33/50], Step [169/375], Loss: 2.2484, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [170/375], Loss: 2.1425, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [171/375], Loss: 2.0299, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [172/375], Loss: 2.3408, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [33/50], Step [173/375], Loss: 2.0418, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [33/50], Step [174/375], Loss: 2.4134, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [175/375], Loss: 2.0104, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [176/375], Loss: 2.2700, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [177/375], Loss: 2.2921, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [178/375], Loss: 2.0916, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [179/375], Loss: 2.2338, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [180/375], Loss: 2.4171, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [33/50], Step [181/375], Loss: 2.2312, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [182/375], Loss: 2.3278, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [183/375], Loss: 2.2191, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [184/375], Loss: 2.1221, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [33/50], Step [185/375], Loss: 2.2164, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [186/375], Loss: 2.3463, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [33/50], Step [187/375], Loss: 2.2407, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [188/375], Loss: 2.1718, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [33/50], Step [189/375], Loss: 2.1958, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [190/375], Loss: 2.3505, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [191/375], Loss: 2.2001, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [192/375], Loss: 2.1595, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [193/375], Loss: 2.2903, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [194/375], Loss: 2.2436, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [195/375], Loss: 2.3336, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [196/375], Loss: 2.2429, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [197/375], Loss: 2.0863, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [33/50], Step [198/375], Loss: 2.1885, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [199/375], Loss: 2.2809, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [200/375], Loss: 2.1851, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [33/50], Step [201/375], Loss: 2.2761, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [202/375], Loss: 2.3490, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [203/375], Loss: 2.2244, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [204/375], Loss: 2.2294, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [205/375], Loss: 2.2536, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [206/375], Loss: 2.4556, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [207/375], Loss: 2.1388, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [208/375], Loss: 2.2388, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [209/375], Loss: 2.2414, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [210/375], Loss: 2.1188, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [211/375], Loss: 2.2630, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [212/375], Loss: 2.6428, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [33/50], Step [213/375], Loss: 2.2026, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [214/375], Loss: 1.9288, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [33/50], Step [215/375], Loss: 2.1575, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [216/375], Loss: 2.2909, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [217/375], Loss: 2.3478, batch time: 1.03, accuracy:  25.00%\n",
      "Epoch [33/50], Step [218/375], Loss: 2.3566, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [33/50], Step [219/375], Loss: 2.2601, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [220/375], Loss: 2.4035, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [33/50], Step [221/375], Loss: 2.2490, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [222/375], Loss: 2.1938, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [223/375], Loss: 2.2486, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [33/50], Step [224/375], Loss: 2.2766, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [225/375], Loss: 2.3461, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [226/375], Loss: 2.2179, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [33/50], Step [227/375], Loss: 2.2790, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [228/375], Loss: 2.2017, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [229/375], Loss: 2.3014, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [230/375], Loss: 2.1811, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [231/375], Loss: 2.4448, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [232/375], Loss: 2.3923, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [233/375], Loss: 2.2067, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [234/375], Loss: 2.1025, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [33/50], Step [235/375], Loss: 2.1782, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [236/375], Loss: 2.2807, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [237/375], Loss: 2.0362, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [238/375], Loss: 2.1031, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [33/50], Step [239/375], Loss: 2.2294, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [240/375], Loss: 2.2217, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [241/375], Loss: 2.2480, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [242/375], Loss: 2.1658, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [243/375], Loss: 2.2576, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [244/375], Loss: 2.3094, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [245/375], Loss: 2.1031, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [246/375], Loss: 2.3413, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [247/375], Loss: 2.3196, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [248/375], Loss: 2.1287, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [249/375], Loss: 2.2835, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [250/375], Loss: 2.0993, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [251/375], Loss: 2.1680, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [252/375], Loss: 2.1989, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [253/375], Loss: 2.2216, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [254/375], Loss: 2.2258, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [255/375], Loss: 2.2641, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [256/375], Loss: 2.0998, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [257/375], Loss: 2.1991, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [258/375], Loss: 2.1507, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [259/375], Loss: 2.1819, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [260/375], Loss: 2.1826, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [261/375], Loss: 2.4682, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [262/375], Loss: 2.2944, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [263/375], Loss: 2.1798, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [264/375], Loss: 2.2528, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [265/375], Loss: 2.2349, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [266/375], Loss: 2.3400, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [267/375], Loss: 2.2369, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [268/375], Loss: 2.0916, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [33/50], Step [269/375], Loss: 2.1786, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [270/375], Loss: 2.1407, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [33/50], Step [271/375], Loss: 2.2988, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [272/375], Loss: 2.1050, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [273/375], Loss: 2.5331, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [33/50], Step [274/375], Loss: 2.3146, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [275/375], Loss: 2.3436, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [276/375], Loss: 2.0998, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [277/375], Loss: 2.1847, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [278/375], Loss: 2.3604, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [33/50], Step [279/375], Loss: 2.2383, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [280/375], Loss: 2.3629, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [281/375], Loss: 2.2750, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [282/375], Loss: 2.1378, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [33/50], Step [283/375], Loss: 2.2785, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [284/375], Loss: 2.1361, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [285/375], Loss: 2.3854, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [286/375], Loss: 2.2376, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [33/50], Step [287/375], Loss: 2.0437, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [288/375], Loss: 2.0856, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [289/375], Loss: 2.2105, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [290/375], Loss: 2.1963, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [291/375], Loss: 2.4067, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [292/375], Loss: 2.2732, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [293/375], Loss: 2.2228, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [294/375], Loss: 2.1370, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [295/375], Loss: 2.3392, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [296/375], Loss: 2.2783, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [297/375], Loss: 2.3034, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [298/375], Loss: 2.2669, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [299/375], Loss: 2.0860, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [300/375], Loss: 2.2678, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [301/375], Loss: 2.2808, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [302/375], Loss: 2.3093, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [303/375], Loss: 2.1424, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [304/375], Loss: 2.0946, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [305/375], Loss: 2.0352, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [33/50], Step [306/375], Loss: 2.3133, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [33/50], Step [307/375], Loss: 2.2259, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [308/375], Loss: 2.3166, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [309/375], Loss: 2.3689, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [310/375], Loss: 2.2680, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [33/50], Step [311/375], Loss: 2.2230, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [312/375], Loss: 2.2357, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [313/375], Loss: 2.3115, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [314/375], Loss: 2.3810, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [315/375], Loss: 2.1770, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [316/375], Loss: 2.1753, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [317/375], Loss: 2.0011, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [33/50], Step [318/375], Loss: 2.3043, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [319/375], Loss: 2.1895, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [320/375], Loss: 2.0952, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [321/375], Loss: 2.2809, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [322/375], Loss: 2.1760, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [33/50], Step [323/375], Loss: 2.2488, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [324/375], Loss: 2.3002, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [325/375], Loss: 2.2575, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [326/375], Loss: 2.1463, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [33/50], Step [327/375], Loss: 2.2372, batch time: 0.84, accuracy:  18.75%\n",
      "Epoch [33/50], Step [328/375], Loss: 2.2215, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [329/375], Loss: 2.3829, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [330/375], Loss: 2.3505, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [33/50], Step [331/375], Loss: 1.9275, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [33/50], Step [332/375], Loss: 2.4709, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [333/375], Loss: 2.3032, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [33/50], Step [334/375], Loss: 2.2366, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [335/375], Loss: 2.1323, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [336/375], Loss: 2.1197, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [33/50], Step [337/375], Loss: 2.4072, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [338/375], Loss: 2.0775, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [33/50], Step [339/375], Loss: 2.2686, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [340/375], Loss: 2.3286, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [33/50], Step [341/375], Loss: 2.4664, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [342/375], Loss: 2.3287, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [343/375], Loss: 2.2557, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [344/375], Loss: 2.0102, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [33/50], Step [345/375], Loss: 2.3488, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [346/375], Loss: 2.1680, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [347/375], Loss: 2.3077, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [348/375], Loss: 2.3205, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [349/375], Loss: 2.2332, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [350/375], Loss: 2.3631, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [351/375], Loss: 2.1930, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [352/375], Loss: 2.3920, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [353/375], Loss: 2.1714, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [354/375], Loss: 2.1427, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [33/50], Step [355/375], Loss: 2.2200, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [356/375], Loss: 2.2734, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [33/50], Step [357/375], Loss: 2.2590, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [358/375], Loss: 2.2319, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [359/375], Loss: 2.2940, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [360/375], Loss: 2.1508, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [33/50], Step [361/375], Loss: 2.2322, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [33/50], Step [362/375], Loss: 2.2326, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [33/50], Step [363/375], Loss: 2.3085, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [33/50], Step [364/375], Loss: 2.1856, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [33/50], Step [365/375], Loss: 2.1356, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [33/50], Step [366/375], Loss: 2.2134, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [367/375], Loss: 2.3339, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [33/50], Step [368/375], Loss: 2.2473, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [33/50], Step [369/375], Loss: 2.0981, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [33/50], Step [370/375], Loss: 2.2342, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [371/375], Loss: 2.2345, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [33/50], Step [372/375], Loss: 2.0917, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [33/50], Step [373/375], Loss: 2.2195, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [33/50], Step [374/375], Loss: 2.0770, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [33/50], Step [375/375], Loss: 2.2380, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [1/375], Loss: 2.3569, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [2/375], Loss: 2.1578, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [3/375], Loss: 2.1717, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [4/375], Loss: 2.3727, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [5/375], Loss: 2.1161, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [34/50], Step [6/375], Loss: 2.2781, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [7/375], Loss: 2.2663, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [8/375], Loss: 2.3570, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [9/375], Loss: 1.8645, batch time: 0.26, accuracy:  56.25%\n",
      "Epoch [34/50], Step [10/375], Loss: 2.3626, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [11/375], Loss: 2.3756, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [12/375], Loss: 2.2350, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [13/375], Loss: 2.3690, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [14/375], Loss: 2.1350, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [15/375], Loss: 2.1830, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [16/375], Loss: 2.1391, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [17/375], Loss: 2.1529, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [18/375], Loss: 2.3774, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [19/375], Loss: 2.1306, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [20/375], Loss: 2.4226, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [21/375], Loss: 2.1884, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [22/375], Loss: 2.1969, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [23/375], Loss: 2.2644, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [24/375], Loss: 2.0463, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [34/50], Step [25/375], Loss: 2.2893, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [26/375], Loss: 2.1530, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [27/375], Loss: 2.1474, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [28/375], Loss: 2.2500, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [29/375], Loss: 2.2997, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [30/375], Loss: 2.2200, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [31/375], Loss: 2.2968, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [32/375], Loss: 2.0736, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [33/375], Loss: 2.1436, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [34/375], Loss: 2.4243, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [35/375], Loss: 2.1680, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [36/375], Loss: 2.1247, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [37/375], Loss: 1.9658, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [34/50], Step [38/375], Loss: 2.1598, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [39/375], Loss: 2.2532, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [40/375], Loss: 2.2705, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [41/375], Loss: 2.3877, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [42/375], Loss: 2.4060, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [43/375], Loss: 2.1113, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [44/375], Loss: 2.2417, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [45/375], Loss: 2.2560, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [46/375], Loss: 2.1765, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [47/375], Loss: 2.2016, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [48/375], Loss: 2.1694, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [49/375], Loss: 2.3436, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [50/375], Loss: 2.1570, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [51/375], Loss: 2.2765, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [52/375], Loss: 2.2166, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [53/375], Loss: 2.2188, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [54/375], Loss: 2.2728, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [55/375], Loss: 2.2302, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [56/375], Loss: 2.1081, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [57/375], Loss: 2.3820, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [58/375], Loss: 2.3315, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [59/375], Loss: 2.2639, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [60/375], Loss: 2.3111, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [61/375], Loss: 2.2606, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [62/375], Loss: 2.2228, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [34/50], Step [63/375], Loss: 2.2436, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [64/375], Loss: 2.1596, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [65/375], Loss: 2.1402, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [34/50], Step [66/375], Loss: 2.5314, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [67/375], Loss: 2.1166, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [68/375], Loss: 2.1729, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [34/50], Step [69/375], Loss: 2.4370, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [70/375], Loss: 2.1867, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [71/375], Loss: 2.2366, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [34/50], Step [72/375], Loss: 2.2942, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [73/375], Loss: 2.1285, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [74/375], Loss: 2.2273, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [75/375], Loss: 2.1356, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [34/50], Step [76/375], Loss: 2.2775, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [77/375], Loss: 2.1909, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [78/375], Loss: 2.0404, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [34/50], Step [79/375], Loss: 2.2595, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [80/375], Loss: 2.2097, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [81/375], Loss: 2.2126, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [82/375], Loss: 2.1225, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [83/375], Loss: 2.4371, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [84/375], Loss: 2.4256, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [85/375], Loss: 2.2731, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [86/375], Loss: 2.2989, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [87/375], Loss: 2.1644, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [88/375], Loss: 2.1629, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [89/375], Loss: 2.1413, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [90/375], Loss: 2.1237, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [91/375], Loss: 2.4142, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [92/375], Loss: 2.2150, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [93/375], Loss: 2.2324, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [94/375], Loss: 2.3486, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [95/375], Loss: 2.2505, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [96/375], Loss: 2.2106, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [97/375], Loss: 2.2822, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [98/375], Loss: 2.3012, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [99/375], Loss: 2.1689, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [100/375], Loss: 2.2205, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [101/375], Loss: 2.3382, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [102/375], Loss: 1.9350, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [34/50], Step [103/375], Loss: 2.2547, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [104/375], Loss: 1.9910, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [105/375], Loss: 2.5168, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [34/50], Step [106/375], Loss: 2.1894, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [107/375], Loss: 2.4673, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [34/50], Step [108/375], Loss: 2.3451, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [109/375], Loss: 2.6068, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [110/375], Loss: 2.2546, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [111/375], Loss: 2.1732, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [112/375], Loss: 2.2732, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [113/375], Loss: 2.2590, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [114/375], Loss: 2.1753, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [115/375], Loss: 2.2796, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [116/375], Loss: 2.3564, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [117/375], Loss: 2.4002, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [118/375], Loss: 2.1225, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [119/375], Loss: 2.3064, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [120/375], Loss: 2.2607, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [121/375], Loss: 2.2998, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [122/375], Loss: 2.2343, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [123/375], Loss: 2.0255, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [34/50], Step [124/375], Loss: 2.3299, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [125/375], Loss: 2.3238, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [126/375], Loss: 2.2645, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [127/375], Loss: 2.2250, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [34/50], Step [128/375], Loss: 2.4858, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [129/375], Loss: 2.2501, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [130/375], Loss: 2.2382, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [131/375], Loss: 2.1251, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [132/375], Loss: 2.0035, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [133/375], Loss: 1.9956, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [34/50], Step [134/375], Loss: 2.2865, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [135/375], Loss: 2.0363, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [34/50], Step [136/375], Loss: 2.2643, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [137/375], Loss: 2.2765, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [138/375], Loss: 2.2826, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [139/375], Loss: 2.0268, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [140/375], Loss: 2.2312, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [141/375], Loss: 2.2463, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [142/375], Loss: 2.3305, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [143/375], Loss: 2.3460, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [144/375], Loss: 2.0931, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [145/375], Loss: 2.2990, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [146/375], Loss: 2.2249, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [147/375], Loss: 2.3005, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [148/375], Loss: 2.1927, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [149/375], Loss: 1.9959, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [150/375], Loss: 2.1618, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [151/375], Loss: 2.3883, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [152/375], Loss: 2.2543, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [153/375], Loss: 2.3121, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [154/375], Loss: 2.3457, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [155/375], Loss: 2.0531, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [34/50], Step [156/375], Loss: 2.2921, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [157/375], Loss: 2.1441, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [158/375], Loss: 2.3001, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [159/375], Loss: 2.0674, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [160/375], Loss: 1.9857, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [161/375], Loss: 2.3968, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [162/375], Loss: 2.3490, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [34/50], Step [163/375], Loss: 2.3042, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [164/375], Loss: 2.1093, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [165/375], Loss: 2.2465, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [166/375], Loss: 1.9951, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [167/375], Loss: 2.2293, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [168/375], Loss: 2.2749, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [169/375], Loss: 2.2912, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [170/375], Loss: 2.2123, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [171/375], Loss: 2.2767, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [172/375], Loss: 2.3053, batch time: 0.93, accuracy:  18.75%\n",
      "Epoch [34/50], Step [173/375], Loss: 2.1562, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [174/375], Loss: 2.2376, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [175/375], Loss: 2.2698, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [34/50], Step [176/375], Loss: 2.2305, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [177/375], Loss: 2.4252, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [178/375], Loss: 2.1493, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [34/50], Step [179/375], Loss: 2.1977, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [180/375], Loss: 2.1915, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [181/375], Loss: 2.2196, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [34/50], Step [182/375], Loss: 2.3710, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [183/375], Loss: 2.0604, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [184/375], Loss: 2.1879, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [185/375], Loss: 2.2323, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [34/50], Step [186/375], Loss: 2.2771, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [187/375], Loss: 2.0700, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [188/375], Loss: 2.1024, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [189/375], Loss: 2.3298, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [34/50], Step [190/375], Loss: 2.2988, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [191/375], Loss: 2.2371, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [192/375], Loss: 2.3194, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [193/375], Loss: 2.3902, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [34/50], Step [194/375], Loss: 2.0381, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [195/375], Loss: 2.2204, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [196/375], Loss: 2.2973, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [197/375], Loss: 2.2308, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [198/375], Loss: 2.0577, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [199/375], Loss: 2.3350, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [200/375], Loss: 2.4107, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [34/50], Step [201/375], Loss: 2.1629, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [202/375], Loss: 2.2323, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [203/375], Loss: 2.0250, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [204/375], Loss: 2.2005, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [205/375], Loss: 2.1728, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [206/375], Loss: 2.2158, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [207/375], Loss: 2.1717, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [208/375], Loss: 2.1781, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [209/375], Loss: 2.1080, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [210/375], Loss: 2.1934, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [211/375], Loss: 2.2765, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [212/375], Loss: 2.1018, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [213/375], Loss: 2.2925, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [214/375], Loss: 2.1528, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [215/375], Loss: 2.2117, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [216/375], Loss: 2.1732, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [217/375], Loss: 2.5049, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [34/50], Step [218/375], Loss: 1.8760, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [34/50], Step [219/375], Loss: 2.4466, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [34/50], Step [220/375], Loss: 2.2464, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [221/375], Loss: 2.1578, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [222/375], Loss: 2.2460, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [223/375], Loss: 2.2827, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [224/375], Loss: 2.2516, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [225/375], Loss: 2.0530, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [34/50], Step [226/375], Loss: 2.2478, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [227/375], Loss: 2.0758, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [228/375], Loss: 2.3152, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [229/375], Loss: 2.4485, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [230/375], Loss: 1.9826, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [34/50], Step [231/375], Loss: 2.1541, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [232/375], Loss: 2.1429, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [233/375], Loss: 2.2545, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [234/375], Loss: 2.2467, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [235/375], Loss: 2.3751, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [236/375], Loss: 2.3327, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [237/375], Loss: 2.1492, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [238/375], Loss: 2.2424, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [239/375], Loss: 2.2585, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [240/375], Loss: 2.3825, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [241/375], Loss: 2.2898, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [242/375], Loss: 2.1093, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [243/375], Loss: 2.1839, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [34/50], Step [244/375], Loss: 2.3206, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [245/375], Loss: 2.2218, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [246/375], Loss: 2.2619, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [247/375], Loss: 2.2127, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [248/375], Loss: 2.2101, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [249/375], Loss: 2.1097, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [34/50], Step [250/375], Loss: 2.3039, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [251/375], Loss: 2.3015, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [252/375], Loss: 2.3847, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [34/50], Step [253/375], Loss: 2.3449, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [254/375], Loss: 2.2413, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [255/375], Loss: 2.2578, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [256/375], Loss: 2.1836, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [257/375], Loss: 2.1965, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [258/375], Loss: 2.1867, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [259/375], Loss: 2.2566, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [260/375], Loss: 2.2022, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [261/375], Loss: 2.3903, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [34/50], Step [262/375], Loss: 2.2483, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [263/375], Loss: 1.9563, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [34/50], Step [264/375], Loss: 2.1183, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [265/375], Loss: 2.2192, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [34/50], Step [266/375], Loss: 2.2340, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [267/375], Loss: 2.1896, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [268/375], Loss: 2.5151, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [269/375], Loss: 2.1310, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [34/50], Step [270/375], Loss: 2.4430, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [34/50], Step [271/375], Loss: 2.3189, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [272/375], Loss: 2.3252, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [273/375], Loss: 2.4528, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [34/50], Step [274/375], Loss: 2.3016, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [275/375], Loss: 2.3259, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [276/375], Loss: 2.2790, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [277/375], Loss: 2.1683, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [278/375], Loss: 2.3076, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [34/50], Step [279/375], Loss: 2.1294, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [280/375], Loss: 2.2032, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [281/375], Loss: 2.3510, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [34/50], Step [282/375], Loss: 2.2856, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [34/50], Step [283/375], Loss: 2.1231, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [284/375], Loss: 2.2359, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [285/375], Loss: 2.2866, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [34/50], Step [286/375], Loss: 2.2593, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [287/375], Loss: 2.2730, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [288/375], Loss: 2.0954, batch time: 0.30, accuracy:  37.50%\n",
      "Epoch [34/50], Step [289/375], Loss: 2.2017, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [290/375], Loss: 2.2676, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [291/375], Loss: 2.2306, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [34/50], Step [292/375], Loss: 2.4036, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [293/375], Loss: 2.3159, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [294/375], Loss: 2.2810, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [295/375], Loss: 2.1706, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [34/50], Step [296/375], Loss: 2.2282, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [297/375], Loss: 2.0814, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [298/375], Loss: 2.2131, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [299/375], Loss: 2.3004, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [300/375], Loss: 2.2764, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [301/375], Loss: 2.1162, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [302/375], Loss: 2.2320, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [303/375], Loss: 2.4028, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [304/375], Loss: 2.1268, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [305/375], Loss: 2.3721, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [306/375], Loss: 2.2517, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [307/375], Loss: 2.1075, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [308/375], Loss: 2.2113, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [309/375], Loss: 2.3825, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [310/375], Loss: 2.1932, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [311/375], Loss: 2.2239, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [312/375], Loss: 2.3600, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [313/375], Loss: 2.1852, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [314/375], Loss: 2.2846, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [315/375], Loss: 2.2510, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [34/50], Step [316/375], Loss: 2.2382, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [317/375], Loss: 2.2123, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [318/375], Loss: 2.5095, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [319/375], Loss: 2.3029, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [320/375], Loss: 2.2228, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [321/375], Loss: 2.2626, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [322/375], Loss: 2.2614, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [323/375], Loss: 2.1406, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [34/50], Step [324/375], Loss: 2.1827, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [325/375], Loss: 2.1688, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [326/375], Loss: 2.2763, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [327/375], Loss: 2.2649, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [34/50], Step [328/375], Loss: 2.2630, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [329/375], Loss: 2.1238, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [330/375], Loss: 2.1667, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [331/375], Loss: 2.3475, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [332/375], Loss: 2.1209, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [34/50], Step [333/375], Loss: 2.2477, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [334/375], Loss: 2.1887, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [335/375], Loss: 2.2769, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [336/375], Loss: 2.2844, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [337/375], Loss: 2.2153, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [338/375], Loss: 2.2353, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [339/375], Loss: 2.1426, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [34/50], Step [340/375], Loss: 2.2750, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [341/375], Loss: 2.1371, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [342/375], Loss: 2.0836, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [343/375], Loss: 2.2240, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [34/50], Step [344/375], Loss: 2.2917, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [345/375], Loss: 2.1591, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [346/375], Loss: 2.1816, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [347/375], Loss: 2.0338, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [34/50], Step [348/375], Loss: 2.2230, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [349/375], Loss: 2.5175, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [350/375], Loss: 2.1612, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [34/50], Step [351/375], Loss: 2.0874, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [352/375], Loss: 2.3587, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [34/50], Step [353/375], Loss: 2.0898, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [354/375], Loss: 2.2974, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [355/375], Loss: 2.3757, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [356/375], Loss: 2.2198, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [357/375], Loss: 2.2212, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [34/50], Step [358/375], Loss: 2.1112, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [359/375], Loss: 2.0434, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [360/375], Loss: 2.4736, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [361/375], Loss: 2.2468, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [362/375], Loss: 2.3717, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [363/375], Loss: 2.5373, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [34/50], Step [364/375], Loss: 2.3293, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [365/375], Loss: 2.4149, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [34/50], Step [366/375], Loss: 2.0996, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [34/50], Step [367/375], Loss: 2.1928, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [34/50], Step [368/375], Loss: 2.3270, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [34/50], Step [369/375], Loss: 2.1354, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [370/375], Loss: 2.0478, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [34/50], Step [371/375], Loss: 2.4953, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [34/50], Step [372/375], Loss: 2.1781, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [34/50], Step [373/375], Loss: 2.1838, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [34/50], Step [374/375], Loss: 2.1979, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [34/50], Step [375/375], Loss: 2.1677, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [1/375], Loss: 2.1680, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [2/375], Loss: 2.1464, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [3/375], Loss: 2.2836, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [4/375], Loss: 2.3513, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [5/375], Loss: 2.3285, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [6/375], Loss: 2.3198, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [7/375], Loss: 2.1573, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [8/375], Loss: 2.2495, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [35/50], Step [9/375], Loss: 2.3192, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [10/375], Loss: 2.2508, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [11/375], Loss: 2.2714, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [12/375], Loss: 2.1626, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [35/50], Step [13/375], Loss: 2.2436, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [14/375], Loss: 2.1617, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [15/375], Loss: 2.1023, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [16/375], Loss: 2.3305, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [17/375], Loss: 2.1388, batch time: 1.04, accuracy:  25.00%\n",
      "Epoch [35/50], Step [18/375], Loss: 2.2728, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [19/375], Loss: 2.2397, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [20/375], Loss: 2.3779, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [35/50], Step [21/375], Loss: 2.4243, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [22/375], Loss: 2.3501, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [23/375], Loss: 2.1377, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [35/50], Step [24/375], Loss: 2.1446, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [25/375], Loss: 2.3792, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [26/375], Loss: 2.2575, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [35/50], Step [27/375], Loss: 2.2749, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [28/375], Loss: 2.0990, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [29/375], Loss: 2.2303, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [30/375], Loss: 2.3703, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [35/50], Step [31/375], Loss: 2.2642, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [32/375], Loss: 2.1999, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [33/375], Loss: 2.1402, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [34/375], Loss: 2.2142, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [35/375], Loss: 2.2253, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [36/375], Loss: 2.0223, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [37/375], Loss: 2.1449, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [38/375], Loss: 2.2750, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [39/375], Loss: 2.1656, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [40/375], Loss: 2.3955, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [35/50], Step [41/375], Loss: 2.1208, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [42/375], Loss: 2.1304, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [43/375], Loss: 2.5126, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [35/50], Step [44/375], Loss: 1.9998, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [35/50], Step [45/375], Loss: 2.2435, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [46/375], Loss: 2.0153, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [35/50], Step [47/375], Loss: 2.3035, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [48/375], Loss: 2.1916, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [49/375], Loss: 2.3315, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [50/375], Loss: 2.2599, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [51/375], Loss: 2.3426, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [52/375], Loss: 2.3378, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [53/375], Loss: 2.2978, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [54/375], Loss: 2.3982, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [35/50], Step [55/375], Loss: 2.0622, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [56/375], Loss: 2.2433, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [57/375], Loss: 2.3138, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [58/375], Loss: 2.3554, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [35/50], Step [59/375], Loss: 2.2194, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [60/375], Loss: 2.2340, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [61/375], Loss: 2.3510, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [62/375], Loss: 2.2830, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [63/375], Loss: 2.3733, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [64/375], Loss: 2.2960, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [65/375], Loss: 2.2649, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [66/375], Loss: 2.3852, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [35/50], Step [67/375], Loss: 2.1589, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [68/375], Loss: 2.1652, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [69/375], Loss: 2.1820, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [70/375], Loss: 2.1431, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [35/50], Step [71/375], Loss: 2.1340, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [35/50], Step [72/375], Loss: 2.3616, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [73/375], Loss: 2.3152, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [74/375], Loss: 2.3299, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [75/375], Loss: 2.2869, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [76/375], Loss: 2.2719, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [77/375], Loss: 2.0963, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [78/375], Loss: 2.2422, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [79/375], Loss: 2.3243, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [80/375], Loss: 2.3934, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [81/375], Loss: 2.0099, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [82/375], Loss: 2.1638, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [35/50], Step [83/375], Loss: 2.3588, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [84/375], Loss: 2.2508, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [85/375], Loss: 2.2424, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [86/375], Loss: 2.1124, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [35/50], Step [87/375], Loss: 2.2098, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [88/375], Loss: 2.2701, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [89/375], Loss: 2.3875, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [90/375], Loss: 2.4068, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [91/375], Loss: 2.0685, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [92/375], Loss: 2.3106, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [93/375], Loss: 2.1110, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [94/375], Loss: 2.1151, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [95/375], Loss: 2.2558, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [96/375], Loss: 2.1370, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [97/375], Loss: 2.3544, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [98/375], Loss: 2.2887, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [99/375], Loss: 2.2781, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [100/375], Loss: 2.0237, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [101/375], Loss: 2.2579, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [102/375], Loss: 2.2730, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [103/375], Loss: 2.2604, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [104/375], Loss: 1.9757, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [35/50], Step [105/375], Loss: 2.0578, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [106/375], Loss: 2.2359, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [107/375], Loss: 2.2241, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [108/375], Loss: 2.2161, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [109/375], Loss: 2.1220, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [110/375], Loss: 2.0902, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [35/50], Step [111/375], Loss: 2.2303, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [112/375], Loss: 2.1616, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [113/375], Loss: 2.3022, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [114/375], Loss: 2.3593, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [115/375], Loss: 2.3396, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [116/375], Loss: 2.1280, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [117/375], Loss: 2.0963, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [118/375], Loss: 2.2660, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [119/375], Loss: 2.1326, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [120/375], Loss: 2.5003, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [35/50], Step [121/375], Loss: 2.3155, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [122/375], Loss: 2.2298, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [123/375], Loss: 2.2053, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [124/375], Loss: 1.8908, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [35/50], Step [125/375], Loss: 1.9746, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [126/375], Loss: 2.2144, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [127/375], Loss: 2.0262, batch time: 0.85, accuracy:  37.50%\n",
      "Epoch [35/50], Step [128/375], Loss: 2.4131, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [129/375], Loss: 2.1895, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [130/375], Loss: 2.3279, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [35/50], Step [131/375], Loss: 2.1931, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [132/375], Loss: 2.3623, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [133/375], Loss: 2.0652, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [35/50], Step [134/375], Loss: 2.2514, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [135/375], Loss: 2.1762, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [136/375], Loss: 2.4012, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [35/50], Step [137/375], Loss: 2.2484, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [138/375], Loss: 2.1545, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [139/375], Loss: 2.2415, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [140/375], Loss: 2.3606, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [141/375], Loss: 2.4246, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [142/375], Loss: 1.9260, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [143/375], Loss: 2.3366, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [144/375], Loss: 2.3511, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [145/375], Loss: 2.3701, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [146/375], Loss: 2.1984, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [147/375], Loss: 2.3104, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [148/375], Loss: 2.3157, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [149/375], Loss: 2.2609, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [150/375], Loss: 2.2617, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [151/375], Loss: 2.2790, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [152/375], Loss: 2.1261, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [35/50], Step [153/375], Loss: 2.0271, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [154/375], Loss: 2.1893, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [155/375], Loss: 2.1531, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [156/375], Loss: 2.2965, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [157/375], Loss: 2.2067, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [158/375], Loss: 2.4625, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [159/375], Loss: 2.3835, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [160/375], Loss: 2.2942, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [161/375], Loss: 2.1320, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [162/375], Loss: 2.2028, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [163/375], Loss: 2.1366, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [164/375], Loss: 2.3630, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [165/375], Loss: 2.3177, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [166/375], Loss: 2.1523, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [167/375], Loss: 2.0155, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [35/50], Step [168/375], Loss: 2.3133, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [169/375], Loss: 2.2140, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [170/375], Loss: 2.2968, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [171/375], Loss: 2.1294, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [172/375], Loss: 2.1798, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [35/50], Step [173/375], Loss: 2.2374, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [174/375], Loss: 2.2138, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [175/375], Loss: 2.2655, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [176/375], Loss: 2.4213, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [177/375], Loss: 2.1894, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [35/50], Step [178/375], Loss: 2.2338, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [179/375], Loss: 2.1433, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [180/375], Loss: 2.3721, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [35/50], Step [181/375], Loss: 2.2798, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [35/50], Step [182/375], Loss: 2.4082, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [183/375], Loss: 2.2901, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [184/375], Loss: 2.2097, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [185/375], Loss: 2.4113, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [186/375], Loss: 2.4178, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [187/375], Loss: 2.2416, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [188/375], Loss: 2.2594, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [189/375], Loss: 2.2557, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [190/375], Loss: 1.9911, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [191/375], Loss: 2.0962, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [192/375], Loss: 2.2820, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [193/375], Loss: 2.1991, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [194/375], Loss: 2.1213, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [195/375], Loss: 2.2208, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [196/375], Loss: 2.3478, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [35/50], Step [197/375], Loss: 2.1894, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [198/375], Loss: 2.2818, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [199/375], Loss: 2.3238, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [200/375], Loss: 2.2375, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [201/375], Loss: 2.1481, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [202/375], Loss: 2.3791, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [203/375], Loss: 2.3385, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [204/375], Loss: 2.1989, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [205/375], Loss: 2.0273, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [206/375], Loss: 2.3560, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [207/375], Loss: 2.3528, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [208/375], Loss: 2.1307, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [209/375], Loss: 2.3053, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [210/375], Loss: 2.2512, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [211/375], Loss: 2.3200, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [212/375], Loss: 2.1981, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [213/375], Loss: 2.0817, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [214/375], Loss: 2.1886, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [215/375], Loss: 2.2513, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [216/375], Loss: 2.2444, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [217/375], Loss: 2.0831, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [218/375], Loss: 2.4595, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [35/50], Step [219/375], Loss: 2.4224, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [220/375], Loss: 2.1312, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [221/375], Loss: 2.3757, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [222/375], Loss: 2.1701, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [223/375], Loss: 2.2981, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [224/375], Loss: 2.3718, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [225/375], Loss: 2.2343, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [226/375], Loss: 2.1327, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [227/375], Loss: 2.1954, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [228/375], Loss: 2.2860, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [35/50], Step [229/375], Loss: 2.3988, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [230/375], Loss: 2.1566, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [231/375], Loss: 2.2413, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [232/375], Loss: 2.3483, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [233/375], Loss: 2.3335, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [35/50], Step [234/375], Loss: 2.2122, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [235/375], Loss: 2.3552, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [35/50], Step [236/375], Loss: 2.3560, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [237/375], Loss: 2.3640, batch time: 0.85, accuracy:  12.50%\n",
      "Epoch [35/50], Step [238/375], Loss: 2.2763, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [239/375], Loss: 2.4517, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [240/375], Loss: 2.2953, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [35/50], Step [241/375], Loss: 2.2433, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [242/375], Loss: 2.0367, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [35/50], Step [243/375], Loss: 2.2227, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [35/50], Step [244/375], Loss: 2.2258, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [245/375], Loss: 2.2265, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [246/375], Loss: 2.2044, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [35/50], Step [247/375], Loss: 2.2211, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [248/375], Loss: 2.1933, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [249/375], Loss: 2.2419, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [250/375], Loss: 2.2772, batch time: 0.29, accuracy:  6.25%\n",
      "Epoch [35/50], Step [251/375], Loss: 2.0891, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [252/375], Loss: 2.2712, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [253/375], Loss: 2.3418, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [254/375], Loss: 2.2030, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [35/50], Step [255/375], Loss: 2.1978, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [256/375], Loss: 2.3273, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [257/375], Loss: 2.2340, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [258/375], Loss: 2.1811, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [35/50], Step [259/375], Loss: 2.2530, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [260/375], Loss: 2.3458, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [261/375], Loss: 2.0645, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [262/375], Loss: 2.2369, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [35/50], Step [263/375], Loss: 2.2520, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [264/375], Loss: 2.1188, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [265/375], Loss: 2.1246, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [266/375], Loss: 2.0543, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [35/50], Step [267/375], Loss: 2.2420, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [268/375], Loss: 2.1205, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [269/375], Loss: 2.0696, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [270/375], Loss: 2.2933, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [271/375], Loss: 2.0886, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [272/375], Loss: 2.2136, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [273/375], Loss: 2.4808, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [274/375], Loss: 2.2574, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [275/375], Loss: 2.2164, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [276/375], Loss: 2.3092, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [277/375], Loss: 2.1387, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [278/375], Loss: 2.0826, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [35/50], Step [279/375], Loss: 2.2374, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [280/375], Loss: 2.1563, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [281/375], Loss: 2.1521, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [282/375], Loss: 2.4735, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [35/50], Step [283/375], Loss: 2.0907, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [284/375], Loss: 2.3308, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [285/375], Loss: 2.3291, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [286/375], Loss: 1.9990, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [35/50], Step [287/375], Loss: 2.4368, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [288/375], Loss: 1.9945, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [289/375], Loss: 2.2056, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [290/375], Loss: 2.4748, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [35/50], Step [291/375], Loss: 2.2939, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [292/375], Loss: 2.0522, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [293/375], Loss: 2.1996, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [294/375], Loss: 2.0387, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [295/375], Loss: 2.1110, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [296/375], Loss: 2.1780, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [297/375], Loss: 2.1775, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [298/375], Loss: 2.1826, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [299/375], Loss: 2.1839, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [300/375], Loss: 2.3640, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [301/375], Loss: 2.4199, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [302/375], Loss: 2.3213, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [303/375], Loss: 2.3793, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [304/375], Loss: 1.8862, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [35/50], Step [305/375], Loss: 2.2839, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [306/375], Loss: 2.2333, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [307/375], Loss: 2.1614, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [308/375], Loss: 2.2391, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [309/375], Loss: 2.2358, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [310/375], Loss: 2.1405, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [311/375], Loss: 2.3731, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [312/375], Loss: 2.3347, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [313/375], Loss: 2.1751, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [314/375], Loss: 2.2339, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [315/375], Loss: 2.2547, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [316/375], Loss: 2.2825, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [317/375], Loss: 2.3100, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [318/375], Loss: 2.1046, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [35/50], Step [319/375], Loss: 2.2557, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [320/375], Loss: 2.4224, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [321/375], Loss: 2.2011, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [322/375], Loss: 2.0929, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [323/375], Loss: 2.2073, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [324/375], Loss: 2.3551, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [325/375], Loss: 2.4406, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [326/375], Loss: 2.3075, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [327/375], Loss: 2.2271, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [328/375], Loss: 2.0310, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [35/50], Step [329/375], Loss: 2.1693, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [330/375], Loss: 2.3346, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [331/375], Loss: 2.1955, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [332/375], Loss: 2.1402, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [333/375], Loss: 2.4258, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [334/375], Loss: 2.0973, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [35/50], Step [335/375], Loss: 2.1317, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [336/375], Loss: 2.2068, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [337/375], Loss: 2.1012, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [338/375], Loss: 2.1984, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [35/50], Step [339/375], Loss: 2.1412, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [340/375], Loss: 2.1698, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [35/50], Step [341/375], Loss: 2.1688, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [342/375], Loss: 2.3316, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [343/375], Loss: 2.3707, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [344/375], Loss: 2.3158, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [35/50], Step [345/375], Loss: 2.1987, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [35/50], Step [346/375], Loss: 2.2071, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [35/50], Step [347/375], Loss: 2.2761, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [35/50], Step [348/375], Loss: 2.2966, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [349/375], Loss: 2.1168, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [350/375], Loss: 2.2551, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [35/50], Step [351/375], Loss: 2.2108, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [352/375], Loss: 2.1789, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [353/375], Loss: 2.1169, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [35/50], Step [354/375], Loss: 2.0050, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [35/50], Step [355/375], Loss: 2.3800, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [356/375], Loss: 1.8746, batch time: 0.30, accuracy:  50.00%\n",
      "Epoch [35/50], Step [357/375], Loss: 2.2183, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [358/375], Loss: 2.1199, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [359/375], Loss: 2.2345, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [35/50], Step [360/375], Loss: 2.1502, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [35/50], Step [361/375], Loss: 2.2673, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [362/375], Loss: 2.3050, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [363/375], Loss: 2.4226, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [35/50], Step [364/375], Loss: 2.4186, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [35/50], Step [365/375], Loss: 2.1527, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [35/50], Step [366/375], Loss: 2.2617, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [367/375], Loss: 2.2726, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [368/375], Loss: 2.3277, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [35/50], Step [369/375], Loss: 2.2516, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [35/50], Step [370/375], Loss: 2.2731, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [35/50], Step [371/375], Loss: 2.2249, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [372/375], Loss: 2.2367, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [35/50], Step [373/375], Loss: 2.3004, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [35/50], Step [374/375], Loss: 2.2223, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [35/50], Step [375/375], Loss: 2.2416, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [1/375], Loss: 2.0862, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [2/375], Loss: 2.1976, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [3/375], Loss: 2.1342, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [4/375], Loss: 2.1958, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [5/375], Loss: 2.2128, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [36/50], Step [6/375], Loss: 2.2282, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [7/375], Loss: 2.4797, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [8/375], Loss: 2.1283, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [9/375], Loss: 2.0932, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [36/50], Step [10/375], Loss: 2.3136, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [11/375], Loss: 2.2902, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [12/375], Loss: 2.3237, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [13/375], Loss: 2.2391, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [14/375], Loss: 2.2106, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [15/375], Loss: 2.4251, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [16/375], Loss: 2.1967, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [17/375], Loss: 2.2274, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [18/375], Loss: 2.2159, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [19/375], Loss: 2.2363, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [20/375], Loss: 2.3248, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [21/375], Loss: 2.3825, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [22/375], Loss: 2.3731, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [23/375], Loss: 2.1505, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [24/375], Loss: 2.3624, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [25/375], Loss: 2.2826, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [26/375], Loss: 2.1708, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [27/375], Loss: 2.3331, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [28/375], Loss: 2.1908, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [29/375], Loss: 2.2281, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [30/375], Loss: 2.2944, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [31/375], Loss: 2.1817, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [32/375], Loss: 2.2552, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [33/375], Loss: 2.3208, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [34/375], Loss: 2.3034, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [35/375], Loss: 2.3275, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [36/375], Loss: 2.0985, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [36/50], Step [37/375], Loss: 2.2114, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [38/375], Loss: 2.1966, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [39/375], Loss: 2.1517, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [40/375], Loss: 2.0940, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [41/375], Loss: 2.3298, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [42/375], Loss: 2.1462, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [43/375], Loss: 2.1286, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [44/375], Loss: 2.2507, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [45/375], Loss: 2.3311, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [46/375], Loss: 2.1593, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [47/375], Loss: 2.2513, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [48/375], Loss: 2.0545, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [49/375], Loss: 2.2324, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [50/375], Loss: 2.1410, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [51/375], Loss: 2.1893, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [52/375], Loss: 2.1978, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [53/375], Loss: 2.3159, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [54/375], Loss: 2.1951, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [55/375], Loss: 2.2799, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [56/375], Loss: 2.2223, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [57/375], Loss: 2.1592, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [58/375], Loss: 2.2229, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [59/375], Loss: 2.1920, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [60/375], Loss: 2.2408, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [61/375], Loss: 2.5066, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [62/375], Loss: 2.1843, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [63/375], Loss: 2.3733, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [64/375], Loss: 2.1073, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [65/375], Loss: 2.0288, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [36/50], Step [66/375], Loss: 2.2349, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [67/375], Loss: 2.0356, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [68/375], Loss: 2.4740, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [36/50], Step [69/375], Loss: 2.0925, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [36/50], Step [70/375], Loss: 2.2890, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [71/375], Loss: 2.2710, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [72/375], Loss: 2.1602, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [73/375], Loss: 2.2608, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [74/375], Loss: 2.0936, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [75/375], Loss: 2.1473, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [76/375], Loss: 2.0567, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [77/375], Loss: 2.3930, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [78/375], Loss: 2.1791, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [79/375], Loss: 2.3880, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [80/375], Loss: 2.4114, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [81/375], Loss: 2.4535, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [82/375], Loss: 2.2399, batch time: 0.85, accuracy:  25.00%\n",
      "Epoch [36/50], Step [83/375], Loss: 2.1018, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [84/375], Loss: 2.3019, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [85/375], Loss: 2.3848, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [36/50], Step [86/375], Loss: 2.2437, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [87/375], Loss: 2.3348, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [88/375], Loss: 2.2449, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [36/50], Step [89/375], Loss: 2.4155, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [90/375], Loss: 1.9715, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [91/375], Loss: 2.0089, batch time: 0.30, accuracy:  43.75%\n",
      "Epoch [36/50], Step [92/375], Loss: 2.3026, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [93/375], Loss: 2.2047, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [94/375], Loss: 2.2361, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [95/375], Loss: 2.3348, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [36/50], Step [96/375], Loss: 1.9860, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [36/50], Step [97/375], Loss: 2.3999, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [98/375], Loss: 2.2939, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [99/375], Loss: 2.2453, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [36/50], Step [100/375], Loss: 2.0546, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [101/375], Loss: 2.2335, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [102/375], Loss: 2.5342, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [103/375], Loss: 2.3638, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [104/375], Loss: 2.3459, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [105/375], Loss: 2.1160, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [106/375], Loss: 2.2041, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [107/375], Loss: 2.3931, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [36/50], Step [108/375], Loss: 2.3155, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [109/375], Loss: 2.2604, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [110/375], Loss: 2.1165, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [111/375], Loss: 2.4651, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [36/50], Step [112/375], Loss: 2.2069, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [113/375], Loss: 2.4050, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [114/375], Loss: 2.1677, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [115/375], Loss: 2.1536, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [36/50], Step [116/375], Loss: 2.2086, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [117/375], Loss: 2.2804, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [118/375], Loss: 2.0851, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [119/375], Loss: 2.2874, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [120/375], Loss: 2.4016, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [121/375], Loss: 2.1922, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [122/375], Loss: 2.2689, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [123/375], Loss: 2.3866, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [124/375], Loss: 2.2326, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [125/375], Loss: 2.2198, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [126/375], Loss: 2.4280, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [127/375], Loss: 2.1627, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [128/375], Loss: 2.3870, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [129/375], Loss: 2.4129, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [130/375], Loss: 2.2536, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [131/375], Loss: 2.3486, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [132/375], Loss: 2.2873, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [133/375], Loss: 2.2027, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [134/375], Loss: 2.3098, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [135/375], Loss: 2.2324, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [136/375], Loss: 2.2496, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [137/375], Loss: 2.3159, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [138/375], Loss: 2.2613, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [139/375], Loss: 2.2436, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [140/375], Loss: 2.2463, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [141/375], Loss: 2.1479, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [142/375], Loss: 2.2575, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [143/375], Loss: 2.3395, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [144/375], Loss: 2.1316, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [145/375], Loss: 2.2624, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [146/375], Loss: 2.3029, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [147/375], Loss: 2.1362, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [148/375], Loss: 2.2347, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [149/375], Loss: 2.2364, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [150/375], Loss: 2.2814, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [151/375], Loss: 2.3972, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [152/375], Loss: 2.3009, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [153/375], Loss: 2.3688, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [36/50], Step [154/375], Loss: 2.0467, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [36/50], Step [155/375], Loss: 2.1078, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [36/50], Step [156/375], Loss: 2.3663, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [36/50], Step [157/375], Loss: 2.1448, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [158/375], Loss: 2.2182, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [159/375], Loss: 2.3064, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [160/375], Loss: 2.1962, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [161/375], Loss: 2.1652, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [162/375], Loss: 2.1998, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [163/375], Loss: 2.2680, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [164/375], Loss: 2.2534, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [165/375], Loss: 2.3162, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [166/375], Loss: 2.3499, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [167/375], Loss: 2.2866, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [168/375], Loss: 2.2454, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [169/375], Loss: 2.0376, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [170/375], Loss: 2.2214, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [171/375], Loss: 2.3802, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [172/375], Loss: 2.2110, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [173/375], Loss: 2.3713, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [174/375], Loss: 2.3600, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [175/375], Loss: 2.3365, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [176/375], Loss: 2.1556, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [177/375], Loss: 2.2429, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [178/375], Loss: 2.1597, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [179/375], Loss: 2.2132, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [180/375], Loss: 2.3969, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [181/375], Loss: 2.2218, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [182/375], Loss: 2.3351, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [36/50], Step [183/375], Loss: 2.0991, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [36/50], Step [184/375], Loss: 2.0212, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [185/375], Loss: 2.2813, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [186/375], Loss: 2.2778, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [187/375], Loss: 2.3006, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [188/375], Loss: 1.9226, batch time: 0.24, accuracy:  56.25%\n",
      "Epoch [36/50], Step [189/375], Loss: 2.2497, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [190/375], Loss: 2.1873, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [191/375], Loss: 2.3350, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [192/375], Loss: 2.1845, batch time: 0.86, accuracy:  25.00%\n",
      "Epoch [36/50], Step [193/375], Loss: 2.4390, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [36/50], Step [194/375], Loss: 2.2069, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [195/375], Loss: 2.0978, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [36/50], Step [196/375], Loss: 2.3808, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [197/375], Loss: 2.4604, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [198/375], Loss: 2.2189, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [36/50], Step [199/375], Loss: 2.3310, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [200/375], Loss: 2.3402, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [201/375], Loss: 2.3453, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [36/50], Step [202/375], Loss: 2.2488, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [203/375], Loss: 2.1451, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [204/375], Loss: 2.3082, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [205/375], Loss: 2.1950, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [36/50], Step [206/375], Loss: 2.2563, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [207/375], Loss: 2.2025, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [208/375], Loss: 2.2280, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [36/50], Step [209/375], Loss: 2.1506, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [36/50], Step [210/375], Loss: 2.0599, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [211/375], Loss: 2.1366, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [212/375], Loss: 2.3007, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [213/375], Loss: 2.0665, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [36/50], Step [214/375], Loss: 2.2406, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [215/375], Loss: 2.2019, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [216/375], Loss: 2.3872, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [217/375], Loss: 2.3191, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [36/50], Step [218/375], Loss: 2.2234, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [219/375], Loss: 2.2770, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [220/375], Loss: 2.1402, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [221/375], Loss: 2.0659, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [36/50], Step [222/375], Loss: 2.3243, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [223/375], Loss: 2.2986, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [224/375], Loss: 2.2035, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [225/375], Loss: 2.1923, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [226/375], Loss: 1.9336, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [227/375], Loss: 2.2878, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [228/375], Loss: 2.2963, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [229/375], Loss: 2.3596, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [230/375], Loss: 2.2918, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [231/375], Loss: 2.2910, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [232/375], Loss: 2.2979, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [233/375], Loss: 2.3798, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [36/50], Step [234/375], Loss: 1.9981, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [235/375], Loss: 2.1111, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [236/375], Loss: 2.2574, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [237/375], Loss: 2.3719, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [36/50], Step [238/375], Loss: 2.4608, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [239/375], Loss: 2.2702, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [240/375], Loss: 2.1498, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [241/375], Loss: 2.1721, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [242/375], Loss: 2.2736, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [243/375], Loss: 2.1256, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [244/375], Loss: 2.0884, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [245/375], Loss: 2.3050, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [246/375], Loss: 2.1088, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [247/375], Loss: 2.3552, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [248/375], Loss: 2.0915, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [249/375], Loss: 2.2025, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [250/375], Loss: 1.9957, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [251/375], Loss: 2.2231, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [252/375], Loss: 2.3291, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [253/375], Loss: 2.0142, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [36/50], Step [254/375], Loss: 2.0425, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [36/50], Step [255/375], Loss: 2.1602, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [256/375], Loss: 2.2170, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [257/375], Loss: 2.3013, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [258/375], Loss: 2.2812, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [259/375], Loss: 2.4368, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [260/375], Loss: 2.1200, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [261/375], Loss: 2.2615, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [262/375], Loss: 2.1485, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [263/375], Loss: 2.0301, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [264/375], Loss: 2.1246, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [265/375], Loss: 2.3887, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [266/375], Loss: 2.1519, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [267/375], Loss: 2.2657, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [268/375], Loss: 2.3275, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [269/375], Loss: 2.1981, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [270/375], Loss: 2.4793, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [36/50], Step [271/375], Loss: 2.2883, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [272/375], Loss: 2.1604, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [273/375], Loss: 2.0071, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [36/50], Step [274/375], Loss: 2.1482, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [275/375], Loss: 2.3545, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [276/375], Loss: 2.3075, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [277/375], Loss: 2.4978, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [36/50], Step [278/375], Loss: 2.0695, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [279/375], Loss: 2.1377, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [280/375], Loss: 2.2698, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [281/375], Loss: 2.2102, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [282/375], Loss: 2.2327, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [283/375], Loss: 2.1034, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [284/375], Loss: 2.2231, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [285/375], Loss: 2.2540, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [286/375], Loss: 2.3755, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [287/375], Loss: 2.2434, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [288/375], Loss: 2.2702, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [36/50], Step [289/375], Loss: 2.1190, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [290/375], Loss: 2.1904, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [291/375], Loss: 2.2571, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [292/375], Loss: 2.3116, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [293/375], Loss: 2.3481, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [36/50], Step [294/375], Loss: 2.3534, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [295/375], Loss: 2.1320, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [296/375], Loss: 2.2013, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [297/375], Loss: 2.4788, batch time: 0.26, accuracy:  0.00%\n",
      "Epoch [36/50], Step [298/375], Loss: 2.1264, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [299/375], Loss: 2.2325, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [300/375], Loss: 2.3137, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [301/375], Loss: 1.9784, batch time: 0.27, accuracy:  50.00%\n",
      "Epoch [36/50], Step [302/375], Loss: 2.2081, batch time: 1.02, accuracy:  25.00%\n",
      "Epoch [36/50], Step [303/375], Loss: 2.1622, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [304/375], Loss: 2.2361, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [305/375], Loss: 2.0781, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [36/50], Step [306/375], Loss: 2.0592, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [307/375], Loss: 2.1981, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [308/375], Loss: 2.1045, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [36/50], Step [309/375], Loss: 2.2717, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [310/375], Loss: 2.3514, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [311/375], Loss: 2.4579, batch time: 0.31, accuracy:  0.00%\n",
      "Epoch [36/50], Step [312/375], Loss: 2.4473, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [313/375], Loss: 2.1692, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [314/375], Loss: 2.1420, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [36/50], Step [315/375], Loss: 2.2276, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [36/50], Step [316/375], Loss: 2.2897, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [317/375], Loss: 2.1345, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [318/375], Loss: 2.2304, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [319/375], Loss: 1.9873, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [36/50], Step [320/375], Loss: 2.2153, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [321/375], Loss: 2.3516, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [322/375], Loss: 2.3941, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [323/375], Loss: 2.3415, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [36/50], Step [324/375], Loss: 2.1922, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [325/375], Loss: 2.4858, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [326/375], Loss: 2.3043, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [327/375], Loss: 1.9889, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [36/50], Step [328/375], Loss: 2.4336, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [329/375], Loss: 2.1123, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [330/375], Loss: 2.1283, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [331/375], Loss: 2.1832, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [36/50], Step [332/375], Loss: 2.0632, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [333/375], Loss: 2.1654, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [334/375], Loss: 2.5172, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [335/375], Loss: 2.1023, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [36/50], Step [336/375], Loss: 2.1690, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [337/375], Loss: 2.2091, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [338/375], Loss: 2.1414, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [36/50], Step [339/375], Loss: 2.1789, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [36/50], Step [340/375], Loss: 2.1128, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [341/375], Loss: 2.2426, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [342/375], Loss: 2.1730, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [343/375], Loss: 2.0981, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [36/50], Step [344/375], Loss: 2.0392, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [36/50], Step [345/375], Loss: 2.3022, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [346/375], Loss: 2.0947, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [347/375], Loss: 2.3494, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [348/375], Loss: 2.2726, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [349/375], Loss: 2.1147, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [350/375], Loss: 2.2453, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [351/375], Loss: 2.3374, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [36/50], Step [352/375], Loss: 2.2390, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [353/375], Loss: 1.9804, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [36/50], Step [354/375], Loss: 2.1598, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [355/375], Loss: 2.2614, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [36/50], Step [356/375], Loss: 2.2042, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [357/375], Loss: 2.2759, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [358/375], Loss: 2.1547, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [359/375], Loss: 2.2892, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [36/50], Step [360/375], Loss: 2.0275, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [36/50], Step [361/375], Loss: 2.2708, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [362/375], Loss: 2.1666, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [363/375], Loss: 2.2146, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [36/50], Step [364/375], Loss: 2.2558, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [36/50], Step [365/375], Loss: 2.3149, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [36/50], Step [366/375], Loss: 2.0988, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [36/50], Step [367/375], Loss: 2.1736, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [368/375], Loss: 2.1788, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [369/375], Loss: 2.3345, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [36/50], Step [370/375], Loss: 2.2662, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [36/50], Step [371/375], Loss: 2.2565, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [36/50], Step [372/375], Loss: 2.2499, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [36/50], Step [373/375], Loss: 2.1619, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [36/50], Step [374/375], Loss: 2.6540, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [36/50], Step [375/375], Loss: 1.9794, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [37/50], Step [1/375], Loss: 2.3904, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [2/375], Loss: 1.9869, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [3/375], Loss: 2.1621, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [4/375], Loss: 2.0888, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [5/375], Loss: 2.1212, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [6/375], Loss: 2.2480, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [7/375], Loss: 2.1546, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [8/375], Loss: 2.3153, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [9/375], Loss: 2.4442, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [10/375], Loss: 2.2508, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [11/375], Loss: 2.3137, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [12/375], Loss: 2.5503, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [13/375], Loss: 1.9856, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [14/375], Loss: 2.1421, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [15/375], Loss: 2.2513, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [16/375], Loss: 2.0092, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [37/50], Step [17/375], Loss: 2.0922, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [18/375], Loss: 2.0512, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [19/375], Loss: 2.3418, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [20/375], Loss: 2.2663, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [37/50], Step [21/375], Loss: 2.1250, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [22/375], Loss: 2.4081, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [23/375], Loss: 2.2281, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [24/375], Loss: 2.0822, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [25/375], Loss: 2.2567, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [26/375], Loss: 2.4207, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [27/375], Loss: 2.2180, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [28/375], Loss: 2.2846, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [29/375], Loss: 2.3378, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [30/375], Loss: 2.3082, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [31/375], Loss: 2.2093, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [32/375], Loss: 2.1489, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [33/375], Loss: 2.4314, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [34/375], Loss: 2.2858, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [35/375], Loss: 2.1191, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [36/375], Loss: 2.0138, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [37/375], Loss: 2.2427, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [38/375], Loss: 2.2792, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [39/375], Loss: 2.1884, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [40/375], Loss: 2.0764, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [41/375], Loss: 2.4502, batch time: 0.87, accuracy:  6.25%\n",
      "Epoch [37/50], Step [42/375], Loss: 2.2785, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [43/375], Loss: 2.1843, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [44/375], Loss: 2.1891, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [37/50], Step [45/375], Loss: 2.0348, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [46/375], Loss: 2.2374, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [47/375], Loss: 2.0573, batch time: 0.30, accuracy:  31.25%\n",
      "Epoch [37/50], Step [48/375], Loss: 2.0778, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [49/375], Loss: 2.4569, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [50/375], Loss: 2.2677, batch time: 0.30, accuracy:  25.00%\n",
      "Epoch [37/50], Step [51/375], Loss: 2.1421, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [52/375], Loss: 2.3182, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [53/375], Loss: 2.1851, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [54/375], Loss: 2.4778, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [37/50], Step [55/375], Loss: 2.1132, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [56/375], Loss: 2.2933, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [57/375], Loss: 2.3219, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [58/375], Loss: 2.3821, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [37/50], Step [59/375], Loss: 2.4118, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [60/375], Loss: 1.9840, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [61/375], Loss: 2.1680, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [62/375], Loss: 2.3654, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [63/375], Loss: 2.2834, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [64/375], Loss: 2.1081, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [65/375], Loss: 2.2404, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [37/50], Step [66/375], Loss: 2.2471, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [67/375], Loss: 2.0012, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [68/375], Loss: 2.4423, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [37/50], Step [69/375], Loss: 2.2300, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [70/375], Loss: 2.1445, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [71/375], Loss: 2.1167, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [72/375], Loss: 2.2855, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [73/375], Loss: 2.0195, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [74/375], Loss: 2.1504, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [75/375], Loss: 2.4253, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [76/375], Loss: 2.2639, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [77/375], Loss: 2.0141, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [37/50], Step [78/375], Loss: 2.2334, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [79/375], Loss: 2.1411, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [80/375], Loss: 2.1256, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [81/375], Loss: 2.2017, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [82/375], Loss: 1.9834, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [83/375], Loss: 2.5525, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [84/375], Loss: 2.1526, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [85/375], Loss: 2.3917, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [86/375], Loss: 2.3298, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [87/375], Loss: 2.0399, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [37/50], Step [88/375], Loss: 2.3088, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [89/375], Loss: 2.3280, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [90/375], Loss: 2.6543, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [91/375], Loss: 2.3260, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [92/375], Loss: 2.3366, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [93/375], Loss: 2.2575, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [94/375], Loss: 1.9884, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [37/50], Step [95/375], Loss: 2.1544, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [96/375], Loss: 2.3051, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [97/375], Loss: 2.1226, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [98/375], Loss: 2.3115, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [99/375], Loss: 2.2618, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [100/375], Loss: 2.2355, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [101/375], Loss: 2.3522, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [102/375], Loss: 2.2942, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [103/375], Loss: 2.1381, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [104/375], Loss: 2.1695, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [105/375], Loss: 2.2886, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [106/375], Loss: 2.1550, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [107/375], Loss: 2.2802, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [108/375], Loss: 2.3384, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [109/375], Loss: 2.1143, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [110/375], Loss: 2.1133, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [37/50], Step [111/375], Loss: 2.3139, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [112/375], Loss: 2.2220, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [113/375], Loss: 2.0637, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [114/375], Loss: 2.3011, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [115/375], Loss: 2.3693, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [116/375], Loss: 2.3190, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [117/375], Loss: 2.2395, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [118/375], Loss: 2.2367, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [37/50], Step [119/375], Loss: 2.2580, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [120/375], Loss: 2.2667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [121/375], Loss: 2.1692, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [122/375], Loss: 2.3489, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [123/375], Loss: 2.2710, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [124/375], Loss: 2.1467, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [125/375], Loss: 2.3793, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [126/375], Loss: 2.4541, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [127/375], Loss: 2.2772, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [128/375], Loss: 2.3678, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [129/375], Loss: 2.2977, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [130/375], Loss: 2.1951, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [131/375], Loss: 2.2556, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [132/375], Loss: 2.2390, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [133/375], Loss: 2.1958, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [134/375], Loss: 2.2845, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [135/375], Loss: 2.3577, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [136/375], Loss: 2.2488, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [137/375], Loss: 2.3277, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [138/375], Loss: 2.2086, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [139/375], Loss: 1.9417, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [37/50], Step [140/375], Loss: 2.2637, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [141/375], Loss: 2.2840, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [142/375], Loss: 2.2246, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [143/375], Loss: 2.3246, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [144/375], Loss: 2.3159, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [145/375], Loss: 2.3619, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [146/375], Loss: 2.3239, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [147/375], Loss: 2.0869, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [148/375], Loss: 2.2290, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [149/375], Loss: 2.3137, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [150/375], Loss: 2.3637, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [151/375], Loss: 2.2023, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [152/375], Loss: 2.3412, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [153/375], Loss: 2.1609, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [154/375], Loss: 2.1400, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [155/375], Loss: 2.4204, batch time: 0.88, accuracy:  12.50%\n",
      "Epoch [37/50], Step [156/375], Loss: 2.0847, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [157/375], Loss: 2.3505, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [158/375], Loss: 2.3705, batch time: 0.30, accuracy:  0.00%\n",
      "Epoch [37/50], Step [159/375], Loss: 2.2172, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [160/375], Loss: 2.1552, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [161/375], Loss: 2.1520, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [37/50], Step [162/375], Loss: 2.2970, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [163/375], Loss: 2.0693, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [164/375], Loss: 2.3203, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [37/50], Step [165/375], Loss: 2.2503, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [166/375], Loss: 2.1306, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [167/375], Loss: 2.2432, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [168/375], Loss: 2.3084, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [169/375], Loss: 2.1780, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [170/375], Loss: 2.2508, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [171/375], Loss: 2.2734, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [172/375], Loss: 2.2648, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [37/50], Step [173/375], Loss: 2.2095, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [174/375], Loss: 2.1823, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [175/375], Loss: 2.2465, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [176/375], Loss: 2.3665, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [37/50], Step [177/375], Loss: 2.1176, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [178/375], Loss: 2.1608, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [179/375], Loss: 2.3404, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [180/375], Loss: 2.2395, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [181/375], Loss: 2.1724, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [182/375], Loss: 2.2229, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [183/375], Loss: 2.2424, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [184/375], Loss: 2.2120, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [37/50], Step [185/375], Loss: 2.3694, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [186/375], Loss: 2.2730, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [187/375], Loss: 2.1295, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [188/375], Loss: 2.4098, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [189/375], Loss: 2.2364, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [190/375], Loss: 2.4343, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [191/375], Loss: 2.1372, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [192/375], Loss: 2.1113, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [193/375], Loss: 2.1486, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [194/375], Loss: 2.1456, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [195/375], Loss: 2.2913, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [196/375], Loss: 2.1195, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [197/375], Loss: 2.3919, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [198/375], Loss: 2.3390, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [199/375], Loss: 2.3921, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [200/375], Loss: 2.3305, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [201/375], Loss: 2.1972, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [202/375], Loss: 2.1925, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [203/375], Loss: 2.2643, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [204/375], Loss: 2.0705, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [37/50], Step [205/375], Loss: 2.1212, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [206/375], Loss: 2.0455, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [207/375], Loss: 2.2500, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [208/375], Loss: 2.2706, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [209/375], Loss: 2.1658, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [210/375], Loss: 2.2413, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [211/375], Loss: 2.3143, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [212/375], Loss: 2.2656, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [37/50], Step [213/375], Loss: 2.0771, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [214/375], Loss: 2.1472, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [215/375], Loss: 2.1759, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [216/375], Loss: 2.0612, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [37/50], Step [217/375], Loss: 2.1284, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [218/375], Loss: 2.0694, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [219/375], Loss: 2.2769, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [220/375], Loss: 2.1284, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [221/375], Loss: 2.2593, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [222/375], Loss: 2.2309, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [223/375], Loss: 1.8960, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [37/50], Step [224/375], Loss: 2.1695, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [225/375], Loss: 2.3586, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [226/375], Loss: 2.0566, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [227/375], Loss: 2.2908, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [228/375], Loss: 2.3703, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [229/375], Loss: 2.3662, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [230/375], Loss: 1.9345, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [37/50], Step [231/375], Loss: 2.2381, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [232/375], Loss: 2.5811, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [37/50], Step [233/375], Loss: 2.1998, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [234/375], Loss: 1.8621, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [37/50], Step [235/375], Loss: 2.3688, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [236/375], Loss: 2.6124, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [237/375], Loss: 2.3543, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [238/375], Loss: 2.1817, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [239/375], Loss: 2.2749, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [240/375], Loss: 2.1681, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [241/375], Loss: 2.3168, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [242/375], Loss: 2.3528, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [243/375], Loss: 2.2205, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [244/375], Loss: 2.3956, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [245/375], Loss: 2.3545, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [246/375], Loss: 2.3375, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [247/375], Loss: 2.0181, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [248/375], Loss: 2.2880, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [37/50], Step [249/375], Loss: 2.3220, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [250/375], Loss: 2.2440, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [251/375], Loss: 2.2063, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [252/375], Loss: 2.1463, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [37/50], Step [253/375], Loss: 2.2624, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [254/375], Loss: 2.3322, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [255/375], Loss: 2.1775, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [256/375], Loss: 2.2526, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [37/50], Step [257/375], Loss: 2.1123, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [258/375], Loss: 2.3094, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [259/375], Loss: 2.3068, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [260/375], Loss: 2.1624, batch time: 0.26, accuracy:  43.75%\n",
      "Epoch [37/50], Step [261/375], Loss: 2.3024, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [262/375], Loss: 2.2040, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [263/375], Loss: 2.1121, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [264/375], Loss: 2.3651, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [37/50], Step [265/375], Loss: 2.2958, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [266/375], Loss: 2.0706, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [267/375], Loss: 2.3655, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [268/375], Loss: 1.9547, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [37/50], Step [269/375], Loss: 2.4307, batch time: 1.06, accuracy:  6.25%\n",
      "Epoch [37/50], Step [270/375], Loss: 2.3008, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [271/375], Loss: 2.1441, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [272/375], Loss: 2.1520, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [37/50], Step [273/375], Loss: 2.2690, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [274/375], Loss: 1.9794, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [37/50], Step [275/375], Loss: 2.1344, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [37/50], Step [276/375], Loss: 2.3174, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [277/375], Loss: 2.2764, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [278/375], Loss: 2.1887, batch time: 0.31, accuracy:  12.50%\n",
      "Epoch [37/50], Step [279/375], Loss: 2.1609, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [280/375], Loss: 2.1976, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [37/50], Step [281/375], Loss: 2.3959, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [282/375], Loss: 2.0202, batch time: 0.28, accuracy:  43.75%\n",
      "Epoch [37/50], Step [283/375], Loss: 2.2117, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [284/375], Loss: 2.1926, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [285/375], Loss: 2.3208, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [286/375], Loss: 2.2676, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [37/50], Step [287/375], Loss: 2.3145, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [288/375], Loss: 2.2035, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [37/50], Step [289/375], Loss: 2.2416, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [290/375], Loss: 2.2728, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [37/50], Step [291/375], Loss: 2.3986, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [37/50], Step [292/375], Loss: 2.3675, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [37/50], Step [293/375], Loss: 2.0569, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [294/375], Loss: 2.1674, batch time: 0.28, accuracy:  37.50%\n",
      "Epoch [37/50], Step [295/375], Loss: 2.3972, batch time: 0.34, accuracy:  6.25%\n",
      "Epoch [37/50], Step [296/375], Loss: 2.2496, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [37/50], Step [297/375], Loss: 2.0643, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [37/50], Step [298/375], Loss: 2.3244, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [37/50], Step [299/375], Loss: 2.2042, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [37/50], Step [300/375], Loss: 2.4673, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [37/50], Step [301/375], Loss: 2.0826, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [302/375], Loss: 2.2099, batch time: 0.36, accuracy:  25.00%\n",
      "Epoch [37/50], Step [303/375], Loss: 2.2627, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [37/50], Step [304/375], Loss: 2.1980, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [37/50], Step [305/375], Loss: 2.3056, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [37/50], Step [306/375], Loss: 2.2996, batch time: 0.36, accuracy:  12.50%\n",
      "Epoch [37/50], Step [307/375], Loss: 2.2021, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [308/375], Loss: 2.2465, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [37/50], Step [309/375], Loss: 1.9710, batch time: 0.33, accuracy:  37.50%\n",
      "Epoch [37/50], Step [310/375], Loss: 2.2784, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [37/50], Step [311/375], Loss: 2.0572, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [312/375], Loss: 2.3503, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [37/50], Step [313/375], Loss: 2.2767, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [37/50], Step [314/375], Loss: 1.9094, batch time: 0.36, accuracy:  43.75%\n",
      "Epoch [37/50], Step [315/375], Loss: 2.2775, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [37/50], Step [316/375], Loss: 2.2157, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [37/50], Step [317/375], Loss: 2.2034, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [318/375], Loss: 2.3758, batch time: 0.34, accuracy:  18.75%\n",
      "Epoch [37/50], Step [319/375], Loss: 2.4323, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [37/50], Step [320/375], Loss: 2.0276, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [37/50], Step [321/375], Loss: 2.2370, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [37/50], Step [322/375], Loss: 1.9719, batch time: 0.36, accuracy:  43.75%\n",
      "Epoch [37/50], Step [323/375], Loss: 2.4468, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [37/50], Step [324/375], Loss: 2.2232, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [37/50], Step [325/375], Loss: 2.1744, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [37/50], Step [326/375], Loss: 2.1914, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [37/50], Step [327/375], Loss: 2.0928, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [37/50], Step [328/375], Loss: 2.2432, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [37/50], Step [329/375], Loss: 1.9760, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [37/50], Step [330/375], Loss: 2.3303, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [37/50], Step [331/375], Loss: 2.0830, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [37/50], Step [332/375], Loss: 2.5238, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [37/50], Step [333/375], Loss: 2.1380, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [334/375], Loss: 2.2971, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [37/50], Step [335/375], Loss: 2.2114, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [336/375], Loss: 2.2593, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [37/50], Step [337/375], Loss: 2.0744, batch time: 0.32, accuracy:  37.50%\n",
      "Epoch [37/50], Step [338/375], Loss: 2.2251, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [37/50], Step [339/375], Loss: 2.0826, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [37/50], Step [340/375], Loss: 1.9779, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [37/50], Step [341/375], Loss: 2.0118, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [37/50], Step [342/375], Loss: 2.1081, batch time: 0.36, accuracy:  25.00%\n",
      "Epoch [37/50], Step [343/375], Loss: 2.2127, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [37/50], Step [344/375], Loss: 2.1408, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [37/50], Step [345/375], Loss: 2.1805, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [37/50], Step [346/375], Loss: 2.0634, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [37/50], Step [347/375], Loss: 2.2290, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [348/375], Loss: 2.2783, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [349/375], Loss: 2.1664, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [350/375], Loss: 2.2174, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [37/50], Step [351/375], Loss: 2.3233, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [352/375], Loss: 2.3656, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [353/375], Loss: 2.3099, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [37/50], Step [354/375], Loss: 2.2869, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [355/375], Loss: 2.1088, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [37/50], Step [356/375], Loss: 2.3489, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [357/375], Loss: 2.3953, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [358/375], Loss: 2.3374, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [359/375], Loss: 2.4259, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [360/375], Loss: 2.2667, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [361/375], Loss: 2.2019, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [362/375], Loss: 2.2802, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [363/375], Loss: 2.2944, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [37/50], Step [364/375], Loss: 2.3730, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [365/375], Loss: 2.3180, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [37/50], Step [366/375], Loss: 2.0911, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [37/50], Step [367/375], Loss: 2.3095, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [368/375], Loss: 2.4207, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [369/375], Loss: 2.1506, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [37/50], Step [370/375], Loss: 2.3386, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [37/50], Step [371/375], Loss: 2.5011, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [37/50], Step [372/375], Loss: 2.2482, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [37/50], Step [373/375], Loss: 2.2993, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [37/50], Step [374/375], Loss: 2.3681, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [37/50], Step [375/375], Loss: 2.2318, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [1/375], Loss: 2.3521, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [2/375], Loss: 2.1707, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [3/375], Loss: 2.2566, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [4/375], Loss: 2.2860, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [5/375], Loss: 2.2249, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [6/375], Loss: 2.0496, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [38/50], Step [7/375], Loss: 2.2081, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [8/375], Loss: 2.1608, batch time: 0.87, accuracy:  25.00%\n",
      "Epoch [38/50], Step [9/375], Loss: 2.3714, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [10/375], Loss: 2.0778, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [11/375], Loss: 2.4360, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [38/50], Step [12/375], Loss: 2.2965, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [13/375], Loss: 2.3677, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [14/375], Loss: 2.1008, batch time: 0.30, accuracy:  37.50%\n",
      "Epoch [38/50], Step [15/375], Loss: 2.3234, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [16/375], Loss: 2.2243, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [17/375], Loss: 2.2293, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [38/50], Step [18/375], Loss: 2.1732, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [19/375], Loss: 2.2632, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [20/375], Loss: 2.0279, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [21/375], Loss: 2.2843, batch time: 0.28, accuracy:  12.50%\n",
      "Epoch [38/50], Step [22/375], Loss: 2.1824, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [23/375], Loss: 2.3007, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [24/375], Loss: 2.0996, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [25/375], Loss: 2.1432, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [26/375], Loss: 2.0418, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [27/375], Loss: 2.2475, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [28/375], Loss: 2.2713, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [29/375], Loss: 2.1600, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [30/375], Loss: 2.3776, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [31/375], Loss: 2.2721, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [32/375], Loss: 2.2569, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [33/375], Loss: 2.0647, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [38/50], Step [34/375], Loss: 2.3541, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [35/375], Loss: 2.1053, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [36/375], Loss: 2.2772, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [37/375], Loss: 2.1964, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [38/375], Loss: 2.3463, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [39/375], Loss: 2.0736, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [40/375], Loss: 2.3551, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [41/375], Loss: 2.3520, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [42/375], Loss: 2.3834, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [43/375], Loss: 1.9924, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [44/375], Loss: 2.2071, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [45/375], Loss: 2.2247, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [46/375], Loss: 2.0777, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [47/375], Loss: 2.3390, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [48/375], Loss: 2.2048, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [49/375], Loss: 2.0234, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [50/375], Loss: 2.4248, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [51/375], Loss: 2.2645, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [52/375], Loss: 2.1560, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [53/375], Loss: 2.1854, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [54/375], Loss: 1.9425, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [38/50], Step [55/375], Loss: 2.1309, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [56/375], Loss: 2.2031, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [57/375], Loss: 2.2238, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [58/375], Loss: 2.1814, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [59/375], Loss: 2.0078, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [60/375], Loss: 2.4092, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [61/375], Loss: 2.2813, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [62/375], Loss: 2.2759, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [63/375], Loss: 2.3039, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [64/375], Loss: 2.3653, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [65/375], Loss: 2.1402, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [66/375], Loss: 2.0718, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [67/375], Loss: 2.1429, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [68/375], Loss: 2.2267, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [69/375], Loss: 2.2299, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [38/50], Step [70/375], Loss: 2.0192, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [71/375], Loss: 1.8001, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [72/375], Loss: 2.2041, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [73/375], Loss: 2.4518, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [38/50], Step [74/375], Loss: 2.2116, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [75/375], Loss: 2.2206, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [38/50], Step [76/375], Loss: 2.2124, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [38/50], Step [77/375], Loss: 2.0866, batch time: 0.35, accuracy:  37.50%\n",
      "Epoch [38/50], Step [78/375], Loss: 2.2836, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [38/50], Step [79/375], Loss: 2.5477, batch time: 0.32, accuracy:  0.00%\n",
      "Epoch [38/50], Step [80/375], Loss: 2.3814, batch time: 0.32, accuracy:  6.25%\n",
      "Epoch [38/50], Step [81/375], Loss: 2.0977, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [38/50], Step [82/375], Loss: 2.0901, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [38/50], Step [83/375], Loss: 2.4303, batch time: 0.33, accuracy:  6.25%\n",
      "Epoch [38/50], Step [84/375], Loss: 2.2295, batch time: 0.33, accuracy:  18.75%\n",
      "Epoch [38/50], Step [85/375], Loss: 2.2606, batch time: 0.35, accuracy:  18.75%\n",
      "Epoch [38/50], Step [86/375], Loss: 2.1085, batch time: 0.33, accuracy:  43.75%\n",
      "Epoch [38/50], Step [87/375], Loss: 2.1560, batch time: 0.31, accuracy:  25.00%\n",
      "Epoch [38/50], Step [88/375], Loss: 2.1767, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [38/50], Step [89/375], Loss: 2.4752, batch time: 0.34, accuracy:  12.50%\n",
      "Epoch [38/50], Step [90/375], Loss: 2.2081, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [38/50], Step [91/375], Loss: 2.3184, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [38/50], Step [92/375], Loss: 2.0335, batch time: 0.32, accuracy:  31.25%\n",
      "Epoch [38/50], Step [93/375], Loss: 2.2696, batch time: 0.35, accuracy:  25.00%\n",
      "Epoch [38/50], Step [94/375], Loss: 2.2261, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [38/50], Step [95/375], Loss: 2.1511, batch time: 0.33, accuracy:  25.00%\n",
      "Epoch [38/50], Step [96/375], Loss: 2.3478, batch time: 0.32, accuracy:  25.00%\n",
      "Epoch [38/50], Step [97/375], Loss: 2.3055, batch time: 0.33, accuracy:  12.50%\n",
      "Epoch [38/50], Step [98/375], Loss: 2.2118, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [38/50], Step [99/375], Loss: 2.0955, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [38/50], Step [100/375], Loss: 2.5220, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [38/50], Step [101/375], Loss: 2.4180, batch time: 0.36, accuracy:  12.50%\n",
      "Epoch [38/50], Step [102/375], Loss: 2.0340, batch time: 0.33, accuracy:  31.25%\n",
      "Epoch [38/50], Step [103/375], Loss: 2.1828, batch time: 0.32, accuracy:  12.50%\n",
      "Epoch [38/50], Step [104/375], Loss: 2.3067, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [38/50], Step [105/375], Loss: 2.0834, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [106/375], Loss: 2.1612, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [107/375], Loss: 2.2393, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [108/375], Loss: 2.1156, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [109/375], Loss: 2.2911, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [110/375], Loss: 2.1371, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [111/375], Loss: 2.2695, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [112/375], Loss: 2.0503, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [113/375], Loss: 2.2775, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [114/375], Loss: 2.4817, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [115/375], Loss: 2.3502, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [116/375], Loss: 2.3025, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [117/375], Loss: 2.4338, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [118/375], Loss: 2.3817, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [119/375], Loss: 2.4434, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [120/375], Loss: 2.2889, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [121/375], Loss: 2.3559, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [122/375], Loss: 2.1783, batch time: 0.87, accuracy:  18.75%\n",
      "Epoch [38/50], Step [123/375], Loss: 2.2683, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [124/375], Loss: 2.1800, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [125/375], Loss: 2.2144, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [38/50], Step [126/375], Loss: 2.3031, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [127/375], Loss: 2.2440, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [128/375], Loss: 2.3350, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [38/50], Step [129/375], Loss: 2.3731, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [38/50], Step [130/375], Loss: 2.1690, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [131/375], Loss: 2.2925, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [38/50], Step [132/375], Loss: 2.2356, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [133/375], Loss: 2.2833, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [134/375], Loss: 2.1717, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [135/375], Loss: 2.2916, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [136/375], Loss: 2.2201, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [137/375], Loss: 2.3354, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [138/375], Loss: 2.1827, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [139/375], Loss: 2.2804, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [140/375], Loss: 2.3003, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [141/375], Loss: 2.1872, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [142/375], Loss: 2.1358, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [143/375], Loss: 2.4065, batch time: 0.27, accuracy:  0.00%\n",
      "Epoch [38/50], Step [144/375], Loss: 2.2494, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [145/375], Loss: 2.2688, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [146/375], Loss: 2.3023, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [147/375], Loss: 2.2389, batch time: 0.27, accuracy:  6.25%\n",
      "Epoch [38/50], Step [148/375], Loss: 2.1012, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [149/375], Loss: 2.3254, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [38/50], Step [150/375], Loss: 2.1798, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [151/375], Loss: 2.0827, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [38/50], Step [152/375], Loss: 2.2590, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [153/375], Loss: 2.2567, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [154/375], Loss: 2.2230, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [155/375], Loss: 2.2341, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [156/375], Loss: 2.3466, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [157/375], Loss: 2.2103, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [158/375], Loss: 2.2139, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [159/375], Loss: 2.2555, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [160/375], Loss: 2.1365, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [161/375], Loss: 2.3064, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [162/375], Loss: 2.2206, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [163/375], Loss: 2.2455, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [38/50], Step [164/375], Loss: 2.0719, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [165/375], Loss: 2.0775, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [166/375], Loss: 2.1404, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [167/375], Loss: 2.3669, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [168/375], Loss: 2.2417, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [169/375], Loss: 2.3145, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [170/375], Loss: 2.1346, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [171/375], Loss: 2.2240, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [172/375], Loss: 2.2664, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [173/375], Loss: 2.0231, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [174/375], Loss: 2.2950, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [175/375], Loss: 2.3986, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [176/375], Loss: 2.1737, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [177/375], Loss: 2.2645, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [178/375], Loss: 2.1817, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [179/375], Loss: 2.2760, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [180/375], Loss: 2.3030, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [181/375], Loss: 2.3435, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [182/375], Loss: 2.3346, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [183/375], Loss: 2.1255, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [184/375], Loss: 2.2480, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [185/375], Loss: 2.2676, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [186/375], Loss: 2.2980, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [187/375], Loss: 2.4005, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [188/375], Loss: 2.3248, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [189/375], Loss: 2.2456, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [190/375], Loss: 2.1900, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [191/375], Loss: 2.2083, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [192/375], Loss: 2.2473, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [193/375], Loss: 2.4104, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [194/375], Loss: 2.1966, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [195/375], Loss: 2.2338, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [196/375], Loss: 2.1175, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [197/375], Loss: 2.4382, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [198/375], Loss: 2.4195, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [199/375], Loss: 2.4278, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [200/375], Loss: 2.2912, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [201/375], Loss: 2.3455, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [202/375], Loss: 2.0636, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [203/375], Loss: 2.2909, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [204/375], Loss: 2.2490, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [205/375], Loss: 2.2592, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [206/375], Loss: 2.3809, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [207/375], Loss: 2.2946, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [208/375], Loss: 2.1436, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [209/375], Loss: 2.1417, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [210/375], Loss: 2.3796, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [38/50], Step [211/375], Loss: 2.1647, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [212/375], Loss: 2.2379, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [213/375], Loss: 2.2734, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [214/375], Loss: 2.1459, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [38/50], Step [215/375], Loss: 2.0140, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [216/375], Loss: 2.1628, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [217/375], Loss: 2.2017, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [218/375], Loss: 2.2825, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [219/375], Loss: 2.2515, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [220/375], Loss: 2.2565, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [221/375], Loss: 2.0440, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [222/375], Loss: 2.3411, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [223/375], Loss: 2.2824, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [224/375], Loss: 2.2126, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [225/375], Loss: 2.1851, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [226/375], Loss: 2.0680, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [227/375], Loss: 2.2555, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [228/375], Loss: 2.2185, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [229/375], Loss: 2.2607, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [230/375], Loss: 2.0978, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [231/375], Loss: 2.2444, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [232/375], Loss: 2.1553, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [233/375], Loss: 2.1957, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [234/375], Loss: 2.1638, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [235/375], Loss: 2.3192, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [38/50], Step [236/375], Loss: 2.1224, batch time: 0.88, accuracy:  18.75%\n",
      "Epoch [38/50], Step [237/375], Loss: 2.1278, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [238/375], Loss: 2.1502, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [239/375], Loss: 2.2522, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [38/50], Step [240/375], Loss: 2.0554, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [241/375], Loss: 2.3257, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [242/375], Loss: 2.4840, batch time: 0.31, accuracy:  6.25%\n",
      "Epoch [38/50], Step [243/375], Loss: 2.0831, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [244/375], Loss: 2.1151, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [245/375], Loss: 2.2268, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [38/50], Step [246/375], Loss: 2.2435, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [247/375], Loss: 2.0631, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [38/50], Step [248/375], Loss: 2.2138, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [249/375], Loss: 2.4307, batch time: 0.29, accuracy:  12.50%\n",
      "Epoch [38/50], Step [250/375], Loss: 2.2980, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [251/375], Loss: 2.2315, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [252/375], Loss: 2.4039, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [253/375], Loss: 2.0648, batch time: 0.28, accuracy:  31.25%\n",
      "Epoch [38/50], Step [254/375], Loss: 2.3414, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [255/375], Loss: 2.1866, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [256/375], Loss: 2.1006, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [257/375], Loss: 2.1742, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [258/375], Loss: 2.1501, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [259/375], Loss: 2.3438, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [260/375], Loss: 2.2414, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [261/375], Loss: 2.2968, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [262/375], Loss: 2.2232, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [263/375], Loss: 2.2671, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [264/375], Loss: 2.2518, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [265/375], Loss: 2.0574, batch time: 0.27, accuracy:  43.75%\n",
      "Epoch [38/50], Step [266/375], Loss: 2.2896, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [267/375], Loss: 2.1855, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [268/375], Loss: 2.2560, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [269/375], Loss: 2.0046, batch time: 0.27, accuracy:  37.50%\n",
      "Epoch [38/50], Step [270/375], Loss: 2.3207, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [271/375], Loss: 2.3605, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [272/375], Loss: 2.3178, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [273/375], Loss: 2.3388, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [274/375], Loss: 2.2764, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [275/375], Loss: 2.1934, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [276/375], Loss: 2.0811, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [277/375], Loss: 2.2334, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [278/375], Loss: 2.1794, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [279/375], Loss: 2.2385, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [280/375], Loss: 2.3003, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [281/375], Loss: 2.2911, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [38/50], Step [282/375], Loss: 2.2382, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [283/375], Loss: 2.1515, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [284/375], Loss: 2.1813, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [285/375], Loss: 2.2940, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [286/375], Loss: 2.3558, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [287/375], Loss: 2.2509, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [288/375], Loss: 2.1707, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [289/375], Loss: 2.1344, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [38/50], Step [290/375], Loss: 2.0387, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [291/375], Loss: 2.1587, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [292/375], Loss: 1.9416, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [293/375], Loss: 2.3216, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [294/375], Loss: 2.2121, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [295/375], Loss: 2.3978, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [296/375], Loss: 2.3389, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [38/50], Step [297/375], Loss: 2.4139, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [38/50], Step [298/375], Loss: 2.2139, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [38/50], Step [299/375], Loss: 2.2853, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [300/375], Loss: 2.2368, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [301/375], Loss: 2.2165, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [38/50], Step [302/375], Loss: 2.3922, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [303/375], Loss: 2.1714, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [304/375], Loss: 2.3373, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [305/375], Loss: 2.2790, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [38/50], Step [306/375], Loss: 2.3184, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [38/50], Step [307/375], Loss: 2.2547, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [308/375], Loss: 2.2307, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [309/375], Loss: 2.2303, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [38/50], Step [310/375], Loss: 1.9728, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [311/375], Loss: 2.4127, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [312/375], Loss: 2.3716, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [313/375], Loss: 2.1532, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [38/50], Step [314/375], Loss: 2.3340, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [315/375], Loss: 2.3520, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [316/375], Loss: 2.1229, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [317/375], Loss: 2.2255, batch time: 0.28, accuracy:  25.00%\n",
      "Epoch [38/50], Step [318/375], Loss: 2.0705, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [319/375], Loss: 1.9396, batch time: 0.25, accuracy:  43.75%\n",
      "Epoch [38/50], Step [320/375], Loss: 2.3046, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [321/375], Loss: 2.0265, batch time: 0.34, accuracy:  31.25%\n",
      "Epoch [38/50], Step [322/375], Loss: 1.9506, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [323/375], Loss: 2.3851, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [324/375], Loss: 2.3010, batch time: 0.30, accuracy:  12.50%\n",
      "Epoch [38/50], Step [325/375], Loss: 2.1282, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [326/375], Loss: 2.1857, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [327/375], Loss: 2.3583, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [328/375], Loss: 2.0004, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [38/50], Step [329/375], Loss: 2.3373, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [330/375], Loss: 2.2836, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [331/375], Loss: 2.4190, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [332/375], Loss: 2.2973, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [333/375], Loss: 2.1438, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [334/375], Loss: 2.4297, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [335/375], Loss: 2.2466, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [336/375], Loss: 2.2766, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [38/50], Step [337/375], Loss: 2.0834, batch time: 0.26, accuracy:  31.25%\n",
      "Epoch [38/50], Step [338/375], Loss: 2.2642, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [339/375], Loss: 2.3391, batch time: 0.24, accuracy:  0.00%\n",
      "Epoch [38/50], Step [340/375], Loss: 2.2088, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [341/375], Loss: 2.1591, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [342/375], Loss: 2.3102, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [38/50], Step [343/375], Loss: 2.1849, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [344/375], Loss: 2.0159, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [38/50], Step [345/375], Loss: 2.2851, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [346/375], Loss: 2.1232, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [38/50], Step [347/375], Loss: 2.1586, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [38/50], Step [348/375], Loss: 2.4280, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [38/50], Step [349/375], Loss: 2.1695, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [38/50], Step [350/375], Loss: 2.1002, batch time: 0.89, accuracy:  31.25%\n",
      "Epoch [38/50], Step [351/375], Loss: 2.2035, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [352/375], Loss: 2.2152, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [353/375], Loss: 2.2671, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [38/50], Step [354/375], Loss: 2.4610, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [38/50], Step [355/375], Loss: 2.2481, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [356/375], Loss: 2.3091, batch time: 0.31, accuracy:  18.75%\n",
      "Epoch [38/50], Step [357/375], Loss: 2.2433, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [358/375], Loss: 2.1999, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [359/375], Loss: 2.2760, batch time: 0.32, accuracy:  18.75%\n",
      "Epoch [38/50], Step [360/375], Loss: 2.2274, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [361/375], Loss: 2.2916, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [362/375], Loss: 2.4173, batch time: 0.25, accuracy:  0.00%\n",
      "Epoch [38/50], Step [363/375], Loss: 2.4490, batch time: 0.28, accuracy:  6.25%\n",
      "Epoch [38/50], Step [364/375], Loss: 2.2825, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [365/375], Loss: 2.2943, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [366/375], Loss: 2.2228, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [367/375], Loss: 2.1402, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [38/50], Step [368/375], Loss: 2.3443, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [369/375], Loss: 2.2342, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [370/375], Loss: 2.0675, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [38/50], Step [371/375], Loss: 2.3852, batch time: 0.26, accuracy:  6.25%\n",
      "Epoch [38/50], Step [372/375], Loss: 2.2174, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [38/50], Step [373/375], Loss: 2.2486, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [38/50], Step [374/375], Loss: 2.1650, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [38/50], Step [375/375], Loss: 2.2431, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [1/375], Loss: 2.0515, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [2/375], Loss: 2.3945, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [39/50], Step [3/375], Loss: 2.1673, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [4/375], Loss: 2.4323, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [5/375], Loss: 2.0976, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [39/50], Step [6/375], Loss: 2.4214, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [7/375], Loss: 2.1547, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [39/50], Step [8/375], Loss: 2.1282, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [39/50], Step [9/375], Loss: 2.3560, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [10/375], Loss: 2.1342, batch time: 0.25, accuracy:  37.50%\n",
      "Epoch [39/50], Step [11/375], Loss: 2.2861, batch time: 0.28, accuracy:  18.75%\n",
      "Epoch [39/50], Step [12/375], Loss: 2.1545, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [39/50], Step [13/375], Loss: 2.2130, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [39/50], Step [14/375], Loss: 2.5183, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [15/375], Loss: 2.4148, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [16/375], Loss: 2.3871, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [17/375], Loss: 2.2963, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [18/375], Loss: 2.1962, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [19/375], Loss: 2.1876, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [20/375], Loss: 2.1632, batch time: 0.26, accuracy:  25.00%\n",
      "Epoch [39/50], Step [21/375], Loss: 1.9334, batch time: 0.25, accuracy:  50.00%\n",
      "Epoch [39/50], Step [22/375], Loss: 2.2804, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [23/375], Loss: 2.2997, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [24/375], Loss: 2.1470, batch time: 0.26, accuracy:  37.50%\n",
      "Epoch [39/50], Step [25/375], Loss: 2.3836, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [26/375], Loss: 2.2798, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [27/375], Loss: 2.4255, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [39/50], Step [28/375], Loss: 2.3364, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [29/375], Loss: 2.3108, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [39/50], Step [30/375], Loss: 2.4641, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [31/375], Loss: 2.3216, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [32/375], Loss: 2.2399, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [33/375], Loss: 2.3211, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [34/375], Loss: 2.3044, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [35/375], Loss: 2.2842, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [36/375], Loss: 2.1966, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [39/50], Step [37/375], Loss: 2.1886, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [39/50], Step [38/375], Loss: 2.3585, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [39/375], Loss: 2.2669, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [40/375], Loss: 2.2498, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [39/50], Step [41/375], Loss: 2.2136, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [39/50], Step [42/375], Loss: 2.3081, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [43/375], Loss: 2.3149, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [39/50], Step [44/375], Loss: 2.1292, batch time: 0.27, accuracy:  25.00%\n",
      "Epoch [39/50], Step [45/375], Loss: 2.1836, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [39/50], Step [46/375], Loss: 2.1831, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [47/375], Loss: 2.2171, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [39/50], Step [48/375], Loss: 2.2352, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [49/375], Loss: 2.2510, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [50/375], Loss: 2.1464, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [39/50], Step [51/375], Loss: 2.2644, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [52/375], Loss: 2.2381, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [39/50], Step [53/375], Loss: 2.0680, batch time: 0.24, accuracy:  37.50%\n",
      "Epoch [39/50], Step [54/375], Loss: 2.1185, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [55/375], Loss: 2.2248, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [56/375], Loss: 2.3940, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [39/50], Step [57/375], Loss: 2.3627, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [58/375], Loss: 2.3441, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [59/375], Loss: 2.2621, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [60/375], Loss: 2.1701, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [39/50], Step [61/375], Loss: 2.3127, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [62/375], Loss: 2.2762, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [63/375], Loss: 2.2724, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [64/375], Loss: 2.3071, batch time: 0.27, accuracy:  18.75%\n",
      "Epoch [39/50], Step [65/375], Loss: 2.0942, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [66/375], Loss: 2.2678, batch time: 0.24, accuracy:  12.50%\n",
      "Epoch [39/50], Step [67/375], Loss: 2.1752, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [68/375], Loss: 2.2791, batch time: 0.26, accuracy:  12.50%\n",
      "Epoch [39/50], Step [69/375], Loss: 2.2471, batch time: 0.24, accuracy:  25.00%\n",
      "Epoch [39/50], Step [70/375], Loss: 2.3071, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [71/375], Loss: 2.2897, batch time: 0.24, accuracy:  6.25%\n",
      "Epoch [39/50], Step [72/375], Loss: 2.3121, batch time: 0.27, accuracy:  12.50%\n",
      "Epoch [39/50], Step [73/375], Loss: 2.2071, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [39/50], Step [74/375], Loss: 1.9746, batch time: 0.24, accuracy:  43.75%\n",
      "Epoch [39/50], Step [75/375], Loss: 2.1768, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [76/375], Loss: 2.2304, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [39/50], Step [77/375], Loss: 2.3083, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [78/375], Loss: 2.2071, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [79/375], Loss: 2.3224, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [80/375], Loss: 2.1125, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [39/50], Step [81/375], Loss: 2.1519, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [82/375], Loss: 2.3341, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [83/375], Loss: 2.3088, batch time: 0.24, accuracy:  18.75%\n",
      "Epoch [39/50], Step [84/375], Loss: 2.1818, batch time: 0.26, accuracy:  18.75%\n",
      "Epoch [39/50], Step [85/375], Loss: 1.9415, batch time: 0.24, accuracy:  50.00%\n",
      "Epoch [39/50], Step [86/375], Loss: 2.1941, batch time: 0.24, accuracy:  31.25%\n",
      "Epoch [39/50], Step [87/375], Loss: 2.4011, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [88/375], Loss: 2.0643, batch time: 0.27, accuracy:  31.25%\n",
      "Epoch [39/50], Step [89/375], Loss: 2.0934, batch time: 0.93, accuracy:  37.50%\n",
      "Epoch [39/50], Step [90/375], Loss: 2.1472, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [91/375], Loss: 2.0986, batch time: 0.25, accuracy:  31.25%\n",
      "Epoch [39/50], Step [92/375], Loss: 2.1091, batch time: 0.30, accuracy:  18.75%\n",
      "Epoch [39/50], Step [93/375], Loss: 2.2257, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [94/375], Loss: 2.3657, batch time: 0.25, accuracy:  12.50%\n",
      "Epoch [39/50], Step [95/375], Loss: 2.2776, batch time: 0.30, accuracy:  6.25%\n",
      "Epoch [39/50], Step [96/375], Loss: 2.3438, batch time: 0.25, accuracy:  6.25%\n",
      "Epoch [39/50], Step [97/375], Loss: 2.1638, batch time: 0.25, accuracy:  18.75%\n",
      "Epoch [39/50], Step [98/375], Loss: 1.9869, batch time: 0.31, accuracy:  31.25%\n",
      "Epoch [39/50], Step [99/375], Loss: 2.1691, batch time: 0.25, accuracy:  25.00%\n",
      "Epoch [39/50], Step [100/375], Loss: 2.1066, batch time: 0.24, accuracy:  18.75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    qt_model.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = qt_model(images)\n",
    "        # print(\"output: \", outputs)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "        # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "        if acc > acc_best:\n",
    "            # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "            acc_best = acc\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if (i+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
