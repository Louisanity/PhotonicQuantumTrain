{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.942335</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.993413</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.301314</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.825884</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.143926</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.906996</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.001541</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.411813</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.798957</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.018237</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.242693</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.163481</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.863586</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.902149</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.117836</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.561212</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.49414</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.981106</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.065864</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.169697</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.876079</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.164292</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.613595</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.946931</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.02749</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.640375</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.801993</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.045401</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.458969</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.320526</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.735409</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.963043</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.216693</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.806018</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.436825</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.524651</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.456699</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.466706</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.754804</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.505321</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.741713</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.175182</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.00193</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.829364</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.755626</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.988841</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.018556</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.03991</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.845032</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.601785</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.518</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.23874</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.480179</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.378174</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.983899</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.823184</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.181418</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.224846</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.510504</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.631457</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.749812</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.233513</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.415103</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.001949</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.879291</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.661919</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.074134</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.73447</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.704348</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.340848</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.36004</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.639022</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.37934</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.287699</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.775126</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.256963</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.383586</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.038099</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.049378</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.515036</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.737976</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.873562</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.763749</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.528668</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.035581</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.197777</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.23338</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.332831</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.254273</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.775685</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.743578</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.11051</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.176875</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.408925</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.237597</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.852071</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7fa3c37bf4f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.659203</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.694688</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.785464</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.227094</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.586423</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.508663</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.570847</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.924351</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.582954</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.51861</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.145539</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.084654</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.749731</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.950987</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.320039</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.138495</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.801236</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.202512</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.511403</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.910503</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.354068</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.889547</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.456218</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.598409</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.652099</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.921539</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.745798</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.872684</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.816917</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.916795</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.532604</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.218469</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.650148</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.101286</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.956331</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.212883</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.332062</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.388022</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.821397</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.100474</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.105222</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.766316</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.515287</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.306492</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.87445</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.242607</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.86551</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.660918</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.346821</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.389261</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.74962</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.001921</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.076362</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.023303</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.986614</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.577242</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.372345</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.505838</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.169657</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.626198</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.140036</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.340413</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.197688</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.624527</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.184369</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.421258</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.220064</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.495268</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.924567</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.561501</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.529491</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.029025</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.193054</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.795366</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.135952</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7fa3c36d6880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 75.33%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=7)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  1519\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  1711\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2622, batch time: 0.11, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 1.9980, batch time: 0.13, accuracy:  27.34%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 1.5296, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.3163, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.1392, batch time: 0.04, accuracy:  69.53%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.2680, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.2656, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.0781, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 0.9909, batch time: 0.10, accuracy:  71.88%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 1.2011, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 0.9650771617889404, accuracy: 69.6 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 0.9848008155822754, accuracy: 67.4 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.006636619567871, accuracy: 67.2 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 0.9274880290031433, accuracy: 70.5 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 0.9566444754600525, accuracy: 69.8 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.1211920976638794, accuracy: 62.8 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 0.964479386806488, accuracy: 68.9 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 0.996874988079071, accuracy: 65.9 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.2734968662261963, accuracy: 55.2 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 0.8958296179771423, accuracy: 70.0 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 0.8215, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 0.7739, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.9709, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.7259, batch time: 0.05, accuracy:  67.97%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.7663, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.7550, batch time: 0.05, accuracy:  71.09%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.8198, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.7517, batch time: 0.06, accuracy:  72.66%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.6347, batch time: 0.10, accuracy:  83.59%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.7008, batch time: 0.11, accuracy:  77.34%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.6268506646156311, accuracy: 81.3 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.660444438457489, accuracy: 79.1 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.6447492837905884, accuracy: 79.7 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.5896208882331848, accuracy: 82.7 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.5796836018562317, accuracy: 83.0 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.5736142992973328, accuracy: 80.9 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.6077102422714233, accuracy: 80.6 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.5629313588142395, accuracy: 82.4 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.569424569606781, accuracy: 82.4 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.5932027697563171, accuracy: 81.3 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.6674, batch time: 0.10, accuracy:  82.03%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.7223, batch time: 0.04, accuracy:  79.69%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.6084, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.6978, batch time: 0.04, accuracy:  76.56%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.6099, batch time: 0.04, accuracy:  81.25%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.5302, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.8340, batch time: 0.10, accuracy:  75.78%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.6265, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.5173, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.6655, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.5148552656173706, accuracy: 84.0 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 0.5158447027206421, accuracy: 84.2 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.5431205630302429, accuracy: 83.1 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.5079792141914368, accuracy: 83.8 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.5364031791687012, accuracy: 82.6 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.5018486380577087, accuracy: 84.4 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.4992164969444275, accuracy: 84.8 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.4916425943374634, accuracy: 84.7 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.4872158169746399, accuracy: 85.1 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.48716703057289124, accuracy: 85.2 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.7875, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.6338, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.6831, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.3305, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.5545, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.5336, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.6252, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.5155, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.5369, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.3654, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.5024932026863098, accuracy: 85.3 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 1.2089625597000122, accuracy: 64.4 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.5920557975769043, accuracy: 83.2 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.45482632517814636, accuracy: 87.6 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.44379371404647827, accuracy: 88.1 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.4401914179325104, accuracy: 88.1 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.44309014081954956, accuracy: 87.6 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.4443102478981018, accuracy: 86.8 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.4358530640602112, accuracy: 88.2 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.43210530281066895, accuracy: 88.7 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.5585, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.3191, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.4931, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.2923, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.5655, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.3272, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.4604, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.5113, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.5438, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.3173, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.3579760193824768, accuracy: 87.8 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 0.3879522979259491, accuracy: 88.2 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.35443782806396484, accuracy: 88.8 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.3537391722202301, accuracy: 88.9 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.37130114436149597, accuracy: 88.8 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.34552717208862305, accuracy: 88.9 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.3461925685405731, accuracy: 89.3 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.3429240882396698, accuracy: 88.5 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.3763088583946228, accuracy: 88.4 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.3479228913784027, accuracy: 88.4 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.3414, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.4324, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.2799, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.3530, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.2068, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.3841, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.3571, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.3201, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.3189, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.1611, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.346925288438797, accuracy: 90.2 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.3947792947292328, accuracy: 89.4 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.3337860703468323, accuracy: 90.8 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.33138808608055115, accuracy: 90.7 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.34915074706077576, accuracy: 89.3 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.40015050768852234, accuracy: 87.8 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.3107057213783264, accuracy: 91.1 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.29462406039237976, accuracy: 91.5 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.2986172139644623, accuracy: 91.0 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.30571821331977844, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.2537, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.4311, batch time: 0.04, accuracy:  85.94%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.3018, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.3117, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.4267, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.3367, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.4268, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.2571, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3430, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.2562, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.287028968334198, accuracy: 90.8 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 6.049489974975586, accuracy: 26.5 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.27754002809524536, accuracy: 91.2 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.27749815583229065, accuracy: 91.2 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.27636706829071045, accuracy: 91.3 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.2798824906349182, accuracy: 91.6 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.28218990564346313, accuracy: 90.8 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.2826702296733856, accuracy: 91.5 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.2719433009624481, accuracy: 91.4 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.26801037788391113, accuracy: 91.3 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.2870, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.3226, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.2351, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.4346, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.3253, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.3586, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.2850, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.6005, batch time: 0.11, accuracy:  78.91%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.2516, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2949, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.25199344754219055, accuracy: 91.2 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.31118953227996826, accuracy: 88.5 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.3292125463485718, accuracy: 90.4 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.27399688959121704, accuracy: 91.2 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.24198728799819946, accuracy: 92.4 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.2375638335943222, accuracy: 92.3 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.24015362560749054, accuracy: 92.2 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.23607027530670166, accuracy: 91.9 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.23598676919937134, accuracy: 91.9 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.2353794276714325, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.4515, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.3117, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.4380, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.2107, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.4342, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.3115, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.2777, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.2783, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.2015, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.2755, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.30521219968795776, accuracy: 91.5 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 3.4620730876922607, accuracy: 48.5 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.2971247732639313, accuracy: 91.9 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.2971247732639313, accuracy: 91.9 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.4311601519584656, accuracy: 88.3 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.2906774878501892, accuracy: 91.9 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.2885928452014923, accuracy: 92.2 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.2851330041885376, accuracy: 92.0 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.2864832878112793, accuracy: 92.6 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.2829132378101349, accuracy: 92.2 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.5790, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.1688, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.5290, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.3109, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.2853, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.3487, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.5724, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.3625, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.3389, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.4114, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.2581331431865692, accuracy: 92.0 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.27569714188575745, accuracy: 91.6 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.28441956639289856, accuracy: 91.3 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.25120341777801514, accuracy: 93.5 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.3004317879676819, accuracy: 91.2 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.4339463710784912, accuracy: 86.8 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.482629656791687, accuracy: 85.6 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.2396460622549057, accuracy: 93.9 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.2378971129655838, accuracy: 93.8 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.23988685011863708, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.2508, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.2603, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.2602, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.3936, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.1713, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.2571, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.2516, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.3181, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.1924, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.3227, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.2529168128967285, accuracy: 91.7 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.36182987689971924, accuracy: 88.9 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.2716955542564392, accuracy: 91.9 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.27645358443260193, accuracy: 91.3 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.24146142601966858, accuracy: 93.3 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.2868870198726654, accuracy: 92.0 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.27566373348236084, accuracy: 91.2 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.3492773473262787, accuracy: 90.2 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.2636823356151581, accuracy: 91.7 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.25982335209846497, accuracy: 91.9 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.3066, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.2052, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.2604, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.2161, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.3571, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.2115, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.2268, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.2648, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.2506, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.2124, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.23050780594348907, accuracy: 94.0 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.290445476770401, accuracy: 91.4 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.23459260165691376, accuracy: 93.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.2505539059638977, accuracy: 92.8 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.21592596173286438, accuracy: 94.3 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.21075493097305298, accuracy: 93.9 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.2133934646844864, accuracy: 94.1 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.21095360815525055, accuracy: 94.5 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.2167600393295288, accuracy: 93.8 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.2086234986782074, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.1715, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2399, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.2766, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.2453, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.3148, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.3833, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.2098, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.2598, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.2697, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.2271, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.22848264873027802, accuracy: 92.8 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.3229939043521881, accuracy: 90.8 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.2655031681060791, accuracy: 92.1 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.26377564668655396, accuracy: 92.1 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.21484750509262085, accuracy: 93.4 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.21209324896335602, accuracy: 93.5 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.2131156176328659, accuracy: 93.4 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.2093036025762558, accuracy: 93.5 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.20987173914909363, accuracy: 93.7 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.2086719274520874, accuracy: 93.5 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.2466, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.2013, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.2367, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.2063, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.2415, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.2476, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.3307, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.1482, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.2240, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.2686, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.2243395447731018, accuracy: 93.9 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.2227025032043457, accuracy: 93.5 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.24564625322818756, accuracy: 92.2 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.20845267176628113, accuracy: 93.9 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.28377804160118103, accuracy: 90.5 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.20047612488269806, accuracy: 94.4 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.29008597135543823, accuracy: 90.8 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.39595460891723633, accuracy: 89.5 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.2435770481824875, accuracy: 93.2 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.18868660926818848, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.1887, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.4512, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.1881, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.3141, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.1899, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.2810, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.2305, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.2364, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.2364, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.2051, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.17347021400928497, accuracy: 94.6 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.18349745869636536, accuracy: 94.4 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.2129867821931839, accuracy: 94.4 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.1637592762708664, accuracy: 95.9 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.17243969440460205, accuracy: 94.7 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.1535184681415558, accuracy: 95.8 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.14982548356056213, accuracy: 95.6 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.148525670170784, accuracy: 95.6 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.14779479801654816, accuracy: 96.0 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.14513100683689117, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.4638, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.2052, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.1931, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.2405, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.2043, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.1777, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.2064, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.1458, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.2252, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.1595, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.20054420828819275, accuracy: 93.8 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.2025938630104065, accuracy: 93.8 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.19846804440021515, accuracy: 93.1 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.18177808821201324, accuracy: 94.9 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.1879042685031891, accuracy: 94.6 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.17424824833869934, accuracy: 95.0 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.17108047008514404, accuracy: 95.4 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.16883276402950287, accuracy: 95.3 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.16703416407108307, accuracy: 95.7 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.16525675356388092, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.2124, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.1707, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.2703, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.2133, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.2686, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.2931, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.2169, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.1125, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.1905, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.1591, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.21572370827198029, accuracy: 92.8 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.21306107938289642, accuracy: 93.0 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.2265896499156952, accuracy: 92.9 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.19366861879825592, accuracy: 94.0 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.23492330312728882, accuracy: 92.5 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.17801786959171295, accuracy: 94.5 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.17220976948738098, accuracy: 94.4 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.17005205154418945, accuracy: 94.6 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.16648130118846893, accuracy: 94.5 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.16675864160060883, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.1517, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.2975, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.1828, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.2027, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.1227, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.1852, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.1322, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.2349, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.1867, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.1425, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.1528499871492386, accuracy: 95.4 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.15611030161380768, accuracy: 95.1 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.17820358276367188, accuracy: 94.4 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.20389807224273682, accuracy: 93.3 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.14394348859786987, accuracy: 95.6 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.1387629359960556, accuracy: 96.4 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.13810864090919495, accuracy: 96.4 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.1345166563987732, accuracy: 96.0 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.1356421411037445, accuracy: 95.8 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.13451112806797028, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.0891, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.1423, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.3067, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.3546, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.2830, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.2265, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.1978, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.2896, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.1800, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.0940, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.16282616555690765, accuracy: 95.5 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.16747960448265076, accuracy: 95.3 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.16970553994178772, accuracy: 95.0 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.16082915663719177, accuracy: 95.5 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.16429691016674042, accuracy: 95.0 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.1502901315689087, accuracy: 95.6 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.14842352271080017, accuracy: 95.7 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.1467675119638443, accuracy: 95.8 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.14658679068088531, accuracy: 96.0 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.1473206877708435, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.1956, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.1570, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.2908, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.1658, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.1633, batch time: 0.29, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.1934, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.2466, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.2531, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.2974, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.2387, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.1673913598060608, accuracy: 94.6 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.634466290473938, accuracy: 83.6 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.15387210249900818, accuracy: 94.9 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.1792743057012558, accuracy: 94.6 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.18694952130317688, accuracy: 93.8 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.15976832807064056, accuracy: 94.9 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.17350630462169647, accuracy: 94.0 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.14157120883464813, accuracy: 95.5 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.14078696072101593, accuracy: 95.6 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.13938800990581512, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.2162, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.1020, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.1111, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.1498, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.2170, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.1623, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.1382, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.2274, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.2567, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.1979, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.19141465425491333, accuracy: 94.0 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.1923242211341858, accuracy: 94.3 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.18688054382801056, accuracy: 93.6 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.18405495584011078, accuracy: 93.7 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.18224848806858063, accuracy: 93.7 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.17894567549228668, accuracy: 93.4 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.18142899870872498, accuracy: 93.3 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.17643168568611145, accuracy: 93.8 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.17376555502414703, accuracy: 94.1 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.17134755849838257, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.1573, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.1235, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.2679, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.1757, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.2862, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.2079, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.2108, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.2078, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.1608, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.2063, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.17714042961597443, accuracy: 94.4 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.17154261469841003, accuracy: 94.3 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.18734309077262878, accuracy: 93.5 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.1646489053964615, accuracy: 94.5 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.17762288451194763, accuracy: 94.2 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.24208569526672363, accuracy: 92.1 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.3186202049255371, accuracy: 89.5 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.21194523572921753, accuracy: 93.0 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.18060724437236786, accuracy: 94.1 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.18047329783439636, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.1358, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.0807, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.1769, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.1029, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.1094, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.1093, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.1559, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.1654, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.2052, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.1695, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.13079407811164856, accuracy: 95.1 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 0.14770172536373138, accuracy: 94.9 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.13103163242340088, accuracy: 95.6 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.12506605684757233, accuracy: 95.4 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.176272913813591, accuracy: 93.5 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.12196057289838791, accuracy: 95.8 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.11842729896306992, accuracy: 95.8 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.11606276780366898, accuracy: 96.0 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.1156228557229042, accuracy: 96.3 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.11566952615976334, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.2425, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.1583, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.1840, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.1936, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.0869, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1686, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.1011, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.1719, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.2151, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.2850, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.14188164472579956, accuracy: 96.1 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.15635496377944946, accuracy: 94.9 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.24054674804210663, accuracy: 92.2 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.20268703997135162, accuracy: 95.1 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.13591423630714417, accuracy: 96.5 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.12346742302179337, accuracy: 96.3 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.12398149073123932, accuracy: 96.6 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.12277201563119888, accuracy: 96.5 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.12553969025611877, accuracy: 96.3 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.12130533158779144, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.1785, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.1621, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.1210, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.1124, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.2497, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.2424, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.1142, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.1171, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.2227, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.1498, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.20736806094646454, accuracy: 93.9 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.26578471064567566, accuracy: 92.6 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.1961427628993988, accuracy: 93.7 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.2536561191082001, accuracy: 91.7 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.20081375539302826, accuracy: 94.6 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.176080584526062, accuracy: 94.9 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.17481380701065063, accuracy: 95.1 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.17037136852741241, accuracy: 95.5 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.17028211057186127, accuracy: 95.4 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.1677285134792328, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.1216, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.0894, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.0898, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.2875, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.2101, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.2075, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.2022, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.1537, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.1781, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.1646, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.10753858089447021, accuracy: 96.3 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.14856816828250885, accuracy: 94.9 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.16335029900074005, accuracy: 94.9 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.1308777779340744, accuracy: 95.6 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.10063398629426956, accuracy: 97.0 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.0974283441901207, accuracy: 97.0 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.09811253845691681, accuracy: 96.8 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.0994141697883606, accuracy: 97.0 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.09540105611085892, accuracy: 97.0 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.09406467527151108, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.1005, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.2499, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.1647, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.1769, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.1189, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.2548, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.1724, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.1418, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.1543, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.1495, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.14102748036384583, accuracy: 96.1 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.17642483115196228, accuracy: 94.8 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.2041047215461731, accuracy: 93.8 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.13553690910339355, accuracy: 96.0 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.12472464889287949, accuracy: 97.0 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.12193205952644348, accuracy: 96.8 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.12382122129201889, accuracy: 96.9 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.12020405381917953, accuracy: 96.9 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.11884084343910217, accuracy: 96.9 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.11862441897392273, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.2595, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.2153, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.0785, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.0686, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.2687, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.0905, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.2226, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.1107, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.1374, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.2436, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.18835873901844025, accuracy: 94.3 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.6532657146453857, accuracy: 81.7 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.1767035871744156, accuracy: 94.1 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.17663365602493286, accuracy: 94.2 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.21736134588718414, accuracy: 93.7 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.17331859469413757, accuracy: 94.1 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.16647875308990479, accuracy: 94.9 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.16466088593006134, accuracy: 94.8 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.16381800174713135, accuracy: 94.8 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.16329671442508698, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.0949, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.0899, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.1209, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.1872, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.0599, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.0915, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.0948, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.2223, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.1466, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.1110, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.09217461198568344, accuracy: 96.7 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 0.6918860077857971, accuracy: 83.3 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.10177003592252731, accuracy: 96.2 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.17521415650844574, accuracy: 93.4 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.1045059859752655, accuracy: 95.6 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.09281755983829498, accuracy: 96.3 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.09451547265052795, accuracy: 96.7 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.0805000513792038, accuracy: 96.9 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.0722244530916214, accuracy: 97.2 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.07098161429166794, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.0914, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.1287, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.1673, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.1236, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.2137, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.1587, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.1695, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.2456, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.2759, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.1510, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.13847824931144714, accuracy: 96.0 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.13288019597530365, accuracy: 96.1 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.15290693938732147, accuracy: 95.3 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.12957808375358582, accuracy: 95.8 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.13645631074905396, accuracy: 95.7 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.16248846054077148, accuracy: 94.7 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.13204754889011383, accuracy: 96.0 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.1314578801393509, accuracy: 95.6 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.14922401309013367, accuracy: 94.5 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.13617314398288727, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.1798, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.1589, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.1597, batch time: 0.07, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.1482, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.1073, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.0622, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.1520, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.0868, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.1486, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.2353, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.09535692632198334, accuracy: 96.7 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.15427963435649872, accuracy: 95.1 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.10041527450084686, accuracy: 96.9 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.10112106800079346, accuracy: 97.0 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.08503450453281403, accuracy: 97.4 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.08474816381931305, accuracy: 97.0 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.08066096156835556, accuracy: 97.3 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.0792374536395073, accuracy: 97.6 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.07795684784650803, accuracy: 97.3 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.07740376144647598, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.1377, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.1248, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.1892, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.1804, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.0731, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.1115, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.0895, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.1365, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.1479, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.1638, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.14674830436706543, accuracy: 95.0 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.14762301743030548, accuracy: 94.7 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.13821837306022644, accuracy: 95.9 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.13088107109069824, accuracy: 95.6 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.21712176501750946, accuracy: 91.2 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.11842067539691925, accuracy: 96.5 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.11499719321727753, accuracy: 96.1 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.10679499804973602, accuracy: 96.6 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.10694321990013123, accuracy: 96.9 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.10292579233646393, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.2282, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.0997, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.0668, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.2758, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.0842, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.0577, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.1754, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.1135, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.1496, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.11236545443534851, accuracy: 96.5 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.12044847011566162, accuracy: 96.3 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.1493871659040451, accuracy: 94.6 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.16465725004673004, accuracy: 94.6 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.10081619769334793, accuracy: 97.0 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.09970112144947052, accuracy: 96.9 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.09641266614198685, accuracy: 97.0 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.09605234116315842, accuracy: 96.8 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.09847212582826614, accuracy: 96.6 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.09739895164966583, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.1264, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.1043, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.2986, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.0961, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.1411, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.1771, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.1996, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.1759, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.1342, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.1595, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.13511520624160767, accuracy: 95.7 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.14401941001415253, accuracy: 95.1 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.14367714524269104, accuracy: 95.5 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.1282716542482376, accuracy: 96.3 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.15170440077781677, accuracy: 94.9 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.12105292081832886, accuracy: 96.7 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.11808092892169952, accuracy: 96.7 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.11454364657402039, accuracy: 96.6 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.11730685085058212, accuracy: 96.1 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.11763154715299606, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.0609, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.1940, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.1413, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.1396, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.0595, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.1463, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.1146, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.1270, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.1038, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.2363, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.11824709177017212, accuracy: 95.8 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.18665416538715363, accuracy: 92.6 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.21011267602443695, accuracy: 92.3 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.10719332098960876, accuracy: 96.2 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.10173220932483673, accuracy: 96.5 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.10103414952754974, accuracy: 96.5 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.09755491465330124, accuracy: 96.6 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.0965217798948288, accuracy: 97.0 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.09302214533090591, accuracy: 97.0 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.09600325673818588, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.1556, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.2973, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.1701, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.0995, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.1324, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.1452, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.1429, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.1516, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.1408, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.0902, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.13459603488445282, accuracy: 95.5 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.13646312057971954, accuracy: 95.4 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.1288248747587204, accuracy: 95.8 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.1266830414533615, accuracy: 96.1 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.11719416826963425, accuracy: 96.3 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.11375503987073898, accuracy: 96.8 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.11309962719678879, accuracy: 96.7 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.1112404316663742, accuracy: 97.0 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.11159314215183258, accuracy: 96.5 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.10854952782392502, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.1339, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.0659, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.2412, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.1781, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.0535, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.0567, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.1392, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.1886, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.1689, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.2205, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.12481819093227386, accuracy: 95.6 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.14912526309490204, accuracy: 95.9 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.1700533628463745, accuracy: 94.4 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.1232430711388588, accuracy: 96.2 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.11078811436891556, accuracy: 96.8 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.09902536869049072, accuracy: 97.0 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.0984916165471077, accuracy: 97.1 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.0935916006565094, accuracy: 97.3 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.09065916389226913, accuracy: 97.5 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.09229353070259094, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.1014, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.0520, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.1284, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.1596, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.1149, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.1080, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.1610, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.0879, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.1706, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.1208, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.11887582391500473, accuracy: 96.1 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.14443263411521912, accuracy: 95.4 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.11660496890544891, accuracy: 95.8 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.17289109528064728, accuracy: 93.1 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.13618135452270508, accuracy: 95.1 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.09923968464136124, accuracy: 96.3 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.0961986854672432, accuracy: 96.7 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.09438662976026535, accuracy: 97.1 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.09593961387872696, accuracy: 96.2 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.09362269937992096, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.2045, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.1955, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.2565, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.3016, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.0979, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.1184, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.0807, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.0840, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.2046, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.1509, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.1461939811706543, accuracy: 95.7 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.1550895720720291, accuracy: 95.3 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.2453370988368988, accuracy: 92.2 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.20180802047252655, accuracy: 93.0 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.15486297011375427, accuracy: 95.1 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.1257849782705307, accuracy: 96.4 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.125443235039711, accuracy: 96.3 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.1220448911190033, accuracy: 96.2 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.12368565052747726, accuracy: 96.1 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.12358373403549194, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.0947, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.1264, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.0715, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.0828, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.1092, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.1348, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.1459, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.1341, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.0938, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.1201, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.12820115685462952, accuracy: 95.7 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.14953921735286713, accuracy: 95.2 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.14326906204223633, accuracy: 95.6 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.14225105941295624, accuracy: 95.2 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.10362498462200165, accuracy: 97.0 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.10097827762365341, accuracy: 96.6 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.10077987611293793, accuracy: 96.5 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.0985988900065422, accuracy: 96.8 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.09852445870637894, accuracy: 96.4 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.10021516680717468, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.1978, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.1896, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.1022, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.2481, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.0418, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.0966, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.0616, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.1293, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.1930, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.1443, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.12882938981056213, accuracy: 96.0 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.13949152827262878, accuracy: 94.9 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.13116958737373352, accuracy: 96.0 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.15767373144626617, accuracy: 94.8 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.12084261327981949, accuracy: 96.3 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.11446504294872284, accuracy: 96.4 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.11550085991621017, accuracy: 96.2 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.11144654452800751, accuracy: 96.3 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.11130856722593307, accuracy: 96.1 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.11379637569189072, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.2319, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.2117, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.0511, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.1797, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.1347, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.0855, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.0742, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.1080, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.1213, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.0962, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.122762031853199, accuracy: 95.7 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.12250294536352158, accuracy: 95.3 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.1098877564072609, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.1098877564072609, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.186336487531662, accuracy: 93.8 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.103348009288311, accuracy: 96.8 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.10424991697072983, accuracy: 96.7 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.09867114573717117, accuracy: 97.0 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.10043563693761826, accuracy: 96.7 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.09665384143590927, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.1127, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.0818, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.1006, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.1421, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.1362, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.1660, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.2035, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.1168, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.0836, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.2645, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.1261424422264099, accuracy: 95.8 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.12275499850511551, accuracy: 95.7 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.12822642922401428, accuracy: 95.8 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.12966717779636383, accuracy: 95.2 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.1083768978714943, accuracy: 96.2 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.10646972060203552, accuracy: 96.1 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.1108669713139534, accuracy: 95.9 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.10477501899003983, accuracy: 96.2 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.10341519862413406, accuracy: 96.5 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.10290264338254929, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.1278, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.1371, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.1138, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.2047, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.1017, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.0632, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.1236, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.1851, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.0463, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.1655, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.09534327685832977, accuracy: 96.6 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.11734703928232193, accuracy: 96.4 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.09923761337995529, accuracy: 96.2 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.09111811220645905, accuracy: 96.7 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.08533068746328354, accuracy: 97.1 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.08274846524000168, accuracy: 97.1 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.08327235281467438, accuracy: 96.7 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.08483976870775223, accuracy: 96.9 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.08097686618566513, accuracy: 97.2 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.07943254709243774, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.2762, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.1830, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.1157, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.1579, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.0540, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.1731, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.0822, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.0916, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.0524, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.0856, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.1316070854663849, accuracy: 95.8 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.14473047852516174, accuracy: 95.6 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.11892811954021454, accuracy: 95.6 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.13950161635875702, accuracy: 95.0 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.21425683796405792, accuracy: 93.2 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.10507716238498688, accuracy: 96.5 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.10012489557266235, accuracy: 96.7 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.10959119349718094, accuracy: 96.2 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.09695006906986237, accuracy: 96.7 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.09716949611902237, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.0953, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.2210, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.0914, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.0576, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.0358, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.1225, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.1297, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.1477, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.0723, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.12638451159000397, accuracy: 95.2 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.13150490820407867, accuracy: 95.3 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.12813623249530792, accuracy: 95.3 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.12169909477233887, accuracy: 95.3 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.11194402724504471, accuracy: 96.1 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.11042077094316483, accuracy: 95.7 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.11042856425046921, accuracy: 95.9 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.10834495723247528, accuracy: 96.0 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.108048215508461, accuracy: 96.1 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.1065140888094902, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.0944, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.1744, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.1555, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.1735, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.1474, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.2402, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.0579, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.0988, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.1173, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.0661, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.09670092165470123, accuracy: 96.7 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.11576783657073975, accuracy: 96.2 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.16362406313419342, accuracy: 93.5 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.1638048142194748, accuracy: 93.8 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.0895136296749115, accuracy: 96.8 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.08372533321380615, accuracy: 96.9 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.08400991559028625, accuracy: 97.2 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.0799601748585701, accuracy: 97.2 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.08553846180438995, accuracy: 97.3 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.07822200655937195, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.1485, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.1150, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.1697, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.1290, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.0987, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1958, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.0974, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.0747, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.1608, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.0634, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.10047928988933563, accuracy: 96.6 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 0.10048487037420273, accuracy: 96.3 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.1423855870962143, accuracy: 94.7 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.1168200820684433, accuracy: 95.7 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.15089301764965057, accuracy: 94.4 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.10317488759756088, accuracy: 96.3 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.0800311490893364, accuracy: 96.8 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.07770004123449326, accuracy: 96.9 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.07700523734092712, accuracy: 97.3 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.07756343483924866, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.1128, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.1500, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.1936, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.1523, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.1060, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.1064, batch time: 0.32, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.1031, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.1608, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.1881, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.0846, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.11989553272724152, accuracy: 94.9 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.11812037229537964, accuracy: 95.9 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.11275285482406616, accuracy: 96.0 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.10813438147306442, accuracy: 96.3 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.1261185109615326, accuracy: 95.3 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.13679519295692444, accuracy: 95.2 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.1420927345752716, accuracy: 95.7 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.10174170136451721, accuracy: 96.4 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.09956079721450806, accuracy: 96.4 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.09756049513816833, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.1153, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.1008, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.2388, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.1413, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0978, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1573, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.1819, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.1848, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.0604, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.1006, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.12751927971839905, accuracy: 95.7 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.13494905829429626, accuracy: 95.5 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.14442938566207886, accuracy: 95.5 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.12043415009975433, accuracy: 96.0 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.1337447613477707, accuracy: 95.4 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.13900971412658691, accuracy: 95.5 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.1054670438170433, accuracy: 96.8 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.11778770387172699, accuracy: 95.2 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.09453422576189041, accuracy: 97.2 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.09468940645456314, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.1209, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.0747, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.1023, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.1089, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.1823, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.0965, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.0638, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.1069, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.0918, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.1049, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.11746164411306381, accuracy: 96.3 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.1714245080947876, accuracy: 93.9 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.11750607937574387, accuracy: 95.6 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.10808247327804565, accuracy: 96.9 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.11193657666444778, accuracy: 96.4 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.10938731580972672, accuracy: 96.1 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.09369295090436935, accuracy: 97.0 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.1569194197654724, accuracy: 95.0 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.1529131382703781, accuracy: 94.4 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.08865032345056534, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.1981, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.1352, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.1129, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.0765, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.1148, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.1055, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.0921, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.1543, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.0937, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.1629, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.15025044977664948, accuracy: 95.0 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.19145381450653076, accuracy: 93.9 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.16735057532787323, accuracy: 94.4 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.15428884327411652, accuracy: 95.7 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.1436886042356491, accuracy: 96.0 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.1492445319890976, accuracy: 95.4 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.13097001612186432, accuracy: 95.6 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.1227843314409256, accuracy: 96.1 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.1158870980143547, accuracy: 96.4 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.11397610604763031, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.1144, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.1943, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.1533, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.0809, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.1273, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.1256, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.1345, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.0945, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.1712, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.1431, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.10237258672714233, accuracy: 96.3 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.14531537890434265, accuracy: 94.6 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.10963801294565201, accuracy: 96.0 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.12055310606956482, accuracy: 96.0 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.09717968106269836, accuracy: 96.5 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.09077142924070358, accuracy: 97.3 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.08947589993476868, accuracy: 96.7 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.08797972649335861, accuracy: 97.0 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.08467806875705719, accuracy: 96.7 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.08414798974990845, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.0515, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.2202, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.1209, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.1493, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.0926, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.2175, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.1102, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.1240, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.1480, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.1023, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.10817348957061768, accuracy: 96.6 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.1050594374537468, accuracy: 96.6 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.10417255759239197, accuracy: 96.1 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.10297176241874695, accuracy: 96.5 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.11341220140457153, accuracy: 96.3 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.1019391268491745, accuracy: 96.4 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.15676969289779663, accuracy: 94.5 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.13705773651599884, accuracy: 95.1 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.09660743921995163, accuracy: 96.7 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.09254803508520126, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.0986, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.1079, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.0771, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.2200, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.1238, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.1540, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.1320, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.1651, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.2539, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.1128459945321083, accuracy: 96.4 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.12763534486293793, accuracy: 95.7 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.10682504624128342, accuracy: 96.4 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.1014379933476448, accuracy: 96.6 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.10192892700433731, accuracy: 96.3 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.10316365957260132, accuracy: 96.1 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.10787374526262283, accuracy: 96.2 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.09171933680772781, accuracy: 96.6 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.0904645100235939, accuracy: 96.6 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.0925147756934166, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.2659, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.1830, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.0987, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.0692, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.1045, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.1627, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.0827, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.1168, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.1450, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.0580, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.11756718903779984, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.44606736302375793, accuracy: 86.8 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.15888608992099762, accuracy: 94.4 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.11075208336114883, accuracy: 96.6 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.1334644854068756, accuracy: 95.8 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.11055648326873779, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.09641636908054352, accuracy: 96.6 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.09416854381561279, accuracy: 96.6 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.0942407101392746, accuracy: 96.6 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.0928136557340622, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.0826, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.1112, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.1016, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.1358, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.3265, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.1053, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1400, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.0680, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.2487, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.11534281820058823, accuracy: 96.5 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.1145864725112915, accuracy: 96.6 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.10901675373315811, accuracy: 96.0 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.09928837418556213, accuracy: 96.7 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.09964637458324432, accuracy: 97.0 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.10030015558004379, accuracy: 96.6 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.09274417906999588, accuracy: 97.2 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.09691735357046127, accuracy: 96.9 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.09393353760242462, accuracy: 96.9 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.08901271224021912, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.0950, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.0822, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.0700, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.2752, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.1181, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.0740, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.1652, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.0632, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.1731, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.0763, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.11236109584569931, accuracy: 96.0 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.11146900802850723, accuracy: 96.2 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.14412066340446472, accuracy: 94.9 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.10628502815961838, accuracy: 96.6 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.14422164857387543, accuracy: 95.4 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.19068393111228943, accuracy: 93.8 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.11984297633171082, accuracy: 95.6 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.09316764771938324, accuracy: 96.8 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.09215150773525238, accuracy: 96.8 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.08929640054702759, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.1348, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.0581, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.0741, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.3157, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.1684, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.1400, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.1348, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.1603, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.0519, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.1173, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.10565599054098129, accuracy: 96.6 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.15509143471717834, accuracy: 94.4 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.11842456459999084, accuracy: 95.8 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.10993250459432602, accuracy: 96.3 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.09625060856342316, accuracy: 96.2 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.09276892244815826, accuracy: 96.6 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.0917649194598198, accuracy: 96.8 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.0908203199505806, accuracy: 96.7 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.08937891572713852, accuracy: 96.8 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.09030576050281525, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.1287, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.1516, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.1791, batch time: 0.12, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.1613, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.1357, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.1533, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.0945, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.0990, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.2269, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.0877, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.10469667613506317, accuracy: 96.0 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.10742176324129105, accuracy: 96.5 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.14701145887374878, accuracy: 94.6 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.098245769739151, accuracy: 96.5 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.15521885454654694, accuracy: 94.4 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.09009554982185364, accuracy: 97.1 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.08756636083126068, accuracy: 96.8 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.08572259545326233, accuracy: 96.9 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.09050389379262924, accuracy: 97.0 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.08167805522680283, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.1679, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.1120, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.1209, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.0791, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.0761, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.0810, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.0803, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.1612, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.1681, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.0719, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.12495505809783936, accuracy: 96.4 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.15051233768463135, accuracy: 95.4 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.12158631533384323, accuracy: 95.8 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.1650581657886505, accuracy: 95.2 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.1194702535867691, accuracy: 96.3 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.10643886774778366, accuracy: 96.2 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.10414598137140274, accuracy: 96.5 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.10282669216394424, accuracy: 96.4 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.10148084163665771, accuracy: 96.5 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.10438396036624908, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.0756, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.1532, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.2577, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.0991, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.1254, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.1572, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.1839, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.0639, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.1217, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.0588, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.10680373013019562, accuracy: 96.5 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.11779095232486725, accuracy: 95.8 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.11150810122489929, accuracy: 96.1 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.10106725245714188, accuracy: 96.7 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.10999003052711487, accuracy: 95.9 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.1038706824183464, accuracy: 96.6 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.13230286538600922, accuracy: 95.4 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.13598039746284485, accuracy: 94.9 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.09109454602003098, accuracy: 97.0 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.0918106734752655, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.0740, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.0486, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.1398, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.0617, batch time: 0.12, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.0970, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.0647, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.0368, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.0609, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.2076, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.0816, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.10642383247613907, accuracy: 96.3 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.09939819574356079, accuracy: 96.2 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.10039541870355606, accuracy: 96.1 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.08522544801235199, accuracy: 97.2 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.08734797686338425, accuracy: 96.9 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.09171103686094284, accuracy: 96.9 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.13585224747657776, accuracy: 95.6 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.08553029596805573, accuracy: 97.1 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.0788845345377922, accuracy: 97.4 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.09796752035617828, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.0842, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.1271, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.1091, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.0813, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.1508, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.1207, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.0927, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.1603, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.0584, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.1111, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.0985511988401413, accuracy: 96.8 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.10811833292245865, accuracy: 96.4 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.1452145278453827, accuracy: 95.2 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.09407025575637817, accuracy: 98.0 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.11390363425016403, accuracy: 96.4 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.0951719656586647, accuracy: 97.2 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.14858832955360413, accuracy: 95.1 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.09083843231201172, accuracy: 97.9 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.08693704754114151, accuracy: 98.0 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.08491344004869461, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.1290, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.0974, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.0828, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.1974, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.1534, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.0541, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.0539, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.1576, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.0884, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.0721, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.10294429212808609, accuracy: 96.1 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.11524126678705215, accuracy: 95.9 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.12487068772315979, accuracy: 95.1 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.0923677533864975, accuracy: 96.8 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.13111744821071625, accuracy: 94.8 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.13149049878120422, accuracy: 95.9 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.09095726162195206, accuracy: 96.9 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.19386224448680878, accuracy: 93.3 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.18297407031059265, accuracy: 93.8 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.08422776311635971, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.1158, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.1133, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.0882, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.2354, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.1235, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1101, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.0828, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.1966, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.0716, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.0874, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.11086524277925491, accuracy: 96.6 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.7880626916885376, accuracy: 79.0 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.10818144679069519, accuracy: 96.5 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.10247776657342911, accuracy: 96.5 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.12203315645456314, accuracy: 96.0 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.10486198216676712, accuracy: 96.4 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.1289673000574112, accuracy: 95.8 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.10179731249809265, accuracy: 96.5 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.08541709929704666, accuracy: 97.5 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.08642273396253586, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.0593, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.1143, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.1325, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.0606, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.2136, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.0789, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.1545, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.0508, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.1564, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.1082, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.11126198619604111, accuracy: 96.4 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.7111920118331909, accuracy: 80.4 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.10068535804748535, accuracy: 96.6 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.09804430603981018, accuracy: 96.9 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.10613766312599182, accuracy: 96.8 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.10482361167669296, accuracy: 96.6 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.10126548260450363, accuracy: 96.8 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.0967414602637291, accuracy: 96.8 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.0930488333106041, accuracy: 97.1 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.08353450894355774, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.1169, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.1627, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.0556, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.1647, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.1245, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.1754, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.1206, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.0534, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.2033, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.2030, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.09472920745611191, accuracy: 97.0 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.10925331711769104, accuracy: 96.1 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.08442117273807526, accuracy: 97.5 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.07666388899087906, accuracy: 98.0 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.07557425647974014, accuracy: 97.9 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.09358833730220795, accuracy: 96.7 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.09335637092590332, accuracy: 96.4 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.0713399201631546, accuracy: 98.1 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.06768058240413666, accuracy: 98.3 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.06741425395011902, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.1594, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.0725, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1065, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.0926, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.0928, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.1657, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.0916, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.1646, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.1928, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.0353, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.11098422855138779, accuracy: 96.4 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.17980006337165833, accuracy: 94.0 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.11175880581140518, accuracy: 95.6 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.13783448934555054, accuracy: 95.6 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.09702759236097336, accuracy: 96.1 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.08976306021213531, accuracy: 96.5 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.08919309079647064, accuracy: 96.8 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.08874253183603287, accuracy: 96.7 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.08799906075000763, accuracy: 96.5 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.08787911385297775, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.1458, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.0927, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.1604, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.0816, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.1211, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.1988, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.0995, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.1139, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.0875, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.10229162126779556, accuracy: 96.0 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.1613263040781021, accuracy: 94.6 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.11906159669160843, accuracy: 95.2 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.10612791776657104, accuracy: 96.6 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.28046026825904846, accuracy: 92.7 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.09170181304216385, accuracy: 96.8 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.0900394544005394, accuracy: 97.0 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.09215008467435837, accuracy: 96.5 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.08964909613132477, accuracy: 96.7 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.08930295705795288, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.1232, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.0712, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.0968, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.1298, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.1073, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.0853, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.0621, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.1560, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.1076, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.0711, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.12061609327793121, accuracy: 95.8 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.10915442556142807, accuracy: 96.0 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.10310584306716919, accuracy: 96.4 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.098573699593544, accuracy: 96.3 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.09339643269777298, accuracy: 97.0 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.11401849240064621, accuracy: 95.8 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.12010646611452103, accuracy: 96.3 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.10035426169633865, accuracy: 96.7 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.11031123995780945, accuracy: 95.9 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.09147530049085617, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.1069, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.0899, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.0841, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.1033, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.1464, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.1805, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.0682, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.1190, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.0704, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.0379, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.1423395425081253, accuracy: 94.9 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.12352155148983002, accuracy: 95.5 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.16808253526687622, accuracy: 94.9 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.09851735085248947, accuracy: 96.3 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.10438147932291031, accuracy: 96.4 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.09493904560804367, accuracy: 96.8 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.10484427958726883, accuracy: 96.6 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.1027488261461258, accuracy: 96.6 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.08921045064926147, accuracy: 97.0 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.0851355642080307, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.1842, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.0547, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.0872, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.0980, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.0532, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.1692, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.0707, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.1231, batch time: 0.25, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.0638, batch time: 0.09, accuracy:  99.22%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.0957, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.1039685383439064, accuracy: 96.8 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 2.0428152084350586, accuracy: 64.4 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.11123025417327881, accuracy: 96.6 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.09676262736320496, accuracy: 96.9 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.11712952703237534, accuracy: 95.8 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.09382523596286774, accuracy: 97.0 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.09483436495065689, accuracy: 97.3 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.09158006310462952, accuracy: 97.2 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.08932173997163773, accuracy: 97.3 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.08928146958351135, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.1103, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.0791, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.2468, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.0747, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.1349, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1045, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.0934, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.1308, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.1738, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.1611, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.1207120269536972, accuracy: 96.7 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.12404750287532806, accuracy: 96.4 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.30207011103630066, accuracy: 89.6 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.1972893327474594, accuracy: 93.7 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.11395169794559479, accuracy: 97.0 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.11081180721521378, accuracy: 96.7 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.11103007942438126, accuracy: 96.5 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.10748451203107834, accuracy: 96.6 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.10674829035997391, accuracy: 96.6 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.10766910016536713, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.0482, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.0260, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.0901, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.1459, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.1042, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.1001, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.0687, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.0451, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.0707, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.1179, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.12263422459363937, accuracy: 96.6 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.12605823576450348, accuracy: 96.2 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.30807918310165405, accuracy: 89.3 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.2744636535644531, accuracy: 93.4 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.11208436638116837, accuracy: 96.7 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.11130651086568832, accuracy: 96.5 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.1121949777007103, accuracy: 96.2 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.10637620091438293, accuracy: 96.7 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.10741622000932693, accuracy: 97.0 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.10484779626131058, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.1390, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.0648, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.1099, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.1176, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.1226, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.0742, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.0871, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.1051, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.0923, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.1560, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.11367517709732056, accuracy: 96.0 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.36484166979789734, accuracy: 90.4 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.15788471698760986, accuracy: 94.6 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.0974259003996849, accuracy: 97.1 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.10650904476642609, accuracy: 96.7 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.10115553438663483, accuracy: 96.8 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.09281543642282486, accuracy: 97.1 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.09881524741649628, accuracy: 96.8 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.10667559504508972, accuracy: 96.1 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.16579590737819672, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.1240, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.1085, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.0849, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.0677, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.1319, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.1081, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.0583, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.1345, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.1299, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.0921, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.09980040043592453, accuracy: 96.7 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.11281326413154602, accuracy: 96.2 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.10933171957731247, accuracy: 96.1 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.09282507747411728, accuracy: 97.1 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.09793207794427872, accuracy: 96.8 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.08181153237819672, accuracy: 97.5 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.08025752753019333, accuracy: 97.3 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.07718738913536072, accuracy: 97.5 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.0777716338634491, accuracy: 97.6 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.07741200923919678, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.0721, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.1278, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.2085, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.0817, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.1040, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.1391, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.1114, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.1767, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.0700, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.1436, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.09370361268520355, accuracy: 96.8 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.09112075716257095, accuracy: 97.0 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.10388971120119095, accuracy: 96.3 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.08685887604951859, accuracy: 96.9 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.09654490649700165, accuracy: 96.4 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.08279059082269669, accuracy: 97.1 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.07890230417251587, accuracy: 97.5 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.07675111293792725, accuracy: 97.8 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.0766049399971962, accuracy: 98.0 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.07433242350816727, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.2249, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.2498, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.1300, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.0535, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.1467, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.1672, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.2082, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.0565, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.1308, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.1250, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.12049786746501923, accuracy: 95.7 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.4562309682369232, accuracy: 87.7 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.11542315036058426, accuracy: 96.4 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.1138552874326706, accuracy: 96.3 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.22293724119663239, accuracy: 92.6 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.12446524202823639, accuracy: 95.6 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.10688260197639465, accuracy: 97.1 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.10460720956325531, accuracy: 96.8 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.10326889902353287, accuracy: 97.1 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.10354622453451157, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.0684, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.1280, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.1179, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.1770, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.1111, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.2362, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.1109, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.1799, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.1732, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.1222, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.09662286937236786, accuracy: 96.5 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.3023119568824768, accuracy: 90.9 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.09461963921785355, accuracy: 96.5 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.09115702658891678, accuracy: 96.6 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.08992496132850647, accuracy: 96.8 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.16765877604484558, accuracy: 94.3 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.11662066727876663, accuracy: 95.3 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.1073329895734787, accuracy: 96.4 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.1542811393737793, accuracy: 95.1 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.07853706181049347, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.0772, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.0640, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.0994, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.0933, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.1135, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.1600, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.0379, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.0494, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.1443, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.08002473413944244, accuracy: 97.2 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.08426664024591446, accuracy: 97.2 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.09418301284313202, accuracy: 96.7 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.09334763139486313, accuracy: 96.9 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.1190841943025589, accuracy: 95.8 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.07323343306779861, accuracy: 97.8 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.07256155461072922, accuracy: 97.7 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.06996196508407593, accuracy: 97.8 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.06885506957769394, accuracy: 97.5 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.06657516956329346, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.1506, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.1725, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.1629, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.0906, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.1916, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.1617, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.0822, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.1124, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.0838, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.0976, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.09326067566871643, accuracy: 96.8 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 1.1153244972229004, accuracy: 77.9 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.08835277706384659, accuracy: 97.1 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.09075208753347397, accuracy: 96.9 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.0813135951757431, accuracy: 97.2 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.13029345870018005, accuracy: 95.6 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.07149447500705719, accuracy: 97.7 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.09308338910341263, accuracy: 96.2 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.08994316309690475, accuracy: 96.7 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.07417941838502884, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.2451, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.1012, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.0914, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.1412, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.0866, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.1217, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.1193, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.1937, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.0679, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.1126, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.10585574805736542, accuracy: 96.9 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.11870916932821274, accuracy: 96.1 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.09884728491306305, accuracy: 96.8 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.09313912689685822, accuracy: 97.0 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.09897501021623611, accuracy: 96.6 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.0884270966053009, accuracy: 96.7 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.1211128830909729, accuracy: 94.6 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.11241528391838074, accuracy: 95.9 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.09156236797571182, accuracy: 96.5 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.0824153795838356, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.1327, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.0919, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.1532, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.1215, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.1139, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.1032, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.0887, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.1702, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.0610, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.0999, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.133443683385849, accuracy: 95.2 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.14013046026229858, accuracy: 94.9 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.10679946839809418, accuracy: 96.1 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.10576993227005005, accuracy: 96.3 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.10969939082860947, accuracy: 95.6 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.11238031834363937, accuracy: 96.0 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.09988325834274292, accuracy: 96.3 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.09783027321100235, accuracy: 96.3 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.09683911502361298, accuracy: 96.1 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.09561357647180557, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.0914, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.1034, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.2616, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.1480, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.1074, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.0736, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.0505, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.1415, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.0599, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.0767, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.10697468370199203, accuracy: 95.6 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.10673002898693085, accuracy: 95.7 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.1350148767232895, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.1008465588092804, accuracy: 95.7 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.11173497140407562, accuracy: 95.4 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.10368674248456955, accuracy: 96.1 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.10710030794143677, accuracy: 96.4 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.09801638126373291, accuracy: 96.0 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.15279468894004822, accuracy: 94.2 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.08942827582359314, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.1353, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.1315, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.0998, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.1232, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.0912, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.0835, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.0947, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.1144, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.0721, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.1321, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.0637529268860817, accuracy: 97.8 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.9047706127166748, accuracy: 75.2 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.05985848978161812, accuracy: 97.9 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.05930153653025627, accuracy: 97.7 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.06057097390294075, accuracy: 97.8 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.09207997471094131, accuracy: 96.9 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.04924552142620087, accuracy: 98.5 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.0472368523478508, accuracy: 98.6 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.04633922129869461, accuracy: 98.2 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.04689732566475868, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.0914, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.1883, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.1639, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.1484, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.1524, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.1365, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.0967, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.1083, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.1038, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.1590, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.10767797380685806, accuracy: 96.6 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.11145726591348648, accuracy: 96.5 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.10301800817251205, accuracy: 96.8 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.10284975916147232, accuracy: 96.7 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.11637430638074875, accuracy: 96.2 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.11241240799427032, accuracy: 96.4 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.10425429046154022, accuracy: 96.3 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.08666064590215683, accuracy: 97.6 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.11738970875740051, accuracy: 96.7 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.1596759706735611, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.0954, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.1264, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.0233, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.1208, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.1611, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.0556, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.0791, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.0977, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.1677, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.1097, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.07785957306623459, accuracy: 97.4 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.09762890636920929, accuracy: 96.4 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.06953403353691101, accuracy: 97.6 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.06289022415876389, accuracy: 98.1 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.08133237063884735, accuracy: 96.8 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.06049361824989319, accuracy: 98.3 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.06400503218173981, accuracy: 97.8 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.057793766260147095, accuracy: 98.6 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.057553406804800034, accuracy: 98.3 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.055438075214624405, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.2150, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.0879, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.0564, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.0854, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.0705, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.1783, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.0973, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.0304, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.0563, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.2232, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.11222163587808609, accuracy: 95.8 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.3425769507884979, accuracy: 89.8 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.4462122619152069, accuracy: 86.4 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.2806776165962219, accuracy: 90.4 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.10515797138214111, accuracy: 95.9 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.09312324970960617, accuracy: 96.2 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.09039637446403503, accuracy: 96.3 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.0882662683725357, accuracy: 96.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.09720347076654434, accuracy: 96.5 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.09055200219154358, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.0982, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.1594, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.1017, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.1184, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.1181, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.1499, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.0939, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.1573, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.0533, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.1641, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.08851820975542068, accuracy: 97.5 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.31972751021385193, accuracy: 89.9 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.38836780190467834, accuracy: 87.2 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.16821223497390747, accuracy: 94.3 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.07755682617425919, accuracy: 97.2 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.07291582971811295, accuracy: 97.4 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.07279378920793533, accuracy: 97.5 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.069698765873909, accuracy: 97.8 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.07105828076601028, accuracy: 97.7 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.06735597550868988, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.0750, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.1026, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.1498, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.1706, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.0846, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.2366, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.1199, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.1061, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.1743, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.0777, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.10449820756912231, accuracy: 96.1 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.10410382598638535, accuracy: 96.1 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.11344266682863235, accuracy: 95.3 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.0931691899895668, accuracy: 96.6 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.09278527647256851, accuracy: 96.4 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.09314515441656113, accuracy: 96.3 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.08395682275295258, accuracy: 96.9 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.08296702057123184, accuracy: 96.7 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.08141149580478668, accuracy: 97.1 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.08031537383794785, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.1032, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.2443, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.0579, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.1138, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.0783, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.1732, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.1663, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.0775, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.1172, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.1390, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.09768132865428925, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.10460151731967926, accuracy: 96.9 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.09085805714130402, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.0907515287399292, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.11205334961414337, accuracy: 96.3 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.09297347068786621, accuracy: 97.0 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.08566273748874664, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.08697470277547836, accuracy: 97.4 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.08466839045286179, accuracy: 98.0 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.08279766887426376, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.0489, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.1612, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.0498, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.0667, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.1459, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.2202, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.0776, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.1130, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.1129, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.0912, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.10098233819007874, accuracy: 96.0 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.3576934337615967, accuracy: 88.9 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.0946771427989006, accuracy: 96.0 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.09226328134536743, accuracy: 96.4 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.11654829233884811, accuracy: 95.9 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.13015471398830414, accuracy: 95.5 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.08743426203727722, accuracy: 96.7 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.08441535383462906, accuracy: 96.9 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.08372816443443298, accuracy: 97.0 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.08360167592763901, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.0807, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.0573, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.1702, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.1352, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.0987, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.1015, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.0994, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.0389, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.0869, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.1831, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.11951711773872375, accuracy: 96.6 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.2065034657716751, accuracy: 92.5 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.11508973687887192, accuracy: 96.3 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.1128053292632103, accuracy: 96.7 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.11039301007986069, accuracy: 96.0 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.13595716655254364, accuracy: 95.7 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.18387934565544128, accuracy: 93.0 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.13420435786247253, accuracy: 95.4 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.11373814940452576, accuracy: 96.1 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.10323598980903625, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.1380, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.1142, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.1330, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.0367, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.0980, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.1005, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.1197, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.1905, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.1355, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.0954, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.11201262474060059, accuracy: 96.3 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.11547418683767319, accuracy: 96.0 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.10757120698690414, accuracy: 96.2 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.10415102541446686, accuracy: 96.7 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.11970918625593185, accuracy: 96.3 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.10044371336698532, accuracy: 97.0 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.09796256572008133, accuracy: 96.8 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.0963192880153656, accuracy: 97.5 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.09577228873968124, accuracy: 97.4 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.09516992419958115, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.1032, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.0655, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.1504, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.1885, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.0537, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.1242, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.1354, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.1051, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.0886, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.0711, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.08819282054901123, accuracy: 97.1 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.09914030879735947, accuracy: 97.0 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.09493284672498703, accuracy: 97.1 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.10407156497240067, accuracy: 96.4 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.0830325111746788, accuracy: 97.5 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.07881077378988266, accuracy: 97.3 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.07870332896709442, accuracy: 97.4 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.07846608757972717, accuracy: 97.7 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.07783433049917221, accuracy: 97.4 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.07822788506746292, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.1081, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.1730, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.0833, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.0941, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.1316, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.0637, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.1078, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.1490, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.1044, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.0845, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.08120496571063995, accuracy: 97.3 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.13981543481349945, accuracy: 94.8 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.07083350419998169, accuracy: 97.7 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.07038174569606781, accuracy: 97.7 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.08764253556728363, accuracy: 97.3 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.06818442791700363, accuracy: 97.8 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.0670095682144165, accuracy: 98.2 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.0662636086344719, accuracy: 98.2 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.06550924479961395, accuracy: 98.2 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.06443937867879868, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.1711, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.1270, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.0972, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.0482, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.1555, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.0873, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.1595, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.1589, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.2547, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.0446, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.10146871954202652, accuracy: 96.2 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.13824892044067383, accuracy: 95.0 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.09111757576465607, accuracy: 96.6 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.08416645973920822, accuracy: 97.4 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.09147589653730392, accuracy: 97.0 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.10549453645944595, accuracy: 96.7 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.11279377341270447, accuracy: 96.0 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.08954046666622162, accuracy: 97.0 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.07905784249305725, accuracy: 97.5 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.12409541010856628, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.1092, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.1202, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.1784, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.1030, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.0884, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.1881, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.1210, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.0905, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.1082, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.0216, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.06753335148096085, accuracy: 97.0 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.6815999746322632, accuracy: 85.6 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.0548827163875103, accuracy: 97.6 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.05215128883719444, accuracy: 97.6 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.064256452023983, accuracy: 97.5 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.04889090731739998, accuracy: 98.3 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.08386243134737015, accuracy: 96.7 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.09068834036588669, accuracy: 96.3 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.08345574885606766, accuracy: 96.6 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.10758134722709656, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.1264, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.0621, batch time: 0.38, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.0739, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.0791, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.0583, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.1402, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.1356, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.1238, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.2407, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.1932, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.10879658162593842, accuracy: 96.7 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.10240252315998077, accuracy: 96.8 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.09401066601276398, accuracy: 97.1 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.09396259486675262, accuracy: 97.1 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.1380365639925003, accuracy: 95.1 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.09058956056833267, accuracy: 97.2 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.0891583263874054, accuracy: 97.2 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.08645539730787277, accuracy: 97.2 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.08726000040769577, accuracy: 97.2 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.08424936234951019, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.1209, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.1293, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.1821, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.0962, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.1450, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.1163, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.1568, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.1983, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.2556, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.0787, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.09439859539270401, accuracy: 97.4 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.10846957564353943, accuracy: 96.4 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.08317877352237701, accuracy: 97.1 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.11054562777280807, accuracy: 96.3 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.08382554352283478, accuracy: 97.5 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.07492425292730331, accuracy: 97.8 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.07428038865327835, accuracy: 98.0 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.07311291992664337, accuracy: 97.8 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.07150835543870926, accuracy: 97.9 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.06970878690481186, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.1152, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.0642, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.1006, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.0599, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.0772, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.1209, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.0766, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.1178, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.1411, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.0796, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.07761859148740768, accuracy: 97.3 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.08201771229505539, accuracy: 97.2 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.2727549374103546, accuracy: 91.2 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.08399257808923721, accuracy: 97.0 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.07394669204950333, accuracy: 97.8 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.07299599051475525, accuracy: 97.5 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.07346561551094055, accuracy: 97.5 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.0706380158662796, accuracy: 97.5 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.07155171781778336, accuracy: 97.9 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.07328321784734726, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.0647, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.0766, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.0878, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.1800, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.0524, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.0869, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.0916, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.1351, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.1103, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.0824, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.07420054823160172, accuracy: 97.4 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.08077781647443771, accuracy: 97.0 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.08233772218227386, accuracy: 97.5 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.13773031532764435, accuracy: 95.6 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.07638753950595856, accuracy: 97.6 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.07362408190965652, accuracy: 97.4 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.06571861356496811, accuracy: 98.0 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.07498639822006226, accuracy: 97.5 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.06390707194805145, accuracy: 98.3 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.06753674894571304, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.0406, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.0592, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.1146, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.1189, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.1427, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.1559, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.1349, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.0184, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.1719, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.0631, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.08870137482881546, accuracy: 96.7 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.0978073850274086, accuracy: 96.4 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.29098495841026306, accuracy: 91.5 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.20652030408382416, accuracy: 92.7 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.08107839524745941, accuracy: 97.1 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.08358047902584076, accuracy: 97.0 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.07854346185922623, accuracy: 97.3 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.07341347634792328, accuracy: 97.5 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.07807012647390366, accuracy: 96.8 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.08735740929841995, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.1116, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.1110, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.1471, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.0787, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.1294, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.0751, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.1782, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.0809, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.1281, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.1613, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.11617381125688553, accuracy: 96.0 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.4708266854286194, accuracy: 85.0 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.11349409818649292, accuracy: 96.6 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.11047548055648804, accuracy: 96.3 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.10791462659835815, accuracy: 96.7 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.14841777086257935, accuracy: 94.8 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.10295461863279343, accuracy: 96.9 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.1565253883600235, accuracy: 94.8 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.10165472328662872, accuracy: 97.1 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.09779489785432816, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.0499, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.1494, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.1728, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.1005, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.0695, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.0976, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.1443, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.1315, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.0417, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.1049, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.10348647832870483, accuracy: 96.2 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.10169690102338791, accuracy: 96.5 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.0937252789735794, accuracy: 96.9 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.09372211992740631, accuracy: 96.9 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.1977866142988205, accuracy: 93.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.08936838060617447, accuracy: 97.5 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.09041998535394669, accuracy: 97.5 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.08890185505151749, accuracy: 97.0 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.09747175872325897, accuracy: 97.0 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.08692741394042969, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.1624, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.1691, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.1761, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.1749, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.1065, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.1195, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.1028, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.0847, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.0747, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.0990, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.08744677156209946, accuracy: 97.1 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.7371702790260315, accuracy: 79.7 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.08278298377990723, accuracy: 97.4 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.08136072009801865, accuracy: 97.5 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.08066417276859283, accuracy: 97.3 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.08181224018335342, accuracy: 97.3 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.07828687131404877, accuracy: 97.3 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.11782920360565186, accuracy: 95.9 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.11269184947013855, accuracy: 96.1 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.07632910460233688, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.0363, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.1260, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.1740, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.2237, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.0788, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.0547, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.1195, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.1176, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.1166, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.0851, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.09279810637235641, accuracy: 97.3 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.11305201798677444, accuracy: 97.2 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.08755248785018921, accuracy: 97.3 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.0854530781507492, accuracy: 97.7 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.08842670917510986, accuracy: 97.3 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.07570657134056091, accuracy: 98.1 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.0739317536354065, accuracy: 98.1 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.06949340552091599, accuracy: 97.9 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.07076463848352432, accuracy: 98.0 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.06799183785915375, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.0934, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.0934, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.1239, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.1303, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.1327, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.0881, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.1696, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.1405, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.1410, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.0666, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.10032841563224792, accuracy: 96.2 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.09208793938159943, accuracy: 96.5 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.08767127990722656, accuracy: 97.1 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.08524785190820694, accuracy: 97.1 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.08286211639642715, accuracy: 97.8 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.09641014784574509, accuracy: 96.3 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.08441378176212311, accuracy: 96.7 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.09646255522966385, accuracy: 96.8 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.08037880063056946, accuracy: 97.4 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.07776448875665665, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.0913, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.0954, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.0906, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.0612, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.0808, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.1088, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.0747, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.0654, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.1330, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.0887, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.09304486215114594, accuracy: 97.2 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.13704565167427063, accuracy: 95.5 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.08620668202638626, accuracy: 97.1 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.0956709012389183, accuracy: 97.0 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.08019136637449265, accuracy: 97.4 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.07704999297857285, accuracy: 97.8 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.07823274284601212, accuracy: 97.4 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.07437048852443695, accuracy: 97.8 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.07350650429725647, accuracy: 97.9 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.07294946163892746, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.0954, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.1743, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.1147, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.1536, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.0516, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.0930, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.0466, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.0841, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.1208, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.0723227933049202, accuracy: 98.0 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.161284327507019, accuracy: 73.8 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.06960099935531616, accuracy: 98.1 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.06959259510040283, accuracy: 98.1 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.07100009173154831, accuracy: 98.2 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.06911147385835648, accuracy: 98.1 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.08603579550981522, accuracy: 97.1 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.0644669458270073, accuracy: 97.9 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.06029188632965088, accuracy: 98.4 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.05882936716079712, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.1121, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.0757, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.1821, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.1302, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.1290, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.0429, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.0855, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.0618, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.0605, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.1018, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.09216894209384918, accuracy: 96.5 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.0930919274687767, accuracy: 96.3 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.0851936936378479, accuracy: 96.8 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.0840991660952568, accuracy: 96.7 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.10539156198501587, accuracy: 96.4 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.08772016316652298, accuracy: 96.7 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.07610194385051727, accuracy: 97.4 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.07114922255277634, accuracy: 97.7 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.07106713205575943, accuracy: 97.3 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.07121414691209793, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.1007, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.0986, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.0445, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.1347, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.0621, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.0938, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.0867, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.1402, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.1316, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.1542, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.08336437493562698, accuracy: 97.1 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.12182643264532089, accuracy: 96.0 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.08956008404493332, accuracy: 97.2 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.09006659686565399, accuracy: 97.3 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.08664263784885406, accuracy: 97.6 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.10845431685447693, accuracy: 96.3 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.07916200906038284, accuracy: 97.7 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.07547102868556976, accuracy: 97.6 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.07180511951446533, accuracy: 97.8 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.07159943878650665, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.0968, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.1379, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.0427, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.1543, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.1385, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.0590, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.0916, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.0459, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.1025, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.0846, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.0783381387591362, accuracy: 97.3 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.07164192199707031, accuracy: 97.4 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.19332192838191986, accuracy: 92.7 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.1389070749282837, accuracy: 95.8 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.07060322910547256, accuracy: 97.2 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.06860651820898056, accuracy: 97.5 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.08192550390958786, accuracy: 97.1 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.06625684350728989, accuracy: 97.6 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.06491388380527496, accuracy: 97.7 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.06440982222557068, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.1351, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.0918, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.1262, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.0649, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.1014, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.1342, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.2046, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.0831, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.1097, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.1121, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.09384502470493317, accuracy: 97.1 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.0948367640376091, accuracy: 97.0 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.08854766935110092, accuracy: 97.2 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.08234817534685135, accuracy: 97.2 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.11019755899906158, accuracy: 96.2 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.09354538470506668, accuracy: 97.1 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.10121085494756699, accuracy: 95.6 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.0959177166223526, accuracy: 96.5 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.09642847627401352, accuracy: 96.3 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.07220251113176346, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.1603, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.0892, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.0950, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.0880, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.0931, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.0719, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.1205, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.0576, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.11074036359786987, accuracy: 96.6 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.1282251626253128, accuracy: 96.3 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.1466415375471115, accuracy: 95.0 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.10024081915616989, accuracy: 96.6 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.12046156823635101, accuracy: 96.1 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.10397721827030182, accuracy: 96.3 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.12453983724117279, accuracy: 95.9 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.09689521044492722, accuracy: 96.6 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.0902717113494873, accuracy: 96.6 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.14005997776985168, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.1190, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.1739, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.1156, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.1229, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.0539, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.0750, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.1177, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.1017, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.1198, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.0353, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.09771895408630371, accuracy: 96.4 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.13004329800605774, accuracy: 95.3 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.09306463599205017, accuracy: 96.4 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.0914265364408493, accuracy: 96.8 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.09255121648311615, accuracy: 96.7 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.07149500399827957, accuracy: 97.9 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.07102019339799881, accuracy: 98.0 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.07009485363960266, accuracy: 98.2 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.07014457881450653, accuracy: 98.6 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.06874827295541763, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.0694, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.0466, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.0394, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.0577, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.1168, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.0795, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.1327, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.0569, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.1054, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.08684024959802628, accuracy: 96.6 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.08380355685949326, accuracy: 97.2 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.10469100624322891, accuracy: 96.0 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.07675290107727051, accuracy: 97.5 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.09522365778684616, accuracy: 96.2 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.06927106529474258, accuracy: 97.8 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.07454884797334671, accuracy: 97.6 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.06689799576997757, accuracy: 97.7 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.0661357119679451, accuracy: 97.6 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.06741604208946228, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.0651, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.1296, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.0882, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.1052, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.1272, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.0454, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.1830, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.0664, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.1384, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.1002, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.12380804121494293, accuracy: 96.2 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.31828993558883667, accuracy: 91.5 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.12473969906568527, accuracy: 95.6 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.15007264912128448, accuracy: 95.4 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.09682589769363403, accuracy: 96.7 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.09176881611347198, accuracy: 97.0 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.0908641517162323, accuracy: 97.0 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.0905366912484169, accuracy: 97.2 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.09014835953712463, accuracy: 96.4 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.08814647793769836, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.0575, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.1491, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.1529, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.0450, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.0463, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.1824, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.1558, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.0526, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.1577, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.09973110258579254, accuracy: 96.9 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.14915205538272858, accuracy: 95.4 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.12143170833587646, accuracy: 95.7 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.11062631011009216, accuracy: 96.0 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.08576449751853943, accuracy: 97.0 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.08563139289617538, accuracy: 97.0 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.08382460474967957, accuracy: 97.3 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.08544868975877762, accuracy: 97.1 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.08281815052032471, accuracy: 97.2 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.08280257880687714, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.1731, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.2443, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.1175, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.0949, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.0762, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.0446, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.0991, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.0836, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.1186, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.0801, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.07600707560777664, accuracy: 97.4 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.07906529307365417, accuracy: 97.3 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.07415532320737839, accuracy: 97.5 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.07165134698152542, accuracy: 97.9 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.09923174977302551, accuracy: 96.7 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.11527024209499359, accuracy: 95.8 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.06770282238721848, accuracy: 97.5 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.06058592349290848, accuracy: 98.4 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.06104462221264839, accuracy: 98.1 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.05577443912625313, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.0915, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.0748, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.0696, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.1224, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.1707, batch time: 0.12, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.1201, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.1387, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.1541, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.0864, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.1224, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.053033020347356796, accuracy: 98.1 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.05558966472744942, accuracy: 98.2 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.051819778978824615, accuracy: 98.4 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.05088529363274574, accuracy: 98.1 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.08838014304637909, accuracy: 96.5 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.050098173320293427, accuracy: 98.4 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.07013071328401566, accuracy: 97.4 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.04714950546622276, accuracy: 98.1 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.04665885120630264, accuracy: 98.1 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.04460926726460457, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.0970, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.1091, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.1858, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.1394, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.0588, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.1031, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0701, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.1077, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.0629, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.0549, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.08844884485006332, accuracy: 97.4 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.2723506689071655, accuracy: 72.7 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.0792117491364479, accuracy: 97.8 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.07845549285411835, accuracy: 97.6 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.08823119103908539, accuracy: 97.1 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.07746554166078568, accuracy: 97.0 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.08113083988428116, accuracy: 97.2 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.07477971911430359, accuracy: 97.9 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.06897501647472382, accuracy: 97.9 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.06791773438453674, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.0768, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.1169, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.1082, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.2463, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.1363, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.1853, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.0505, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.0604, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.1250, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.08623305708169937, accuracy: 96.4 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.2606492340564728, accuracy: 90.9 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.07561849802732468, accuracy: 97.6 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.07849550992250443, accuracy: 96.9 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.08601481467485428, accuracy: 97.3 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.05930575355887413, accuracy: 98.7 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.07936416566371918, accuracy: 97.7 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.05732005834579468, accuracy: 98.7 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.0565866194665432, accuracy: 98.7 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.05403745174407959, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.1242, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.1051, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.0736, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.1161, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.1034, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.1101, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.0771, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.1836, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.1524, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.1049, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.08279532939195633, accuracy: 97.2 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.25999242067337036, accuracy: 91.4 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.065409354865551, accuracy: 97.7 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.0647420734167099, accuracy: 97.8 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.09007187932729721, accuracy: 96.1 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.06929247081279755, accuracy: 97.4 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.05865103751420975, accuracy: 98.3 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.10222264379262924, accuracy: 95.9 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.06340640038251877, accuracy: 97.9 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.0541328489780426, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.0830, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.0935, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.1316, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.1784, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.0629, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.1157, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.0845, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.1159, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.0858, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.1115, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.08654449880123138, accuracy: 96.9 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.08545003086328506, accuracy: 96.9 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.08995191007852554, accuracy: 97.2 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.07760503143072128, accuracy: 97.4 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.08808263391256332, accuracy: 96.8 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.08639591187238693, accuracy: 97.4 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.07210355252027512, accuracy: 97.2 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.0721559152007103, accuracy: 97.3 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.07011643797159195, accuracy: 97.5 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.07097023725509644, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.0948, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.1190, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.1335, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.1233, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.0315, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.0822, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.0862, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.1413, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.1000, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.1882, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.07832356542348862, accuracy: 97.3 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.2657131254673004, accuracy: 91.6 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.07004047185182571, accuracy: 97.6 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.06289290636777878, accuracy: 98.0 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.05927561596035957, accuracy: 97.7 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.060815513134002686, accuracy: 97.5 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.06583194434642792, accuracy: 97.3 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.08645026385784149, accuracy: 97.2 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.05736411362886429, accuracy: 97.8 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.05520591884851456, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.1120, batch time: 0.31, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.1818, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.0413, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.0986, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.0855, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.1487, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.1852, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.1323, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.0989, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.0346, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.07092838734388351, accuracy: 97.6 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.07058485597372055, accuracy: 97.9 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.06573383510112762, accuracy: 97.6 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.06382406502962112, accuracy: 97.9 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.0877004936337471, accuracy: 96.9 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.09470504522323608, accuracy: 97.6 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.06258458644151688, accuracy: 97.8 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.059040170162916183, accuracy: 98.4 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.05906412750482559, accuracy: 98.4 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.060612499713897705, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.1316, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.0875, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.1378, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.0814, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.1079, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.0587, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.0905, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.0954, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.1485, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.0411, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.11718118190765381, accuracy: 96.1 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.5930705070495605, accuracy: 79.8 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.10619156062602997, accuracy: 96.7 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.11335177719593048, accuracy: 96.6 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.12633924186229706, accuracy: 95.6 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.14162229001522064, accuracy: 95.6 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.13682861626148224, accuracy: 95.4 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.15035295486450195, accuracy: 94.5 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.10399463027715683, accuracy: 96.8 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.1054210290312767, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.0553, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.1456, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.0759, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.0527, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.0640, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.1238, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.0331, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.1260, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.1445, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.2048, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.08752461522817612, accuracy: 97.0 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.07677087187767029, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.07600510120391846, accuracy: 97.5 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.07582179456949234, accuracy: 97.7 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.07516662031412125, accuracy: 97.6 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.1335858553647995, accuracy: 96.2 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.11492422223091125, accuracy: 96.3 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.08319710195064545, accuracy: 97.4 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.0795794203877449, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.07113382965326309, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.0932, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.1146, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.0401, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.0596, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.0318, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.1044, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.0430, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.0796, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.2348, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.0302, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.09279581159353256, accuracy: 96.6 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.5556625127792358, accuracy: 84.4 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.08642445504665375, accuracy: 96.8 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.08363735675811768, accuracy: 97.2 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.0865023210644722, accuracy: 96.9 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.07806654274463654, accuracy: 97.1 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.13342837989330292, accuracy: 94.9 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.07341626286506653, accuracy: 97.2 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.07314520329236984, accuracy: 97.4 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.08422357589006424, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.0990, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.1849, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.0519, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.0311, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.0997, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.0435, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.0559, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.0559, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.0734, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.1951, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.08843853324651718, accuracy: 97.4 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.08789586275815964, accuracy: 97.5 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.07376598566770554, accuracy: 97.6 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.07276023179292679, accuracy: 97.7 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.12740059196949005, accuracy: 95.1 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.07530831545591354, accuracy: 96.9 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.07450111210346222, accuracy: 97.4 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.06728672236204147, accuracy: 97.6 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.06618745625019073, accuracy: 97.6 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.06432736665010452, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.1628, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.1793, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.1292, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.1165, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.1859, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.0685, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.0796, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.1150, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.0656, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.0767, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.09920250624418259, accuracy: 97.1 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.09896329045295715, accuracy: 97.3 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.09198208898305893, accuracy: 97.4 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.0913567990064621, accuracy: 97.5 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.08834024518728256, accuracy: 97.2 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.16883103549480438, accuracy: 95.1 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.11997144669294357, accuracy: 95.6 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.0792439803481102, accuracy: 97.6 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.0787416398525238, accuracy: 97.6 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.0765022411942482, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.1253, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.0251, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.0639, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.1553, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.0964, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.0700, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.1027, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.0636, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.1131, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.0948, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.08575206995010376, accuracy: 97.2 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.0861416906118393, accuracy: 97.0 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.12099644541740417, accuracy: 95.8 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.10335289686918259, accuracy: 96.4 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.0765177384018898, accuracy: 97.4 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.07424474507570267, accuracy: 97.7 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.073360376060009, accuracy: 97.3 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.07250259816646576, accuracy: 97.3 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.07344252616167068, accuracy: 97.4 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.07248170673847198, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.1008, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.2018, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.0440, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.1077, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.0608, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.1511, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.0678, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.1799, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.1041, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.1369, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.10158249735832214, accuracy: 97.0 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 0.1487383395433426, accuracy: 95.2 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.12487625330686569, accuracy: 95.9 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.10686787217855453, accuracy: 96.3 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.08571699261665344, accuracy: 96.9 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.07817210257053375, accuracy: 97.3 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.07816991209983826, accuracy: 97.2 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.07562733441591263, accuracy: 97.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.07566697150468826, accuracy: 97.5 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.07489244639873505, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.0800, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.1366, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.1463, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.0888, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.0658, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.0711, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.1634, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.1794, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.0941, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.0560, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.07983863353729248, accuracy: 96.9 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.08270470798015594, accuracy: 96.7 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.07732703536748886, accuracy: 97.1 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.07727424800395966, accuracy: 97.1 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.07743491232395172, accuracy: 97.2 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.10244899243116379, accuracy: 96.3 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.07109525799751282, accuracy: 97.5 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.06922565400600433, accuracy: 97.4 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.06752661615610123, accuracy: 97.4 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.06599172949790955, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.0982, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0318, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.0484, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.0923, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.1169, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.1026, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.0675, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.0379, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.0887, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.0644, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.08911364525556564, accuracy: 96.7 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.09240235388278961, accuracy: 97.0 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.09091633558273315, accuracy: 96.8 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.07933052629232407, accuracy: 97.0 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.08862734586000443, accuracy: 96.8 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.09918901324272156, accuracy: 96.8 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.0823013037443161, accuracy: 96.9 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.08187112957239151, accuracy: 97.0 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.07612829655408859, accuracy: 97.0 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.0742219090461731, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.1429, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.0697, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.1324, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.1115, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.1359, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.0826, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.0798, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.0699, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.0599, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.0871, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.0831485390663147, accuracy: 97.4 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.08412306010723114, accuracy: 97.4 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.10886605829000473, accuracy: 96.5 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.11718263477087021, accuracy: 96.1 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.07268048822879791, accuracy: 97.7 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.07282719016075134, accuracy: 97.6 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.07306770980358124, accuracy: 97.6 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.07045946270227432, accuracy: 97.9 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.06914763897657394, accuracy: 97.8 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.06979784369468689, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.1804, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.0753, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.0701, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.0809, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.1190, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.1528, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.0950, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.1713, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.0917, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.0664, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.11569301784038544, accuracy: 96.2 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.16526250541210175, accuracy: 94.8 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.19783569872379303, accuracy: 93.2 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.23061081767082214, accuracy: 93.9 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.10174240171909332, accuracy: 96.1 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.09155150502920151, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.10516919195652008, accuracy: 96.3 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.08664907515048981, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.09027648717164993, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.08528055995702744, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.1774, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.1403, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.1586, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.0907, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.1130, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.0809, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.1066, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.0934, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.1635, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.0733, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.1291182041168213, accuracy: 96.1 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.574116051197052, accuracy: 83.4 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.11330819129943848, accuracy: 96.1 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.10756692290306091, accuracy: 96.3 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.11718492209911346, accuracy: 96.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.11634944379329681, accuracy: 96.3 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.09818663448095322, accuracy: 96.8 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.09323094040155411, accuracy: 96.8 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.09216953068971634, accuracy: 96.9 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.09152234345674515, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.0367, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.1661, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.1236, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.0617, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.1133, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.0895, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.0824, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.0886, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.0959, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.08565573394298553, accuracy: 97.1 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.13334235548973083, accuracy: 95.9 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.15552745759487152, accuracy: 94.6 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.08104739338159561, accuracy: 97.4 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.0916249006986618, accuracy: 97.0 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.0835537388920784, accuracy: 97.5 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.07498905807733536, accuracy: 98.0 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.0717846155166626, accuracy: 97.9 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.07147887349128723, accuracy: 98.2 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.07052051275968552, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.0811, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.1318, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.0491, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.1784, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.1001, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.1386, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.0660, batch time: 0.42, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.1022, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.0794, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.11426649987697601, accuracy: 96.5 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.1172042042016983, accuracy: 96.8 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.10200436413288116, accuracy: 96.8 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.09844876825809479, accuracy: 96.9 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.10295328497886658, accuracy: 96.9 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.09242814034223557, accuracy: 97.5 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.11943778395652771, accuracy: 96.6 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.11108285188674927, accuracy: 96.4 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.15366725623607635, accuracy: 95.2 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.09905348718166351, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.1489, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.0990, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.0875, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.1016, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.1030, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.1309, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.1177, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.1035, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.1047, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.0305, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.07955586910247803, accuracy: 97.3 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.2423049360513687, accuracy: 91.8 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.07413983345031738, accuracy: 97.6 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.0755377933382988, accuracy: 97.1 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.08752304315567017, accuracy: 96.5 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.08060891181230545, accuracy: 96.9 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.1035810187458992, accuracy: 96.5 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.06448336690664291, accuracy: 97.5 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.06354127824306488, accuracy: 97.6 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.0625038594007492, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.0745, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.1082, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.0671, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.0851, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.0943, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.1195, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.0777, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.1517, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.1463, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.1470, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.0691160336136818, accuracy: 97.3 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.0691419169306755, accuracy: 97.3 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.07629092037677765, accuracy: 97.4 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.09728524833917618, accuracy: 96.5 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.07126165181398392, accuracy: 97.4 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.05605238676071167, accuracy: 98.0 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.05650714412331581, accuracy: 98.0 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.052911486476659775, accuracy: 98.0 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.052023351192474365, accuracy: 98.1 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.05184377357363701, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.1363, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.1360, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.0324, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.1082, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.0977, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.0544, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.1465, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.0966, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.0753, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.1133, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.086249940097332, accuracy: 97.5 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.08586278557777405, accuracy: 97.4 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.08074985444545746, accuracy: 97.7 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.080020010471344, accuracy: 97.7 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.07576442509889603, accuracy: 97.7 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.08346086740493774, accuracy: 97.7 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.07013420015573502, accuracy: 98.2 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.06882576644420624, accuracy: 98.0 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.0681537464261055, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.07723373919725418, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.1138, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.1168, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.1451, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.0988, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.0514, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.0478, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.0426, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.0659, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.1485, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.0867, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.08082808554172516, accuracy: 97.3 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.47110193967819214, accuracy: 84.8 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.07163333147764206, accuracy: 97.7 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.07059008628129959, accuracy: 97.6 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.10661126673221588, accuracy: 96.4 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.07845866680145264, accuracy: 97.2 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.08752774447202682, accuracy: 97.1 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.07118688523769379, accuracy: 97.7 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.07597554475069046, accuracy: 97.1 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.06365883350372314, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.1190, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.0979, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.0809, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.0946, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.1201, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.0774, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.0869, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.0363, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.0466, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.0469, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.0725807398557663, accuracy: 97.3 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.08300112932920456, accuracy: 97.7 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.06786737591028214, accuracy: 97.7 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.06780718266963959, accuracy: 97.6 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.08510482311248779, accuracy: 97.6 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.09877705574035645, accuracy: 96.1 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.08655430376529694, accuracy: 96.8 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.07168816030025482, accuracy: 97.3 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.06115657463669777, accuracy: 98.0 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.05956052243709564, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.0536, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.0529, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.1351, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.0443, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.1504, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.1142, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.0830, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.1150, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.0727, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.0429, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.0929991602897644, accuracy: 97.0 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 1.4421536922454834, accuracy: 72.9 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.08441885560750961, accuracy: 97.6 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.08385245501995087, accuracy: 97.7 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.08349510282278061, accuracy: 97.3 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.08336736261844635, accuracy: 97.5 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.0918932557106018, accuracy: 97.0 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.08397980034351349, accuracy: 97.3 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.09966666251420975, accuracy: 96.7 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.10675220936536789, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.1659, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.1498, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.0781, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.0609, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0425, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.0354, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0596, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.0448, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.0575, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.1321, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.11607196927070618, accuracy: 95.9 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 2.717437505722046, accuracy: 65.3 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.10966996103525162, accuracy: 96.2 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.10516674816608429, accuracy: 96.5 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.16401013731956482, accuracy: 95.1 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.11347725242376328, accuracy: 95.5 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.10425487160682678, accuracy: 96.2 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.10930942744016647, accuracy: 95.9 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.15243276953697205, accuracy: 95.2 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.1788928210735321, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.0380, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.0396, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.1492, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.0853, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.1128, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.1526, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.0449, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.0868, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.0750, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.0625, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.08241971582174301, accuracy: 97.2 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.38199707865715027, accuracy: 87.6 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.06945304572582245, accuracy: 97.2 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.06856194883584976, accuracy: 97.2 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.06548169255256653, accuracy: 97.4 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.071627177298069, accuracy: 96.9 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.07451067119836807, accuracy: 96.8 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.060599133372306824, accuracy: 97.6 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.07344081252813339, accuracy: 96.9 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.07206675410270691, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.0921, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.0624, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.1379, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1217, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.0284, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.1088, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.1235, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.0652, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.1492, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.0762702077627182, accuracy: 97.5 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.07262283563613892, accuracy: 97.6 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.07305721938610077, accuracy: 97.5 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.06835512816905975, accuracy: 97.8 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.07405820488929749, accuracy: 97.7 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.11254168301820755, accuracy: 96.2 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.06907178461551666, accuracy: 98.0 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.059980928897857666, accuracy: 98.3 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.05887966975569725, accuracy: 98.1 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.057543180882930756, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.1003, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.0981, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.2204, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.0795, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.0618, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.0914, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.0956, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.1093, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.0832, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.1341, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.0638296902179718, accuracy: 98.0 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.14704778790473938, accuracy: 93.9 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.07900059968233109, accuracy: 97.4 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.05744260922074318, accuracy: 97.9 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.07580975443124771, accuracy: 97.2 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.059064317494630814, accuracy: 98.0 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.050900898873806, accuracy: 98.2 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.04929981753230095, accuracy: 98.2 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.050089601427316666, accuracy: 98.3 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.051245056092739105, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.0518, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.1255, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.0574, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.2553, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.0583, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.0597, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.0600, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.1374, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.06852979958057404, accuracy: 97.8 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 1.294463872909546, accuracy: 77.6 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.06721372902393341, accuracy: 97.5 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.06721372902393341, accuracy: 97.5 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.09925001114606857, accuracy: 96.1 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.06213290989398956, accuracy: 97.8 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.06095477193593979, accuracy: 98.1 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.06383132189512253, accuracy: 97.9 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.06049232929944992, accuracy: 98.2 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.05929017812013626, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.0670, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.0755, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.0714, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.0551, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.0622, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.1688, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.0944, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.1449, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.1490, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.1373, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.08725089579820633, accuracy: 97.1 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.10411520302295685, accuracy: 96.5 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.07285401970148087, accuracy: 97.9 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.08192408829927444, accuracy: 97.1 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.07562275975942612, accuracy: 97.6 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.08506707847118378, accuracy: 96.7 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.05832003057003021, accuracy: 98.2 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.055730272084474564, accuracy: 98.3 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.054339613765478134, accuracy: 98.5 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.05337342619895935, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.1303, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.1433, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.0787, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.1395, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.0775, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.1767, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.0663, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.1364, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.1077, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.1545, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.09293601661920547, accuracy: 96.9 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.09176771342754364, accuracy: 96.8 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.09802892059087753, accuracy: 96.4 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.07976844161748886, accuracy: 97.2 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.083613820374012, accuracy: 96.8 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.07420023530721664, accuracy: 97.1 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.10072316229343414, accuracy: 96.3 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.1259799301624298, accuracy: 96.1 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.08313161134719849, accuracy: 97.3 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.0690419003367424, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.0428, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.1249, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.0401, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.0384, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.0911, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.0315, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.0523, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.0874, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.1163, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.0678, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.0896885022521019, accuracy: 97.1 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.08346261084079742, accuracy: 97.4 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.07788211852312088, accuracy: 97.4 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.07788211852312088, accuracy: 97.4 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.11353813111782074, accuracy: 95.8 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.06777770072221756, accuracy: 97.9 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.11724796146154404, accuracy: 95.7 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.06090114638209343, accuracy: 98.4 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.05898672714829445, accuracy: 98.3 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.05776569992303848, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.0841, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.1031, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.0495, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.1277, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.0707, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.0720, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.0662, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.1012, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.1493, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.0590, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.07676985114812851, accuracy: 97.2 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.07504410296678543, accuracy: 97.3 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.07113494724035263, accuracy: 97.8 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.06944294273853302, accuracy: 97.4 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.11637602746486664, accuracy: 96.0 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.10739956796169281, accuracy: 96.3 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.1038283109664917, accuracy: 95.8 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.059378333389759064, accuracy: 97.9 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.05880684405565262, accuracy: 98.1 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.05736345425248146, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.0851, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.0416, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.1171, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.1620, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.0991, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.0974, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.1513, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.0906, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.0496, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.0843, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.061429712921381, accuracy: 98.2 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.062096621841192245, accuracy: 98.3 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.06014440208673477, accuracy: 98.1 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.06672003120183945, accuracy: 98.0 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.060888517647981644, accuracy: 98.2 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.05617625638842583, accuracy: 98.3 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.05706062912940979, accuracy: 98.4 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.05479077249765396, accuracy: 98.1 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.05520687997341156, accuracy: 98.6 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.05479030683636665, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.1196, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.0939, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.0608, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.0859, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.0657, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.0737, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.0646, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.0726, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.0720, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.1968, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.1230972558259964, accuracy: 95.1 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 3.3782706260681152, accuracy: 51.5 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.11030013859272003, accuracy: 95.4 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.10436755418777466, accuracy: 96.3 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.10278604924678802, accuracy: 96.4 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.12046047300100327, accuracy: 95.9 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.13174311816692352, accuracy: 95.7 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.09869740903377533, accuracy: 96.6 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.09569653123617172, accuracy: 96.9 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.09537777304649353, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.0379, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.1364, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.0964, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.0364, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.1216, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.0955, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.1195, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0743, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.1151, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.0579, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.09417954832315445, accuracy: 96.6 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.11098501086235046, accuracy: 95.6 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.08412957191467285, accuracy: 96.8 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.08082063496112823, accuracy: 96.9 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.08090087026357651, accuracy: 97.4 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.07556042820215225, accuracy: 97.3 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.07312512397766113, accuracy: 97.1 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.07023332267999649, accuracy: 97.5 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.06874136626720428, accuracy: 97.5 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.06894074380397797, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.0856, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.0673, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.0810, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.0783, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.1067, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.0682, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.1862, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.0418, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.0804, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.1686, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.08075913041830063, accuracy: 97.2 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.9058393239974976, accuracy: 68.9 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.07584691792726517, accuracy: 97.7 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.07165780663490295, accuracy: 97.6 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.09586817771196365, accuracy: 96.8 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.068015456199646, accuracy: 97.5 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.11681830883026123, accuracy: 95.7 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.06386548280715942, accuracy: 97.9 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.062360286712646484, accuracy: 98.0 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.06285961717367172, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.1191, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.0877, batch time: 0.12, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.0386, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.1256, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.0911, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.0944, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.0368, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.1172, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.0976, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.2390, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.11387792229652405, accuracy: 95.4 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.12635575234889984, accuracy: 95.3 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.09588940441608429, accuracy: 97.1 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.09588940441608429, accuracy: 97.1 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.11546716839075089, accuracy: 95.6 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.09168188273906708, accuracy: 97.0 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.1398799568414688, accuracy: 95.6 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.1419205367565155, accuracy: 95.2 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.11664414405822754, accuracy: 95.7 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.08751551806926727, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.1224, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.0812, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.0797, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.1793, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.0348, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.1814, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.1373, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.1720, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.0938, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.1838, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.07163716852664948, accuracy: 97.7 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.07130714505910873, accuracy: 97.7 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.06425893306732178, accuracy: 98.0 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.06345581263303757, accuracy: 98.1 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.09225814044475555, accuracy: 96.9 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.11132259666919708, accuracy: 96.5 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.0668453574180603, accuracy: 97.8 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.06470247358083725, accuracy: 98.0 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.06285939365625381, accuracy: 97.9 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.06606177240610123, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.1019, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.1177, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.0801, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.0938, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.0563, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.0703, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.0830, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.0381, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.0823, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.1064, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.08145452290773392, accuracy: 98.0 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.09854771941900253, accuracy: 97.2 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.07020667940378189, accuracy: 97.6 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.06938323378562927, accuracy: 97.8 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.06742627173662186, accuracy: 98.0 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.07843499630689621, accuracy: 98.0 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.06209927797317505, accuracy: 98.4 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.0786682739853859, accuracy: 97.3 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.06011783704161644, accuracy: 98.5 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.05880458652973175, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.0426, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.1406, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.0615, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.1335, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.0607, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.0537, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.0584, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.1160, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.0551, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.1743, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.1039811447262764, accuracy: 95.9 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.10397681593894958, accuracy: 96.1 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.10364113003015518, accuracy: 96.1 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.09751032292842865, accuracy: 96.1 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.09715107083320618, accuracy: 96.3 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.09497581422328949, accuracy: 96.3 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.0944582000374794, accuracy: 96.2 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.09547024220228195, accuracy: 95.7 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.13904234766960144, accuracy: 94.2 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.08845075219869614, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.1383, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.1506, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.0409, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.2450, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.0775, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.0566, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.0423, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.0858, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.1521, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.0707, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.11033794283866882, accuracy: 96.1 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.23829929530620575, accuracy: 91.5 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.10701431334018707, accuracy: 96.2 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.09626565128564835, accuracy: 96.4 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.09913995116949081, accuracy: 96.6 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.1193169578909874, accuracy: 95.8 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.09326524287462234, accuracy: 97.0 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.09352438896894455, accuracy: 96.9 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.09819257259368896, accuracy: 96.9 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.12492960691452026, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.0596, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.0407, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.0735, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.0870, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.1647, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.1087, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.0964, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.1405, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.1072, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.1526, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.07391390204429626, accuracy: 97.7 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 2.1264848709106445, accuracy: 65.0 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.06565139442682266, accuracy: 98.0 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.06540985405445099, accuracy: 98.2 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.061866533011198044, accuracy: 97.8 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.05462673306465149, accuracy: 98.4 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.07877340912818909, accuracy: 97.3 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.05118683725595474, accuracy: 98.7 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.10509023070335388, accuracy: 96.3 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.04577101022005081, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.1181, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.0997, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.0620, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.0784, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.0773, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.1010, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.0410, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.0456, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.0459, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.1741, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.09311994165182114, accuracy: 97.3 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.08925116062164307, accuracy: 97.3 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.08594496548175812, accuracy: 97.4 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.08554033190011978, accuracy: 97.2 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.12014792114496231, accuracy: 95.6 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.08396518230438232, accuracy: 96.9 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.0754360780119896, accuracy: 97.7 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.073824442923069, accuracy: 97.3 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.07152821123600006, accuracy: 97.6 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.06978534907102585, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.1293, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.0618, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.1118, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.0435, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.1169, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.1278, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.1110, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.1051, batch time: 0.36, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.0924, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.1127, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.06340007483959198, accuracy: 98.0 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.06296157091856003, accuracy: 98.3 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.05966895446181297, accuracy: 98.5 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.0590103454887867, accuracy: 98.4 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.06875215470790863, accuracy: 97.8 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.07889125496149063, accuracy: 96.9 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.0964294895529747, accuracy: 96.9 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.10511205345392227, accuracy: 96.6 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.06986170262098312, accuracy: 97.9 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.13243243098258972, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.0419, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.1239, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.1564, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.0535, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.1251, batch time: 0.35, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.0577, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.1036, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.0656, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.0779, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.08002405613660812, accuracy: 97.3 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.07853008806705475, accuracy: 97.5 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.08633501082658768, accuracy: 96.5 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.07188902795314789, accuracy: 97.6 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.07144392281770706, accuracy: 97.8 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.06256908178329468, accuracy: 98.2 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.08193667232990265, accuracy: 97.8 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.07225725799798965, accuracy: 97.7 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.06906713545322418, accuracy: 98.0 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.06221083179116249, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.0927, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.0961, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0841, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.1437, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.1210, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.1541, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.0763, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.1120, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0921, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.0935, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.06728985905647278, accuracy: 97.6 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.0706026554107666, accuracy: 97.5 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.06309985369443893, accuracy: 97.6 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.06258410215377808, accuracy: 97.7 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.06072382628917694, accuracy: 97.7 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.059048205614089966, accuracy: 98.0 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.056057218462228775, accuracy: 98.0 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.06433290988206863, accuracy: 98.0 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.05573377013206482, accuracy: 97.9 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.05502450466156006, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.0396, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.1386, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.1028, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.0429, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.0467, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.0677, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.1141, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.1338, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.0629, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.0632, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.07908729463815689, accuracy: 96.7 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.08234976977109909, accuracy: 96.8 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.12642739713191986, accuracy: 96.0 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.07445486634969711, accuracy: 97.0 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.09044839441776276, accuracy: 96.6 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.06286706030368805, accuracy: 98.0 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.052541594952344894, accuracy: 98.3 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.04829370975494385, accuracy: 98.6 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.04836491495370865, accuracy: 98.3 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.047256145626306534, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.1073, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.0693, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.1134, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.0339, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.1022, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.1340, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.1579, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.0845, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.0621, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.0442, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.09891519695520401, accuracy: 96.5 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.19142985343933105, accuracy: 94.2 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.09578555822372437, accuracy: 96.4 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.10449818521738052, accuracy: 96.8 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.0898091271519661, accuracy: 97.0 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.07825110852718353, accuracy: 97.6 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.07744240760803223, accuracy: 97.3 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.0749543085694313, accuracy: 97.5 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.07443512231111526, accuracy: 97.6 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.0756019726395607, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.1148, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.1201, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.0616, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.1047, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.0423, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.1846, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.1108, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.1020, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.2000, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.0870, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.09860425442457199, accuracy: 96.1 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.09941450506448746, accuracy: 95.8 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.09548630565404892, accuracy: 95.9 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.0881582722067833, accuracy: 96.3 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.1229931116104126, accuracy: 95.2 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.21984517574310303, accuracy: 93.6 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.10780578851699829, accuracy: 95.7 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.07488276809453964, accuracy: 96.7 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.07879152148962021, accuracy: 96.7 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.12955138087272644, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.0875, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.0441, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.0707, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.0438, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.1241, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.1037, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.0978, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.1078, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.1224, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.0564, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.06984893232584, accuracy: 97.7 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.06944909691810608, accuracy: 97.4 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.06867381930351257, accuracy: 97.6 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.06850606203079224, accuracy: 98.0 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.11106565594673157, accuracy: 95.6 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.07902353256940842, accuracy: 97.4 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.0646466463804245, accuracy: 97.9 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.05984890088438988, accuracy: 98.4 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.05856901779770851, accuracy: 98.4 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.05687929317355156, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.1168, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.1320, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.0530, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.0806, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.0604, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.0834, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.1438, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.1180, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.0882, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.1130, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.07590342313051224, accuracy: 97.9 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.07734989374876022, accuracy: 97.6 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.10216700285673141, accuracy: 96.5 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.07379376143217087, accuracy: 97.8 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.08045247942209244, accuracy: 97.3 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.10150294005870819, accuracy: 96.8 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.09025789797306061, accuracy: 96.8 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.0661095455288887, accuracy: 97.8 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.06290329247713089, accuracy: 98.1 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.06061630696058273, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.0611, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.1266, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.1109, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.1099, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0659, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.0942, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.0960, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.1205, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.1767, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.0577, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.06833899766206741, accuracy: 97.6 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.06725315004587173, accuracy: 97.5 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.06529517471790314, accuracy: 97.5 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.06312955170869827, accuracy: 97.8 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.06942251324653625, accuracy: 97.7 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.06238197162747383, accuracy: 97.5 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.05841007083654404, accuracy: 98.2 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.05702104791998863, accuracy: 98.0 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.05787614360451698, accuracy: 98.0 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.057769738137722015, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.0340, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.2243, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.0696, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.0673, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.1040, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.0965, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.0356, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.1662, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.0808, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.1239, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.12127699702978134, accuracy: 95.6 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.21803072094917297, accuracy: 91.8 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.11280469596385956, accuracy: 96.3 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.13407506048679352, accuracy: 95.2 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.10269444435834885, accuracy: 97.2 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.10099655389785767, accuracy: 97.4 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.10029762983322144, accuracy: 97.5 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.0984913557767868, accuracy: 97.3 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.09731041640043259, accuracy: 97.2 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.09596391767263412, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.0710, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.0661, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.1604, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.1281, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.0282, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.1233, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.0678, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.1675, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.0907, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.0575, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.0716993659734726, accuracy: 97.7 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 1.5692099332809448, accuracy: 72.1 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.07519866526126862, accuracy: 97.3 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.0686803087592125, accuracy: 97.4 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.08957622945308685, accuracy: 96.9 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.0778864398598671, accuracy: 97.4 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.06499253213405609, accuracy: 97.6 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.0631602555513382, accuracy: 97.7 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.06223784759640694, accuracy: 97.7 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.06295705586671829, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.1162, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.0102, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.0837, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.0544, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.0767, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.0973, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.0637, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.0775, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.0937, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.06461001187562943, accuracy: 97.6 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.06451497972011566, accuracy: 97.6 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.06193890795111656, accuracy: 98.1 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.060139965265989304, accuracy: 98.1 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.09619921445846558, accuracy: 96.8 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.10914917290210724, accuracy: 96.3 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.07008294761180878, accuracy: 97.7 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.054816391319036484, accuracy: 98.5 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.053406357765197754, accuracy: 98.4 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.052958011627197266, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.1552, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.1146, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.0560, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.0787, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.0309, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.2092, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.0433, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.2350, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.1228, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.0521, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.05932490527629852, accuracy: 97.9 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.6696357727050781, accuracy: 56.6 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.05470827966928482, accuracy: 98.3 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.05762050300836563, accuracy: 98.3 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.0637182965874672, accuracy: 97.8 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.05441594868898392, accuracy: 98.6 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.05386603996157646, accuracy: 98.4 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.058332618325948715, accuracy: 98.1 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.04339923709630966, accuracy: 99.1 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.042168907821178436, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.0865, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.1157, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.1384, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.1010, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.0465, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.0586, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.0678, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.0683, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.1485, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.0711, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.06641551107168198, accuracy: 97.3 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.09974796324968338, accuracy: 96.5 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.06502364575862885, accuracy: 97.8 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.08403372764587402, accuracy: 96.7 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.05845685303211212, accuracy: 97.9 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.05679361894726753, accuracy: 97.9 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.05901187285780907, accuracy: 98.2 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.057635143399238586, accuracy: 97.9 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.0574723519384861, accuracy: 97.8 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.05374062433838844, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.1466, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.1029, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.0559, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.0533, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.1736, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.1175, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.0554, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.1181, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.1125, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.0669, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.060892313718795776, accuracy: 98.0 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.05993591994047165, accuracy: 97.8 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.1275445818901062, accuracy: 95.3 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.0580432265996933, accuracy: 98.1 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.0676540657877922, accuracy: 97.7 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.06054751202464104, accuracy: 97.7 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.06507685035467148, accuracy: 97.8 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.0688743069767952, accuracy: 97.5 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.0723629891872406, accuracy: 97.5 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.12857869267463684, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.0490, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.0684, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.1145, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.0754, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.1224, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.1029, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.0750, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.0804, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.0792, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.0605, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.08583100885152817, accuracy: 97.1 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.08387444168329239, accuracy: 96.9 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.08570047467947006, accuracy: 97.1 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.07847264409065247, accuracy: 97.1 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.1029960960149765, accuracy: 96.6 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.09919185191392899, accuracy: 96.3 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.09176971763372421, accuracy: 96.1 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.0745646134018898, accuracy: 97.5 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.07168883830308914, accuracy: 98.0 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.07082153111696243, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.1161, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.1069, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.0484, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.0999, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.0594, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.1097, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.0270, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.0485, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.0753, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.0766, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.059670332819223404, accuracy: 98.1 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 1.1045002937316895, accuracy: 73.0 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.05308736115694046, accuracy: 98.4 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.07688702642917633, accuracy: 97.6 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.05157191678881645, accuracy: 98.5 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.06606417149305344, accuracy: 97.9 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.06549743562936783, accuracy: 98.1 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.05221936106681824, accuracy: 97.9 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.07440926879644394, accuracy: 97.6 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.05334889516234398, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.0726, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.2008, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.0133, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.1805, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.0653, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.0783, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.1569, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.0725, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.0234, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.0800, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.05059277266263962, accuracy: 98.5 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 6.903705596923828, accuracy: 31.0 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.056766752153635025, accuracy: 98.3 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.04618751257658005, accuracy: 98.6 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.05514981597661972, accuracy: 98.3 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.06960449367761612, accuracy: 96.9 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.06504692882299423, accuracy: 97.9 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.06087091192603111, accuracy: 98.1 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.050670087337493896, accuracy: 98.3 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.04793666675686836, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.1232, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.0831, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.0612, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.0413, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.1728, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.1105, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.0604, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.1029, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.0382, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.1180, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.08113189041614532, accuracy: 96.8 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.07884972542524338, accuracy: 96.9 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.07795298099517822, accuracy: 97.1 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.0762220025062561, accuracy: 97.0 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.10631822049617767, accuracy: 96.0 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.11819852143526077, accuracy: 96.5 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.09187091141939163, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.08145010471343994, accuracy: 97.3 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.1027618870139122, accuracy: 96.7 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.061735548079013824, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.0586, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.1026, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.1173, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.0980, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.1449, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.1301, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.1905, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.1945, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.0512, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.0871, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.06626337766647339, accuracy: 97.9 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.48504638671875, accuracy: 72.4 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.07020536810159683, accuracy: 97.7 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.062175750732421875, accuracy: 98.1 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.09972640872001648, accuracy: 96.8 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.09075538069009781, accuracy: 96.9 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.1416151523590088, accuracy: 95.4 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.10163886100053787, accuracy: 96.6 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.05789924040436745, accuracy: 98.2 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.05326923727989197, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.0416, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.0755, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.1008, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.0731, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.1051, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.0389, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.1134, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.1130, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.0271, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.0662, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.0797339603304863, accuracy: 97.1 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.07612849771976471, accuracy: 97.5 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.07587599009275436, accuracy: 98.0 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.06539548933506012, accuracy: 98.0 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.10403819382190704, accuracy: 96.3 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.0624023862183094, accuracy: 98.0 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.061958398669958115, accuracy: 97.9 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.05926021561026573, accuracy: 98.1 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.06158651411533356, accuracy: 98.0 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.05734240636229515, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.1268, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.0345, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.1220, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.0578, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.0822, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.0188, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.1603, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.0686, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.0506, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.1059, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.07198717445135117, accuracy: 97.9 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.13098260760307312, accuracy: 95.7 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.07566513866186142, accuracy: 97.7 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.06269598752260208, accuracy: 98.1 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.08955840766429901, accuracy: 97.1 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.06117402762174606, accuracy: 98.4 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.06049644201993942, accuracy: 98.2 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.058961644768714905, accuracy: 98.6 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.058318283408880234, accuracy: 98.6 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.05758288875222206, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.0832, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.0812, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.0769, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.0749, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.0411, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.1187, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.0801, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.0867, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.0480, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.0792, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.12545081973075867, accuracy: 94.7 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.12436909973621368, accuracy: 95.3 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.11809881776571274, accuracy: 95.2 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.11270450800657272, accuracy: 95.6 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.09608108550310135, accuracy: 96.4 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.11576511710882187, accuracy: 95.5 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.08929259330034256, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.0876760259270668, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.08879794925451279, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.08526471257209778, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.0797, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.1356, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.0952, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.0704, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.0655, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.0552, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.1074, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.1149, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.1423, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.07482361048460007, accuracy: 98.2 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 0.07632486522197723, accuracy: 98.0 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.0697726234793663, accuracy: 98.1 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.0690729022026062, accuracy: 98.2 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.09364714473485947, accuracy: 97.0 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.07841887325048447, accuracy: 97.7 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.06618257611989975, accuracy: 98.0 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.06620416045188904, accuracy: 98.0 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.06055600568652153, accuracy: 98.4 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.06237262487411499, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.0704, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.1564, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.0571, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.0926, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.1175, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.0413, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.0317, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.1039, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.0876, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.0772, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.06844364106655121, accuracy: 97.8 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 1.3565231561660767, accuracy: 74.7 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.10386498272418976, accuracy: 96.3 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.066427081823349, accuracy: 97.7 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.06302434951066971, accuracy: 97.9 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.09581618010997772, accuracy: 97.1 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.0840936079621315, accuracy: 97.1 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.07547511905431747, accuracy: 97.2 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.05518524348735809, accuracy: 98.3 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.05375058948993683, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.0622, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.0804, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.0602, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.0768, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.1204, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.0623, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.0944, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.1557, batch time: 0.07, accuracy:  95.31%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.0554, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.0379, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.07227208465337753, accuracy: 97.3 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.07249178737401962, accuracy: 97.0 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.08138228207826614, accuracy: 96.8 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.07064128667116165, accuracy: 97.7 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.0810125544667244, accuracy: 97.3 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.0677584633231163, accuracy: 97.8 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.06840262562036514, accuracy: 97.7 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.0655476525425911, accuracy: 97.7 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.0737130343914032, accuracy: 97.3 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.06353097409009933, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.0751, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.0765, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.0101, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.0967, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.0982, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.1208, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.0637, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.0578, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.0749, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.0614, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.07522069662809372, accuracy: 97.7 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.0762505829334259, accuracy: 97.7 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.07929303497076035, accuracy: 97.4 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.07192699611186981, accuracy: 97.9 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.07106444239616394, accuracy: 97.9 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.11163484305143356, accuracy: 95.6 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.07674887776374817, accuracy: 97.5 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.07481878995895386, accuracy: 97.6 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.07205850630998611, accuracy: 97.8 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.07284551113843918, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.1089, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.0441, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.0951, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.0339, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0816, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.1573, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.0583, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.0713, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.0975, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.0685596689581871, accuracy: 97.5 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.2141222059726715, accuracy: 92.9 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.06359674036502838, accuracy: 97.7 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.061740752309560776, accuracy: 97.8 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.061721932142972946, accuracy: 97.7 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.05940406769514084, accuracy: 98.2 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.056589458137750626, accuracy: 98.1 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.05694420263171196, accuracy: 98.2 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.057295165956020355, accuracy: 98.3 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.05564802512526512, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0634, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.0805, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.0963, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.1179, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.1075, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.1121, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.1430, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.0585, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.1286, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.06222439929842949, accuracy: 98.0 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 1.6128721237182617, accuracy: 69.3 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.05921591818332672, accuracy: 98.1 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.057190991938114166, accuracy: 98.3 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.1212821900844574, accuracy: 95.4 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.08923421800136566, accuracy: 96.9 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.054415952414274216, accuracy: 98.0 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.0536075234413147, accuracy: 98.7 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.05241887643933296, accuracy: 98.5 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.051658112555742264, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.1043, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.0815, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.0349, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.0571, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.0633, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.0660, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.2120, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.0473, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.0867, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.0952, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.06297009438276291, accuracy: 98.4 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.1819872111082077, accuracy: 94.2 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.0626625195145607, accuracy: 97.6 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.055605724453926086, accuracy: 98.1 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.055768296122550964, accuracy: 97.9 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.08531836420297623, accuracy: 96.6 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.05488962307572365, accuracy: 98.2 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.05674537643790245, accuracy: 98.2 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.04885729402303696, accuracy: 98.7 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.04739464446902275, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.0509, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.1111, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.0755, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.0715, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.0783, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.0987, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.0816, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.0623, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.0727, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.1006, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.07625754177570343, accuracy: 97.2 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.07722224295139313, accuracy: 97.4 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.07437373697757721, accuracy: 97.2 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.07326553761959076, accuracy: 97.7 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.07627514004707336, accuracy: 97.1 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.06622406095266342, accuracy: 97.6 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.05908363685011864, accuracy: 97.9 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.0561428926885128, accuracy: 97.9 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.05609717592597008, accuracy: 98.1 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.05558168888092041, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.0426, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.0943, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.0294, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.1321, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.1213, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.2052, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.0945, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1129, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.0198, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.1009, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.07926926761865616, accuracy: 97.4 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.07918685674667358, accuracy: 97.4 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.07352977991104126, accuracy: 97.6 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.07186582684516907, accuracy: 97.5 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.17633993923664093, accuracy: 95.2 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.08380836993455887, accuracy: 97.6 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.13498836755752563, accuracy: 94.7 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.062161676585674286, accuracy: 98.1 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.06104915216565132, accuracy: 98.3 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.06189684197306633, accuracy: 97.9 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8iklEQVR4nO29eXxcdb3//5p9MtnTNEvbdKULpbSFlpaCoEihIIJcN0QERAXF4kWrXigKuJfrgvzuvUgVrXC/iuACeGVTKBTElhZaytKN7nvSpmn2ZNbz++PM53M+58yZLZlkkszr+XjkAZ31nDnL5/V5vZePQ9M0DYQQQgghecKZ7w0ghBBCSGFDMUIIIYSQvEIxQgghhJC8QjFCCCGEkLxCMUIIIYSQvEIxQgghhJC8QjFCCCGEkLxCMUIIIYSQvOLO9wZkQiwWw5EjR1BaWgqHw5HvzSGEEEJIBmiaho6ODowZMwZOZ3L/Y1iIkSNHjqChoSHfm0EIIYSQPnDw4EGMGzcu6fPDQoyUlpYC0HemrKwsz1tDCCGEkExob29HQ0ODHMeTMSzEiAjNlJWVUYwQQgghw4x0KRZMYCWEEEJIXqEYIYQQQkheoRghhBBCSF6hGCGEEEJIXqEYIYQQQkheoRghhBBCSF6hGCGEEEJIXqEYIYQQQkheoRghhBBCSF6hGCGEEEJIXqEYIYQQQkheoRghhBBCSF4ZFgvlDRS//uceHDrZg6sXjMf0utQrChJCCCFkYChoZ+Tpd47iobX7sP9EV743hRBCCClYClqMuJ36ksbRmJbnLSGEEEIKlwIXI/ruhylGCCGEkLxR2GLEJZyRWJ63hBBCCClcCluMxMM04SidEUIIISRfFLYYcem7z5wRQgghJH8UthiJOyORKMM0hBBCSL4obDESd0YidEYIIYSQvFHYYkQ6IxQjhBBCSL6gGAGdEUIIISSfFLYYcTFnhBBCCMk3hS1GnMwZIYQQQvJNQYsRlwzT0BkhhBBC8kVBixGPizkjhBBCSL4paDHiEmEaVtMQQggheaOgxYjHxVV7CSGEkHxT0GLEJdemYc4IIYQQki8KWox4uDYNIYQQkncKWoy4uGovIYQQkncKWoyIDqxRlvYSQggheYNiBECYYRpCCCEkbxS2GBGr9jKBlRBCCMkbhS1GnCztJYQQQvJNYYuRuDPCBFZCCCEkfxS2GKEzQgghhOSdwhYjLjY9I4QQQvJNYYsROiOEEEJI3ilwMRLPGaEYIYQQQvJGYYsRF5ueEUIIIfmmsMWIU/QZoTNCCCGE5IvCFiNxZyTCMA0hhBCSNwpbjMQTWNmBlRBCCMkfhS1GRDt4OiOEEEJI3ihsMSKdEYoRQgghJF8UthhhzgghhBCSdwpbjAhnhKW9hBBCSN4ocDGi736UYRpCCCEkbxS0GHHFnZEwnRFCCCEkbxS0GPHEq2m4Ng0hhBCSPwpajEhnJKpB0yhICCGEkHxQ0GLEE6+mAQCaI4QQQkh+KGgxIpwRAAizCyshhBCSFwpajIicEYB5I4QQQki+6JMYuf/++zFx4kT4/X4sXLgQGzZsSPn6++67D9OnT0dRUREaGhrwta99Db29vX3a4FyiOiPswkoIIYTkh6zFyGOPPYZly5bh7rvvxqZNmzBnzhwsWbIEx44ds339I488gttvvx133303tm3bht/85jd47LHHcMcdd/R74/uLWxUjLO8lhBBC8kLWYuTee+/FjTfeiBtuuAEzZ87EypUrEQgEsGrVKtvXr127Fueeey4+/elPY+LEibj44otx9dVXp3VTBgOHwyHdEbaEJ4QQQvJDVmIkFAph48aNWLx4sfEBTicWL16MdevW2b7nnHPOwcaNG6X42LNnD5555hl86EMfSvo9wWAQ7e3tpr+Bwk0xQgghhOQVdzYvbm5uRjQaRW1trenx2tpabN++3fY9n/70p9Hc3Iz3ve990DQNkUgEX/rSl1KGaVasWIHvfve72Wxan3E7HQgCiLCahhBCCMkLA15Ns2bNGvzoRz/CL37xC2zatAmPP/44nn76aXz/+99P+p7ly5ejra1N/h08eHDAts8dr6ihM0IIIYTkh6yckerqarhcLjQ1NZkeb2pqQl1dne177rzzTlx77bX4whe+AAA4/fTT0dXVhZtuugnf+ta34HQm6iGfzwefz5fNpvUZGaZhNQ0hhBCSF7JyRrxeL+bNm4fVq1fLx2KxGFavXo1FixbZvqe7uztBcLhcLgAYEi3Y3S7REp5hGkIIISQfZOWMAMCyZctw/fXXY/78+ViwYAHuu+8+dHV14YYbbgAAXHfddRg7dixWrFgBALj88stx77334owzzsDChQuxa9cu3Hnnnbj88sulKMknbicXyyOEEELySdZi5KqrrsLx48dx1113obGxEXPnzsVzzz0nk1oPHDhgckK+/e1vw+Fw4Nvf/jYOHz6M0aNH4/LLL8cPf/jD3O1FPxDOCPuMEEIIIfnBoQ2FWEka2tvbUV5ejra2NpSVleX0sy/82RrsPt6Fx246Gwsnj8rpZxNCCCGFTKbjd0GvTQMYYRpW0xBCCCH5gWLExaZnhBBCSD6hGJGlvcwZIYQQQvIBxQibnhFCCCF5peDFiItNzwghhJC8UvBixMPSXkIIISSvFLwYcYlqGjojhBBCSF4oeDHiiYdp2IGVEEIIyQ8FL0ZEzkiYYRpCCCEkLxS8GPG4uDYNIYQQkk8KXoxIZ4Q5I4QQQkheKHgxIjqwRhmmIYQQQvICxQidEUIIISSvUIwwZ4QQQgjJKxQjXJuGEEIIySsUI06uTUMIIYTkE4oR2Q6eYoQQQgjJBxQjXCiPEEIIySsUI04ulEcIIYTkE4oRF3NGCCGEkHxS8GLExWoaQgghJK8UvBjxMIGVEEIIySsFL0ZcorSXCayEEEJIXih4MeKRa9NQjBBCCCH5oODFiLFqL3NGCCGEkHxQ8GLEww6shBBCSF4peDHCDqyEEEJIfil4McLSXkIIISS/FLwY8bDpGSGEEJJXCl6M0BkhhBBC8kvBixGW9hJCCCH5peDFiGh6FmbTM0IIISQvFLwY8TjpjBBCCCH5pODFiGx6FmPOCCGEEJIPCl6MuOPVNHRGCCGEkPxAMSKraShGCCGEkHxAMSI7sDJMQwghhOQDihGxNg2dEUIIISQvUIxwbRpCCCEkr1CMsAMrIYQQklcoRrg2DSGEEJJXKEacDNMQQggh+YRiROnAqmkUJIQQQshgQzHiNH4CuiOEEELI4EMxEq+mAdiFlRBCCMkHBS9GxNo0ABBmRQ0hhBAy6BS8GPG4jJ+AzgghhBAy+BS8GFGMEYTZhZUQQggZdApejDgcDnhcRkUNIYQQQgaXghcjgJE3wpwRQgghZPChGAHgiZf30hkhhBBCBh+KEaiL5dEZIYQQQgYbihEALifXpyGEEELyBcUIIBNYI6ymIYQQQgYdihEwgZUQQgjJJxQjMBqfMYGVEEIIGXwoRqA6IxQjhBBCyGBDMQLA7WTTM0IIISRfUIzAKO0Ns7SXEEIIGXQoRgC4RdMzhmkIIYSQQYdiBEaYxq7p2ZYjbfjZP3agOxQZ7M0ihBBCCgKKEagdWBOdkf/vhZ347xd34YVtxwZ7swghhJCCgGIERpjGrulZe28YANAVpDNCCCGEDAR9EiP3338/Jk6cCL/fj4ULF2LDhg0pX9/a2oqlS5eivr4ePp8P06ZNwzPPPNOnDR4IUjkjoYgeuomwIRohhBAyILizfcNjjz2GZcuWYeXKlVi4cCHuu+8+LFmyBDt27EBNTU3C60OhEC666CLU1NTgz3/+M8aOHYv9+/ejoqIiF9ufE2TOiI3gEL1H2IOEEEIIGRiyFiP33nsvbrzxRtxwww0AgJUrV+Lpp5/GqlWrcPvttye8ftWqVWhpacHatWvh8XgAABMnTuzfVucYd4qF8qQzwrJfQgghZEDIKkwTCoWwceNGLF682PgApxOLFy/GunXrbN/zf//3f1i0aBGWLl2K2tpazJo1Cz/60Y8QjUaTfk8wGER7e7vpbyBxuZI7I6H4Y3RGCCGEkIEhKzHS3NyMaDSK2tpa0+O1tbVobGy0fc+ePXvw5z//GdFoFM888wzuvPNO/OxnP8MPfvCDpN+zYsUKlJeXy7+GhoZsNjNrPM5MckYoRgghhJCBYMCraWKxGGpqavCrX/0K8+bNw1VXXYVvfetbWLlyZdL3LF++HG1tbfLv4MGDA7qNrhRhmiDDNIQQQsiAklXOSHV1NVwuF5qamkyPNzU1oa6uzvY99fX18Hg8cLlc8rFTTz0VjY2NCIVC8Hq9Ce/x+Xzw+XzZbFq/8LiSr00TiujhJIZpCCGEkIEhK2fE6/Vi3rx5WL16tXwsFoth9erVWLRoke17zj33XOzatQsxxVl47733UF9fbytE8oGxam/ynBGW9hJCCCEDQ9ZhmmXLluHBBx/Eww8/jG3btuHmm29GV1eXrK657rrrsHz5cvn6m2++GS0tLbj11lvx3nvv4emnn8aPfvQjLF26NHd70U88rvjaNCmraeiMEEIIIQNB1qW9V111FY4fP4677roLjY2NmDt3Lp577jmZ1HrgwAE4nYbGaWhowN///nd87Wtfw+zZszF27FjceuutuO2223K3F/3EcEbMgiMSjUFoEDvXhBBCCCH9J2sxAgC33HILbrnlFtvn1qxZk/DYokWL8Nprr/XlqwYFt8wZMQuOkCJAWE1DCCGEDAxcmwaAJ+7kvLTjOF7f1yIfD0cMARJmNQ0hhBAyIFCMADh/2mgEvC7sOtaJT6xch/98bjsAIKg0ZqMzQgghhAwMFCMAFkyqwppvfAD/dsZYAMBz7+oN3ETyKsA+I4QQQshAQTESp6bMj8+dOwkA0BvWHRFVjLDPCCGEEDIwUIwo+Dz6zyG6rpoTWOmMEEIIIQMBxYiCzx0XIzbOCPuMEEIIIQMDxYiC36O3rO8VzogpTENnhBBCCBkIKEYUhDMSjWmIRGNmZ4Q5I4QQQsiAQDGi4HMbi/kFIzEEFTckzDANIYQQMiBQjCgIZwTQK2pMYZoIwzSEEELIQEAxouB0OuB1GRU1ap4I+4wQQgghAwPFiAW1vJc5I4QQQsjAQzFiQeSNJIRp6IwQQgghAwLFiAXZayQS46q9hBBCyCBAMWLBHw/TJDgjFCOEEELIgEAxYkGEaYKRmGwLDzCBlRBCCBkoKEYsyARWizPCMA0hhBAyMFCMWPC7jZbwas4I28ETQgghAwPFiIWkzgg7sBJCCCEDAsWIBVM1jSJGojENmkZBQgghhOQaihELcuXecDQhNMOKGkIIIST3UIxYSOaMAKyoIYQQQgYCihELwhmxrtoL0BkhhBBCBgKKEQvSGbEksAJAhBU1hBBCSM6hGLGgNj1LDNPQGSGEEEJyDcWIhWTt4AH2GiGEEEIGAooRCyZnJGoN09AZIYQQQnINxYgF2fQsYpMzwmoaQgghJOdQjFiQ7eDDiTkjrKYhhBBCcg/FiAWTM8IwDSGEEDLgUIxYMEp7E50RqzghhBBCSP+hGLHgE+3gbZ0RihFCCCEk11CMWLBzRtxOBwD2GSGEEEIGAooRC3ZNzwJe/TH2GSGEEEJyD8WIBVPTs7j4KPa5ATCBlRBCCBkIKEYsCGekJxRFNB6WEc4I+4wQQgghuYdixIJwRjpDEfmYcEbYZ4QQQgjJPRQjFoQzoim6o8hDZ4QQQggZKChGLIimZypFMoGVzgghhBCSayhGLIh28AKv2wmPS/+ZmMBKCCGE5B6KEQselwMOh/Fvn8sJj0v0GWGYhhBCCMk1FCMWHA6HbHwG6M6I26n/m2EaQgghJPdQjNjg9xihGq/bCbdwRtj0jBBCCMk5FCM2WJ0RT9wZYTt4QgghJPdQjNjgU5JYvS7DGWE7eEIIIST3UIzY4PdYnBFW0xBCCCEDBsWIDSZnxO2Uq/aGWU1DCCGE5ByKERtUZ8TjcsJNZ4QQQggZMChGbFCdEZ9b6TPCnBFCCCEk51CM2GCqpnEpfUZYTUMIIYTkHIoRG9hnhBBCCBk8KEZsSOgzIkt76YwQQgghuYZixAZ15V5TmIbOCCGEEJJzKEZssJb2GgmsdEYIIYSQXEMxYoPP0vRMlvayzwghhBCScyhGbEja9IzOCCGEEJJzKEZsUJue+VxKO3g6I4QQQkjOoRixQXVGPKaF8uiMEEIIIbmGYsQG60J5opqGfUYIIYSQ3EMxYkPSahp2YCWEEEJyDsWIDYlNz0SfEYoRQgghJNdQjNhgagfvYjt4QgghZCChGLEhmTPCMA0hhBCSe/okRu6//35MnDgRfr8fCxcuxIYNGzJ636OPPgqHw4Err7yyL187aKhixGfqMzKwzsiuYx340v/biK1H2gf0ewghhJChRNZi5LHHHsOyZctw9913Y9OmTZgzZw6WLFmCY8eOpXzfvn378I1vfAPnnXdenzd2sLCu2iudkQHOGfnzxsN4bksj/rzx0IB+DyGEEDKUyFqM3Hvvvbjxxhtxww03YObMmVi5ciUCgQBWrVqV9D3RaBTXXHMNvvvd72Ly5Mn92uDBwLxQnsvIGRngpmcnu0IAgGAkOqDfQwghhAwlshIjoVAIGzduxOLFi40PcDqxePFirFu3Lun7vve976Gmpgaf//znM/qeYDCI9vZ2099gktgOfnCqadp6wgC4IB8hhJDCIisx0tzcjGg0itraWtPjtbW1aGxstH3Pq6++it/85jd48MEHM/6eFStWoLy8XP41NDRks5n9Rm165nE5lFV7B9YZae3RnZEw284TQggpIAa0mqajowPXXnstHnzwQVRXV2f8vuXLl6OtrU3+HTx4cAC3MpEEZ0T0GRngapq2noj+PXRGCCGEFBDubF5cXV0Nl8uFpqYm0+NNTU2oq6tLeP3u3buxb98+XH755fKxWHzW73a7sWPHDkyZMiXhfT6fDz6fL5tNyymmhfLcTnicg+OMtHWHBuV7CCGEkKFEVs6I1+vFvHnzsHr1avlYLBbD6tWrsWjRooTXz5gxA++88w42b94s/6644gpccMEF2Lx586CHXzLF67ImsOr/jmlAbADdEZEzMtAlxIQQQshQIitnBACWLVuG66+/HvPnz8eCBQtw3333oaurCzfccAMA4LrrrsPYsWOxYsUK+P1+zJo1y/T+iooKAEh4fCjhdjlRXuRBR28YZUVuOOPOCKDnc/icrhTv7hvhaAxdoWj8/xmmIYQQUjhkLUauuuoqHD9+HHfddRcaGxsxd+5cPPfcczKp9cCBA3A6h39j119eOw9tPWFUBLzoCRmltuGoBl/Wv1p6hCuifwedEUIIIYVDn4bVW265Bbfccovtc2vWrEn53oceeqgvXznonD15lPx/0WcE6Hs+x9G2Hvxl4yF8euEEVBV7E55v7TbECEt7CSGEFBLD38IYBNxqmKaPQmHVq3vx03+8hz++YV8ZZHJGWNpLCCGkgKAYyQCHwyEFSV+7sLbHy3ZV0aHSFu8xAjBMQwghpLCgGMkQ2RK+j85IKC4wwhF7oaGKFIZpCCGEFBIUIxnikS3h++ZaCDESSvJ+NWck2WsIIYSQkQjFSIYYi+X1zbUQjkgyMUNnhBBCSKFCMZIhsiV8H10L8b5gkjCNuZqGzgghhJDCgWIkQ4yW8P3MGUnyftUZCdEZIYQQUkBQjGSIx63/VH2tpglHdIERikRtnzeFaVjaSwghpICgGMkQUdrb1z4j6ZyR1m6ltDdJKIcQQggZiVCMZIgnnjPS1zCNyBkJZVDaGx7AxfgIIYSQoQbFSIaIapq+dkcVIiRZ2S7XpiGEEFKoUIxkiNs5cM6IpmkmMaJpQJTuCCGEkAKBYiRDPLIDa19Le7X4fxPf3x2KJuSS0B0hhBBSKPRp1d5CRDgjfc3nMBJYDZFx55Pvwu1y4AvnTQYAOBy6KyJe5/e4+rHFhBBCyPCAYiRD3P10RmTOSPy/7b1h/L/X9gMAFk4aBQCoDHjR0hWKfw/DNIQQQgoDhmkyJFfVNCIc0xs2+o38Y0sjAKAy4EG8gphhGkIIIQUDxUiGyD4jfW16ZmkHryayvrCtCQBQEfAabeeZwEoIIaRAoBjJkP44I7GYlpDAqq5R094bAQCUF3ngld9DZ4QQQkhhQDGSIbLPSB9EguqmCEckGE78nIoiT7++hxBCCBmOUIxkiKym6YMzor5H9huxERtlRZ5+fQ8hhBAyHKEYyRC7PiMPrNmNpY9sStugTF1rJhLTEItpCIYTF8yrCHjgpTNCCCGkwKAYyRCjHbwhPFa+vBtPv30U7zV1pHyv1QUJRWOmnBFBeZHHSGClM0IIIaRAoBjJEKMdvC4iNE1DR6/ewr0rGEn5XmsL+FA0Jh+bWlMCV7xSpyLgkQ4MnRFCCCGFAsVIhsgwTdwZ6QlHIUySzjRixCoswhHDGaks9mLehEoAQENloN/9TAghhJDhBjuwZogRPtFFRGevIUC6Q4n5HyrWkIseptHf43M78eOPz8b2xg7Mm1CZcnXgnlAURV62iCeEEDKyoDOSIR6nSGDVhUWH4oZkG6YJRzT5mM/tRH15ES6YXgOHwyGdkbDlPT/5+3bM+e4/sOVIW/92hBBCCBliUIxkiHBGIrFEZyStGElIYI3KMI3PbXY6PCI3xVKh88a+kwhFY3j3MMUIIYSQkQXFSIYYzch0kaDmiXSlDdNYxEhEM4VpVDxu+wRWsZZNupAQIYQQMtygGMkQ4WAIR6MjC2ckQYwo1TReixhJ1vRMiBCKEUIIISMNipEMKfPrub7tPXo5r+qMpBMICTkjSp+RBGckydo0PXFnpIdihBBCyAiDYiRDyos8AIDWuBgRPUYAe2dk17FOHGntAWAXpjGcEZ/HkjOSpM+ICNN0hVK7MIQQQshwg2IkQ4QYkc6IGqaxCISO3jAu+69/4pO/XAcACNmW9sbDNC5LmCZJB1bhiNAZIYQQMtKgGMmQ8oAuRtpswjRdQbNAaO4MIRiJ4dDJHmialtiBNRJLnsBq44xomoZuJrASQggZoVCMZIhwRtp6wnoreFPOiNkZUd2LYCSW2IFVzRnxWMSITWlvMBKDponvohghhBAysqAYyRAhRqIxDV2hqClM02lxRnojxr97w1HbnJFkYRpR2qu6Kb3KCr89YeaMEEIIGVlQjGRIkcclhUNbT9hSTWMWCGbxELWvpgnbJ7DKBfmUdvCqG0JnhBBCyEiDYiRDHA4HykSopjts6cBqFghCaABAbziW2IE1YjyWLGdEXSivRxE33UGKEUIIISMLipEsKC/Se4209oRSrk1jckZCUYQj1moaDcH4a6xNz0SfEVXAqDko3QzTEEIIGWFQjGSBWt6r9hnpCUcRVRJOTTkjkdQ5I9a1aeQaOEmcEZb2EkIIGWlQjGSBWlHTaXFD1LyR3rA5+dSumiaUpAOr16a0t4c5I4QQQkYwFCNZYBIjvVYxYq6gUf8/mKLPSMLaNDZNz3osCbExy4q+hBBCyHCGYiQLhBhpag/KPiBup+5kqHkjvZYE1pR9RhIWyosnsMbsS3s1zRwGIoQQQoY7FCNZIMTI4ZP6mjMOBzCqxAvAXFGTkMAaFyMOXWcgqK5NY8kZEU6JKmCsoRmGagghhIwkKEayoDygC49Drd0AgBKfGyU+vcJGXZ8mMYFVd1FKvPprVWckIUzjtAnTWMQHk1gJIYSMJChGssDqjJT63CiOixE1gVXtM9ITMpqeBXy6C5Lt2jRqzoj+XRQjhBBCRg4UI1kgxMjJbr2st8TvRnHc7VBbwlvXphE9Q4RwCanVNNa1aexKexPCNOw1QgghZORAMZIFQowISnxuFMfdju5gkjCNUtorQjo9oShEQYzPZc4ZsW16FmaYhhBCyMiFYiQLEsSI34OAdEbUahr7BNZim9danRG3bAefXIx0UYwQQggZQVCMZIFVjJhzRlQ3RCnLjRg5I8JF6VB6lCSs2ivEiNrRlWEaQgghIxiKkSywDdN4dYFhqqYxOSMxhOL5H0K4CGfE43LAGe8rIpBhmkjy0l6GaQghhIwkKEaywO9xmpyMUr8bAVHaa8oZMTsj4Yg5gVU4I9YeI4BR2qs6I6ymIYQQMpKhGMkCh8OB8oDhjpT43SiRCaxKBY3aDj4UlcmoJdIZ0atxrGW9AOB1Jy/tLRUJsGGKEUIIISMHipEsUUM1JT63TGBNFqZRV+0NxEM6IqfE2vAMUJwRm9LeKtntlTkjhBBCRg4UI1miipFSv9KBNZgkgTUck2Ea8VqBnTPiTtH0bFSxLkb6E6bZuP8kPvvbDdh1rLPPn0EIIYTkEoqRLDE7Ix7pdiRrB98TiiYksArsnBGvK3FtGuGMjCrxmf7dFx57/QDW7DiOv711pM+fQYYnT755GFf8z6s4dLI735tCCCEmKEayxCRG/EZpb1eSPiN6aa/+b6sYsU1gtenA2mt1RvqRM9LWE07YXlIY/GXTIbx9qA3/3Nmc700hhBATFCNZYs0ZKbaEaTRNM4dpQsZCeaIMWGAXphF9RkI2q/aKFYJ7+tFnRFTydGX4GW3dYUSVyh4yfBEClNVYhJChBsVIlpRZckaEwBCNyIJKWS+gl/mGLWvTCOzCNHJtmrgA0DRN5oxUFfvi39X3waS9V3dG1LV0knGwpRtn/fAF3Prom33+vqFEJBrDdas2YMUz2/K9KXlBnDfddMUIIUMMipEsqbCKEYsz0pvQEyQihYVoBy+wTWCNN0GLxjTEYppJ3IgwTX/awbf3xGfHGQxIOxo7EIrG8Ma+k33+vqHEzmOdeOW94/j9+gP53pS8IEQtlxMghAw13OlfQlSsYZpYXCuIlXjVEA1grqwR7eAFdjkjHkWghGMxkwuSmzCNcEbSf4bITTneGUQ0psFl6RY73GiNr7YcjBTmYCydES4nQAgZYtAZyRJVjBR73QgoAqMnFJXOiMNm3LaW9tqGaZzGY5GoEaLxup3y/X0N02iahvYsckaEexKNaWjuDPbpO4cSbT0hAEA4qhVkHoyowurKIERHCCGDCcVIlogOrCU+N5xOBzwupxQVnaGILOst83sS3hvIoM+ISGAF9PJeMYAUeVyywVpfS3u7Q1E5CHdnMCCpdv7Rtt4+fedQQjgjgHntn0JA0zTpiNAZIYQMNShGsmRCVQBupwOTqovlYzKJNRiRYZkSn9sU1nA5HfBbxIfPk/jzq+8JRzXptOhiRCTL9k2MiORVILMwjRoOahwJYqTH2H9rbs9IJxiJQZhBrKYhhAw1+iRG7r//fkycOBF+vx8LFy7Ehg0bkr72wQcfxHnnnYfKykpUVlZi8eLFKV8/1Kkp8+PvXzsfD39ugXzMaAlvhGn8HqdJfHhdTricDlP4xutKzBlxOBymxmdi4Ah4XSiKi5GecBSxPoQZRFkvkFmfEdUZaWofAWJEcUasVU8jHVWA0BkhI4VdxzrwhYdfx2t7TuR7U0g/yVqMPPbYY1i2bBnuvvtubNq0CXPmzMGSJUtw7Ngx29evWbMGV199NV566SWsW7cODQ0NuPjii3H48OF+b3y+mDK6BFXxyhYASkv4iCJGDPEA6OEXVWgA9s4IYLSEV3NG/IozAvRtsbx2xRnozkDQqOGgxhEgRtp6VDFSWO6AKkCYM0JGAr3hKG7+3Sa8sO0Yfvfa/nxvDuknWYuRe++9FzfeeCNuuOEGzJw5EytXrkQgEMCqVatsX//73/8eX/7ylzF37lzMmDEDv/71rxGLxbB69ep+b/xQQSSxdilhGr/HZaqWEXklJjFikzMCGOW94ZiSM+J1we92SWelL1a7GqbRtPSCRnVPmkZAmEYksAKF54z00BkhI4wVz2zDzvgaW+pEY6Tx5JuH8YWH38gotD6cyUqMhEIhbNy4EYsXLzY+wOnE4sWLsW7duow+o7u7G+FwGFVVVUlfEwwG0d7ebvobykhnJBSRM26/x2lxRuJiRA3dJBEj4vFwNIaesH4CBrwuOJ0OFHnioZq+iJEe88mcrqKmewQnsAbDhSVG1GPJPiNkuPPSjmN4eJ3hhqgh6JHGqn/txQvbmvDa7pEdispKjDQ3NyMajaK2ttb0eG1tLRobGzP6jNtuuw1jxowxCRorK1asQHl5ufxraGjIZjMHHblYXlDJGXG74PckCg+PyRlJzBkBALfTWJ+mJ2Q4Lep3dYezv/g6es2zh3R2vTqDHmk5I70FF6ZRnBGbGdYfNhzAt598p0+5SIQMNo/EGxeeNqYMQOK9bSQhrt1Ml/AYrgxqNc0999yDRx99FE888QT8fn/S1y1fvhxtbW3y7+DBg4O4ldlTGi/jbesJS8fC73FJFwOwd0aShWk8bmN9mh6lmgaAdFv6FqaxOCNpbL8uS86Ipg3vgcqUM1JgzkiPIl67w9GEY/mzf7yH3712AO8d6xjsTSMka8S1/P5powGMbGdEuO0jvQouqw6s1dXVcLlcaGpqMj3e1NSEurq6lO/96U9/invuuQcvvPACZs+enfK1Pp8PPp8vm03LK6JNe0tXCC6nvt0+j1O6GYAhRtQ+IsnCNB6TM6JfZEKMBDzxxmd9SEJs77E6I/pn//Zfe+F1O3HNwgmm51VnpDsURUcwYts/ZbhQyAmsqgumaXpnYDWMKM6FzhF8UycjB3FvqivXJ7UjWYyIPMSRLkaycka8Xi/mzZtnSj4VyaiLFi1K+r4f//jH+P73v4/nnnsO8+fP7/vWDlGqFDGiVtOYEljjIsSrPJY0gTX+2rDqjHitzkj2F1+7NUwTiqC1O4Tv/m0r7vrrloQB2nry9yWJtbGtd0h0Ow1HY6YEsEJOYAXMlq+maTJsNdKT5MjIQEzGast0MdITjsoFSUcawfgY0J9lQIYDWYdpli1bhgcffBAPP/wwtm3bhptvvhldXV244YYbAADXXXcdli9fLl//n//5n7jzzjuxatUqTJw4EY2NjWhsbERnZ2fu9iLPCDFyoitkVNO4zaW9RjWN4YwkyxnxKH1GRM6I+Cyxvk2fSnsts4fOYBTNnXqFSTSmJcwuxAUvKniyTWJ9fNMhnL1iNX7y9x1Zb2uusWbbF5ozYhWvqrMWjMSgsSEaGUaI81SIEWDkunq9ETojtlx11VX46U9/irvuugtz587F5s2b8dxzz8mk1gMHDuDo0aPy9Q888ABCoRA+/vGPo76+Xv799Kc/zd1e5BmxgF1LVzBp07NsckbcLiVMY80Z8fR9fRprmKY7GMHJbqPc1SpGxOx5bEURgOx6jbR2h/D9p7YCAN4+1Jr1tgqOd+RmTRw1eRVAwoKGw4HNB1tx7W/WY9vR7KvLusPJnRE1fyaTZniFTmcwUnDLCQw1xPlb5nfLe2O+QzUDkVOnaZo81yhGbLjllluwf/9+BINBrF+/HgsXLpTPrVmzBg899JD89759+6BpWsLfd77znf5u+5ChqljPE2npDCmlvdamZ3bVNElKe9UwTcgo7VX/258EVtG+vjMYwckuVYyofUg0ae1PHl0CILswzU/+vgMn4wLgRGcozavteXTDAZz1wxfw2OsH+vR+FbXHCGBYn8OJP288iH/ubMYfNmT/e1jDNKpTorpsFCOp6QpGcN5/vohP/jKzVgYk9+jrLOnnbLHPjVK/PkGzhqEHk3/tasbp3/lHTu5VKmo4eaT3B+LaNDlglF2YJkkCq8kZSdaBNZ7AGo6ZO7AChhjpS/xQiA2R9NUVjCZ1RkLRGCLxXI/J8XV4MnVG3j7UikeUAfNEV9/cjS1H2uOf19an96tYnZHhmDPSFu8Ts6Mx+4oXq3hVE1rVdXrYgyQ1B09242R3GG8famUZdJ4IRmIyDy3gdUkxkk9n5N7n30NnMIJX3mvO6eeqriWdEZIWkTMSjMTQEncaijwukxjx2fQZsVubBlASWCMx9MRPRmtpb18GDdH0rL5cD7t0hyLSvQDMF7OaUzB5tC5GMu01surVvdA04JwpowDoib19W0tH3zZVMPWVxJyR4SdGxO+xo6kja0vYeiNTZ1lqz5WRPvvqL+IaiWn6Kt1k8FHP5YDXLVsr5KvXyDuH2rBx/0kAmSWAR2Marlu1Ad9+8p20r1Wvzb6u1j5coBjJAQGvS4qNw609AACfx9z0zCOradI7I6JlfCSWPEzTpw6s8Yu1Pu6MpArTiBwDr9spc0YyTWA9En/dx+eNA6DfuFv70K5ZXNgtXf0XI4nOyPC7sEXOT2t3OOtcmoQE1pD9TU51TFq7Q8O+t0yuUa+Rtu6R22irL0Rj2qCIWRFK9Hv0xUfz7Yw8tHaf/P9MwpwHW7rxynvH8YcNB9NeX3RGSFY4HA5Ul+h5I0fiYiRp07NM1qaROSNKmEaKEWNRvmzoDUdlIlR9hXBGkodpRJfOYq9LZqxn6owI8VBX5kd5kT5rOdGZfahGbM/Jrv7f9K1iaDgmsKrHZ3uWoZqEME1IDdMkJrBu3H8SZ37/eax4dntfNnXEoh6DkbweSl/4wsOvY+GPVpsmOAOBuCcWx++FZXl0Rpo7g/jbW0fkvzNxRsRrojEtrUNrci2HYZ5bNlCM5AgRqhE3fb/bkjNis1Be0qZnptJeczVNRUC/8NTB9c8bD+GeZ7enVNniJupwADWlunDqDEbQ0mUfphGDVcDrlk5Kc2dICpoDJ7px0/++gU0HTiZ8lxAjVSVeWWkkSogPtnRLSzMd0hnJMEzT1hNO2tOkzfIZw9IZUW627zWlFiOdwQg+/sBa/GLNLgCG+yEWYVRbwqs5I+L83XKkDTENeGNfS242foTQTjGSlI37T6KjN4Jdxwe2bYMQzCJknU9n5NENBxCKxkzrk6VDnUimcztMzsgITy6nGMkRQowIrM6IECGi1TuQvs9IJKrJWasIz6jdXgXf/dsWrHx5d8rZshjISpXs866g3vRM0BlUwjRKeKiq2CtDTgdPdgMAHn39AP6xtQl/WG/OHo/GNOm2VBV7UR2vNBJJrDf/fiM+vnIt3j2cPilViJGTXenDBc9vbcKCH76Am/73DdvnhXirjouj4dgOPhtnZP2eE3hj/0n8/jX9+IjjKc5TszNi/L/4zUVI6FiOSquTEYrEsOVIG5588zD2DPAglgtMYRqKEYmmaabrdSCRlTRxZ0SKkTwM1uv26IvXfezMsQDSr/cFmAVLOofbnM81/CZQ2UAxkiNG2YgRu4Xy1KTVpGvTuIy1abot7eBHxcNBIuzRE4rKQerQyZ6k2ycGl7Iij7yIu0JRk+tgl8Aa8LrgcDhwSo1e3ruzSR8wxMzcakue7A7JBlqVAa+pO200pmH70Q5oGvDMO0eRDtHEKBLTUt5ont/ahC//fiOCkRjeStLTROSM1JTqLs9wS2ANR2Omm1E6Z+RAiy4ahWgV7xXhRHWW1WNyRuJiJP7bH+sIDljeyKYDeijosv96FV99bDNu+n8bB+R7col6jVjzkAqZrlAUwpQUv8vxjiCu/c16PPdu+ms9q++Kn7sBn3BG8hemEfs6tbYUQGZhGlWwpHNS1ElTXxpdDicoRnJEojNiLe3VBYbqjCQL09g1PROfJcuI42GPZiUX43DctbBDDC5lfo+8iHVnJFmYRjgjunCZVqNfbDvjg+B7cVFivfjE4FcR8MDjcprCNMc6emW58AvbzOsb2aEKkGSzrfV7TuDLv9+IcFT/3PaeiO3gKWaxtWX6YCzCNHubu/Cfz23PaDZ3tK0HH/mfV/GbV/emfW2usVrQ7zV1pGyzL8RITziKnlBUnkej4yG6ZDkjnfEbpbixhyIxWYWVa9buakZnMCKF9u7jnSaXZihCZ8Qe9Xdpjff0Wb2tCf/c2YyH1+7P6Xclc0asHaYHA3H/HFup5+GFIrG0belVNySdk9JrM1EYCB7dcAB/fP1gzppM9gWKkRxRVWLnjCQmsPri/3U6jPi9FU/88baesBwoyuKJoMIZ6QhG0BuO4rgiRo6kqHYRN4tSv1vGNzt6w6YwjZqT0CObCun7IJT/zmOd6AlFZbjGah0KkSTEmerkHFacm/eaOrH/RFfS7Q1GoqYul3YVNbGYhu/+bSvCUQ0XTNdX7wxFY7auhyFGdGdE/K6/emUPHlizG6v+lV5g/PLlPXjrUBse7UPTsf4ijp/f44TP7URvOIaDLcnFp/rcia6gvOlJZyRJ0zPpjCgC5FhH+sTlR9YfyPp3EWLzmoXjEfC6oGlGNVo2HG3rweJ7Xx4UkcgEVnvU30U2O4xfs32ppEtFl6XC0HBGBl+MiHNgXLwoAEgfeuk05YykcUaUe1lvODZgvW3uX7ML//GXt7G9MfvuzrmCYiRHJIRp3GYx4rX0GfG59fCHHeI1O+PLuY8q9sqqlDK/W7osLV0hNHeozkiqME3cGSnyoDguRo53BKGe2+pFImbORcIZqdXDNO81dWDXsU4ZirFeeCI3RPweIkfjRGcoYaB5fmtyd8Q6Y7DrNfLUO0ex9Wg7Snxu/PQTcyC0nbXtPQApumrKRJhG/3zhiPxzZ+pmRW09YfzxjYMAclNqnC3i+FUUeTE1fixS5Y0cUMRIS1dIlohXl5oTrQFL07P4764K03R5I+29YXzryXdwxxPvZDV7E4NHqd+D8VUBAEgpsJLx2p4T2HWsM+fdL+2gGLFHveaEWyCuE2vyeH8xJkqWnJFBDtOoi29Wl/jkPT5dqMYUpsnCGQEGJlRzrL0XB1t64HAAcxsqcv75mUIxkiNES3iB3+O0TWCVuSNJQjSAEaYReQGT4h1QAb2MuEoJ1TQrrdZTzSrF4FLmN3JGrCJbvdGKwUu0jp8Wd0b2HO/CNkU9W2OespJGOCNKAqvYPvFbpBIj1kWvWizlveFoDPf+Q1+A76bzJ2NUiU/OkKxtoWMxzSZMEzNt/9uHWlO2k37s9QNyAG/pDg36SsTiRltW5Mb02jIA5ryRJ988jOtWbZC9QQ62GOfCia6QLAscbeOM9Nq0g1ct73TOyLH2XmhavJ9MFnkU4hiX+N1o6IcYEd+570T3gHdF7TSJkcEXpUMVcy6N/ru0DJQzouSzAfmrplHFaFmRx6ioSSMwurNIYLW6vJlU62SLqIicXlsq76H5gGIkR1hzRhKbnlmdkeQ/vVibpqldn5GqYgQwBvjmrqA5Z8QiRkKRGF7d2Yy9zV1KAqtbhl6sqDMLtbQX0BfLK/K4EIrG8IIiIrqD9mEaEZ5RVzQWzs1ls+sBAK/va0maq9ERNN/ArK/74xsHse9EN0YVe/G5902S+wYYbdONz4pI4SUTWONhGnEziGnA+j32ZayRaAwP/Wuf/Lem5aYrbDbIaii/B9PrdGdEbQv/23/txSvvHcez7zaiuTNkmkE1tvVKJ0uEaZK1g+8JR+MrOCvOSHtqZ0R9Ppv1QdTQYUOlLkYO9EGMiEEhFInhSJt+jj2+6RBu/N83MkoozIZ25ozYov4urZYwTXcomtNS+m5LmEb0GbFzRAcSsZ9lfjdcToe8r6Y757IJ0yQ4IwNQUSNaLcybUJnzz84GipEckVhNY3FGLI5Isu6rgOGMCCaNtogRsUpwZ8gkRo536KsGdwYjuPuv72LBj17AZ36zHlfe/y9ZaVPq90iBIRAhILumZ+KCdzqNipo17x2Xr0vmjKQK0yyYVIUZdaWIacCa947Z/gYJzohl8P/zxkMAgJs/MEXOSMqSOCOiU2aRx4Wy+CxK3BzVQflfu+xDNc9tacSRtl5Ul3jlLGywQzUyzOZ3Y3K1fhz2txg5N2L2+fahtoQB/ZCS2CzOnWQ5I+Lf5pyR1GJEzVvKpiupuCmX+twYX6XH3FVHJ1NUN2Zfs76v972wE89vbcI/lXM1GQdbunHz7zbiTZueOVYYprHHnDOiXxvqBCKX3WqtyfX5c0ZEsr5+TRVn2JCyyyYcngyrMzIQ5b0UIyMMNYHV4dBDEb4UHVi9rlRixJxLMtnijIjZ7QmLMwLos+AnNh3Cw+v2y5t0W08YT72tdwkUKl4VShNG6bPS7lBUhh/ESR9QXBSRqxCyJFVFlOxxkTNiTWBt6wlj/wl9oBhbUYT5E/UTf+9x+yTWhJJh5cYWjWnYdlQPFX1geo18PNkMSQwaFQGPPCYigVUVU8nEiHBMrpw7VibAWn/3gUZ1Rirjv606GIr/f+dwa0KoQwhRn9spbVizM2KxgoMRszOSRoyozkg2A7QpZ2RU5s7I0bYevK40Y1OP997mTnT0huXnZJIQ+5dNh/Dsu4343Wvpc046bByAoUwkGhuUlv52Jc+qYM9lqEa4scWW0t6ecDRtJUsuEfspGlEaYRr9t3hp+zGsskmq7lSuvXSNzKzOSK7FSDASxbuH9XspxcgIodRnJJb648mpRTalvdIZSdLwDEgUKpNHl5j+reaMWEuxDrf24M0DrQCAz54zEb+45kwARn6IqMoRyV8ApEUOGI6EtXwOMPJGrKhtiq3VNBVFHplYurdZFx5jK4tQGZ9NJLtJWWc56o1t34ku9IZj8HucphCWCNNYS/xEqWF5kUeGx2TOiHIz2HmsE8dsWt6LmV59RVFCafVgIUuzi9xGF974zVDNidl+VE8wVhHiJOB1yRygVM7Iye6QaUZm95uomJyRPoiREiVMc7ClO+3g+eXfb8InVq7D7niTtFaTGOk2ha+OtKavBBLhw3Tbrjb2yuT1+aYnFMXF972Cjz2wtt+CZGdTR8puvHalvepq3bkUbsmcESDRUR1IxD6VW+6p4hz5j7+8je89tVXe9wSmnJEsnZFch2nePdyOUDSG6hKvTCLPFxQjOUJNLBW5Ih6XQw7EXkvOSMoEVqXk1+FAwkmi9u4QCawinHK4tQeb442/3j99NC6dVYfTx5bL9wr3oERxPGrKjExwMQMXF7xouQwYFTWAHn4xWosbF4gRptEdEafTkZBPM7aiSF7AyW7oouxT/BRqjoZwRabXlsKl/FbJnBF1BiMqnGSYRjYD07dx7e4TCdsi3l8Z8Mjfvi9r7fSHDsUZqVDCatF4Qzgx1kRiGv6xtRGAsSCicEYCXjcCsm21ccyCFjHSaCkRT++MGK/PpteDuGmX+NwYFxcjHcFI2kFeiKt98Zt8m8UZEecHYKwVlQqRZ5KuGkNt7KW/PjLoiczZsHZ3M/Yc78KmA639qsLQNA3X/Ho9PvWr15L2oVAnD71hffVy1XFrzWGOVbel7YDH5ZT33MEM1bRKx1W/J6jOSDSmSffUeq8w9xnJ1hnJ7f5tiodozhhfmbS6c7CgGMkhoqJGDHiqOyIG+7njK1Bf7sdFM2uTfo5HESpjK4pMJcIATC3WRWnvrLjg2H60A3vioY854yrgcDiw7OJp8r0iZ0LNG6kKeOXjHSmckak1pab/FwJIDXVIMaKErUYplUbVJV74PS7p0CSbMYkZzph4/b7qjIjB5tT6MtN7xGdac0aEkKko8pqckXA0JkNOi0/Vj4ddqKZVxoY9SnVQvnJGPHI/9cfDCeJLNKSbM64CgCEmihRnJBQxwmvWME2CGBkAZ0R1Gcr8bhR5XXLNpHShGnGOyj4W3apr1o2tRxVnpC0DMRJ3T9INZEKsqO2BBjtpMhte2mHkY/XHmWjrCeNYRxCRmJYwyxdYhZy1tX9OwzSW5HoASSvpBhIZ/pXOiLgfRtHWE5YTBOs22bVQSMZA54wMlXwRgGIkp4jZtSoexP8LR2RsRRHW3v5BLL3glKSf43Eah8VaSQMYA/2R1h7pIMwZp4uRv2/RZ8UNVUXSkfjAtNG4aGYtKgMeOYCXKGGaimKvvJjFhSIz1hUHRVTUALpLUmyJkUZjmkw0VRN6VWEixEVFGmdErJMjXKGTys10W3ywSRAj0hkxDypiJj22skiKkVAkZpqVnDdVb5pm17vDcFaMhf8GW4yopb0el1Mev9aecNLfcO74CtO/A16X6QYuwmvWWfPRuBgRArUrFE05gzNV02Q46IiqHUAP0wBQynuTC4hQxGhqJ/tYKMf7QEs33jncKv+dzhnRNE3mlVgruKx0yFCZR4q6oRqq0TQNL203knf7U/2l5t0cbrUXilYht8eSC5bTBFa5orgqRgY/iVX0TxFhUzVMo06erPejrixyRqyuZS7FiKZp2HiAYmREIgZ/tWzXKkYApLXD1ARWa/IqYCSFigve63JiRp0+MIsbx+z4rFh838rPzMMb375IJj+q5b1VAW9C4yC5No0irJxOhwzVTK0tVcSI/tpWdV0akxgxnJGxcTEiwjTJBi/hjAgx0qr09kjujIicEfNn7o1XWEwcFTAlFYsbhtfllJVCdrNyKUaKPAlrAw0WagIrYPx+rd2hpLNeawOjgNcFr9uZEF6zWsHCGRlTUSTdr1ShGvW5TAdnMWioydTiWKdyRtQZ+IlOfd0ctd9HNKbJhDxAD2WmajF/ostYiTpTZ6TU704bZsw3u451mkSEOEeOtffi/pd2ZZWArebdJGusaL3mdjdbnZHch2nUEHI+1qcRbo84F9QwTbLO1oBlobwsOrACuQ3TNLb34nhHEG6nwxTKzxcUIzlEiBH1IpleVwq304GJ1ZknB6nCxZq8Chiug1jnpbrEi3GVRabXzFXECKDf9NX8ioDijFQGPEqLeEuYRnkdACy94BRcNLMWl51en5AMKQZ3vUussQ+qSyLFiEjCTJMzImbLMU0XLq3dITlzn1FvTqhNljMi2s5PrC6GXxGKYnuLfS40xEtL23rCplmc2mWxMuBFdb4SWJXSXsCYjbUpzoioigL0MuapNeZzR7gi1vCacEaEID0aD8uU+t0ydHKsvRfrdp/AL1/ebWosFoxEbat60iGTV31uKc4bMhAjqsV9oisUr6DQt0fdf7W0/miKZRJU56Sz135dI4HIhyn1GaGyoSpGXtxuLpkXYmTVv/bhJ3/fYeqbkw51zatk1UlWIbf7mNkZyWUCq7jfqBMqa5h5MEiVwKo6ueo2aZpmchnTOR1CSIt7dy4TWMV1UVvmT0gFyAcUIzlEDLp+pVJm5WfmYd3yC1FfXpTsbQl4FGckVZhGUF3qk+EPwexxqZVuiWJxVhYnOiN2CawAcPFpdXjwuvmoLPbKwU0MECJ0Ua04IYBFjFSKMI1Rnmo3AAhnpCLgkTealu4QtsZdkXGVRVJ8CIycEeNij8U07G8Rzkgx3C6nvLDF9ga8bgS8brndB5Wbr7jhOBz656tN3AYTEUKwOiOqGJlaUyrFw/iqACoCXqgmnDiW4qYpnBHRAE7sf2M8z6LM75FN4o629WLpI5uw4tntpt4w1oTGTMM0avKqoCF+bhxKseCjemNv6TJcIbfTgdPGGE7Z9NpSea6lCtWoz0ViWkL+DAB5fhqlyEpFU5r93dnUgcc3HRqU8loVNV8EMMI0R+PHdn8WzeXUNa+SrQwufhtxDu1JcEZyGaZJzGez3r80TcP/vXUEt/357bQ5T33FmsCqhq3VsJh6TfSGY0mX4LBDOCMirC1Cqye7QqaWCn1BXLti8cx8QzGSQ8S6J2qpmdftzPpgq66CnRgJeN2msuHqEh/qyv0ysc7pMBJak6E6HlVKzohemaHZJrAmfoZwRuJt0i2t4AWpwjTRmIauUBSapmHpI5uw/PG3AZgHK/F5J7tCSfNFAGV2pFz8je29CEVi8LgcsrpEhNHE9ooBUTTeUmfmIgRQ5vfA5XTkL0wTd0bKi8zOSGt32NRHRYTnGqoCcDkdsoQaMEJuyZwR8TuLGVOp343R8fb5T7x5WP5eL+8wchGsYiRzZ8QIeQgyCdOolndLV8i07+q1cmp9mRToqXqNHLaU/lpt/kfWH8BZP3wB7x5uM1U0ZRqmuf3xd7Dsj2/JJn2DQXtvGG/s03MBzp5cBcDYTuHoZVJlJDDnjKQO08hrKN5TqFI4eBk4Iyue2YbvP7U15WtiMWMl84AapvEZFWbbG9vx8ZXr8O9/eBOPvXEQf918JO13q2xvbDeVhyfDmjNSIldDj5r6IqnnrFV8WDtYWxHOiAh794SiOHCiGwt+9AK+8oc3025jKihGRjCXzqrDjedNwi0fTJ6cmglupfzX6ngIVHekusQLj8spG3JNrSlNCK9YUS3OioDHlAAWisZkfkYgSet4/TPMCaxigE4UI4nOiN/jlBVGIvTy9NtH8YcNB9HeGza6c/rd8kI80RVKmi8C2FfT7IuHaBoqA/J3tYoRsY92g+FJpawXMJKU23sjpuZvmaBpGnY0dvTpfTKBVToj8T4t3WFTH5VFU0YBgHQJ1GMRsDojcTEibnjCwVITNYXT8rLSyfQVZVFBkS8iftNMxUin4jIIROOzwyd75PkXjsbwx9cPysFT7SNxotNwRsqKPJg4yixGxlbo10OmzgiQWJr87LtH0dwZwovbjxm/i5Izks4JElUlD7y8e9DKgDfsaUEkpmFSdbGsqBKDo8gVOZqNGFHckCOtPQkuTyxmVEaJUJsIIYswc7oE2rbuMH75yh785tW9KfNZ1GRr9R4nzqOT3WF8dtXrskoEMFd7paM7FMEnHliHj9z/alpHRTojIkzjtQ/TqAms1pyPTHNGxP2nKxjBO4fbEI5qePtQWya7lBQhRmooRkYepX4PvnXZTFPyaF8Qg8KMOnMfDdNrFLdBWKPCdZjTkD4ZSVzIxV4XfG4XSn2Gzamq9UCKWGJAtj/WX3/CpqxX3R91Gx0Oh2l2qc6wj7T2GIuo+TyoCqjOiC5GZlryRQBFjPQYsX/R9VXNJxAN5xKdkUQxIuPC8W0o83tkAmhLl55Um2mlwN+3NGLJfa/gx89tz+j1ArW/hXCw1JyRdiWR7rpFE/DoTWfj5g9MAQD52wFGnlDAazhammbMNEdZwmt6zog/YXv2NnfJCiVx3MSgk23OiLowV22pH16XE5GYJkXCk28exn/85W3c8+x20/sAizNS5MHk0RZnpDy7MI3++ebtF8m8B1q6TQJKWPOp+mf0hqNyUNpzvEtWug00wr2YUVcqc7PEdohzvqkjmLE4Un+j3nAsIUTZFTL63Fh7IokE/HQ5I6rjkup4icHb6TAXCojz6O9bGtHY3otRxV589pyJALJbumHP8S50BCPoDcfwyIbkHXnVRoPlNh1YkyWwCtEmbuviGkyGdEbi51t3OIqmuEjq75IUQqTRGSFJOW1MGe7/9Jn4+VVzk75GHeDFySTcAjE7ToUQI+KmamSjR+QF73U7E9bJMX1GkgTWUZYVjIW7M6rYKwUIgKRi5PBJo2S5xGc4IzuPdWJnvIdGqjBNKGqUf4rGWBOUWbNokCSdkfh+2K0cK2Z0YmbidDrk9jR3BvHtJ9/BWT98Aa/t0Zul9Yaj+MFTW/Hcu0cTtk/MZNbtMTdW6w1H8atXduPa36y37eMgBkiPyyG3XVbT9BgDcnmRBx6XE2dPHiUT0kzOiAzTGDkjoWhMDiTW9ZX0nBHjWNaV+TE/XgL4yk7dKRHOiKhGCkZiKatX5D7Z5Iw4nQ5MiX/OliO66BQzXOmMKDZ3Tzgq81vKizyYXF0Ch0NP9ptRXyrPu1RdWBPFiHmm2hi/8R840Z11mMa6wOD9L+0alNwR4VCOKvHKQaytJ4RYTJPnfDSmpV2NGdATlMUxFudest/M43KgrtwsXjMVqUfbMhMjssrP6zZVJQpnRIiay+eMwYw6fcKSzaCtdi/+3WsHkrqYHb2GALMmsHZZS3uVc0pM3ITwj8a0hIqZgy3d8nsNZ8QI0zTFj1tPONqvhFaGaUhaHA4HLptdjyk2lTQCdeAQzsjtl87AIzcuxBVzxqb9DiEkxGAlLubO3og8wYu9qTOsjW6e5gRWa5hmTEURfnHNmfjltfNMNxDZa6Q7bLJSDyvOSKnfyBn5f+v2IxSN4fSx5bati4u9bjnjEG6BCNNMtHFGTshqmuTOSFu32YoFjN++uTOIZ99tRCgaww+f3oZYTMMv1uzGr1/di+8/tS1h+0Quxs6mTrmGxtpdzVh878v40TPb8c+dzfjTGwcT3ids3lK/R/5+6m+nihEr6ppJIoFVzRnpDRk3QqujVVbkQU2ZcaP68Ox6fGC63o/llXjYRtzQJlUXy2TZTBpPiYG9xG8OJ86Nu3pvxbsIvxUXcEIUWp0LId4qAl5UFnvx44/Nxr2fnIMyv0cRI+lzRqzVZIBYo0f/9/6WLlMCaybVNGKArS7xIeB1YcuRdtMikwPF8U4jkbxScUbae8MyfAJk1ipfOEN+j9I+4KS9GCn1e0w5SoCR89YZjKRcN0Y9RsmSZAG1Fbz53lRqOY8+eubYlMnmL793HD/7x44Ed2i30qytuTOIZ95JnFQARqlyIO4sA+ZqGtUJUnPYREhbTfJXq2veOtiK8378Em77i547Z80Z6Q5FTCI3m/4xXcEIXttzQu6zFCMlFCOkH9iFaYp9bpwzpTppaEdl9rhy+NxOmeBmdkYSOxzaIRK2xGxFnZFZ+dDp9Zg/scr0WDJnZP+Jbhk6KPG55Q0uFL+Z3fGhU217tTidjoROjCJMM1FJbhQrJos4uoj1qjkLIlNddm8NJIq/1/e1yJvOO4fbsPKV3Vj58m4A+kBkvfmKG24oGsOe412IxTT8+6Nv4tDJHllBJRwBlXaZL6I0qlOqOawlhiqjTDkjIjQnckai6I23xXc6jM8UWMM0l88ZI5vDrd11AuFoDMc7RHmgL6ul3O1yRgCjN8pbB1vRE4rivSY9kVDsY0JzrbgYEfv+ifkN+MhcXYyPVRJY7RyJ3nBU5ieI/jmq2GlUcgaa2oNSMGfqjIj3TxldjGsWjgcA/OCprXIpgoHCuA59Sm6RsXSEIJMkVuE0jKkoku0DrEms7UoycoXlHFSTilP9VmrFTiqRlKzlgNqVeMroYpw+ttxY3bzL7FBpmobb//I2/vvFXQnr7QgxIpLdf7t2n+12tNpMUmSYJhQ1V9Mo55QQU6V+owhBLe/dsFffHtF80Zoz0hOKmhytbFyfFc9uw6d+9RqejgssOiMkJ1SXqGGaxME/HafUlOKtuy/Gty6bCcCYobb3hmVXQOvsw4q1tDdZNU0ykokRMQAB+k2nqti44BefWpsyDCUan7XF80YMZ0QRI5YEVnFjU3MWhIvRqlRrCMRN7u9bmgAY8d8fP7dD2qsxDTK2K1D7XWw72o5dxzvR3BlCkceF3352AQB7MWJ0XzW2QZ2Zi5t8mZ0zYpPAGpBZ/4YLVuRxJVROlfn1CpWZ9WU4b2o1Zo8rx6yx5agMeNARjGDzwVYlCc6fVSMwmaBsGVTmxMXI24fasOVIm5zFtcZLwDss1Qii8Z+dEKst98Hh0G/odjdtMesPeF0yRKeKnSZLf5Kt8WOjDrqpciHE8a8r9+OWC6aiusSL3ce78KuX9yR9D6DPfj/+wFrc+48dKV+XDOEEjC7xorLY2E7rb3A0g1b5wgUZW1EkxZ3VuVAroyoszsjoUp8U0al+q6OZ5owkuTepovajZ46Dw2FUkp3sMn/voZM98lpstFyjIkzzjYunw+t24q2DrXh+a1PCdsiGZ8r+iqKAaEwzLanQbnHbAF24GO3jjeeFGBKCXghXwxmJoqmPzog4f9893AZN0yhGSG4wV9P07WRSG92o1TRy7YcMK3LSlfYmQ218pooRUb7rc+sVN2LNH5fTgdsvnZHyM8sUZ+RYRxC94RhcToes4tE/15rAqv/b6XRgXLw0UeSNtMqcEWOfxP6JG9d1iyZKB8LjMhJzVTs7ZrlBbTvajtfjs7IzxlfgzAkVcDh0a9iaxW+EaRRnRKmmabMRTNZtBZQ+IzbOiN/jSphtlvrd8LqdeObW8/C/n1sAh0NvnHfuKdUAgP/bfETmE9SU+rISI3YJrICx5lFnMIIn3jwsH4/GNLT3RhKcEbH2jN2++9wuaUHbzbbVWb88/xWxYx2oxCBfmmE1jRjw6sr9KA94cOeHdeH/3y/tkrlMdqzf24I39p/EIxsSQ3aZ0Kw4I/I86QknVKlkEqYRrxlTXiSvIaszIo+lz2M6Dk6H7hxUKHkrSb9HdUZSiKSeJC0H1J5DH5k7BoCRu9YZjJjcKLXSRnWLItEY9sW7NS+YVCXdrFsffRPvHjZXrrTK9a6M71W3ST2PQkoeVWfQcHasBQCAcU9pj4tv0fdGJKLrYqRvzogQkfuau9DeE5FOc1/Hj1xDMTJMEQO0Ovj1BzF76QwaCaypKmkA4+LrCkUQicaUGVlmJ7fJGVFulM3SDtc//5wpo3D+tNG468MzZaJk8v0wBglxwx9XWWTq3SIS8Yx+Bcl7Xagr/gqsF+/7p43Gf1wyHYDeoXZmPLlWvak2dwXlxQ8AW4+24/W4JTt/YhUCXresPLC6I9ayXnV7WrtDcjCwzRlRxIg4XnbOiJ0YUZ0WNSz26QX6Tfqx1w9KMTK61Ge047esxWGHXQIroAtO0SNHFSNiXzt7jSZ0ABKSCK2k6jViFiOJ7cStYkSQaZhGOiPxkvsr5ozBeVOrEYrEsOLZxJwiwe74gKQvr5B9wqvoJTKq2CvPk2jMcAkFmTgjwqUYW2k4I9ackXYl5KaK9sqAF06nw9QTJxmZJrDKELKl5cCMulIsPrUGX3r/FLkCdFmR21T5JnhdCc2oAu3gyR6EojH4PU6MrSjCHR86Fe87pRrdoShueOh10znUbjMBcDodSd1kuRq6XFfHldAaATCcEVHRIxDOSEtXyCTIM+1s2xs2EpH3nejC8U5j/amh0H0VoBgZtohBs6EqkJOln9WF8qxLdCfDmj2uafpsyFoimoxyNYHVZu0TsU3FPjf+93MLcH28VC8Vxvo0EXnzVStpAMMZEagDolWMnJRiRF2F2Oz8nDm+EledNR6b7rwIt144Ven8aQxmRy2zUN0Z0WdoC+K5NKeN0QfhLUfMs7B2m/wKcRNUExLTiRHhjIjfta0nLG94fo8zIWHZms8hOOeUapw9ucrUj6a6JFtnxD6BFTDyRqytslu7w/JGXF9mrtqwc0YAI2/kr5sP46F/7TVVSsmBtsJvu9CacLKsl1eZ0oG1KxRNmpgpnBGRf+BwOHDbJbqz98+dzUk7aIo8mIjSvyNTesNR+Z7qUh/8HpcU32LWLSqkMnFGVMGW3BkxqozU/kFiAC1PE9Kyuoap1hOSreAtzojb5cSvrz/L5Jw6HEblm7p8g6kHiXLfESJwcnUJnE4HPC4nfvGZMzGjrhTHO4J4WMkfsZukAOZcFr/HKSd5QqB3yVb27oRqxBOdQVN/EnXbZM6I5XfJ1BlRj9n+E90y1DNUQjQAxciwZVJ1MX517Tzc/+kzc/J54mYcjWlojl8E6RJYZVVG0FDdo0p8GSXQAuZeGXZixDprzgTVPt8nkleVShrA3J8AMM+yrGKkzcaOVcXW1JoSGW6qKvbC4XDI2bgaWxczvxl1pXA69Bvu4dYeuJwOnBFfXXfWWN1RsTojYhamOiNFHpdp2YCA12Vyf+S2KmXW4niNVlYeFmGaIq8rISxnbbev8vWLp8v/rwx44HU7s8sZSZLACkA26hLUxit6TioukFVgJnNGRC7Is+824jt/24qvPbZZPifEyJjyJM6IWAOpzlxGXur3mMJLyfa3SVn7QzCzvgxlfje6Q1EZjvzTGwfxyZXr5DWwWykvTTaAa5qGdw61JbgIYqbvdTllPo5wK3bH82uE85SNMzKmwi+FXVtP2CSSjCZ57niuhnE9AIaQT9YSvrkriHBUg9OBtOsJiZCGdZmKZIjwhrHCcxg7lJw01RnZFXclpijua5nfg0/MbwBgdmyMRfLMExP1nlUV8Ep3scPqjPjcRjVifJ92W1Y6FomqDkfy8zvTnBFVhAcjMRl2ohghOeHi0+ps+230hSKPS4oIUceeLoFV7eTZlzIxcYEdae2Rir9e6VPQFzGi5oyI7pcJzojHfNqrsxlrrxGjA6u6CrHx//MnJi69bdf5U8xCp4wuMVX2nDamTH6/4YxYxIjSEVWgN40ztiPZzapSSf4Vx1OIqebOIHpFmMbtMq1X5HU5U9q3Z02swvnT9MoaUXGTzeJxap6BFbVp39iKIlni3tptDILWhSetg4Lg+nMm4DNnj8eFM2oAwNTHRRyT+ooi24XWRJhl4SRzFViJ3w2X0yGF1D+2NCU0P9P7eOjXhNp7w+l04Mx4r5Y39rdA0zT87B/vYcO+FvzfW3rb8j3KNtoNNi+/dxz/9ou1uPx/XsU1v15vCuU0y7Jer1EGHj9398RFjlihtbkzlLSyJxbToGmanFGPjYeyxO+kntuqMwIY+UzCQTSSfe0HTuEa1pT6064nZDgjGYoRsZRE/LvfPHASauRLFSNCBJ5iaakgigVUdyW5M6J2tjaW2RDXsBAeJT5XgjOi9jgBjB4+frcr6cQwU2fEmnQsXNnRNk0N8wXFCAGgD25i8F+9TV9ky646Q6VYUfZCxat9KdIhBhCxaFfA6zLlhNhZ+OkoU5wRYcdaFw20hmmKbXJG9rd0ozcclSKpXK2mUUIf8yaYByoAGFuhf8YRmwqB+nK/SUDOV94vWrgfaOk2lQOqpZMq6o0wmRjxuV2YP6ESYyuK5KAocl6aO4ImZ0SdbYpwVypuv2QGKgMeXHiqPtBnVdobTO6MjK0okgPA7HHlRlVEd0hZAyUzZ6S+vAg/uPJ0/PjjswHobpCoeBI5IfXlScI08ecXKGLE6TAGQtHh9Y4n3sG8H7yAO554R5bVnugMIhLTZ/tWgT5fipGT2HKkXX7P5oOtCS7hSYsz8urOZly/agM2H2wFoIsrNbdFLesVCDEg8nSm1JTI0E2jjQPxz53HMe3bz+Kin7+CYCQGh8MQVGNs8kbUNvmAcV4azkjqMI28Nir8adcTEoN5uuR6QZVFSIh7gijlVn9rwxkxn1vCXVQHfpGMay1lLjYtQOpRwjT6vnfKaiAlgTU+IbCKESGGfR4n/B6nKVwocmEydkYsi0++sV/PmxkqreABihGiIJeQb+tFZcCDT8btyWSIm3IoGpPNo7I5udXF8gDdMhynVL1Yyz4zQVz8mw+2obkzBK/bmShGEpwRYxCeMCoAp0O/cYrFslxOh6nHh3qjFwOLypi4M6L2t5D5AxVFMsEVAM5SnJWKgFda4VsVd8S42ZtvfOqNMFUS8x+/uAgvfeMDUoSJgb4rFJVljz63C163E954qMda5WLHzDFl2Pjti/Af8TyITMM06lomdoLT4XDgjPH67zK3oUIOZie7QoYzMsrqjKTe3sqAV4a1xGxY3Oxry3wokQut6dseicbkQHXG+Ap58y/xGZ0/7/vUXFy3aAJOqSlBNKbhkfUH8IGfrsGL25ukQBhd6kvoYiwE7MZ9J6XwB4DNB09KN09gdRNe3K6//vxpo2UPj3cPG+eKTF5V3DvVHQOA6mKvFFJ2g/4LW5sQiWlycBxd4pPnjnAO1WTYDkvITYjHUdackSTnhaikGVNeZHIV3zrYisv+659Yu9tYC6knnJ0zMqrYHKYRyauXzKoHoP9ewgWSzoglSX6UDGsawiVZbx/Vza1QwjRCRAsXpMTnVhbW0x/bfTy5M+JwOEwFBcItbOlKL/wBwxkR17fYfoZpyJBE3PQbqorwl5vPSVu5olqH++M3p2xObuuFPLrEJwdjoH/OiFjD5oyGigQnJJUzEvC6MT2eI7AmvjpteZHHlCRc4nNj6QVTcNP5k01r3gjE7K47FJUDs6isGVPuN4kRayO4mWMS80bErMrqIti11rfD6XTIpEKx/eLf4iYly37jN8iyDH97p5IfpIqRjftbcNG9L8tOrSqdSl+FZKG45ZfOwFc+eAquXTRBDm6HW3ulxa6GugJel2n/km2ncCia2nvRHTLKhGvLEp2R451BxDR9BlpT6pciWRVpp9aX4XsfmYUXlr0fj910NmbWl6GjN4Lv/W2rUtabuNDl3AZd3DS29+KPSsfdgy09crVdwUmLDS/O6w/PrscZ8URfNeFZVKWpFV/WENaoEh/q44O+NbEa0KtKAOCy0+ux5LRafHOJkR8kWqxvtT0/9d9m3oRKOByQgrIyzTo+R5W8FHU9of9avRNbjrTjj68bv1FXMLECLhVqF9ZwNIa3Duq/1ZLTagHoScKimq+9NwKnw9yTCDALGrXvDWB2TAFzyLcy4JETCHFemUp7LTkjQvyJ+7DotComT0XKPs+Ir81lPT+SIa7zeZbJ01DpvgpQjBCFr144DVcvaMBfbj5HrimRCnUmLZJF7RZWS0aCGCn1mfqB9CdnRLBgUmIYxZrAai1pFQmlL+3QZ6F2lRrfXDIjaSdYv8cl3Qcx8zyq5CecOaEStWU+nD9tdIJ4E6Gat+I2fGcwImfL1s625RmEaexwOIyB+VDcvvXHfxNxk08XorNDFSMPvrIXO4914vtPbU0oTxXJq6nyUiaPLsHXL56OgNeoXBF5PB6XQw5aQKJVnoyaeCLpsY6gDE8Ue13xhFRznxHxfE2pnpA9Pj5AJaswWjh5FP74pUXwupzYd6Iba3fps/k6m7Blkdclj7M4P8R58JdNh0yvbVFCG5qmYVujWCiyzFa42jojlvN3VInhjNglsYrk7asXjMcvr50vEzgB4/zcejTRuRO/zY3nT8Zbd1+MC+J5Omqi+tG2Hmw6YBZcRtVRkRTyW460y5WiDyohIZkzkqbSTyBzRrpC2H28Ez3hKEp9bpxaVya363hnELuP6ZOphqpAwjkpKnJimiGojA6s5muy2JLAWmoJ05hKe5WckZ5QVJ4LZ8ZFnAh9+93mZRwAI6m6JcPy70PxY/q+qdWmx+mMkCHJ4pm1WPHR2VkJClGJInp6ZBOm8bqdpgtsdKnPNMj0xxkRZCZGzDcf2ZI8vj5KpoOdihpbD0dj8sYypkLvVLru9gvx0GfPSnifaCj27LtHsbe5C797bT/aeyOYVF2MuQ3mWU1FBgmsyRCDldUZEQIw2aCbCrENJ7pCeDU+GO881olXdjabXicGr0yPr0jAFINkic9t6iFRbun6mQxxbh5r75VhlNp4LoSY1YciMQQjRmMp8fz4eDO8VBVGJT637A78l016j5S6MvtrSc01mj2uHOfH2+yLNuDi91fdhMb2XrR2h+FyOnBKTYlMeFZdChGCUme8qph2OHSnol6s22PJGYnFNCn67NZ/Et/5XlOHzL2xJrAC9j1xdh3rxAd/+jI++ou1pq6m0jVUcka2HGmXZevqWlF9dUZaukIy7Dq9rhROp8OUOyXzRWwmYR6XU+7Dia5QfMVesUyENUxjTmC1hmlM1TRKzogI0VQVe6XbanVGTGIk7oyEIjF0h6LY19yF36/fb5uQ3B2KyB5Q7zuFYoSMUESIQ4Qjsj251UF0dInZGelTzoiSeOlyOuQsQ0Wd+TiUckLBmXFnREw4rIt/ZcJYZZG2pvZexDR9Rl8dT4ZzOh2mEIfgrIlV+MD00QhHNXzvb1vw63/qrcOXXnBKQsl0Jgmsyai2OiNiRV8ZpslegIkb7/GOoKn08zev7jW9rjNoH3ZKhpjZiyovsWCg0ccis8+pVZwRKTbiwlt14Tp6Iwk9QibEE2bTJfYunqnb/2L/7cI0gLkK64MzauQCgQJx3qoJrCJEM2V0Mfwel3RGDrf2SLte5DWozkiFpRGZy+nAmPLEii9AdwmCkRicDshQjsq4Sr1bbThq5JRYE1itiDBRd8hICF/xzDbZn0W6huVFppwxuU0dQdmcrzvJQnnJMMI0QSlGpsVDTcK91J0R+3wRgbo4ph7y0eBwJN7vTGEaUwKrqKYxxIg457qDESlGpowultey1RlRE8wnjio2LWtx1/9twbeeeBff+9vWhG0XE44yvxun1peZ7iMUI2TEYL0pZOOqABYxUupDXZlfXix9ckaUQXSWUjarojojxZalyAG96ZE6UFrjwpkwRpl5qm3B7QSIlTs+dCqcDuClHcfR3BlCQ1WRbHGtYsoZyXIbxY1YlBwKMSLEZX+cEcHZk6vgdOgr/KrrDUlnJEOxKQZTIQ7F+4zS0eyckab2Xtn0SVSJuJwO08q90jmJC5gPz9FXLP7M2RNSfsdFp9aa/l1Xbn+zVxOfF59am+B6idi+6oyIviQi56i8yCPdCxE2MbqvGt9badOwT7xv+9EOk80vXIgxFUW2fWscDof8/i1H2vRkZLn4m/05WFfuh8/thNvpwLKLpmFUsRd7mrvwyPoDiCiuYX2FH7Vlflk14nAY16oQzZku4mnsr1EJI8TIDClG9OeOdwRNYsD2c0qMzxECrrbUn/AbJUtg7ejV27uL7S/xuaXw7wxGpLA7paZE3sOEELVzRmrLfCbX5+24i/v79QcSVhoWv924ygC8bqecKLmcjj5NtAYKihHSL6yDfb+ckXjlgbC27XpQpEMN09iFaADApzghdrFnp9MhQzVA/5yRwyd7lLJe+1mylWm1pbg63nIdAL78gVNsB4b+OCPWLrmi1LO4P86IRcB85uwJWHJaHQDge3/bKnNfshUj1pwHIZSqLNUa6ai1yRlRG5IZSaxh2bBMnIv15UV46IYF+MD0mpTfUVfuN1Vv1SYJ09SU+fHVxVNx43mTcNqYMsyoL5UDr9/jlAO+WropBIdaGn7aGEMYAEaYpjpJmEY4JmdOqITf40Rje68MDQFIGaIxvrNcbk9nKCJFYjIBW+Jz4/9ueR9eWPZ+/PuFU/HVi6YBAO574T1s2NuCmKbnD1UX++B1O6VoXDipSoZNRGlqdzC7nBG5UGBPWDpL02p1MSLuVc2doYydkROdIZlnY+ccJTQ9kwuQRhCMGB2LAz6XaY2otw7px29GXVnC+SwS7os8xkQh4DVa72872m4qm77tL2+bmpwdbNG3tyEeahRhoFHF3owbVA4GFCOkX6g3hVKfO+POiAL1whM30Etm1WFUsRenW0pyM9oer0uuortgkv3qviZnJMmAqIqRfuWMtBorhKqVQun42kXTUFvmw7TaEnzszHG2r8m0msYO6/o6wgqeVK3fjKekqaSyw+1yypuxy+nAeVNH44vvnwKX04FXdzXjwntfxn/8+S2lb0pm22wVg+J91j4W6RA9cJrag6ayXuNzE50RtWFZpixW3JFUAvSri6fhW5fNhMOhtx4XnVEnV5fI/hjqirPbjqQSI+2IxjRZwlqdJIFViFC/x4Vzpuj5AyJRGzCckdRixPjOjgySkQE9T0NUQF19VgOmjC7Gye4wPv3r9QDMrqGoZrly7lijI3I8Qb7bZj2pVFQqrprIj5lea3ZGDrR0yefsckYApby3MyjbGIyxuZ7N1TReU+8ddQ2aYq9bOh3tvWFsivc/mT+xMuFatk4UhMAV5/+/dp8AAEyuLsYZ4yvQ0RvBf7+4U75fdUYAyJLwoRSiAShGSD9Rbwqjs2h4JlAHEnFx3PnhmXj9W4uTzipT4XDoeSKjir1YODmJM2IJ09ghKmoAoCLDVYhVxipiRCT31mcxsFWX+PDyNy/A377yvqRlq2ouQPZixLxPQkR+/eJpePbW83DprLqsPk8gZoLzJug31bkNFfjjFxdh8ak10DTgj28cwl83651GMw0FlRV5TA2fxPvEDH163HZPhwghHu8wEljrTM6IYak3tiU+nykXxfNGnI7s3i8E8OTRxQnlsN2hCPbGy+fNYsTo2nuyOwSxVJG6JpFa2qs27Ltgup40u2a7UX4txEhDCjEiclW2HWnH81saAWQn2twuJ/6/T52BOQ0VshpPzaH5zhWn4a4Pz8Qn5jfI2fyBlh70hqOm1vOZ4HE5TddGTalP5hqJJN8N8QUrq0u8pmtKRYR7mpUwjd3kwhSmKfYoYZqI0co+3u1aCJf9J7rRGYyg1OfWnZGAvTMixIsQ0GI/1sX7sMwaW45bL5wKQF/5WSCcEZGPI8ReX+6vA0n2gWFCFNTmQ32pWVdvFGrSXSa5Fcn4w01nIxrTks7U/GnCNABMMfy+OCMiEfd4RxCPxvskjLVJzktFutU0c+qMxGdfHpezX0sMlBV5cKStFx+cYYQz5k2oxK+vPwv3PLsdK1/eLW/+mYoRl1NfmVpY0eJ9Xzx/Mi6dVWfb68UOcRNv7gzBGVc3tTbLDxzrCMoyy3EpBuVkzKgrxR0fmoGANzun8PPvm4QjrT340vunSDejKxRFMBLFjsYOaJp+3NQZrXAp9hzvlImKlQGPqdGaKUyj5JLoIact2HjgJNq6wygPeDIK05xSUwKv24mOYAT/+dwOAHo5bzbMGluOvy49F5FoDEfbek0uw6n1ZfIcFNtx8GQ33j7UhmhMQ22ZL6t7zahir0ywV4WrGqYBkLKdQbXijIjQht3kQggMt9OBUp/btDxFp5K8qv5XMG9iZbzBor0zIsI0Ium6Kn5cxfafWl+GM+M9Xvaf6Maxjl7UlPpxqDUuMOPOyEfmjsE7h9vwqbNSN7UcbOiMkH6hXlA1fVDaYiZSEfAkNCPrK540lnEmzkhVsReT43ZmX1omVwY8csD3up24bHY9Lju9PuvPSUWmHVjtsIoRa0VRX/nUWQ2Y01CBj545NuG5z54zUZbjAtn1kVH3VYgRp9OBidXFGa9aXRnwyu+X68bY5Iy8vOM4wlENY8r9suokGxwOB246f0raZFcrYyqK8MBn5mHW2HKU+T0y3NjaHZbJq6fWm12gmjI/akp9iGnAH9YfAJCYD+RRwmeq4G+oCmBqvHvsKzt1dyQTZ8TjcspQR084ilNqSnB1Hwc2t8uJhqpA0tyFccpaUaKVu95ULfPJSqXiBontBhKvgVRNHsVveqIzlDJMIxypmlIfHA5j/SK1AaKYAFm7yJ4Vb4CYLGdkaryFvQjnVVoc21PrS1Hm98h93LjvJEKRGPYeN3qoiH35+VVzsXCyfRg7X9AZIf3CJEb6MGgLG3MwOwGqoidZzggA/Pjjs/H6vpMJXVIzweFw4H8/twB7m7tw3rTqPiWEpqMi4MH500YjFtNMtnwmWBuo+XIkRj577iR89txJts/VlftxxZwxePxNvQdHNtVSFQEvcEL0Genbb+l0OlBT6pP5AdbSTBGm+We8R8rZU0ZlNejlEqfTgYqAFy1dIZzsDsnky5k2rtW1Z0/Az55/D4/Fu7laQ3CAfq50BiMJz10wowY7j3XipR3HcNHMWllllMoZEdvxTnzl12996NSElve5YrxJjOiOml25firUa2Oa4oxUl5p/i2T5IupntHSFZGM8uzDNlNHFuOvDM6VwUN2/xnbduRITIOv6OmJBxmQ5I586qwHnTBklfxPrNS/cpPkTK7G9sQNv7D8Jn8eJrlAUNaU+TO1DHthgQmeE9Atr07JsEWtRZGq15wJ1bZpUWfnzJ1bh5g9M6XPG+cwxZbhsdv2ACBHAEDy/+8LCrAfNyoAX6m7lyhlJxxfOM+z8TBNYAXMSZl/KjgWjFSdkVLHPVKUk8l1EM6+z8zxzNNbkMSpB7EJonz9vkmkiYHVGAGDOOL0F/cx6c1L4BfHqoJd3HJfrzZT43AkVTFZEpdp5U6vxgXjuyUAgBvyuUBT/2qUnalpbmqdDzZOZoYgRNWQFpHZGhIhrbO+VFUt2YRqHw4HPvW8Szos3sXO7nNIBEYnswqVSrzmv2ykT9v0ep1xHCTAmTw6HAxNGGU6gmthdVeyV54BwWN7Y14Kn3tbLfD90en2/Qt+DAZ0R0i9K+umMvH9aDe67aq4pgW2gMeWMZJiVP9JwOR2oKvbJG2u6/JRcMXNMGS6YPhov7TiOKdX2PR3sUG+8/REjtco5au0BYv3cRXkWI/o+d+Fkd0iW39qJkYDXjWUXTcPtj78DQF8Iz8p/XX0G2nvCCdb+/Il6sveJrhDueXY7AN3OTydu/+2MsagIeHD25IF1j/weF+rK/Ghs70VPOAqv2ymTdjNFOAgOh1lweN16Z1WRi5QyTBMXLt3xPiE+tzNjN7KsyIOuUBSvW3KlXE4Hijwu9ISjmKusoeVw6DlSIhfE77H3DNTvP7W+VB4H4eRuOdKOPfEQzWWzcxsiHgjojJB+oVbTZNvwDNAvyCvPGCvLzgYDNWck06XIRyKqZT9YzggA3H/NmfjzlxbJ1umZUJEjMVKjVHzVWs5X1akZV1mUMm9iMBDuxDuH29AZjMDrcmJykqZcH583TtrwdrlbLqcjQYgAev7H1+J9P8TCkKL1fSqcTgcuPLU2ZZgzVzQo2zNnXHnaRRGtiEF7fFUgoSRY5I0UeVyoT5HzVl7kMTmkYyuKMhZh4nx9Kf77XqE0MBS/3wJLKFjtl2RdvkKgCvRT6wyROraiCPXlfkRiGjqCEdSW+TAvy9BWPqAYIf1CDXMMtbr1ZPhMK9gO3iA81FAT+JLNvgaCgNeN+ROrsktCNIVp+h72UgVIbblVjBgDVb5dEcAQYGvjfSSm1pbYNr8D9HDA/3z6THzm7PH45Pzskkk/dVaDKXzRMIgTg0xQReGZWYZoAGBqPKHzLJvcLyHIp9QUpwxjOJ0OkxNhl7yaDDVM+75TqnHFHEOMiPPa2oZAzRtJ5lqKhm5AomOm5rkNhxANQDFC+onZGRkuYsS4uDNtnjQSyZcz0hfUXi99Wc1ZoPZWsPYAUUVOvvNFAMUZibf6tkteVZleV4ofXHl61pMCt8uJOz88U/57/CDmb2WCKo76MsM/f2o1/nbL+/C9j5yW8NzouDhNlbwqUHNPsukZJFwOr9uJH1w5yyTCv3PFafjmkuk4d4p5ATtVwPiSTBRUZ2SGpcpKXW7gw8MgRANQjJB+IpwRj8uRcSfMfONxOWQTrf4MbMMdNdExV9U0A4VdaW9fUBvzJYoRxRnJIoQ0UKhL1wP2+SK54txTqvHRM8bC7XQMCSGmMr6fzojD4cDp48ptJx7T4qGtTCp01Aq0bJwRsd7NrRdOlV1oBeeeUo2lF5yS4FyYnJEkLQ/8Hhcum12PRZNHmUqWxee6nA5MHBXAGQ1DP0QDMIGV9BNRkttQmT7pbajgcDjgd+uJY5mu/jkSUcM0Q90ZMSew5iZMU2PpGKwnbuq9KLIZbAYKaxv8gRQjAPDTT8zBD/5t1pBzC8Wsf3ptaUJvkP7yxfdPwTmnjMKccRVpX6tW32SztMOyi6bjQ6fXm5aYSIcqRpI5IwBw/6fPtH38lJoSPPHlc1Bd4hsWIRqAYoT0k6m1pfjpJ+akzEQfivg8TvSEowXujOiDndMBUynhUER13fpzzFQBYm1hPraiCM/8+3kJPVjyhbW8Nl2Ypr84nY4hJ0QAveX9bz97VoKrkAu8bifmTcisj5B6XtgtkpeMIq8LZ2QZXlLb3SdzRtIxOwOBNZQYemceGXZ8fJ79Qm5DmSKPC60IZ9V4a6QxWqkkGOqu1rjKInhdTowu9fVrpdGqgBfVJT50hyK2FVwD7T5kg1pBNKbcn7BmSSFxgbK8QL5QXZmBds4ydUZGEoV7JyYFzS0fPAUb95/MumfBSEIkOg6H8uaKgBePf/mcfjeQczodeOLL5yAYGfqumKl0cwiJpELFVE2TYjXmXGASIzlaJmOoM7SvRkIGiGsWTsA1C7NbO2SkMbO+DDecO3HYDHRiTY7+ku/+IZmihmmGyzEayYhqmsqAJ6sFEPuCubSXzgghZATjdDpw9+WJ5Y5kaFBBZ2RIcWp9GdxOR9Zr4/QFU2kvnRFCCCH5wut2orpEb9k/e1zhhhOHCg1VAbx2x4VZr5DdF8qYM0IIIWSo8Mtrz0RzZ2jYhJZGOrkuLU5GJh1YRxoUI4QQMkTJtOyUjCyqir3wupxwOod+D6BcQTFCCCGEDCGKfW788tp5cDodSdcjGmlQjBBCCCFDjKHQW2Uw6ZPkuv/++zFx4kT4/X4sXLgQGzZsSPn6P/3pT5gxYwb8fj9OP/10PPPMM33aWEIIIYSMPLIWI4899hiWLVuGu+++G5s2bcKcOXOwZMkSHDt2zPb1a9euxdVXX43Pf/7zePPNN3HllVfiyiuvxLvvvtvvjSeEEELI8MehaZqWzRsWLlyIs846C//zP/8DAIjFYmhoaMBXvvIV3H777Qmvv+qqq9DV1YWnnnpKPnb22Wdj7ty5WLlyZUbf2d7ejvLycrS1taGsjPX2hBBCyHAg0/E7K2ckFAph48aNWLx4sfEBTicWL16MdevW2b5n3bp1ptcDwJIlS5K+HgCCwSDa29tNf4QQQggZmWQlRpqbmxGNRlFbW2t6vLa2Fo2NjbbvaWxszOr1ALBixQqUl5fLv4aGhmw2kxBCCCHDiCFZM7R8+XK0tbXJv4MHD+Z7kwghhBAyQGRV2ltdXQ2Xy4WmpibT401NTairq7N9T11dXVavBwCfzwefb3A63RFCCCEkv2TljHi9XsybNw+rV6+Wj8ViMaxevRqLFi2yfc+iRYtMrweA559/PunrCSGEEFJYZN30bNmyZbj++usxf/58LFiwAPfddx+6urpwww03AACuu+46jB07FitWrAAA3HrrrXj/+9+Pn/3sZ7jsssvw6KOP4o033sCvfvWr3O4JIYQQQoYlWYuRq666CsePH8ddd92FxsZGzJ07F88995xMUj1w4ACcTsNwOeecc/DII4/g29/+Nu644w5MnToVTz75JGbNmpW7vSCEEELIsCXrPiP5gH1GCCGEkOHHgPQZIYQQQgjJNRQjhBBCCMkrw2LVXhFJYidWQgghZPggxu10GSHDQox0dHQAADuxEkIIIcOQjo4OlJeXJ31+WCSwxmIxHDlyBKWlpXA4HDn73Pb2djQ0NODgwYMjNjGW+zj8Gen7B3AfRwIjff+Akb+PA7F/mqaho6MDY8aMMVXaWhkWzojT6cS4ceMG7PPLyspG5Imlwn0c/oz0/QO4jyOBkb5/wMjfx1zvXypHRMAEVkIIIYTkFYoRQgghhOSVghYjPp8Pd99994helI/7OPwZ6fsHcB9HAiN9/4CRv4/53L9hkcBKCCGEkJFLQTsjhBBCCMk/FCOEEEIIySsUI4QQQgjJKxQjhBBCCMkrBS1G7r//fkycOBF+vx8LFy7Ehg0b8r1JfWLFihU466yzUFpaipqaGlx55ZXYsWOH6TUf+MAH4HA4TH9f+tKX8rTF2fOd73wnYftnzJghn+/t7cXSpUsxatQolJSU4GMf+xiampryuMXZM3HixIR9dDgcWLp0KYDhdwxfeeUVXH755RgzZgwcDgeefPJJ0/OapuGuu+5CfX09ioqKsHjxYuzcudP0mpaWFlxzzTUoKytDRUUFPv/5z6Ozs3MQ9yI1qfYxHA7jtttuw+mnn47i4mKMGTMG1113HY4cOWL6DLvjfs899wzyniQn3XH87Gc/m7D9l1xyiek1Q/k4pts/u2vS4XDgJz/5iXzNUD6GmYwPmdw/Dxw4gMsuuwyBQAA1NTX45je/iUgkkrPtLFgx8thjj2HZsmW4++67sWnTJsyZMwdLlizBsWPH8r1pWfPyyy9j6dKleO211/D8888jHA7j4osvRldXl+l1N954I44ePSr/fvzjH+dpi/vGaaedZtr+V199VT73ta99DX/729/wpz/9CS+//DKOHDmCj370o3nc2ux5/fXXTfv3/PPPAwA+8YlPyNcMp2PY1dWFOXPm4P7777d9/sc//jH+67/+CytXrsT69etRXFyMJUuWoLe3V77mmmuuwZYtW/D888/jqaeewiuvvIKbbrppsHYhLan2sbu7G5s2bcKdd96JTZs24fHHH8eOHTtwxRVXJLz2e9/7num4fuUrXxmMzc+IdMcRAC655BLT9v/hD38wPT+Uj2O6/VP36+jRo1i1ahUcDgc+9rGPmV43VI9hJuNDuvtnNBrFZZddhlAohLVr1+Lhhx/GQw89hLvuuit3G6oVKAsWLNCWLl0q/x2NRrUxY8ZoK1asyONW5YZjx45pALSXX35ZPvb+979fu/XWW/O3Uf3k7rvv1ubMmWP7XGtrq+bxeLQ//elP8rFt27ZpALR169YN0hbmnltvvVWbMmWKFovFNE0b3scQgPbEE0/If8diMa2urk77yU9+Ih9rbW3VfD6f9oc//EHTNE3bunWrBkB7/fXX5WueffZZzeFwaIcPHx60bc8U6z7asWHDBg2Atn//fvnYhAkTtJ///OcDu3E5wm4fr7/+eu0jH/lI0vcMp+OYyTH8yEc+on3wgx80PTacjqF1fMjk/vnMM89oTqdTa2xslK954IEHtLKyMi0YDOZkuwrSGQmFQti4cSMWL14sH3M6nVi8eDHWrVuXxy3LDW1tbQCAqqoq0+O///3vUV1djVmzZmH58uXo7u7Ox+b1mZ07d2LMmDGYPHkyrrnmGhw4cAAAsHHjRoTDYdPxnDFjBsaPHz9sj2coFMLvfvc7fO5znzMtDjncj6Fg7969aGxsNB2z8vJyLFy4UB6zdevWoaKiAvPnz5evWbx4MZxOJ9avXz/o25wL2tra4HA4UFFRYXr8nnvuwahRo3DGGWfgJz/5SU7t78FgzZo1qKmpwfTp03HzzTfjxIkT8rmRdBybmprw9NNP4/Of/3zCc8PlGFrHh0zun+vWrcPpp5+O2tpa+ZolS5agvb0dW7Zsycl2DYuF8nJNc3MzotGo6YcFgNraWmzfvj1PW5UbYrEYvvrVr+Lcc8/FrFmz5OOf/vSnMWHCBIwZMwZvv/02brvtNuzYsQOPP/54Hrc2cxYuXIiHHnoI06dPx9GjR/Hd734X5513Ht599100NjbC6/Um3OBra2vR2NiYnw3uJ08++SRaW1vx2c9+Vj423I+hijgudtegeK6xsRE1NTWm591uN6qqqoblce3t7cVtt92Gq6++2rQI2b//+7/jzDPPRFVVFdauXYvly5fj6NGjuPfee/O4tZlzySWX4KMf/SgmTZqE3bt344477sCll16KdevWweVyjajj+PDDD6O0tDQhBDxcjqHd+JDJ/bOxsdH2WhXP5YKCFCMjmaVLl+Ldd9815VMAMMVnTz/9dNTX1+PCCy/E7t27MWXKlMHezKy59NJL5f/Pnj0bCxcuxIQJE/DHP/4RRUVFedyygeE3v/kNLr30UowZM0Y+NtyPYSETDofxyU9+Epqm4YEHHjA9t2zZMvn/s2fPhtfrxRe/+EWsWLFiWLQd/9SnPiX///TTT8fs2bMxZcoUrFmzBhdeeGEetyz3rFq1Ctdccw38fr/p8eFyDJOND0OBggzTVFdXw+VyJWQLNzU1oa6uLk9b1X9uueUWPPXUU3jppZcwbty4lK9duHAhAGDXrl2DsWk5p6KiAtOmTcOuXbtQV1eHUCiE1tZW02uG6/Hcv38/XnjhBXzhC19I+brhfAzFcUl1DdbV1SUklEciEbS0tAyr4yqEyP79+/H888+nXZp94cKFiEQi2Ldv3+BsYI6ZPHkyqqur5Xk5Uo7jP//5T+zYsSPtdQkMzWOYbHzI5P5ZV1dne62K53JBQYoRr9eLefPmYfXq1fKxWCyG1atXY9GiRXncsr6haRpuueUWPPHEE3jxxRcxadKktO/ZvHkzAKC+vn6At25g6OzsxO7du1FfX4958+bB4/GYjueOHTtw4MCBYXk8f/vb36KmpgaXXXZZytcN52M4adIk1NXVmY5Ze3s71q9fL4/ZokWL0Nraio0bN8rXvPjii4jFYlKIDXWEENm5cydeeOEFjBo1Ku17Nm/eDKfTmRDaGC4cOnQIJ06ckOflSDiOgO5Wzps3D3PmzEn72qF0DNOND5ncPxctWoR33nnHJCqFsJ45c2bONrQgefTRRzWfz6c99NBD2tatW7WbbrpJq6ioMGULDxduvvlmrby8XFuzZo129OhR+dfd3a1pmqbt2rVL+973vqe98cYb2t69e7W//vWv2uTJk7Xzzz8/z1ueOV//+te1NWvWaHv37tX+9a9/aYsXL9aqq6u1Y8eOaZqmaV/60pe08ePHay+++KL2xhtvaIsWLdIWLVqU563Onmg0qo0fP1677bbbTI8Px2PY0dGhvfnmm9qbb76pAdDuvfde7c0335SVJPfcc49WUVGh/fWvf9Xefvtt7SMf+Yg2adIkraenR37GJZdcop1xxhna+vXrtVdffVWbOnWqdvXVV+drlxJItY+hUEi74oortHHjxmmbN282XZuiAmHt2rXaz3/+c23z5s3a7t27td/97nfa6NGjteuuuy7Pe2aQah87Ojq0b3zjG9q6deu0vXv3ai+88IJ25plnalOnTtV6e3vlZwzl45juPNU0TWtra9MCgYD2wAMPJLx/qB/DdOODpqW/f0YiEW3WrFnaxRdfrG3evFl77rnntNGjR2vLly/P2XYWrBjRNE377//+b238+PGa1+vVFixYoL322mv53qQ+AcD277e//a2maZp24MAB7fzzz9eqqqo0n8+nnXLKKdo3v/lNra2tLb8bngVXXXWVVl9fr3m9Xm3s2LHaVVddpe3atUs+39PTo335y1/WKisrtUAgoP3bv/2bdvTo0Txucd/4+9//rgHQduzYYXp8OB7Dl156yfa8vP766zVN08t777zzTq22tlbz+XzahRdemLDfJ06c0K6++mqtpKREKysr02644Qato6MjD3tjT6p93Lt3b9Jr86WXXtI0TdM2btyoLVy4UCsvL9f8fr926qmnaj/60Y9MA3m+SbWP3d3d2sUXX6yNHj1a83g82oQJE7Qbb7wxYVI3lI9juvNU0zTtl7/8pVZUVKS1trYmvH+oH8N044OmZXb/3Ldvn3bppZdqRUVFWnV1tfb1r39dC4fDOdtOR3xjCSGEEELyQkHmjBBCCCFk6EAxQgghhJC8QjFCCCGEkLxCMUIIIYSQvEIxQgghhJC8QjFCCCGEkLxCMUIIIYSQvEIxQgghhJC8QjFCCCGEkLxCMUIIIYSQvEIxQgghhJC8QjFCCCGEkLzy/wNsAbYtwSjnIwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.926859438419342, 0.5798824429512024, 0.5765262842178345, 0.38911333680152893, 0.6162475347518921, 0.3056570589542389, 0.2140362560749054, 0.3249744772911072, 0.19822916388511658, 0.12390418350696564, 0.29658371210098267, 0.13050994277000427, 0.38102489709854126, 0.1391666829586029, 0.34387943148612976, 0.31914642453193665, 0.4085780680179596, 0.11901049315929413, 0.1600409597158432, 0.312234491109848, 0.17195749282836914, 0.10009543597698212, 0.16789646446704865, 0.11662297695875168, 0.1459205001592636, 0.14809320867061615, 0.13619808852672577, 0.23572465777397156, 0.11186514794826508, 0.1921180933713913, 0.08588744699954987, 0.09134189784526825, 0.22589051723480225, 0.16829000413417816, 0.1316504180431366, 0.1680798977613449, 0.040479350835084915, 0.10419356822967529, 0.17800596356391907, 0.1881958693265915, 0.11618566513061523, 0.16707682609558105, 0.14713512361049652, 0.05685112997889519, 0.12246113270521164, 0.07150429487228394, 0.182701975107193, 0.10442238301038742, 0.11543530970811844, 0.14875611662864685, 0.16032394766807556, 0.16643764078617096, 0.06855683028697968, 0.0939795970916748, 0.1373254507780075, 0.22518393397331238, 0.03436705842614174, 0.1595362424850464, 0.1362185925245285, 0.0901525616645813, 0.061917878687381744, 0.14661933481693268, 0.16042281687259674, 0.08841226249933243, 0.11509829014539719, 0.10363399982452393, 0.11387105286121368, 0.06228894367814064, 0.06442445516586304, 0.11806720495223999, 0.08481373637914658, 0.11072732508182526, 0.11411463469266891, 0.08215785026550293, 0.07125178724527359, 0.08377014100551605, 0.1844082921743393, 0.14918021857738495, 0.060840409249067307, 0.1520085632801056, 0.12206719815731049, 0.16842199862003326, 0.09294694662094116, 0.2332819700241089, 0.10102049261331558, 0.031814638525247574, 0.1977538764476776, 0.07086123526096344, 0.1718328446149826, 0.10929672420024872, 0.1271364539861679, 0.1049775555729866, 0.09304902702569962, 0.15692034363746643, 0.06366594135761261, 0.08471304178237915, 0.0709020271897316, 0.0681011900305748, 0.054466672241687775, 0.16325189173221588, 0.16443350911140442, 0.11782340705394745, 0.08884026855230331, 0.11864031106233597, 0.03551216423511505, 0.14267781376838684, 0.06827908754348755, 0.157740980386734, 0.11593253910541534, 0.149246945977211, 0.09694492071866989, 0.09687308222055435, 0.0355883426964283, 0.09428124129772186, 0.14643308520317078, 0.041025854647159576, 0.06524989753961563, 0.12275989353656769, 0.07753617316484451, 0.1826504021883011, 0.09199946373701096, 0.09042970836162567, 0.08690689504146576, 0.06697844713926315, 0.12414806336164474, 0.11127519607543945, 0.10144217312335968, 0.0748482495546341, 0.09542932361364365, 0.06679590791463852, 0.10630650818347931, 0.024346468970179558, 0.05778365582227707, 0.09091684967279434, 0.09397436678409576, 0.06205039098858833, 0.05084054544568062, 0.1208549216389656, 0.14198294281959534, 0.057625263929367065, 0.12969033420085907, 0.07601676881313324, 0.054918400943279266, 0.04421194642782211, 0.09055928885936737, 0.08840232342481613, 0.1400599330663681, 0.08927033841609955, 0.05705525726079941, 0.06798502057790756, 0.17176957428455353, 0.08744070678949356, 0.16282029449939728, 0.07609961926937103, 0.08052238076925278, 0.06950219720602036, 0.06840993463993073, 0.12223253399133682, 0.07005349546670914, 0.08739044517278671, 0.04063459858298302, 0.06768124550580978, 0.20008358359336853, 0.20870451629161835, 0.10429811477661133, 0.12113429605960846, 0.12464088946580887, 0.04918114095926285, 0.08449647575616837, 0.11097754538059235, 0.04373687133193016, 0.08203530311584473, 0.121119424700737, 0.10684315115213394, 0.0998196229338646, 0.027854012325406075, 0.08060462772846222, 0.1681142896413803, 0.18238304555416107, 0.061901796609163284, 0.1433105319738388, 0.04371311515569687, 0.053529176861047745, 0.17659179866313934, 0.04835459589958191, 0.07398831844329834, 0.11257441341876984, 0.018880698829889297, 0.20332331955432892, 0.06288564205169678, 0.12323945015668869, 0.0446975901722908, 0.07821487635374069, 0.0698595717549324, 0.0435844361782074, 0.06181991100311279, 0.11016310751438141, 0.06692808121442795, 0.13194571435451508, 0.15902996063232422]\n",
      "[68.75, 80.35714285714286, 83.03571428571429, 86.60714285714286, 83.92857142857143, 92.85714285714286, 93.75, 91.07142857142857, 93.75, 97.32142857142857, 93.75, 97.32142857142857, 91.96428571428571, 96.42857142857143, 91.07142857142857, 86.60714285714286, 91.96428571428571, 97.32142857142857, 97.32142857142857, 87.5, 96.42857142857143, 96.42857142857143, 96.42857142857143, 94.64285714285714, 94.64285714285714, 91.96428571428571, 95.53571428571429, 88.39285714285714, 95.53571428571429, 91.07142857142857, 96.42857142857143, 97.32142857142857, 91.07142857142857, 93.75, 94.64285714285714, 95.53571428571429, 98.21428571428571, 96.42857142857143, 91.96428571428571, 91.96428571428571, 96.42857142857143, 96.42857142857143, 97.32142857142857, 99.10714285714286, 95.53571428571429, 97.32142857142857, 94.64285714285714, 96.42857142857143, 96.42857142857143, 93.75, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 94.64285714285714, 93.75, 99.10714285714286, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 96.42857142857143, 95.53571428571429, 95.53571428571429, 97.32142857142857, 96.42857142857143, 95.53571428571429, 97.32142857142857, 95.53571428571429, 97.32142857142857, 96.42857142857143, 97.32142857142857, 96.42857142857143, 98.21428571428571, 97.32142857142857, 96.42857142857143, 92.85714285714286, 96.42857142857143, 98.21428571428571, 95.53571428571429, 95.53571428571429, 94.64285714285714, 96.42857142857143, 91.96428571428571, 97.32142857142857, 100.0, 95.53571428571429, 97.32142857142857, 94.64285714285714, 97.32142857142857, 95.53571428571429, 97.32142857142857, 96.42857142857143, 93.75, 98.21428571428571, 97.32142857142857, 98.21428571428571, 97.32142857142857, 98.21428571428571, 92.85714285714286, 94.64285714285714, 95.53571428571429, 96.42857142857143, 95.53571428571429, 100.0, 94.64285714285714, 99.10714285714286, 91.96428571428571, 94.64285714285714, 94.64285714285714, 98.21428571428571, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 99.10714285714286, 98.21428571428571, 96.42857142857143, 94.64285714285714, 95.53571428571429, 97.32142857142857, 96.42857142857143, 97.32142857142857, 98.21428571428571, 97.32142857142857, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 95.53571428571429, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 98.21428571428571, 95.53571428571429, 94.64285714285714, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 97.32142857142857, 98.21428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 97.32142857142857, 97.32142857142857, 91.96428571428571, 98.21428571428571, 95.53571428571429, 97.32142857142857, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 93.75, 91.96428571428571, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 95.53571428571429, 96.42857142857143, 95.53571428571429, 94.64285714285714, 100.0, 97.32142857142857, 94.64285714285714, 95.53571428571429, 98.21428571428571, 94.64285714285714, 99.10714285714286, 97.32142857142857, 94.64285714285714, 99.10714285714286, 96.42857142857143, 95.53571428571429, 100.0, 92.85714285714286, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 97.32142857142857, 98.21428571428571, 97.32142857142857, 95.53571428571429, 98.21428571428571, 95.53571428571429, 94.64285714285714]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.2594882249832153, 0.6869522929191589, 0.600184977054596, 0.690629780292511, 0.5204206109046936, 0.2701438069343567, 0.35688140988349915, 0.2761969268321991, 0.27368226647377014, 0.22630558907985687, 0.2644679546356201, 0.31281813979148865, 0.19735634326934814, 0.3686358332633972, 0.23618724942207336, 0.19789843261241913, 0.2886165976524353, 0.12022083252668381, 0.2554399073123932, 0.1768033653497696, 0.16303955018520355, 0.23466429114341736, 0.20896689593791962, 0.1168498769402504, 0.21713821589946747, 0.18200276792049408, 0.1991729885339737, 0.2869015336036682, 0.16159529983997345, 0.13324055075645447, 0.2778576910495758, 0.2161935269832611, 0.15066981315612793, 0.14978404343128204, 0.06754697859287262, 0.15028057992458344, 0.17551803588867188, 0.11478453129529953, 0.12406468391418457, 0.15874741971492767, 0.2458413690328598, 0.17700816690921783, 0.0767260193824768, 0.10013774782419205, 0.25924259424209595, 0.1627066284418106, 0.19659772515296936, 0.059449702501297, 0.07740725576877594, 0.15473364293575287, 0.07163126021623611, 0.10921919345855713, 0.12561890482902527, 0.12441316992044449, 0.09992308914661407, 0.23122504353523254, 0.12597858905792236, 0.09121876955032349, 0.17455177009105682, 0.17380677163600922, 0.15454497933387756, 0.20913219451904297, 0.11671821027994156, 0.09485926479101181, 0.1715610921382904, 0.08929944783449173, 0.11672364175319672, 0.050766509026288986, 0.11602672189474106, 0.10676075518131256, 0.15511228144168854, 0.1518099159002304, 0.07946570962667465, 0.11004823446273804, 0.07473564893007278, 0.1973530501127243, 0.08515294641256332, 0.13601332902908325, 0.09825979918241501, 0.07607413083314896, 0.13540029525756836, 0.2706320881843567, 0.06872200220823288, 0.09723210334777832, 0.05753154307603836, 0.1335270255804062, 0.13564208149909973, 0.0967550203204155, 0.15338574349880219, 0.062255654484033585, 0.14555026590824127, 0.07070455700159073, 0.10438094288110733, 0.16043983399868011, 0.1740056574344635, 0.15924787521362305, 0.10191033780574799, 0.05572715774178505, 0.09756623208522797, 0.032436028122901917, 0.10798289626836777, 0.07723087817430496, 0.20012210309505463, 0.13653628528118134, 0.053586434572935104, 0.07284535467624664, 0.14428162574768066, 0.15057626366615295, 0.11712069064378738, 0.10265036672353745, 0.04047949239611626, 0.16345693171024323, 0.15780557692050934, 0.11145796626806259, 0.16627787053585052, 0.11629368364810944, 0.11891280859708786, 0.08022469282150269, 0.12088615447282791, 0.04112016037106514, 0.06751764565706253, 0.07758527249097824, 0.14866051077842712, 0.14494386315345764, 0.030841810628771782, 0.09701882302761078, 0.17838908731937408, 0.07223965227603912, 0.09194641560316086, 0.07086469978094101, 0.10021968930959702, 0.1019633486866951, 0.19615688920021057, 0.07017975300550461, 0.12827789783477783, 0.09756279736757278, 0.06477174907922745, 0.03693106025457382, 0.12096627801656723, 0.1674477756023407, 0.08270222693681717, 0.2489703744649887, 0.055797941982746124, 0.08574305474758148, 0.06824671477079391, 0.14880366623401642, 0.09384167939424515, 0.18580509722232819, 0.176776722073555, 0.14625534415245056, 0.1140652447938919, 0.08417453616857529, 0.08993501961231232, 0.10395150631666183, 0.14252249896526337, 0.16465027630329132, 0.06642190366983414, 0.10371024906635284, 0.18705402314662933, 0.12385065108537674, 0.0821157768368721, 0.12157001346349716, 0.1689579337835312, 0.06763536483049393, 0.041486140340566635, 0.14797332882881165, 0.04949511960148811, 0.09390725195407867, 0.08525027334690094, 0.08405773341655731, 0.13683179020881653, 0.01874631643295288, 0.10958188027143478, 0.06646334379911423, 0.11896442621946335, 0.16517449915409088, 0.21837686002254486, 0.15120212733745575, 0.12754613161087036, 0.07414811104536057, 0.10529939830303192, 0.11322859674692154, 0.10119344294071198, 0.05486499145627022, 0.07976572215557098, 0.13962598145008087, 0.08104024827480316, 0.08338843286037445, 0.08739305287599564, 0.07880588620901108, 0.07057607173919678, 0.030428621917963028, 0.08385681360960007, 0.11176357418298721, 0.036409616470336914, 0.1095203086733818, 0.05477362498641014, 0.11000562459230423, 0.044935666024684906, 0.13466167449951172]\n",
    "# acc_list_epoch_ = [49.107142857142854, 78.57142857142857, 85.71428571428571, 78.57142857142857, 85.71428571428571, 90.17857142857143, 85.71428571428571, 89.28571428571429, 89.28571428571429, 94.64285714285714, 91.96428571428571, 88.39285714285714, 94.64285714285714, 88.39285714285714, 91.96428571428571, 96.42857142857143, 91.07142857142857, 95.53571428571429, 91.07142857142857, 93.75, 93.75, 92.85714285714286, 97.32142857142857, 96.42857142857143, 94.64285714285714, 94.64285714285714, 93.75, 89.28571428571429, 95.53571428571429, 94.64285714285714, 92.85714285714286, 91.96428571428571, 91.96428571428571, 95.53571428571429, 98.21428571428571, 95.53571428571429, 93.75, 96.42857142857143, 94.64285714285714, 94.64285714285714, 96.42857142857143, 93.75, 96.42857142857143, 94.64285714285714, 92.85714285714286, 92.85714285714286, 94.64285714285714, 98.21428571428571, 99.10714285714286, 95.53571428571429, 97.32142857142857, 97.32142857142857, 95.53571428571429, 96.42857142857143, 97.32142857142857, 93.75, 93.75, 97.32142857142857, 94.64285714285714, 97.32142857142857, 92.85714285714286, 92.85714285714286, 94.64285714285714, 96.42857142857143, 95.53571428571429, 98.21428571428571, 97.32142857142857, 98.21428571428571, 97.32142857142857, 95.53571428571429, 94.64285714285714, 92.85714285714286, 97.32142857142857, 96.42857142857143, 98.21428571428571, 93.75, 97.32142857142857, 94.64285714285714, 95.53571428571429, 99.10714285714286, 96.42857142857143, 91.96428571428571, 97.32142857142857, 96.42857142857143, 98.21428571428571, 96.42857142857143, 95.53571428571429, 97.32142857142857, 94.64285714285714, 99.10714285714286, 95.53571428571429, 99.10714285714286, 97.32142857142857, 96.42857142857143, 94.64285714285714, 94.64285714285714, 95.53571428571429, 97.32142857142857, 97.32142857142857, 99.10714285714286, 95.53571428571429, 98.21428571428571, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 95.53571428571429, 97.32142857142857, 96.42857142857143, 95.53571428571429, 99.10714285714286, 95.53571428571429, 93.75, 97.32142857142857, 95.53571428571429, 98.21428571428571, 96.42857142857143, 97.32142857142857, 98.21428571428571, 98.21428571428571, 97.32142857142857, 98.21428571428571, 96.42857142857143, 93.75, 99.10714285714286, 96.42857142857143, 93.75, 95.53571428571429, 95.53571428571429, 98.21428571428571, 94.64285714285714, 96.42857142857143, 94.64285714285714, 96.42857142857143, 97.32142857142857, 95.53571428571429, 98.21428571428571, 99.10714285714286, 94.64285714285714, 96.42857142857143, 95.53571428571429, 92.85714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 97.32142857142857, 96.42857142857143, 93.75, 94.64285714285714, 97.32142857142857, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 93.75, 96.42857142857143, 98.21428571428571, 94.64285714285714, 96.42857142857143, 95.53571428571429, 97.32142857142857, 95.53571428571429, 96.42857142857143, 98.21428571428571, 99.10714285714286, 97.32142857142857, 98.21428571428571, 96.42857142857143, 96.42857142857143, 98.21428571428571, 94.64285714285714, 100.0, 95.53571428571429, 97.32142857142857, 97.32142857142857, 93.75, 92.85714285714286, 94.64285714285714, 95.53571428571429, 98.21428571428571, 93.75, 95.53571428571429, 98.21428571428571, 98.21428571428571, 97.32142857142857, 97.32142857142857, 98.21428571428571, 95.53571428571429, 96.42857142857143, 97.32142857142857, 96.42857142857143, 99.10714285714286, 97.32142857142857, 96.42857142857143, 98.21428571428571, 96.42857142857143, 99.10714285714286, 94.64285714285714, 98.21428571428571, 96.42857142857143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 97.45%\n",
      "Loss on the train set: 0.08\n",
      "Accuracy on the test set: 94.83%\n",
      "Loss on the test set: 0.20\n",
      "Generalization error: 0.12118273\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
