{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.444765</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.298896</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.981285</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.375231</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.6115</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.461337</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.474976</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.349573</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.305988</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.574446</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.403466</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.942909</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.606352</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.701782</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.072704</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.574327</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.148787</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.722258</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.178445</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.97144</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.57073</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.417943</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.102391</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.459313</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.667875</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.536508</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.958556</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.362757</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.459828</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.736105</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.879323</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.977139</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.251554</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.010125</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.454192</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.810115</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.494684</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.505693</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.3382</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.459349</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.350814</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.808876</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.77443</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.37609</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.770093</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.174574</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.257113</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.944567</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.736673</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.686891</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.531709</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.413771</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.646092</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.109678</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.643471</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.314868</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.745689</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.930977</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.502027</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.10276</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.285512</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.544522</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.488994</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.892229</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.703332</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.478073</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.596283</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.655749</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.471293</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.765415</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.959203</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.694512</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.957973</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.69004</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.521754</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.352868</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.487804</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.977791</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.847887</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.407042</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.57355</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.480239</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.296327</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.030575</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.082543</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.182459</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.590332</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.257814</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.291499</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.624778</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.852239</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.903811</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.578281</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.294706</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.242244</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.586577</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x70c36814ec10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.647809</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.369767</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.869716</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.795248</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.789224</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.563946</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.699773</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.080052</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.937829</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.026983</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.985566</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.213765</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.627006</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.42577</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.217352</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.514882</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.885561</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.117004</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.652238</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.143742</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.206169</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.239271</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.945104</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.110243</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.006088</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.068199</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.422157</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.326301</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.570646</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.890898</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.927472</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.164064</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.270471</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.325139</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.900582</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.218173</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.850722</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.19663</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.576028</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.977152</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.227004</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.689973</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.409185</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.695622</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.205899</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.946235</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.749327</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.405655</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.496854</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.672297</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.133069</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.459075</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.581623</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.682833</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.656808</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.101103</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.982407</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.051732</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.558024</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.523207</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.124299</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.90716</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.356173</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.467076</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.686721</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.890042</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.291661</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.939502</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.694339</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.387371</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.311519</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.516684</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.488237</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.052907</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.898473</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x70c3680ec1f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 76.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [4, 20, 4], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  249\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 23.3158, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 7.8557, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 5.8248, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 3.9349, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 3.4255, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 3.1977, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.6821, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.6513, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.5457, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.4442, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 2.4348578453063965, accuracy: 11.4 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 2.520401954650879, accuracy: 7.6 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 2.4168031215667725, accuracy: 10.0 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 2.9141383171081543, accuracy: 2.0 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 2.374950408935547, accuracy: 9.5 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 2.369163990020752, accuracy: 7.5 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 2.363171100616455, accuracy: 5.2 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 2.3598203659057617, accuracy: 7.1 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 2.3582763671875, accuracy: 5.7 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 2.353318452835083, accuracy: 5.2 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3512, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.4037, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.2909, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3695, batch time: 0.09, accuracy:  0.00%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.2788, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.2781, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.2566, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.2790, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3500, batch time: 0.09, accuracy:  3.91%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3272, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 2.290604829788208, accuracy: 5.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 2.566690683364868, accuracy: 12.1 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 2.310879945755005, accuracy: 8.2 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 2.3517990112304688, accuracy: 8.9 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 2.2822656631469727, accuracy: 4.8 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 2.2770941257476807, accuracy: 5.6 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 2.277609348297119, accuracy: 5.7 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 2.2733407020568848, accuracy: 6.0 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 2.2732224464416504, accuracy: 5.5 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 2.2648115158081055, accuracy: 6.8 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.2512, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.2996, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.2641, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.2427, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.2871, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.2926, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.2240, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.2087, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.2638, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.2431, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 2.256948947906494, accuracy: 8.2 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.300255298614502, accuracy: 2.9 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 2.2565603256225586, accuracy: 5.3 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 2.2692601680755615, accuracy: 12.0 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 2.2353570461273193, accuracy: 7.7 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 2.2304458618164062, accuracy: 8.4 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 2.234391927719116, accuracy: 9.0 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 2.221421241760254, accuracy: 8.6 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 2.221047878265381, accuracy: 9.2 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 2.216609001159668, accuracy: 7.8 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.1998, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.2700, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.1834, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.2188, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.2164, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.2092, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.2323, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.2223, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.2309, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.2486, batch time: 0.09, accuracy:  3.12%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 2.216799259185791, accuracy: 11.9 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 2.5939581394195557, accuracy: 11.9 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 2.209998369216919, accuracy: 12.1 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 2.204937696456909, accuracy: 12.9 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 2.213822603225708, accuracy: 10.9 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 2.21588134765625, accuracy: 11.7 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 2.205475330352783, accuracy: 13.2 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 2.1934030055999756, accuracy: 14.2 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 2.1890177726745605, accuracy: 13.5 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 2.1855263710021973, accuracy: 12.6 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.1995, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.1958, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.1460, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.1622, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.1276, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.1613, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.1258, batch time: 0.09, accuracy:  15.62%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.1436, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.2101, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.1616, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 2.1443593502044678, accuracy: 12.4 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 2.142643451690674, accuracy: 13.4 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 2.141946792602539, accuracy: 13.7 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 2.1384084224700928, accuracy: 12.9 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 2.134042501449585, accuracy: 13.4 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 2.132399559020996, accuracy: 13.7 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 2.146646738052368, accuracy: 14.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 2.1460039615631104, accuracy: 13.8 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 2.130126476287842, accuracy: 15.1 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 2.1363511085510254, accuracy: 13.6 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.1835, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.1581, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.0896, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.0988, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.0731, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.1167, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.1342, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.1983, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.1613, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.1991, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 2.1506853103637695, accuracy: 12.7 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 2.1519014835357666, accuracy: 12.7 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 2.1473207473754883, accuracy: 12.9 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 2.1511425971984863, accuracy: 14.7 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 2.1404201984405518, accuracy: 13.1 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 2.139662027359009, accuracy: 12.8 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 2.139547109603882, accuracy: 13.3 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 2.1379644870758057, accuracy: 13.1 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 2.1385908126831055, accuracy: 12.9 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 2.1356446743011475, accuracy: 13.5 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.1847, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.1464, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.1060, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.1246, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.1769, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.1475, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.1661, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.1595, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.0888, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.1390, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 2.12713360786438, accuracy: 11.7 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 2.125703811645508, accuracy: 12.7 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 2.1194939613342285, accuracy: 13.2 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 2.1397078037261963, accuracy: 14.3 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 2.186918020248413, accuracy: 15.2 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 2.1157360076904297, accuracy: 13.6 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 2.1210007667541504, accuracy: 14.0 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 3.1866660118103027, accuracy: 9.3 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 2.1158950328826904, accuracy: 13.9 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 2.1129820346832275, accuracy: 13.4 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.9912, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.1437, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.1833, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.1728, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.1016, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.0968, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.0576, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.1187, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.0736, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.1330, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 2.1232852935791016, accuracy: 12.5 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.1209230422973633, accuracy: 13.8 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 2.2736704349517822, accuracy: 4.9 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 2.120422840118408, accuracy: 13.2 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 2.117565393447876, accuracy: 13.9 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 2.11586594581604, accuracy: 13.2 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 2.115412950515747, accuracy: 13.4 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 2.1147844791412354, accuracy: 13.9 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 2.11423921585083, accuracy: 14.6 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 2.1134514808654785, accuracy: 14.4 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.2183, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.0967, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.1230, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.0743, batch time: 0.09, accuracy:  15.62%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.0381, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.1124, batch time: 0.09, accuracy:  17.97%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.0887, batch time: 0.10, accuracy:  17.19%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.1198, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.1071, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.1421, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 2.1030805110931396, accuracy: 13.0 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 2.1073124408721924, accuracy: 16.4 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 2.1103456020355225, accuracy: 15.8 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 2.116654872894287, accuracy: 15.9 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 2.1119272708892822, accuracy: 16.7 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 2.09513783454895, accuracy: 16.1 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 2.0933139324188232, accuracy: 16.3 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 2.0925216674804688, accuracy: 17.3 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 2.0904855728149414, accuracy: 16.1 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 2.0899033546447754, accuracy: 16.7 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.0553, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.1253, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.0948, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.0659, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.1568, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.0996, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.0536, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.0998, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.0228, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.1054, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 2.083620548248291, accuracy: 19.4 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 2.085116386413574, accuracy: 20.6 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 2.078847885131836, accuracy: 20.1 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 2.0781567096710205, accuracy: 20.2 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 2.1483988761901855, accuracy: 12.6 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 2.12076473236084, accuracy: 14.7 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 2.0732030868530273, accuracy: 20.7 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 2.0892081260681152, accuracy: 16.6 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 2.105072021484375, accuracy: 18.3 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 3.7401282787323, accuracy: 7.4 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.1612, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.1224, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.0440, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.1775, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.1316, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.0854, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.0865, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.0602, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.0746, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.0620, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 2.091045379638672, accuracy: 17.0 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 2.1046509742736816, accuracy: 18.3 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 2.3862624168395996, accuracy: 12.8 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 2.097787618637085, accuracy: 18.2 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 2.084503412246704, accuracy: 18.1 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 2.0827372074127197, accuracy: 18.3 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 2.082307815551758, accuracy: 18.3 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 2.081263780593872, accuracy: 18.6 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 2.0803022384643555, accuracy: 19.3 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 2.078839063644409, accuracy: 19.2 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.1126, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.1009, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.0636, batch time: 0.09, accuracy:  17.97%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 1.9995, batch time: 0.05, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.1044, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.0873, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.1276, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.1261, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.0899, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 1.9982, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 2.0627686977386475, accuracy: 18.8 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 2.0736804008483887, accuracy: 18.4 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 2.097321033477783, accuracy: 17.6 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 2.0573947429656982, accuracy: 23.8 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 2.0903944969177246, accuracy: 18.8 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 2.0556375980377197, accuracy: 23.3 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 2.0537285804748535, accuracy: 24.4 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 2.080070734024048, accuracy: 21.9 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 2.0809690952301025, accuracy: 19.6 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 2.0691463947296143, accuracy: 20.2 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.0305, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.0313, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.1000, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.0795, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.1113, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 1.9072, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.0182, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.0435, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.0732, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.0245, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 2.047680616378784, accuracy: 22.7 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 2.0785458087921143, accuracy: 20.8 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 2.0812153816223145, accuracy: 21.0 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 2.0508530139923096, accuracy: 24.2 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 2.043198585510254, accuracy: 24.0 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 2.04052472114563, accuracy: 23.1 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 2.039886236190796, accuracy: 24.1 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 2.0386247634887695, accuracy: 24.8 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 2.03813099861145, accuracy: 24.0 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 2.037336826324463, accuracy: 25.2 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 1.9824, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.0648, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 1.9947, batch time: 0.22, accuracy:  25.78%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.0122, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.1593, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 1.9291, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 1.9694, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.0170, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.0668, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.0087, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 2.0245068073272705, accuracy: 24.3 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 2.078305244445801, accuracy: 18.2 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 2.034930467605591, accuracy: 27.0 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 2.1027119159698486, accuracy: 18.0 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 2.0163419246673584, accuracy: 31.6 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 2.0151309967041016, accuracy: 30.5 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 2.016752243041992, accuracy: 29.9 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 2.016425609588623, accuracy: 28.9 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 2.0265321731567383, accuracy: 29.3 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 2.0141780376434326, accuracy: 29.5 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.0542, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.0854, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.0028, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.1168, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.0561, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.0531, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 1.9661, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.0948, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 1.9748, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 1.9787, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 2.0146758556365967, accuracy: 26.2 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 2.052020788192749, accuracy: 20.8 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 2.0231528282165527, accuracy: 26.9 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 2.008572816848755, accuracy: 26.6 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 2.083308458328247, accuracy: 23.4 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 6.057612419128418, accuracy: 9.2 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 2.0030245780944824, accuracy: 27.7 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 2.0003230571746826, accuracy: 30.2 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 1.9989066123962402, accuracy: 29.5 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 1.9984990358352661, accuracy: 28.5 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 1.9581, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.0797, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.0032, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.0256, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.0488, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.0077, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.0082, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.0481, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 1.9689, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.0592, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 2.027233600616455, accuracy: 27.0 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 2.0386455059051514, accuracy: 28.6 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 2.0148348808288574, accuracy: 29.1 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 2.0148048400878906, accuracy: 28.2 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 2.0341029167175293, accuracy: 20.8 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 2.0112390518188477, accuracy: 26.5 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 2.012805700302124, accuracy: 26.5 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 2.0410749912261963, accuracy: 26.9 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 2.012032985687256, accuracy: 29.5 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 2.028721570968628, accuracy: 21.3 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 1.9235, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 1.9339, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 1.9844, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.0438, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.0339, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 1.9174, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 1.8991, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 1.9585, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.0241, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.1628, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 1.9774317741394043, accuracy: 24.3 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 1.9676810503005981, accuracy: 23.1 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 1.9640103578567505, accuracy: 22.7 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 2.025756597518921, accuracy: 22.7 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 1.9621992111206055, accuracy: 24.6 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 1.9607774019241333, accuracy: 24.6 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 1.9600961208343506, accuracy: 23.7 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 1.962768793106079, accuracy: 24.0 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 1.9599887132644653, accuracy: 24.5 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 1.9584568738937378, accuracy: 24.0 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 1.9439, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.0851, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 1.9271, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.0878, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 1.9198, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 1.9623, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.0048, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 1.9636, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 1.9468, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.0341, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 2.0060958862304688, accuracy: 24.2 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 2.0618488788604736, accuracy: 23.5 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 2.010439872741699, accuracy: 22.7 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 2.012202262878418, accuracy: 22.6 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 2.002305507659912, accuracy: 25.4 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 1.9989413022994995, accuracy: 25.7 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 1.9994220733642578, accuracy: 25.2 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 1.998317003250122, accuracy: 25.1 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 2.0038001537323, accuracy: 25.4 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 1.9949179887771606, accuracy: 26.6 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 1.9714, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 1.9492, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 1.9855, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 1.9864, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 1.9643, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 1.9367, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.0033, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.0516, batch time: 0.25, accuracy:  19.53%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.0103, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 1.9165, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 1.9716589450836182, accuracy: 25.5 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 2.0074875354766846, accuracy: 22.5 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 1.9891051054000854, accuracy: 27.2 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 1.9798643589019775, accuracy: 27.3 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 1.9706753492355347, accuracy: 25.0 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 1.97207510471344, accuracy: 26.0 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 1.968501091003418, accuracy: 26.5 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 1.9657660722732544, accuracy: 25.8 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 1.9660331010818481, accuracy: 25.0 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 1.9717744588851929, accuracy: 26.1 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.0168, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 1.9806, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 1.9534, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.0659, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 1.9872, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.9757, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 1.9331, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 1.9642, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.0741, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.1385, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 1.9812853336334229, accuracy: 24.9 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 2.082566499710083, accuracy: 24.8 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 2.0203018188476562, accuracy: 23.7 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 1.9870038032531738, accuracy: 26.4 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 1.9801914691925049, accuracy: 27.3 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 1.9767324924468994, accuracy: 26.8 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 1.9765793085098267, accuracy: 26.8 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 1.980367660522461, accuracy: 26.5 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 1.9759495258331299, accuracy: 26.6 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 1.9797478914260864, accuracy: 27.0 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 1.9769, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 1.9978, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.0180, batch time: 0.08, accuracy:  28.91%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.1588, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.0644, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 1.9619, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.0833, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.0196, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.0533, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 1.9746, batch time: 0.10, accuracy:  24.22%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 1.9974277019500732, accuracy: 22.4 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 2.005415439605713, accuracy: 23.5 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 1.9894212484359741, accuracy: 22.3 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 1.9870704412460327, accuracy: 23.8 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 2.022275686264038, accuracy: 22.7 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 1.9870951175689697, accuracy: 23.5 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 1.9876033067703247, accuracy: 24.0 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 1.9853005409240723, accuracy: 24.0 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 1.9857540130615234, accuracy: 24.6 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 1.984352707862854, accuracy: 24.4 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 1.9782, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.0631, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.0039, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 1.9785, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.0057, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.0654, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 1.9425, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 1.9483, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.0344, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.0026, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 2.0017218589782715, accuracy: 22.2 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 2.0025463104248047, accuracy: 22.4 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 2.001262903213501, accuracy: 23.7 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 2.027855634689331, accuracy: 23.3 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 2.0158257484436035, accuracy: 22.2 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 2.6111817359924316, accuracy: 9.2 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 1.9983234405517578, accuracy: 23.2 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 1.9955031871795654, accuracy: 23.4 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 1.9951260089874268, accuracy: 23.1 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 1.9943242073059082, accuracy: 24.0 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 1.9397, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.1256, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 1.9419, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 1.9613, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.0148, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 1.9258, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 1.8963, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.1087, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.0096, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 1.9503, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 1.9786425828933716, accuracy: 24.7 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 1.982627034187317, accuracy: 23.4 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 1.975565791130066, accuracy: 25.6 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 1.9743714332580566, accuracy: 26.8 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 2.001641273498535, accuracy: 27.4 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 1.9724568128585815, accuracy: 27.5 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 1.9718549251556396, accuracy: 28.0 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 1.9702547788619995, accuracy: 27.7 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 1.9696699380874634, accuracy: 27.7 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 1.97105872631073, accuracy: 26.9 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.0203, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.0190, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 1.9979, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 1.8863, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 1.9357, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.0088, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 1.8790, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 1.9779, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.0309, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 1.9613, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 1.956997036933899, accuracy: 24.3 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 1.9543102979660034, accuracy: 22.7 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 1.9278548955917358, accuracy: 23.8 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 1.925737738609314, accuracy: 26.1 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 1.9474354982376099, accuracy: 21.1 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 1.9237794876098633, accuracy: 26.0 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 1.923431634902954, accuracy: 25.5 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 1.919303059577942, accuracy: 26.5 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 1.9186851978302002, accuracy: 26.4 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 1.9251207113265991, accuracy: 26.3 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 1.9789, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 1.9407, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.0045, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 1.9978, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.0398, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 1.9150, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 1.9789, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.0769, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.0554, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 1.8460, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 1.9605094194412231, accuracy: 24.1 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 1.9575783014297485, accuracy: 23.1 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 1.9518393278121948, accuracy: 24.0 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 1.9517935514450073, accuracy: 23.9 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 2.0563251972198486, accuracy: 20.4 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 1.9519010782241821, accuracy: 23.5 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 1.9517229795455933, accuracy: 22.8 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 1.9474436044692993, accuracy: 22.7 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 1.9455723762512207, accuracy: 23.7 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 1.9436049461364746, accuracy: 23.9 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.0059, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 1.9389, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.0051, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 1.9651, batch time: 0.08, accuracy:  18.75%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.0408, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.0922, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 1.9647, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 1.8626, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 1.9994, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 1.9733, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 1.9527119398117065, accuracy: 22.7 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 2.0877599716186523, accuracy: 22.1 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 2.0045785903930664, accuracy: 19.9 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 1.9580802917480469, accuracy: 22.2 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 1.939283013343811, accuracy: 23.6 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 1.9400646686553955, accuracy: 23.5 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 1.9369479417800903, accuracy: 24.4 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 1.9376777410507202, accuracy: 24.2 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 1.9347249269485474, accuracy: 24.2 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 1.9365142583847046, accuracy: 24.1 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.0376, batch time: 0.18, accuracy:  19.53%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.0033, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 1.9401, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 1.7870, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.0690, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 1.9077, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 1.9498, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 1.9511, batch time: 0.26, accuracy:  21.88%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.0003, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 1.9120, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 1.9240906238555908, accuracy: 21.7 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 2.083828926086426, accuracy: 19.9 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 1.928292155265808, accuracy: 21.2 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 1.9374685287475586, accuracy: 21.6 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 1.9222326278686523, accuracy: 22.0 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 1.9239619970321655, accuracy: 22.9 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 1.9234185218811035, accuracy: 21.3 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 1.9180145263671875, accuracy: 21.4 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 1.9175699949264526, accuracy: 22.0 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 1.9209798574447632, accuracy: 22.6 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 1.9758, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.9433, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 1.9597, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 1.9009, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 1.9618, batch time: 0.05, accuracy:  23.44%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 1.9374, batch time: 0.11, accuracy:  25.00%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 1.9915, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 1.9884, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 1.9028, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 1.9339, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 1.9713958501815796, accuracy: 22.7 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 1.9481847286224365, accuracy: 21.5 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 1.9423316717147827, accuracy: 21.8 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 1.936863660812378, accuracy: 23.3 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 1.9559959173202515, accuracy: 23.4 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 1.9949458837509155, accuracy: 22.7 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 1.9433135986328125, accuracy: 26.6 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 1.9244744777679443, accuracy: 27.5 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 1.9235033988952637, accuracy: 27.6 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 1.9205260276794434, accuracy: 28.9 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 1.9166, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.0183, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 1.8562, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 1.8016, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 1.9420, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 1.8087, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 1.9486, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 1.9565, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 1.9656, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 1.9426, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 1.9085254669189453, accuracy: 25.2 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 1.976552963256836, accuracy: 23.7 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 1.9064007997512817, accuracy: 25.3 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 1.9295638799667358, accuracy: 23.8 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 1.9643616676330566, accuracy: 22.3 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 2.055375576019287, accuracy: 18.5 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 1.907118797302246, accuracy: 25.0 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 1.9037740230560303, accuracy: 26.1 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 1.8979265689849854, accuracy: 25.9 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 1.8988703489303589, accuracy: 26.8 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 1.9086, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 1.9200, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 1.9763, batch time: 0.05, accuracy:  20.31%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 1.8633, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 1.9274, batch time: 0.06, accuracy:  25.78%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 1.8695, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 1.8915, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 1.9553, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 1.9074, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.0152, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 1.9251699447631836, accuracy: 24.3 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 1.924363613128662, accuracy: 28.1 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 1.8853265047073364, accuracy: 28.5 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 1.8836716413497925, accuracy: 27.1 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 1.9626970291137695, accuracy: 26.4 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 1.901946783065796, accuracy: 26.8 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 1.8853604793548584, accuracy: 27.0 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 1.8729597330093384, accuracy: 27.9 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 1.8724660873413086, accuracy: 27.3 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 1.8733179569244385, accuracy: 27.9 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 1.9360, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 1.9163, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 1.8868, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 1.9481, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.0436, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 1.9655, batch time: 0.07, accuracy:  25.00%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 1.9574, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 1.7828, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 1.8616, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 1.8847, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 1.8680462837219238, accuracy: 27.2 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 2.112149477005005, accuracy: 14.4 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 3.131784200668335, accuracy: 11.4 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 2.1660172939300537, accuracy: 17.4 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 1.8610599040985107, accuracy: 27.2 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 1.8792632818222046, accuracy: 26.8 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 1.8710832595825195, accuracy: 25.9 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 1.8654956817626953, accuracy: 24.7 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 1.8637818098068237, accuracy: 24.8 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 1.8561594486236572, accuracy: 26.9 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 1.7958, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 1.7846, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 1.8476, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 1.8482, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.0265, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 1.8917, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 1.8199, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 1.9084, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 1.7934, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 1.9010, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 1.845175862312317, accuracy: 27.5 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 2.1673424243927, accuracy: 15.4 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 1.8518966436386108, accuracy: 27.0 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 1.8435425758361816, accuracy: 27.2 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 1.8635900020599365, accuracy: 26.6 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 1.9494229555130005, accuracy: 21.8 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 1.8390676975250244, accuracy: 26.6 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 1.8369511365890503, accuracy: 27.0 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 1.8361443281173706, accuracy: 27.4 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 1.8351322412490845, accuracy: 26.3 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 1.8844, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 1.9222, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 1.8019, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 1.9357, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 1.8278, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 1.9286, batch time: 0.05, accuracy:  26.56%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 1.9356, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 1.7676, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 1.8906, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 1.8857, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 1.8306246995925903, accuracy: 26.8 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 2.1607627868652344, accuracy: 17.1 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 4.911021709442139, accuracy: 10.8 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 2.7317917346954346, accuracy: 17.1 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 1.8286722898483276, accuracy: 28.2 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 1.8406506776809692, accuracy: 27.8 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 1.8598597049713135, accuracy: 25.3 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 1.8334100246429443, accuracy: 25.6 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 1.8254477977752686, accuracy: 27.1 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 1.8282558917999268, accuracy: 26.9 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 1.7950, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 1.8561, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 1.7407, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 1.8615, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 1.9356, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 1.8039, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 1.9179, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 1.7402, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 1.9427, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 1.8152, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 1.8577375411987305, accuracy: 26.0 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 1.872178077697754, accuracy: 25.2 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 1.854222297668457, accuracy: 25.9 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 1.8537455797195435, accuracy: 25.6 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 2.084927558898926, accuracy: 20.6 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 1.8441567420959473, accuracy: 26.8 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 1.8424667119979858, accuracy: 27.6 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 1.8415292501449585, accuracy: 27.0 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 1.8377798795700073, accuracy: 26.8 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 1.8485983610153198, accuracy: 26.3 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.9344, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 1.8684, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 1.8557, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 1.8112, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.9025, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 1.9162, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.8002, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 1.8697, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 1.9317, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 1.7647, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 1.8407763242721558, accuracy: 23.8 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 1.8742470741271973, accuracy: 22.5 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 1.834127426147461, accuracy: 25.4 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 1.834127426147461, accuracy: 25.4 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 1.8380153179168701, accuracy: 26.4 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 1.8407140970230103, accuracy: 24.6 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 1.8333781957626343, accuracy: 26.0 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 1.832931399345398, accuracy: 26.3 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 1.8283774852752686, accuracy: 25.8 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 1.8280225992202759, accuracy: 25.7 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.8435, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 1.8868, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 1.9052, batch time: 0.10, accuracy:  24.22%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 1.8540, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 1.8222, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 1.8251, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 1.7933, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 1.8501, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 1.9192, batch time: 0.10, accuracy:  19.53%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 1.8313, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 1.8406649827957153, accuracy: 26.4 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 1.8610243797302246, accuracy: 26.7 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 1.835050344467163, accuracy: 25.7 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 1.833824634552002, accuracy: 26.2 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 1.8816590309143066, accuracy: 25.1 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 1.8323839902877808, accuracy: 25.7 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 1.8298742771148682, accuracy: 25.7 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 1.8282058238983154, accuracy: 24.9 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 1.8245545625686646, accuracy: 25.3 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 1.8237332105636597, accuracy: 24.9 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 1.8627, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 1.8117, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 1.7701, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 1.7611, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 1.8196, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 1.9173, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 1.7786, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 1.7300, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 1.9483, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 1.8237, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 1.8430315256118774, accuracy: 23.7 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 1.9056384563446045, accuracy: 20.3 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 1.8362643718719482, accuracy: 24.5 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 1.8333464860916138, accuracy: 26.7 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 1.832876443862915, accuracy: 26.4 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 1.8856420516967773, accuracy: 24.0 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 1.8665658235549927, accuracy: 25.9 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 1.829004168510437, accuracy: 26.3 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 1.82841157913208, accuracy: 26.0 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 1.8370823860168457, accuracy: 25.4 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 1.7725, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 1.8450, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 1.6408, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 1.8764, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 1.8132, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 1.7707, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 1.8632, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 1.7659, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 1.8848, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.9217, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 1.8172746896743774, accuracy: 27.4 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 1.8179752826690674, accuracy: 27.4 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 3.021697759628296, accuracy: 14.5 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 1.907857060432434, accuracy: 26.4 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 1.8243217468261719, accuracy: 26.4 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 1.824163556098938, accuracy: 25.2 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 1.9113880395889282, accuracy: 21.7 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 1.8061219453811646, accuracy: 25.8 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 1.8101780414581299, accuracy: 27.0 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 1.930465579032898, accuracy: 23.3 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 1.7772, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 1.8249, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 1.6956, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 1.8149, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 1.7487, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 1.7839, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 1.8104, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 1.9525, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 1.8232, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.7052, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 1.8244819641113281, accuracy: 28.3 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 1.9312684535980225, accuracy: 21.7 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 1.810788631439209, accuracy: 27.0 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 1.9037162065505981, accuracy: 24.3 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 1.8014215230941772, accuracy: 27.7 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 1.8007946014404297, accuracy: 28.0 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 1.8076766729354858, accuracy: 27.1 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 1.8122777938842773, accuracy: 27.9 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 1.8061492443084717, accuracy: 25.9 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 1.80478835105896, accuracy: 28.1 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 1.8159, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 1.8014, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 1.8848, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 1.7645, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 1.8312, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 1.7830, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 1.7087, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 1.7230, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 1.6771, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 1.7449, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 1.8022472858428955, accuracy: 26.4 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 1.8359675407409668, accuracy: 24.3 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 1.8015905618667603, accuracy: 26.8 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 1.8015905618667603, accuracy: 26.8 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 1.824312448501587, accuracy: 24.8 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 1.8209153413772583, accuracy: 23.9 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 1.799514889717102, accuracy: 25.7 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 1.7978521585464478, accuracy: 26.0 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 1.796812653541565, accuracy: 26.3 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 1.7965859174728394, accuracy: 26.6 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 1.8079, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 1.8423, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 1.7419, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 1.8073, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 1.8052, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 1.7451, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 1.7349, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 1.7753, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 1.7113, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 1.8912, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 1.7762258052825928, accuracy: 26.9 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 1.7911127805709839, accuracy: 26.1 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 1.8126156330108643, accuracy: 24.6 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 1.8892269134521484, accuracy: 24.5 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 1.7702642679214478, accuracy: 26.2 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 1.773475170135498, accuracy: 26.2 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 1.761773943901062, accuracy: 26.1 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 1.7603716850280762, accuracy: 26.9 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 1.7596315145492554, accuracy: 27.0 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 1.7719017267227173, accuracy: 26.4 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 1.9682, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 1.8046, batch time: 0.05, accuracy:  23.44%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 1.7894, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 1.7412, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 1.8161, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 1.9010, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 1.7385, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 1.7644, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 1.8234, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 1.8624, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 1.8443877696990967, accuracy: 23.2 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 1.8501992225646973, accuracy: 22.5 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 1.8315736055374146, accuracy: 24.8 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 1.829977035522461, accuracy: 25.0 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 1.8784199953079224, accuracy: 24.5 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 1.8704038858413696, accuracy: 23.6 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 1.825008511543274, accuracy: 24.6 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 1.8224341869354248, accuracy: 24.9 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 1.8218179941177368, accuracy: 25.3 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 1.8220874071121216, accuracy: 25.6 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 1.7188, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 1.8244, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 1.8506, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 1.9288, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.8170, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 1.7055, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 1.7372, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.0125, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 1.6912, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 1.8053, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 1.7638767957687378, accuracy: 26.4 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.7786734104156494, accuracy: 25.5 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 1.7635619640350342, accuracy: 27.5 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 1.760103464126587, accuracy: 26.5 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 1.7710084915161133, accuracy: 25.8 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 1.7825158834457397, accuracy: 24.2 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 1.7695385217666626, accuracy: 24.4 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 1.761472225189209, accuracy: 25.5 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 1.7689621448516846, accuracy: 24.8 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 1.8854466676712036, accuracy: 23.1 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 1.7750, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 1.7600, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.7625, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 1.9811, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 1.8206, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 1.7612, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 1.7825, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 1.8123, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.7429, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 1.8483, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 1.7691410779953003, accuracy: 26.5 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 1.8004848957061768, accuracy: 25.1 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 1.7609422206878662, accuracy: 27.1 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 1.7596595287322998, accuracy: 27.8 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 1.7614117860794067, accuracy: 27.4 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 1.818293571472168, accuracy: 24.7 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 1.8917421102523804, accuracy: 22.5 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 1.7525897026062012, accuracy: 27.8 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 1.7518457174301147, accuracy: 27.8 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 1.7495479583740234, accuracy: 28.0 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.7605, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 1.8780, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.6889, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 1.7128, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.8154, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 1.7216, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.8048, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.7738, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 1.8623, batch time: 0.06, accuracy:  21.88%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 1.7485, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 1.8047428131103516, accuracy: 24.9 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.833851933479309, accuracy: 23.3 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 1.8047046661376953, accuracy: 25.0 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 2.0146143436431885, accuracy: 19.8 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 1.8032060861587524, accuracy: 25.9 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 1.7979625463485718, accuracy: 25.7 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 1.8002407550811768, accuracy: 25.0 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 1.7959461212158203, accuracy: 25.3 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 1.7963643074035645, accuracy: 25.5 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 1.7932994365692139, accuracy: 25.5 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 1.8171, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 1.9121, batch time: 0.09, accuracy:  17.19%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.7967, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 1.7881, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 1.6588, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 1.7016, batch time: 0.17, accuracy:  30.47%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.8250, batch time: 0.06, accuracy:  25.00%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 1.8729, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 1.6154, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 1.7301, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 1.8162508010864258, accuracy: 25.3 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 1.833783745765686, accuracy: 22.8 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 1.8061879873275757, accuracy: 26.2 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 1.7971582412719727, accuracy: 27.0 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 1.919420599937439, accuracy: 25.3 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 1.7969229221343994, accuracy: 25.8 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 1.7953239679336548, accuracy: 26.4 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 1.7944670915603638, accuracy: 26.1 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 1.7935360670089722, accuracy: 26.7 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 1.8012568950653076, accuracy: 23.7 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 1.7882, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 1.7556, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.8487, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 1.7158, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 1.7766, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.8631, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.7809, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.6868, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.7102, batch time: 0.05, accuracy:  25.78%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 1.7457, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 1.7307281494140625, accuracy: 27.3 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.748503565788269, accuracy: 26.3 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 1.7254345417022705, accuracy: 25.8 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 1.72506582736969, accuracy: 26.3 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 2.298001289367676, accuracy: 22.0 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 1.7205030918121338, accuracy: 25.3 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 1.7198625802993774, accuracy: 25.7 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 1.7280709743499756, accuracy: 27.0 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 1.7213706970214844, accuracy: 25.3 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 1.7176941633224487, accuracy: 26.0 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.9194, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.7618, batch time: 0.10, accuracy:  24.22%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.8087, batch time: 0.11, accuracy:  22.66%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 1.6862, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.8329, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.7880, batch time: 0.09, accuracy:  18.75%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.5969, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.7026, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.7634, batch time: 0.05, accuracy:  25.78%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.7907, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 1.7698777914047241, accuracy: 26.5 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 1.7864291667938232, accuracy: 26.1 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 1.7638959884643555, accuracy: 26.0 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 1.7597665786743164, accuracy: 25.4 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 1.759253978729248, accuracy: 25.3 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 2.244278907775879, accuracy: 23.2 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 1.7552443742752075, accuracy: 26.6 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 1.754513144493103, accuracy: 25.6 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 1.7517991065979004, accuracy: 26.9 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 1.7525376081466675, accuracy: 26.8 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.7713, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.8440, batch time: 0.10, accuracy:  21.88%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 1.6937, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.6807, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.6729, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.8177, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.7387, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 1.7663, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 1.7936, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.7640, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 1.74624764919281, accuracy: 30.3 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 2.5104732513427734, accuracy: 25.2 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 1.7421021461486816, accuracy: 29.7 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 1.7333370447158813, accuracy: 30.8 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 1.7325578927993774, accuracy: 31.0 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 1.8610206842422485, accuracy: 29.5 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 2.267918348312378, accuracy: 24.5 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 1.734856367111206, accuracy: 29.1 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 1.7249042987823486, accuracy: 30.8 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 1.7238563299179077, accuracy: 31.1 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 1.7802, batch time: 0.11, accuracy:  27.34%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 1.7786, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.8420, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.8543, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 1.8872, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 1.6735, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.7214, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 1.8216, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.7872, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.7602, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 1.7545439004898071, accuracy: 28.7 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 1.7813504934310913, accuracy: 26.0 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 1.7527467012405396, accuracy: 29.2 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 1.7520006895065308, accuracy: 30.0 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 1.8682162761688232, accuracy: 29.3 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 1.7975945472717285, accuracy: 26.4 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 1.7879319190979004, accuracy: 30.9 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 1.7523910999298096, accuracy: 28.4 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.750657320022583, accuracy: 29.3 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 1.7520331144332886, accuracy: 29.2 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.7065, batch time: 0.11, accuracy:  31.25%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.8056, batch time: 0.11, accuracy:  30.47%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.6939, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 1.7059, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.7424, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.8097, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.6889, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.8023, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.7732, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 1.7823, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 1.7520502805709839, accuracy: 28.6 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 1.7774280309677124, accuracy: 27.5 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 1.8097500801086426, accuracy: 27.5 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 1.7424569129943848, accuracy: 29.2 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 1.9230678081512451, accuracy: 28.9 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 1.918664574623108, accuracy: 23.5 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 1.8108015060424805, accuracy: 26.9 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 1.8344566822052002, accuracy: 24.9 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 2.342055082321167, accuracy: 24.8 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 1.7917782068252563, accuracy: 25.7 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.7799, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.8532, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.6783, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.7608, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.7824, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.8790, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.6755, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.8311, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.9123, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.8655, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 1.7322444915771484, accuracy: 27.0 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 1.7665534019470215, accuracy: 26.3 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 1.7468352317810059, accuracy: 26.1 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 1.7291167974472046, accuracy: 27.4 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 2.090536594390869, accuracy: 31.0 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 1.726112723350525, accuracy: 27.6 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 1.736385703086853, accuracy: 27.3 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 1.7314189672470093, accuracy: 27.3 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 1.7255712747573853, accuracy: 27.2 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 1.7232860326766968, accuracy: 27.9 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.7689, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.6385, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.8169, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.7551, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.7264, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.8444, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.6980, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.7155, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 1.7432, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.8305, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 1.7693250179290771, accuracy: 25.4 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 1.7809207439422607, accuracy: 23.2 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 1.7676057815551758, accuracy: 24.8 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 1.7665631771087646, accuracy: 24.9 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 1.7661465406417847, accuracy: 25.2 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 1.7871122360229492, accuracy: 25.2 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 2.2973875999450684, accuracy: 15.3 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 1.7653840780258179, accuracy: 25.3 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 1.7634849548339844, accuracy: 24.9 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 1.7630412578582764, accuracy: 24.5 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.7597, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 1.7176, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 1.7086, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.7281, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 1.8093, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.7370, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.7789, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.7072, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.7888, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.8028, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 1.7340705394744873, accuracy: 28.1 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.7745211124420166, accuracy: 25.8 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 1.7575632333755493, accuracy: 27.3 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 1.7330232858657837, accuracy: 27.4 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 1.9107826948165894, accuracy: 29.2 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 1.805163860321045, accuracy: 30.1 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 1.7318981885910034, accuracy: 28.0 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 1.7319504022598267, accuracy: 27.2 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 1.846699595451355, accuracy: 24.6 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 1.7323415279388428, accuracy: 28.1 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.7691, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.5975, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.8039, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.7729, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.7795, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.8546, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.7780, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.8078, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.6944, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.6912, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 1.7155946493148804, accuracy: 27.9 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 4.353414058685303, accuracy: 10.4 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 12.09654712677002, accuracy: 11.0 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 2.4287257194519043, accuracy: 21.1 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.7135179042816162, accuracy: 27.8 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.713293194770813, accuracy: 28.1 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 1.7142925262451172, accuracy: 27.8 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 1.7165671586990356, accuracy: 27.4 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 1.7120778560638428, accuracy: 28.2 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 1.715053677558899, accuracy: 27.2 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.9652, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.6452, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 1.7160, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.8109, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.8089, batch time: 0.10, accuracy:  21.09%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.7050, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.7570, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.5805, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.7157, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.8160, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 1.7273203134536743, accuracy: 28.4 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 2.070364236831665, accuracy: 15.3 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 1.730723261833191, accuracy: 28.2 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 1.7276864051818848, accuracy: 28.4 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 1.724243402481079, accuracy: 28.6 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 1.7227863073349, accuracy: 29.0 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 1.7227306365966797, accuracy: 28.5 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 1.7213608026504517, accuracy: 28.4 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 1.719846487045288, accuracy: 28.9 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 1.718157172203064, accuracy: 28.9 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.7629, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.7111, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.7408, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.7175, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.6735, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.6428, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.8211, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.7978, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.7311, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.8126, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 1.710296392440796, accuracy: 32.5 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 2.034245729446411, accuracy: 20.2 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 2.064744472503662, accuracy: 29.9 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 1.762779712677002, accuracy: 28.6 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 1.7083967924118042, accuracy: 32.3 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.7072854042053223, accuracy: 32.1 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 1.7099435329437256, accuracy: 30.9 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 1.7075114250183105, accuracy: 33.5 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 1.7180191278457642, accuracy: 31.0 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 1.7198222875595093, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.6846, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.8178, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.7465, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.9005, batch time: 0.12, accuracy:  20.31%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.6870, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.7584, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.7887, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.7690, batch time: 0.05, accuracy:  29.69%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.8291, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.8523, batch time: 0.06, accuracy:  21.09%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 1.7459791898727417, accuracy: 26.0 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 1.907562255859375, accuracy: 22.6 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 1.979972243309021, accuracy: 28.4 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 1.7470506429672241, accuracy: 25.0 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 1.7583765983581543, accuracy: 24.5 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 1.748116374015808, accuracy: 24.8 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 1.7438490390777588, accuracy: 24.7 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 1.7429454326629639, accuracy: 24.9 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 1.74015212059021, accuracy: 24.9 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 1.7473174333572388, accuracy: 24.6 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.7940, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.7761, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.6898, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.7238, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.7764, batch time: 0.10, accuracy:  20.31%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.8413, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.7299, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.6349, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.8313, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.7702, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 1.8070900440216064, accuracy: 26.6 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 4.459942817687988, accuracy: 10.7 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 8.633563041687012, accuracy: 10.3 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 2.1764185428619385, accuracy: 25.4 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 1.8396427631378174, accuracy: 25.1 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 1.9144378900527954, accuracy: 23.2 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 1.7992959022521973, accuracy: 28.4 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 1.7971627712249756, accuracy: 28.2 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 1.7997362613677979, accuracy: 28.3 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 1.804984211921692, accuracy: 27.1 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.7079, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.7019, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.6993, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.8315, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.8372, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.8633, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.7053, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.8267, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.6694, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.7402, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 1.7513933181762695, accuracy: 27.3 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 1.791046142578125, accuracy: 25.3 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 1.7464152574539185, accuracy: 28.4 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 1.7447638511657715, accuracy: 29.0 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 1.9040958881378174, accuracy: 32.2 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 1.7430726289749146, accuracy: 29.3 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 1.74708890914917, accuracy: 33.3 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 1.7958884239196777, accuracy: 28.0 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 1.7526310682296753, accuracy: 29.6 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 1.7372865676879883, accuracy: 31.9 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.8081, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.6630, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.7064, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.6427, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.7979, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.7033, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.7597, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.6758, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.7619, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.7071, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 1.8034977912902832, accuracy: 24.1 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 1.7984857559204102, accuracy: 24.7 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 1.7725718021392822, accuracy: 25.1 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 1.7696490287780762, accuracy: 25.2 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 2.032301187515259, accuracy: 22.6 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 1.813612937927246, accuracy: 24.2 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 1.7682589292526245, accuracy: 25.5 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 1.7613046169281006, accuracy: 26.2 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 1.7611967325210571, accuracy: 26.5 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 1.7598413228988647, accuracy: 25.9 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.8558, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.8129, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.8667, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.7308, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.6231, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.7594, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.7002, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.6911, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.5867, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.8320, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 1.79877507686615, accuracy: 27.5 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 1.7948462963104248, accuracy: 27.9 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 1.7746882438659668, accuracy: 28.0 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 1.7733064889907837, accuracy: 27.7 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 1.77153742313385, accuracy: 27.9 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 1.8138993978500366, accuracy: 27.9 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 2.86997127532959, accuracy: 20.1 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 1.776953935623169, accuracy: 27.6 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 1.7722958326339722, accuracy: 27.3 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 1.7693803310394287, accuracy: 27.8 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.7389, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.6681, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.7335, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.6901, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.7319, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.7406, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.7807, batch time: 0.10, accuracy:  32.03%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.7037, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.7741, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.7760, batch time: 0.08, accuracy:  32.81%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 1.7542935609817505, accuracy: 25.7 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 1.9036495685577393, accuracy: 22.4 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 2.075770854949951, accuracy: 24.5 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 1.795711636543274, accuracy: 24.1 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 1.7520604133605957, accuracy: 26.1 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 1.762941837310791, accuracy: 24.4 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 1.7808263301849365, accuracy: 26.2 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 1.7540194988250732, accuracy: 26.6 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 1.750175952911377, accuracy: 26.7 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 1.7489653825759888, accuracy: 26.2 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.8463, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.7808, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.8080, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.8641, batch time: 0.05, accuracy:  18.75%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.9428, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.7123, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.7964, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.7358, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.7400, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.6933, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 1.7860889434814453, accuracy: 24.6 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 1.8109378814697266, accuracy: 22.9 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 1.7729836702346802, accuracy: 24.9 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 1.7726659774780273, accuracy: 25.5 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 1.8612492084503174, accuracy: 22.8 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 1.8089537620544434, accuracy: 26.0 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 1.7765381336212158, accuracy: 25.8 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 1.7709591388702393, accuracy: 25.1 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 1.7702006101608276, accuracy: 25.2 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 1.7733070850372314, accuracy: 25.5 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.7720, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.6990, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.7749, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.7422, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.6934, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.8617, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.7532, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.7186, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.6533, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.6770, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 1.7115957736968994, accuracy: 32.6 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 1.7227954864501953, accuracy: 31.6 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 1.7107638120651245, accuracy: 32.3 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 1.7086044549942017, accuracy: 30.8 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 1.7525403499603271, accuracy: 30.3 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 1.7478797435760498, accuracy: 34.0 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 1.7079269886016846, accuracy: 30.6 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 1.7077562808990479, accuracy: 32.3 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 1.7083618640899658, accuracy: 30.4 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 1.7072077989578247, accuracy: 32.0 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.7020, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.5063, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.8064, batch time: 0.10, accuracy:  17.97%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.5875, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.7169, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.7775, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.7816, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.7869, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.7687, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.7399, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 1.734782338142395, accuracy: 33.0 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 2.2488746643066406, accuracy: 15.4 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 1.7435154914855957, accuracy: 33.9 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 1.7543799877166748, accuracy: 32.6 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 1.7340549230575562, accuracy: 34.0 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 1.7571818828582764, accuracy: 31.4 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 1.7502493858337402, accuracy: 33.9 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 1.7439780235290527, accuracy: 33.5 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 1.7307034730911255, accuracy: 33.3 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 1.7292972803115845, accuracy: 33.7 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.6674, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.9158, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.7707, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.8142, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.8295, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.7751, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.7529, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.7245, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.7470, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.7654, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 1.7616760730743408, accuracy: 31.1 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 1.793961763381958, accuracy: 30.2 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 1.7586318254470825, accuracy: 30.6 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 1.757948875427246, accuracy: 30.9 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 1.755042314529419, accuracy: 31.0 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 1.8838157653808594, accuracy: 23.0 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 1.9308643341064453, accuracy: 19.6 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 1.8325867652893066, accuracy: 26.3 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 1.7468554973602295, accuracy: 30.1 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 1.7516191005706787, accuracy: 31.3 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.8150, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.7623, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.6846, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.7238, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.6974, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.8071, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.7430, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.7387, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.6260, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.7827, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 1.701895833015442, accuracy: 33.0 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 1.7478928565979004, accuracy: 29.1 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 1.6978241205215454, accuracy: 32.6 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 1.9216270446777344, accuracy: 24.3 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 1.7702277898788452, accuracy: 28.8 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 1.6951857805252075, accuracy: 34.4 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 1.6943812370300293, accuracy: 34.1 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 1.694399356842041, accuracy: 34.1 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 1.6937566995620728, accuracy: 34.2 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 1.699948787689209, accuracy: 32.2 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.7870, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.8073, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.8235, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.8316, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.7636, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.6485, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.7256, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.6711, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.7448, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.6709, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 1.7107328176498413, accuracy: 28.6 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 1.7201308012008667, accuracy: 29.1 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 1.7085298299789429, accuracy: 28.9 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 1.7080943584442139, accuracy: 29.1 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 1.7077351808547974, accuracy: 28.9 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 1.7650256156921387, accuracy: 30.9 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 1.7363455295562744, accuracy: 28.4 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 1.7168878316879272, accuracy: 29.7 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 1.8801381587982178, accuracy: 26.6 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 1.7067469358444214, accuracy: 31.6 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.7602, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.7363, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.7155, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.8193, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.6976, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.7337, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.7904, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.7541, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.6995, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.7846, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 1.7066972255706787, accuracy: 30.1 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 1.7185931205749512, accuracy: 29.0 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 1.7215369939804077, accuracy: 31.2 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 1.7038601636886597, accuracy: 29.8 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.7770678997039795, accuracy: 30.4 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 1.7062709331512451, accuracy: 28.9 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 1.6998013257980347, accuracy: 30.7 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 1.6968519687652588, accuracy: 29.6 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 1.7051069736480713, accuracy: 29.1 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 1.6962032318115234, accuracy: 29.7 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.8445, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.7510, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.7392, batch time: 0.11, accuracy:  28.12%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.7548, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.7388, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.5878, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.6404, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.8095, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.6903, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.6693, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 1.8164314031600952, accuracy: 26.2 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 3.9920918941497803, accuracy: 9.0 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 6.27520227432251, accuracy: 18.7 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 1.7659567594528198, accuracy: 28.5 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 1.8181294202804565, accuracy: 31.0 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 1.9864197969436646, accuracy: 26.3 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 1.759575605392456, accuracy: 28.3 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 1.7792714834213257, accuracy: 26.7 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 1.7560994625091553, accuracy: 29.2 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 1.7556979656219482, accuracy: 29.6 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.7637, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.7876, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.6796, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.8295, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.7542, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.6464, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.8279, batch time: 0.10, accuracy:  32.03%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.7505, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.8231, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.6355, batch time: 0.06, accuracy:  40.62%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 1.7602657079696655, accuracy: 35.1 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 2.248262643814087, accuracy: 15.0 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 3.973703384399414, accuracy: 22.5 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 1.7798463106155396, accuracy: 30.4 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 1.8328040838241577, accuracy: 32.2 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 1.7513401508331299, accuracy: 33.9 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 1.8718992471694946, accuracy: 33.2 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 1.7581157684326172, accuracy: 32.5 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 1.7475370168685913, accuracy: 33.4 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 1.7381436824798584, accuracy: 35.1 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.6355, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.8528, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.7449, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.7087, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.7377, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.7225, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.7894, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.6611, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.6007, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.9363, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 1.7600232362747192, accuracy: 27.7 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 1.7781256437301636, accuracy: 27.1 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 1.754852056503296, accuracy: 27.7 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 1.9430691003799438, accuracy: 21.2 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 1.7537360191345215, accuracy: 27.0 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 1.7517304420471191, accuracy: 27.6 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 1.7526710033416748, accuracy: 27.6 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 1.75801420211792, accuracy: 27.8 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 1.7699434757232666, accuracy: 26.4 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 1.751205325126648, accuracy: 27.5 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.6627, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.7970, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.7686, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.7673, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.7846, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.7076, batch time: 0.05, accuracy:  29.69%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.7662, batch time: 0.05, accuracy:  21.09%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.8475, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.6959, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.7351, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 1.780781865119934, accuracy: 29.2 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 1.8287065029144287, accuracy: 24.3 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 1.779962182044983, accuracy: 29.0 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 1.779793620109558, accuracy: 28.7 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 2.296009063720703, accuracy: 26.6 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 1.7776323556900024, accuracy: 28.6 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 1.7806224822998047, accuracy: 28.9 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 1.7756727933883667, accuracy: 27.7 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 1.775371789932251, accuracy: 27.7 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 1.788559079170227, accuracy: 25.7 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.6128, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.6615, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.6978, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.8247, batch time: 0.11, accuracy:  28.91%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.8249, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.7186, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.6748, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.7448, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.6157, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.6940, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 1.7352689504623413, accuracy: 28.7 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 1.7452980279922485, accuracy: 26.5 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 1.7352650165557861, accuracy: 28.7 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 1.748692512512207, accuracy: 28.0 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 1.7364636659622192, accuracy: 28.6 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 1.7311086654663086, accuracy: 27.6 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 1.7355233430862427, accuracy: 28.7 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 1.7313518524169922, accuracy: 27.6 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 1.7313647270202637, accuracy: 27.7 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 1.731641411781311, accuracy: 28.7 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.6299, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.7585, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.5481, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.8605, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.9071, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.8086, batch time: 0.04, accuracy:  19.53%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.6466, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.7909, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.7184, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.7170, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 1.7090984582901, accuracy: 29.0 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 1.7484288215637207, accuracy: 26.5 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 1.7030788660049438, accuracy: 28.5 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 1.700731635093689, accuracy: 28.1 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 1.7319836616516113, accuracy: 28.6 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 1.6978356838226318, accuracy: 28.5 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 1.6965336799621582, accuracy: 29.8 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 1.7015974521636963, accuracy: 28.4 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 1.6938273906707764, accuracy: 29.8 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 1.7066428661346436, accuracy: 29.9 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.8209, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.9344, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.6442, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.6483, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.7818, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.7237, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.7935, batch time: 0.09, accuracy:  19.53%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.7738, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.8114, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.8107, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 1.7339487075805664, accuracy: 29.6 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 4.917094707489014, accuracy: 10.3 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 6.027743339538574, accuracy: 13.9 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 2.749229907989502, accuracy: 23.3 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 1.730997920036316, accuracy: 31.4 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 1.7269444465637207, accuracy: 31.7 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 1.7276694774627686, accuracy: 31.6 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 1.7398159503936768, accuracy: 33.3 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 1.7301572561264038, accuracy: 31.2 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 1.7255520820617676, accuracy: 32.4 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.8017, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.8069, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.7810, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.7176, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.8541, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.7836, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.7971, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.7879, batch time: 0.06, accuracy:  29.69%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.8432, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.7830, batch time: 0.08, accuracy:  28.12%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 1.732853889465332, accuracy: 31.2 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.7681608200073242, accuracy: 28.7 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 1.75877845287323, accuracy: 31.1 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 1.7081599235534668, accuracy: 34.8 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 1.714988112449646, accuracy: 33.9 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 1.7835571765899658, accuracy: 36.6 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 1.7096627950668335, accuracy: 35.7 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 1.7036266326904297, accuracy: 36.1 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 1.7018585205078125, accuracy: 36.4 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 1.7061160802841187, accuracy: 36.4 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.8591, batch time: 0.05, accuracy:  21.88%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.7149, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.7874, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.7157, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.7808, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.6975, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.7504, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.8093, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.5928, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.8117, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 1.7978013753890991, accuracy: 28.7 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 1.7957558631896973, accuracy: 27.8 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 1.8919655084609985, accuracy: 25.4 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 1.7333033084869385, accuracy: 29.6 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 1.739358901977539, accuracy: 29.2 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 1.730156660079956, accuracy: 29.7 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 1.730746865272522, accuracy: 29.1 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 1.729393720626831, accuracy: 29.3 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 1.7332311868667603, accuracy: 29.3 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 1.7222506999969482, accuracy: 30.0 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.6886, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.7387, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.6404, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.7970, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.8550, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.7266, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.8446, batch time: 0.09, accuracy:  22.66%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.8054, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.8069, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.6715, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 1.7009806632995605, accuracy: 28.7 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.787506103515625, accuracy: 25.5 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 1.7008099555969238, accuracy: 28.8 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.7353383302688599, accuracy: 29.7 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.7048431634902954, accuracy: 28.2 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 1.7210626602172852, accuracy: 28.3 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 1.7354856729507446, accuracy: 28.7 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 1.694571852684021, accuracy: 29.2 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 1.7081615924835205, accuracy: 29.6 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 1.692376971244812, accuracy: 28.5 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.6782, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.7411, batch time: 0.11, accuracy:  26.56%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.7945, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.8031, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.7099, batch time: 0.08, accuracy:  25.78%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.7483, batch time: 0.12, accuracy:  24.22%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.7896, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.7045, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.8075, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.8254, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 1.7840131521224976, accuracy: 25.9 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 1.7978949546813965, accuracy: 25.7 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 1.865465521812439, accuracy: 25.1 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 1.7771497964859009, accuracy: 25.7 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 2.1265687942504883, accuracy: 26.4 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 1.783503770828247, accuracy: 24.8 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 1.7683473825454712, accuracy: 25.7 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 1.7720935344696045, accuracy: 25.4 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 1.7903733253479004, accuracy: 24.1 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 1.7637319564819336, accuracy: 25.0 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.6805, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.9948, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.6502, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.7278, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.6218, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.7610, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.6821, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.6354, batch time: 0.05, accuracy:  25.78%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.6883, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.6849, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 1.7217248678207397, accuracy: 27.2 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 1.9445453882217407, accuracy: 19.8 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 1.861177921295166, accuracy: 30.5 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 1.8402522802352905, accuracy: 30.3 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 1.7210216522216797, accuracy: 28.1 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 1.7252134084701538, accuracy: 27.5 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 1.7197649478912354, accuracy: 27.7 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 1.7288035154342651, accuracy: 27.1 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 1.7185784578323364, accuracy: 27.6 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 1.7379319667816162, accuracy: 26.6 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.6827, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.6475, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.8548, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.6295, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.8744, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.6631, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.7322, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.6120, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.8147, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.7563, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 1.7359216213226318, accuracy: 28.3 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 1.7434048652648926, accuracy: 27.4 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 1.7338554859161377, accuracy: 28.6 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 1.733638882637024, accuracy: 28.4 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 1.7342194318771362, accuracy: 28.6 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 1.7652809619903564, accuracy: 27.2 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 1.7978770732879639, accuracy: 26.1 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 1.7724199295043945, accuracy: 26.0 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 1.7302324771881104, accuracy: 28.4 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 1.728703498840332, accuracy: 28.6 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.6964, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.7667, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.6203, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.5995, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.5881, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.6960, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.6866, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.6383, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.8060, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.6671, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 1.7395679950714111, accuracy: 28.1 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 1.8499516248703003, accuracy: 24.2 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 2.036985397338867, accuracy: 27.2 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 2.0250513553619385, accuracy: 23.0 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 1.7372547388076782, accuracy: 27.8 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 1.7356477975845337, accuracy: 28.2 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 1.7442468404769897, accuracy: 28.6 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 1.7375597953796387, accuracy: 28.0 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 1.7404229640960693, accuracy: 28.4 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 1.759606957435608, accuracy: 28.0 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.7738, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.6767, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.7062, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.7303, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.6976, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.6562, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.7059, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.6348, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.6865, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.8172, batch time: 0.06, accuracy:  21.88%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 1.7519285678863525, accuracy: 25.7 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 1.7792742252349854, accuracy: 24.6 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 1.7440823316574097, accuracy: 25.2 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 1.747991919517517, accuracy: 25.3 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 1.7418447732925415, accuracy: 25.1 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 1.7503050565719604, accuracy: 24.3 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 1.7408201694488525, accuracy: 24.7 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 1.7407948970794678, accuracy: 24.6 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 1.7409238815307617, accuracy: 24.8 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 1.7417528629302979, accuracy: 24.4 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.6873, batch time: 0.11, accuracy:  24.22%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.8280, batch time: 0.12, accuracy:  23.44%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.7759, batch time: 0.12, accuracy:  25.00%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.8330, batch time: 0.11, accuracy:  21.09%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.7022, batch time: 0.12, accuracy:  30.47%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.6861, batch time: 0.11, accuracy:  34.38%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.7543, batch time: 0.12, accuracy:  21.88%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.7473, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.7468, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.6465, batch time: 0.12, accuracy:  26.56%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 1.7313300371170044, accuracy: 26.7 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 1.8142987489700317, accuracy: 24.0 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 1.7844327688217163, accuracy: 24.4 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 1.7270458936691284, accuracy: 27.6 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 1.7637534141540527, accuracy: 26.7 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 1.746976613998413, accuracy: 26.9 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 1.7376832962036133, accuracy: 27.6 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 1.7184873819351196, accuracy: 26.9 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 1.7510684728622437, accuracy: 26.6 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 1.727966070175171, accuracy: 26.4 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.7161, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.6874, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.6684, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.0089, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.8390, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.7127, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.8924, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.6451, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.7701, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.7293, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 1.7266333103179932, accuracy: 26.8 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 1.7605117559432983, accuracy: 25.4 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 1.72357976436615, accuracy: 27.0 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 2.779850721359253, accuracy: 17.4 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 1.7289173603057861, accuracy: 26.2 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 1.7253093719482422, accuracy: 26.3 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 1.721758246421814, accuracy: 27.0 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 1.7200331687927246, accuracy: 26.7 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 1.7199217081069946, accuracy: 27.3 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 1.7239652872085571, accuracy: 27.6 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.6345, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.8975, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.7703, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.6425, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.6533, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.8491, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.8288, batch time: 0.04, accuracy:  22.66%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.8068, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.6741, batch time: 0.11, accuracy:  31.25%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.7068, batch time: 0.11, accuracy:  31.25%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 1.736957311630249, accuracy: 29.9 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 1.7631545066833496, accuracy: 28.0 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 1.7311822175979614, accuracy: 29.6 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 1.7308615446090698, accuracy: 29.8 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 1.8937928676605225, accuracy: 25.4 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 1.7307214736938477, accuracy: 30.4 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 1.7270303964614868, accuracy: 31.0 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 1.7269047498703003, accuracy: 30.2 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 1.7245522737503052, accuracy: 30.1 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 1.7222594022750854, accuracy: 31.0 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.6271, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.7259, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.6614, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.8479, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.7949, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.7234, batch time: 0.09, accuracy:  23.44%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.7424, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.7488, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.7013, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.7770, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 1.7461895942687988, accuracy: 26.1 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 1.7683324813842773, accuracy: 26.1 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 1.746166706085205, accuracy: 26.2 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 1.8122332096099854, accuracy: 23.6 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 1.7457051277160645, accuracy: 26.0 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 1.7370854616165161, accuracy: 26.6 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 1.736355185508728, accuracy: 26.7 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 1.735108733177185, accuracy: 26.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 1.7397602796554565, accuracy: 26.8 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 1.7436132431030273, accuracy: 27.8 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.7681, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.7576, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.6064, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.7267, batch time: 0.06, accuracy:  27.34%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.6563, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.7081, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.6621, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.6389, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.5975, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.7312, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 1.7664586305618286, accuracy: 26.9 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 1.7561877965927124, accuracy: 28.1 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 1.7494207620620728, accuracy: 27.9 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 1.7491401433944702, accuracy: 27.8 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 1.7592723369598389, accuracy: 26.4 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 1.7470934391021729, accuracy: 27.3 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 1.7472054958343506, accuracy: 26.9 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 1.7433444261550903, accuracy: 28.0 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 1.7411762475967407, accuracy: 27.2 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 1.7451744079589844, accuracy: 28.1 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.8159, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.6751, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.6585, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.8109, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.6989, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.7113, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.8187, batch time: 0.10, accuracy:  20.31%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.6810, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.5683, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.8161, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 1.6853735446929932, accuracy: 30.0 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 1.7124714851379395, accuracy: 29.4 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 1.681792140007019, accuracy: 30.6 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 1.6817612648010254, accuracy: 30.4 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 1.7556970119476318, accuracy: 26.3 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 1.7815889120101929, accuracy: 29.5 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.6776973009109497, accuracy: 30.8 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 1.6902307271957397, accuracy: 30.3 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 1.671333909034729, accuracy: 31.0 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.6707977056503296, accuracy: 30.7 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.6515, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.7420, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.7081, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.7021, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.6882, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.7828, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.8682, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.7164, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.8205, batch time: 0.10, accuracy:  21.09%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.7739, batch time: 0.10, accuracy:  24.22%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 1.7149510383605957, accuracy: 28.5 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.7244974374771118, accuracy: 27.9 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 1.7069944143295288, accuracy: 29.4 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 2.209033250808716, accuracy: 24.4 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 1.7058769464492798, accuracy: 28.6 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 1.706249713897705, accuracy: 29.1 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 1.708582878112793, accuracy: 29.1 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 1.7065627574920654, accuracy: 28.8 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 1.7048190832138062, accuracy: 28.9 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 1.7017418146133423, accuracy: 29.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.6627, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.7791, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.7196, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.6836, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.7546, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.8388, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.6301, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.6516, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.6807, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.6502, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 1.7452634572982788, accuracy: 27.2 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 1.7469021081924438, accuracy: 27.2 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 1.7437468767166138, accuracy: 27.8 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 1.7385339736938477, accuracy: 28.2 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 1.8740153312683105, accuracy: 24.2 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 1.73849356174469, accuracy: 27.7 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 1.7382522821426392, accuracy: 27.7 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 1.7447807788848877, accuracy: 27.8 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 1.7356730699539185, accuracy: 27.7 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 1.733134150505066, accuracy: 28.1 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.7287, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.7310, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.7194, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.6995, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.7061, batch time: 0.10, accuracy:  26.56%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.7297, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.6094, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.6825, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.7593, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.6670, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 1.7848466634750366, accuracy: 27.0 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 2.556835412979126, accuracy: 23.2 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 1.7783219814300537, accuracy: 26.7 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 1.898911476135254, accuracy: 26.7 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 1.8801745176315308, accuracy: 27.9 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 1.8615243434906006, accuracy: 27.4 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 1.806747555732727, accuracy: 25.8 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 1.7729649543762207, accuracy: 26.3 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 1.7688305377960205, accuracy: 26.8 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 1.7806620597839355, accuracy: 27.7 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.7364, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.6748, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.7541, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.6769, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.7528, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.8645, batch time: 0.10, accuracy:  22.66%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.6926, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.7052, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.5961, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.7371, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 1.6895936727523804, accuracy: 28.7 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.7021735906600952, accuracy: 27.8 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 1.6894479990005493, accuracy: 28.8 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 1.7501211166381836, accuracy: 28.9 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 1.7144849300384521, accuracy: 28.3 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 1.6854753494262695, accuracy: 28.7 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 1.6852186918258667, accuracy: 28.8 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 1.6968783140182495, accuracy: 29.0 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 1.6861108541488647, accuracy: 28.6 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 1.6883755922317505, accuracy: 29.4 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 1.8210, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.7179, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.7779, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.5687, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.8529, batch time: 0.09, accuracy:  20.31%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.5927, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.7339, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.7026, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.6847, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.7347, batch time: 0.11, accuracy:  25.78%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 1.7096304893493652, accuracy: 27.7 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 1.729691743850708, accuracy: 27.9 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 1.7092220783233643, accuracy: 27.7 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 1.8741978406906128, accuracy: 23.0 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 1.7066009044647217, accuracy: 27.8 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 1.7046434879302979, accuracy: 28.0 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 1.7014881372451782, accuracy: 28.2 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 1.7024062871932983, accuracy: 27.7 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 1.702142596244812, accuracy: 28.5 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 1.7447381019592285, accuracy: 27.2 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.7656, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.5425, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.7833, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.6052, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.6276, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.6420, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.6676, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.6584, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.7125, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.7571, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 1.667243242263794, accuracy: 28.4 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 1.6812620162963867, accuracy: 28.4 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 1.6667875051498413, accuracy: 28.6 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 2.2732439041137695, accuracy: 21.8 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 1.6649169921875, accuracy: 28.7 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 1.6714450120925903, accuracy: 28.9 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 1.6618751287460327, accuracy: 28.7 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 1.6651697158813477, accuracy: 28.7 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 1.894882082939148, accuracy: 24.1 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 1.6637905836105347, accuracy: 28.9 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.7412, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.6816, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.5969, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.7753, batch time: 0.10, accuracy:  23.44%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.8745, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.6209, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.7066, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.5478, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.7040, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.6842, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 1.7036741971969604, accuracy: 29.9 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 1.7255538702011108, accuracy: 28.8 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 1.7031487226486206, accuracy: 29.7 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 1.7647582292556763, accuracy: 26.1 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 1.7059452533721924, accuracy: 28.8 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 1.7000255584716797, accuracy: 29.7 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 1.732377290725708, accuracy: 30.0 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 1.7027180194854736, accuracy: 29.3 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 1.7007085084915161, accuracy: 28.9 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 1.7018556594848633, accuracy: 29.4 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.6825, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.7937, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.7143, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.8008, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.7371, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.7063, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.6620, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.8348, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.6433, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.6033, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 1.6636537313461304, accuracy: 30.5 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.7025412321090698, accuracy: 28.7 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 1.6580992937088013, accuracy: 31.2 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 1.6580920219421387, accuracy: 31.1 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 1.886957049369812, accuracy: 30.2 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 1.6545476913452148, accuracy: 30.4 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 1.6545363664627075, accuracy: 30.8 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 1.652052402496338, accuracy: 30.9 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 1.6547999382019043, accuracy: 31.6 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 1.657409429550171, accuracy: 32.0 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.6874, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.7050, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.6669, batch time: 0.05, accuracy:  30.47%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.7201, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.6674, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.7009, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.6318, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.7244, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.7053, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.6354, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 1.6919543743133545, accuracy: 28.9 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 1.6910672187805176, accuracy: 29.2 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 1.7771109342575073, accuracy: 27.0 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 1.761790156364441, accuracy: 26.8 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 1.6877834796905518, accuracy: 30.5 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 1.686697244644165, accuracy: 29.6 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 1.6817283630371094, accuracy: 30.5 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 1.6805683374404907, accuracy: 30.3 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 1.680302619934082, accuracy: 31.3 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 1.6990554332733154, accuracy: 29.8 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.7184, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.8960, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.7253, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.8367, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.7651, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.7153, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.7432, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.6163, batch time: 0.05, accuracy:  25.78%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.6377, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.7164, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 1.65872061252594, accuracy: 31.3 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 1.7163832187652588, accuracy: 28.3 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 1.6578929424285889, accuracy: 31.4 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 1.6548513174057007, accuracy: 31.2 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 1.7014681100845337, accuracy: 28.9 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 1.6522605419158936, accuracy: 30.9 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 1.662583827972412, accuracy: 31.6 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 1.658348798751831, accuracy: 31.1 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 1.651811957359314, accuracy: 31.2 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 1.6489516496658325, accuracy: 31.8 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.7568, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.8532, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.8389, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.7434, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.5809, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.7268, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.7357, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.8132, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.8254, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.7138, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 1.6845004558563232, accuracy: 30.2 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 1.7007607221603394, accuracy: 29.7 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 1.7201879024505615, accuracy: 28.1 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 1.6718803644180298, accuracy: 31.1 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 1.677483081817627, accuracy: 30.6 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 1.6704612970352173, accuracy: 31.0 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 1.6860084533691406, accuracy: 30.0 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 1.6766200065612793, accuracy: 30.8 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 1.6702274084091187, accuracy: 31.7 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 1.6651304960250854, accuracy: 31.8 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.7121, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.6780, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.7940, batch time: 0.10, accuracy:  29.69%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.6594, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.7970, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.7452, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.6296, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.7406, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.5251, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.8283, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 1.6715853214263916, accuracy: 31.8 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 1.711120367050171, accuracy: 28.2 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 1.6574015617370605, accuracy: 31.0 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 1.9568346738815308, accuracy: 25.9 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 1.656051754951477, accuracy: 30.5 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 1.6499474048614502, accuracy: 30.7 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 1.6521611213684082, accuracy: 30.5 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 1.643639326095581, accuracy: 31.8 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 1.6502207517623901, accuracy: 31.0 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 1.6441068649291992, accuracy: 32.1 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.7605, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.6444, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.6009, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.6775, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.5574, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.6799, batch time: 0.04, accuracy:  25.78%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.4960, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.6219, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.6144, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.6637, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 1.699257254600525, accuracy: 30.5 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 1.7529501914978027, accuracy: 28.2 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 1.6977943181991577, accuracy: 30.6 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 1.7031605243682861, accuracy: 30.4 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 1.7002359628677368, accuracy: 31.5 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 1.695972204208374, accuracy: 30.6 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 1.7084046602249146, accuracy: 30.7 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 1.7030894756317139, accuracy: 30.5 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 1.6921614408493042, accuracy: 31.5 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 1.691547155380249, accuracy: 31.2 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.6570, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.7891, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.6763, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.7080, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.7547, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.6149, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.6593, batch time: 0.10, accuracy:  25.78%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.7200, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.7031, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.7759, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 1.6563371419906616, accuracy: 31.1 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 1.710923194885254, accuracy: 30.1 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 1.6558787822723389, accuracy: 31.4 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 1.7162402868270874, accuracy: 27.7 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 1.6582143306732178, accuracy: 31.6 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 1.6650919914245605, accuracy: 31.2 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 1.6973367929458618, accuracy: 30.4 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 1.7086862325668335, accuracy: 32.3 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 1.658219814300537, accuracy: 32.4 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 1.6511757373809814, accuracy: 32.1 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.6457, batch time: 0.06, accuracy:  30.47%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.6582, batch time: 0.06, accuracy:  28.91%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.6688, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.8481, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.7691, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.7220, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.7033, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.5786, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.7319, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.6743, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 1.6430714130401611, accuracy: 32.9 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 1.7282707691192627, accuracy: 29.9 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 1.641818642616272, accuracy: 32.8 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 2.487316131591797, accuracy: 17.6 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 1.7276568412780762, accuracy: 30.3 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 1.6336745023727417, accuracy: 33.4 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 1.6364516019821167, accuracy: 33.9 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 1.6626828908920288, accuracy: 32.2 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 1.631588339805603, accuracy: 33.5 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 1.6310393810272217, accuracy: 33.5 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.6101, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.6304, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.6564, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.6915, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.6912, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.6171, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.6513, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.6928, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.6403, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.7092, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 1.6379765272140503, accuracy: 30.3 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 1.6381475925445557, accuracy: 30.7 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 1.674961805343628, accuracy: 37.0 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 2.156400442123413, accuracy: 23.3 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 1.6441680192947388, accuracy: 29.9 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 1.6520181894302368, accuracy: 28.4 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 1.645714521408081, accuracy: 30.4 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 1.6341725587844849, accuracy: 30.5 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 1.6345652341842651, accuracy: 30.7 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 1.6337467432022095, accuracy: 30.8 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.6231, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.6996, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.5718, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.6403, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.6147, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.4734, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.7424, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.7018, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.5786, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.6479, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 1.6548563241958618, accuracy: 30.8 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 1.7139568328857422, accuracy: 28.9 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 1.6542015075683594, accuracy: 31.2 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 2.0432322025299072, accuracy: 26.4 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 1.665846824645996, accuracy: 31.3 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 1.6528997421264648, accuracy: 31.6 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 1.6561235189437866, accuracy: 31.4 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 1.6671350002288818, accuracy: 31.7 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 1.6597535610198975, accuracy: 30.1 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 1.8368569612503052, accuracy: 26.5 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.6855, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.5728, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.6243, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.6998, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.6989, batch time: 0.10, accuracy:  27.34%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.7453, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.8561, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.7058, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.6460, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.6448, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 1.6382023096084595, accuracy: 31.7 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 1.7607108354568481, accuracy: 28.3 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 1.6372541189193726, accuracy: 31.6 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 1.931180477142334, accuracy: 25.8 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 1.6367741823196411, accuracy: 32.3 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 1.6344741582870483, accuracy: 32.1 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 1.6356992721557617, accuracy: 31.7 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 1.6938942670822144, accuracy: 31.7 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 1.6368693113327026, accuracy: 32.5 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 1.6419432163238525, accuracy: 31.5 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.7583, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.5655, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.6728, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.5938, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.6910, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.5905, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.7324, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.5733, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.8435, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.7004, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 1.6509276628494263, accuracy: 32.9 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 1.6542876958847046, accuracy: 31.2 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 1.6551841497421265, accuracy: 34.7 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 1.6425827741622925, accuracy: 32.3 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 1.76068115234375, accuracy: 29.9 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 1.7245663404464722, accuracy: 31.4 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 1.6399519443511963, accuracy: 33.0 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 1.635411262512207, accuracy: 33.3 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 1.6320958137512207, accuracy: 33.1 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 1.6323808431625366, accuracy: 33.2 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.6888, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.7001, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.5929, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.7165, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.7857, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.6702, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.6452, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.5695, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.6029, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.6704, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 1.6538584232330322, accuracy: 31.1 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.8747857809066772, accuracy: 26.3 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 1.65379798412323, accuracy: 31.1 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 3.230111837387085, accuracy: 15.9 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 1.6746593713760376, accuracy: 31.6 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 1.6517351865768433, accuracy: 31.5 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 1.6469531059265137, accuracy: 32.8 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 1.66961669921875, accuracy: 31.5 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 1.6496669054031372, accuracy: 31.8 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 1.6444389820098877, accuracy: 31.7 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.5987, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.6676, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.6604, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.7497, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.5765, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.7054, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.5309, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.5959, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.7185, batch time: 0.04, accuracy:  28.12%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.6214, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 1.6291203498840332, accuracy: 32.3 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 3.9863579273223877, accuracy: 13.2 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 1.64533269405365, accuracy: 33.4 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 1.6290401220321655, accuracy: 32.3 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 1.748841643333435, accuracy: 29.3 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 1.6288402080535889, accuracy: 32.7 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 1.6286742687225342, accuracy: 32.6 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 1.6271402835845947, accuracy: 32.5 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 1.6269865036010742, accuracy: 32.5 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 1.6264702081680298, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.7684, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.5521, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.5553, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.7020, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.5494, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.6537, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.5999, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.5907, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.5886, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.5970, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 1.6241936683654785, accuracy: 33.8 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1.7050580978393555, accuracy: 30.4 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 1.6230729818344116, accuracy: 33.2 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 1.6230729818344116, accuracy: 33.2 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 1.6499369144439697, accuracy: 30.8 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 1.648054838180542, accuracy: 37.3 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 1.618796706199646, accuracy: 33.2 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 1.6184520721435547, accuracy: 32.9 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 1.6186076402664185, accuracy: 33.3 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 1.6166977882385254, accuracy: 32.1 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.5566, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.5703, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.7220, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.7003, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.5899, batch time: 0.10, accuracy:  32.03%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.6107, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.7107, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.7195, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.7357, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.6459, batch time: 0.09, accuracy:  26.56%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 1.6600173711776733, accuracy: 32.6 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 1.8077199459075928, accuracy: 29.2 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 1.6598477363586426, accuracy: 32.8 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 1.7703769207000732, accuracy: 29.2 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 1.663094401359558, accuracy: 31.9 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 1.6574063301086426, accuracy: 32.6 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 1.6548388004302979, accuracy: 32.6 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 1.6701462268829346, accuracy: 34.3 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 1.7017930746078491, accuracy: 35.4 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.6490917205810547, accuracy: 33.8 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.7010, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.6326, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.5900, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.6126, batch time: 0.38, accuracy:  36.72%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.6254, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.5810, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.7625, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.6034, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.4719, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.6694, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 1.6630761623382568, accuracy: 33.4 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 1.6864956617355347, accuracy: 32.1 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 1.6596869230270386, accuracy: 35.6 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 1.6594645977020264, accuracy: 35.9 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 1.876539707183838, accuracy: 34.6 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 1.6599864959716797, accuracy: 34.7 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 1.695299506187439, accuracy: 33.5 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 1.6765918731689453, accuracy: 34.0 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 1.655240774154663, accuracy: 36.8 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 1.6545746326446533, accuracy: 35.9 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.6195, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.6195, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.7427, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.5629, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.6258, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.6701, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.4987, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.7462, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.5080, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.6763, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 1.6301887035369873, accuracy: 34.5 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 1.7013400793075562, accuracy: 31.2 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 1.6204948425292969, accuracy: 35.9 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 2.737516403198242, accuracy: 23.4 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 1.635335087776184, accuracy: 37.0 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 1.6166023015975952, accuracy: 36.5 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 1.6165863275527954, accuracy: 36.3 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 1.619878888130188, accuracy: 33.7 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 1.6143345832824707, accuracy: 36.3 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 1.6125142574310303, accuracy: 35.9 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.6485, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.5408, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.6937, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.6089, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.7472, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.6672, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.8430, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.6843, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.8136, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.6875, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 1.6471682786941528, accuracy: 35.2 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 2.5157995223999023, accuracy: 29.3 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 1.671247959136963, accuracy: 35.4 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 1.6456058025360107, accuracy: 35.1 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 1.6474758386611938, accuracy: 35.0 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 1.6558786630630493, accuracy: 35.0 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 1.640632152557373, accuracy: 36.2 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 1.6392513513565063, accuracy: 35.7 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 1.6404130458831787, accuracy: 35.6 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 1.6377004384994507, accuracy: 36.2 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.6938, batch time: 0.06, accuracy:  32.81%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.6288, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.6424, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.5996, batch time: 0.08, accuracy:  38.28%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.5502, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.7893, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.4773, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 1.6214, batch time: 0.37, accuracy:  43.75%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 1.5752, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 1.7359, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 1.6238712072372437, accuracy: 33.7 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 1.9029051065444946, accuracy: 27.8 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 1.6476281881332397, accuracy: 36.1 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 1.6611641645431519, accuracy: 32.9 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 1.6454836130142212, accuracy: 31.6 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 1.670362949371338, accuracy: 32.5 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 1.6207292079925537, accuracy: 34.8 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 1.6178114414215088, accuracy: 35.6 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 1.6170055866241455, accuracy: 35.4 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 1.6214519739151, accuracy: 36.0 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 1.5203, batch time: 0.06, accuracy:  41.41%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 1.7811, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 1.6881, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 1.7069, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 1.5141, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 1.5985, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 1.5922, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 1.6517, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 1.5973, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 1.5551, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 1.6290227174758911, accuracy: 37.4 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 1.722139835357666, accuracy: 36.3 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 1.6138876676559448, accuracy: 38.9 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 1.720999836921692, accuracy: 33.5 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 1.6141413450241089, accuracy: 38.3 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 1.6068624258041382, accuracy: 38.8 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 1.606347918510437, accuracy: 38.2 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 1.5986337661743164, accuracy: 38.1 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 1.6068480014801025, accuracy: 37.6 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 1.5978878736495972, accuracy: 38.8 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 1.7727, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 1.5356, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 1.6706, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 1.5303, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 1.4681, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 1.6691, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 1.6959, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 1.6287, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 1.7866, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 1.6664, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 1.6367623805999756, accuracy: 40.0 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.6891520023345947, accuracy: 37.6 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 1.6366283893585205, accuracy: 40.0 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 2.4191055297851562, accuracy: 29.6 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 1.6536955833435059, accuracy: 39.6 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 1.6588820219039917, accuracy: 40.3 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 1.643275260925293, accuracy: 40.7 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 1.6365199089050293, accuracy: 40.3 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 1.6355748176574707, accuracy: 40.1 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 1.6284435987472534, accuracy: 39.8 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 1.5215, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 1.5629, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 1.6892, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 1.6055, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 1.5519, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 1.4452, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 1.6537, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 1.6599, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 1.6650, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 1.6175, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 1.6067430973052979, accuracy: 39.2 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 3.225792407989502, accuracy: 20.2 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 4.461709499359131, accuracy: 15.3 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 3.9211087226867676, accuracy: 20.2 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 1.6131497621536255, accuracy: 38.4 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 1.6129549741744995, accuracy: 40.4 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 1.6029452085494995, accuracy: 38.7 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 1.5979721546173096, accuracy: 39.0 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 1.6108070611953735, accuracy: 38.7 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 1.596495270729065, accuracy: 38.8 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 1.5730, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 1.5745, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 1.4645, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 1.6422, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 1.5542, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 1.6206, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 1.6566, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 1.7448, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 1.4955, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 1.8052, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 1.6193079948425293, accuracy: 34.2 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 1.7409430742263794, accuracy: 30.3 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 1.6179420948028564, accuracy: 34.2 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 1.9787312746047974, accuracy: 28.4 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 1.6219439506530762, accuracy: 34.9 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 1.6156718730926514, accuracy: 36.5 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 1.6309876441955566, accuracy: 33.6 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 1.6648883819580078, accuracy: 35.1 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 1.6246005296707153, accuracy: 36.1 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 1.616101861000061, accuracy: 34.8 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 1.6649, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 1.6564, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 1.6856, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 1.7696, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 1.5574, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 1.8503, batch time: 0.04, accuracy:  32.03%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 1.6469, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 1.6277, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 1.6618, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 1.5699, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 1.627560019493103, accuracy: 39.4 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.702903151512146, accuracy: 36.5 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 1.656162977218628, accuracy: 40.9 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 1.6166472434997559, accuracy: 40.3 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 1.7095112800598145, accuracy: 36.9 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 1.6398988962173462, accuracy: 39.1 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 1.6154656410217285, accuracy: 42.1 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 1.6469454765319824, accuracy: 38.3 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 1.8304715156555176, accuracy: 36.9 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 1.8425568342208862, accuracy: 36.9 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 1.7459, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 1.5704, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 1.6379, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 1.5514, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 1.7859, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 1.6227, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 1.5054, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 1.5865, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 1.7694, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 1.5191, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 1.622930645942688, accuracy: 39.5 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 1.7283413410186768, accuracy: 34.2 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 1.620094895362854, accuracy: 40.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 1.6243113279342651, accuracy: 38.6 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 1.6219080686569214, accuracy: 39.3 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 1.6158711910247803, accuracy: 39.2 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 1.6861952543258667, accuracy: 37.8 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 1.613930106163025, accuracy: 39.5 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 1.6138535737991333, accuracy: 39.3 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 1.6134871244430542, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 1.6839, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 1.5136, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 1.6802, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 1.6320, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 1.6219, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 1.7100, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 1.5866, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 1.5419, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 1.5597, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 1.8170, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 1.63625967502594, accuracy: 40.0 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1.8143095970153809, accuracy: 34.3 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 1.6340386867523193, accuracy: 40.2 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 2.4884769916534424, accuracy: 30.8 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 1.6318610906600952, accuracy: 40.1 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 1.656973958015442, accuracy: 38.3 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 1.6386463642120361, accuracy: 39.2 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 1.63237464427948, accuracy: 38.6 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 1.6274832487106323, accuracy: 39.1 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 1.6274807453155518, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 1.6797, batch time: 0.08, accuracy:  35.16%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 1.5477, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 1.6715, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 1.4050, batch time: 0.31, accuracy:  46.88%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 1.5381, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 1.5694, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 1.6941, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 1.5922, batch time: 0.08, accuracy:  45.31%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 1.6238, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 1.7437, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 1.5959529876708984, accuracy: 39.9 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 1.835146427154541, accuracy: 31.6 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 1.5915504693984985, accuracy: 40.1 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 1.5895471572875977, accuracy: 40.7 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 1.703478217124939, accuracy: 37.6 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 1.5877764225006104, accuracy: 41.4 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 1.5898454189300537, accuracy: 39.8 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 1.5840320587158203, accuracy: 40.3 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 1.5853445529937744, accuracy: 40.5 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 1.6102840900421143, accuracy: 38.5 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 1.7028, batch time: 0.12, accuracy:  34.38%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 1.5897, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 1.7687, batch time: 0.11, accuracy:  35.16%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 1.7981, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 1.5579, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 1.5969, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 1.6034, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 1.6684, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 1.6375, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 1.7331, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 1.6779435873031616, accuracy: 37.1 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 1.695830225944519, accuracy: 35.8 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 1.7116611003875732, accuracy: 37.0 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 1.6756277084350586, accuracy: 38.4 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 1.6977007389068604, accuracy: 37.3 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 1.6781409978866577, accuracy: 37.6 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 1.6794712543487549, accuracy: 39.3 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 1.6764227151870728, accuracy: 38.2 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 1.7215512990951538, accuracy: 36.3 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 1.6712126731872559, accuracy: 39.0 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 1.6062, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 1.6565, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 1.6105, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 1.5422, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 1.5653, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 1.5390, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 1.6549, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 1.6829, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 1.5397, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 1.5504, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 1.5829322338104248, accuracy: 37.3 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 1.5902689695358276, accuracy: 37.6 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 1.752131462097168, accuracy: 34.8 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 3.792806386947632, accuracy: 23.4 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 1.7510097026824951, accuracy: 29.3 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 1.5954152345657349, accuracy: 35.6 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 1.5813106298446655, accuracy: 37.4 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 1.5872451066970825, accuracy: 38.4 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 1.5757323503494263, accuracy: 37.7 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 1.5745314359664917, accuracy: 38.0 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 1.6696, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 1.5152, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 1.6090, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 1.6213, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 1.6614, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 1.6200, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 1.6008, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 1.6986, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 1.7886, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 1.7723, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 1.6398977041244507, accuracy: 38.3 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 1.772890567779541, accuracy: 32.6 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 1.6337430477142334, accuracy: 38.8 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 1.6324223279953003, accuracy: 39.3 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 4.577803134918213, accuracy: 20.6 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 1.6292248964309692, accuracy: 39.5 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 1.6357158422470093, accuracy: 39.3 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 1.6358296871185303, accuracy: 39.5 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 1.6710834503173828, accuracy: 36.5 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 1.624190330505371, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 1.7025, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 1.5707, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 1.6445, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 1.6015, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 1.4741, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 1.6689, batch time: 0.10, accuracy:  28.12%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 1.6988, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 1.6187, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 1.6781, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 1.5980, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 1.6047232151031494, accuracy: 36.7 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 1.6665056943893433, accuracy: 36.4 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 1.6026628017425537, accuracy: 36.7 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 1.6007159948349, accuracy: 35.1 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 1.6064263582229614, accuracy: 36.2 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 1.8831576108932495, accuracy: 28.9 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 1.5975022315979004, accuracy: 35.8 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 1.59707772731781, accuracy: 35.2 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 1.5937639474868774, accuracy: 35.4 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 1.5942224264144897, accuracy: 35.9 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 1.5715, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 1.6575, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 1.5257, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 1.6323, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 1.6125, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 1.6337, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 1.6603, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 1.6677, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 1.5622, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 1.5070, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 1.6380869150161743, accuracy: 41.3 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 1.7849048376083374, accuracy: 36.8 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 1.6171833276748657, accuracy: 41.6 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 1.6171427965164185, accuracy: 41.8 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 1.6196131706237793, accuracy: 41.0 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 1.6138849258422852, accuracy: 41.9 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 1.618269681930542, accuracy: 41.9 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 1.6792755126953125, accuracy: 39.6 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 1.699833631515503, accuracy: 38.1 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 1.6694549322128296, accuracy: 39.5 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 1.5466, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 1.5918, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 1.6129, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 1.6249, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 1.6819, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 1.6129, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 1.6492, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 1.6275, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 1.5481, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 1.6740, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 1.6171714067459106, accuracy: 41.0 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 3.580416440963745, accuracy: 25.5 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 1.762349009513855, accuracy: 37.0 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 1.66753089427948, accuracy: 38.5 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 1.6223212480545044, accuracy: 42.3 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 1.6602870225906372, accuracy: 36.5 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 2.216254949569702, accuracy: 33.7 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 1.7564053535461426, accuracy: 37.3 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 1.610142707824707, accuracy: 42.8 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 1.6091011762619019, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 1.5954, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 1.5242, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 1.5782, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 1.5937, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 1.7192, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 1.5682, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 1.6220, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 1.5868, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 1.6661, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 1.4794, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 1.6109199523925781, accuracy: 41.0 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 3.8406481742858887, accuracy: 24.4 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 1.6847198009490967, accuracy: 38.2 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 1.6913065910339355, accuracy: 38.1 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 1.6633691787719727, accuracy: 39.7 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 1.630415678024292, accuracy: 40.5 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 1.6015506982803345, accuracy: 40.6 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 1.707465410232544, accuracy: 37.9 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 1.6000620126724243, accuracy: 39.1 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 1.5949345827102661, accuracy: 40.1 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 1.7212, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 1.5603, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 1.5888, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 1.6266, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 1.6305, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 1.6531, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 1.6914, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 1.4955, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 1.5127, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 1.6859, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 1.6330070495605469, accuracy: 39.3 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.6731973886489868, accuracy: 37.2 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 1.6327738761901855, accuracy: 39.3 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 1.9596046209335327, accuracy: 33.4 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 1.6417851448059082, accuracy: 37.9 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 1.628182053565979, accuracy: 39.5 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 1.65147066116333, accuracy: 39.0 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 1.6665287017822266, accuracy: 36.8 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 1.6704695224761963, accuracy: 40.0 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 1.6305301189422607, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 1.5206, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 1.6489, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 1.6848, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 1.6774, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 1.7323, batch time: 0.13, accuracy:  28.91%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 1.5583, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 1.6065, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 1.4902, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 1.5465, batch time: 0.12, accuracy:  39.84%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 1.5759, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 1.675684928894043, accuracy: 38.6 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.6796475648880005, accuracy: 38.0 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 1.6755906343460083, accuracy: 38.8 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 1.8827472925186157, accuracy: 29.5 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 1.6766598224639893, accuracy: 38.2 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 1.7105120420455933, accuracy: 38.5 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 1.7851884365081787, accuracy: 36.1 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 1.6710408926010132, accuracy: 38.5 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 1.6702624559402466, accuracy: 38.9 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 1.6829477548599243, accuracy: 38.9 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 1.6314, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 1.5926, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 1.6950, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 1.5924, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 1.7043, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 1.6313, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 1.6570, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 1.4642, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 1.6463, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 1.4911, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 1.6180254220962524, accuracy: 41.6 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 1.951185941696167, accuracy: 31.6 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 1.617111086845398, accuracy: 41.8 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 1.6138559579849243, accuracy: 41.7 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 1.8012895584106445, accuracy: 34.2 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 1.6212555170059204, accuracy: 39.3 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 1.6111012697219849, accuracy: 40.1 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 1.6104902029037476, accuracy: 39.0 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 1.6111985445022583, accuracy: 38.4 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 1.6141533851623535, accuracy: 38.6 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 1.7270, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 1.7059, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 1.6676, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 1.7166, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 1.5668, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 1.5711, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 1.6168, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 1.6298, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 1.6688, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 1.5984, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 1.6042594909667969, accuracy: 41.5 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 3.8855693340301514, accuracy: 23.2 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 1.6512629985809326, accuracy: 38.9 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 2.0685460567474365, accuracy: 23.6 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 1.614351511001587, accuracy: 41.6 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 1.6024222373962402, accuracy: 42.3 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 1.6161175966262817, accuracy: 41.4 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 1.601401686668396, accuracy: 42.4 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 1.6016788482666016, accuracy: 41.9 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 1.6013586521148682, accuracy: 42.0 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 1.6430, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 1.5948, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 1.7208, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 1.6553, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 1.6152, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 1.5661, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 1.6874, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 1.6864, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 1.7972, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 1.5927, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 1.6199407577514648, accuracy: 42.6 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 3.870248556137085, accuracy: 23.7 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 1.6611899137496948, accuracy: 40.5 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 1.9154322147369385, accuracy: 30.3 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 1.6211087703704834, accuracy: 41.7 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 1.6268283128738403, accuracy: 41.0 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 1.6368507146835327, accuracy: 40.8 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 1.6173532009124756, accuracy: 42.3 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 1.615502953529358, accuracy: 40.6 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 1.6399588584899902, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 1.4986, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 1.5568, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 1.7256, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 1.5053, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 1.6176, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 1.5986, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 1.6561, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 1.6825, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 1.5879, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 1.5124, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 1.6401420831680298, accuracy: 39.9 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 3.7029497623443604, accuracy: 22.2 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 1.6890097856521606, accuracy: 34.6 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 1.8805404901504517, accuracy: 35.3 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 1.6408305168151855, accuracy: 41.3 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 1.7139467000961304, accuracy: 30.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 2.02363657951355, accuracy: 29.4 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 1.6342496871948242, accuracy: 37.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 1.6361135244369507, accuracy: 38.7 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 1.6318275928497314, accuracy: 36.5 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 1.5437, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 1.6795, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 1.5518, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 1.4807, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 1.6124, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 1.6443, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 1.5918, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 1.7395, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 1.6300, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 1.5244, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 1.6303856372833252, accuracy: 38.7 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 1.6689409017562866, accuracy: 36.9 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 1.6302076578140259, accuracy: 38.1 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 1.6733359098434448, accuracy: 36.2 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 1.7776505947113037, accuracy: 34.4 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 1.6256307363510132, accuracy: 39.9 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 1.6344794034957886, accuracy: 39.4 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 1.6399519443511963, accuracy: 39.3 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 1.6357555389404297, accuracy: 36.8 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 1.6250804662704468, accuracy: 38.0 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 1.7189, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 1.4904, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 1.5209, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 1.5789, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 1.6831, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 1.7588, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 1.5672, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 1.5652, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 1.5006, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 1.5299, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 1.6289006471633911, accuracy: 40.8 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 3.0956945419311523, accuracy: 22.5 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 1.6539759635925293, accuracy: 34.8 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 1.7449606657028198, accuracy: 37.3 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 1.78256094455719, accuracy: 36.4 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 1.625888466835022, accuracy: 42.5 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 1.6251049041748047, accuracy: 43.1 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 1.6292572021484375, accuracy: 43.1 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 1.6264430284500122, accuracy: 43.1 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 1.6240668296813965, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 1.5752, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 1.6284, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 1.7122, batch time: 0.11, accuracy:  35.16%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 1.6549, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 1.5249, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 1.5502, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 1.6488, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 1.6370, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 1.6563, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 1.5326, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 1.6166141033172607, accuracy: 42.1 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 1.621385931968689, accuracy: 41.9 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 1.7304188013076782, accuracy: 37.1 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 1.621137261390686, accuracy: 41.6 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 1.6316514015197754, accuracy: 40.5 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 1.677943468093872, accuracy: 40.3 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 1.615290880203247, accuracy: 40.7 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 1.6492795944213867, accuracy: 43.0 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 1.6381639242172241, accuracy: 41.7 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 1.6136800050735474, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 1.4987, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 1.4933, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 1.6220, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 1.6018, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 1.6461, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 1.5988, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 1.6260, batch time: 0.11, accuracy:  39.06%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 1.5926, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 1.7213, batch time: 0.12, accuracy:  29.69%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 1.5875, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 1.5736911296844482, accuracy: 41.3 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 1.9317833185195923, accuracy: 32.4 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 1.571014165878296, accuracy: 41.9 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 1.6045583486557007, accuracy: 42.0 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 1.5851552486419678, accuracy: 40.4 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 1.5787370204925537, accuracy: 41.6 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 1.6094149351119995, accuracy: 38.8 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 1.5668481588363647, accuracy: 41.4 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 1.5664957761764526, accuracy: 41.3 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 1.5659915208816528, accuracy: 40.8 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 1.6820, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 1.6250, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 1.5671, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 1.5455, batch time: 0.11, accuracy:  42.97%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 1.6399, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 1.7704, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 1.6008, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 1.4017, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 1.6077, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 1.5731, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 1.556386947631836, accuracy: 44.0 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 3.0488762855529785, accuracy: 23.7 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 1.5960150957107544, accuracy: 42.0 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 1.555238962173462, accuracy: 43.8 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 1.6948872804641724, accuracy: 39.3 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 1.556359052658081, accuracy: 43.1 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 1.5594792366027832, accuracy: 43.6 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 1.5520371198654175, accuracy: 44.3 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 1.5507290363311768, accuracy: 44.5 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 1.5508781671524048, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 1.5826, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 1.5255, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 1.5774, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 1.6087, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 1.5870, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 1.5493, batch time: 0.12, accuracy:  42.97%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 1.6753, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 1.4063, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 1.6356, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 1.7019, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 1.6054999828338623, accuracy: 38.4 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 2.707981824874878, accuracy: 24.5 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 4.586048603057861, accuracy: 19.1 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 3.47161865234375, accuracy: 21.0 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 1.60503351688385, accuracy: 36.9 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 1.6003246307373047, accuracy: 37.4 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 1.722628116607666, accuracy: 35.8 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 1.7714624404907227, accuracy: 31.4 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 1.6047794818878174, accuracy: 39.2 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 1.597883939743042, accuracy: 38.5 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 1.5333, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 1.6348, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 1.5608, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 1.6616, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 1.6652, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 1.5367, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 1.6462, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 1.6597, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 1.6554, batch time: 0.11, accuracy:  35.94%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 1.5257, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 1.6221429109573364, accuracy: 40.6 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 2.4811928272247314, accuracy: 28.0 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 1.6775721311569214, accuracy: 39.2 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 1.6218180656433105, accuracy: 40.7 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 1.6253103017807007, accuracy: 40.3 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 1.6186456680297852, accuracy: 40.5 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 1.6186808347702026, accuracy: 40.9 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 1.6254221200942993, accuracy: 40.8 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 1.6213984489440918, accuracy: 40.8 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 1.6154531240463257, accuracy: 40.6 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 1.7327, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 1.5102, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 1.5825, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 1.6231, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 1.4991, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 1.5921, batch time: 0.04, accuracy:  33.59%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 1.6554, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 1.5723, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 1.6699, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 1.6559, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 1.572242021560669, accuracy: 41.3 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 1.5880393981933594, accuracy: 40.7 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 1.7575976848602295, accuracy: 35.2 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 2.5195868015289307, accuracy: 22.1 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 1.6634372472763062, accuracy: 33.9 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 1.885744333267212, accuracy: 30.1 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 1.5638587474822998, accuracy: 39.6 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 1.5581421852111816, accuracy: 40.1 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 1.5566017627716064, accuracy: 40.9 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 1.5603108406066895, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 1.4774, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 1.6263, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 1.5290, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 1.6806, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 1.5448, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 1.6106, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 1.6884, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 1.5016, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 1.5697, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 1.7776, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 1.6376749277114868, accuracy: 38.1 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 1.959663987159729, accuracy: 31.0 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 1.693464994430542, accuracy: 34.8 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 1.7600958347320557, accuracy: 37.3 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.6484489440917969, accuracy: 36.9 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 1.6328052282333374, accuracy: 38.4 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 1.7433148622512817, accuracy: 33.2 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 1.6440138816833496, accuracy: 36.4 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 1.80120849609375, accuracy: 33.7 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 1.6333577632904053, accuracy: 37.7 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 1.6601, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 1.5523, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 1.7319, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 1.6358, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 1.5762, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 1.5826, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 1.7502, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 1.5188, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 1.5480, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 1.5936, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 1.595583438873291, accuracy: 37.9 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 2.2153306007385254, accuracy: 24.8 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 3.3689217567443848, accuracy: 23.5 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 1.795839548110962, accuracy: 28.6 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 1.6112196445465088, accuracy: 34.6 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 1.660114049911499, accuracy: 41.3 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 1.6487493515014648, accuracy: 36.4 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 1.5933558940887451, accuracy: 42.0 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 1.5890883207321167, accuracy: 41.0 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 1.585269808769226, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 1.6538, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 1.6021, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 1.6736, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 1.8627, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 1.5564, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 1.6160, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 1.5144, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 1.6832, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 1.5451, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 1.5121, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 1.5705384016036987, accuracy: 42.4 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.7873492240905762, accuracy: 35.6 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 1.5687464475631714, accuracy: 42.4 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 1.9249553680419922, accuracy: 33.9 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 1.5749695301055908, accuracy: 42.3 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 1.5677406787872314, accuracy: 41.4 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 1.570314645767212, accuracy: 40.6 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 1.5590745210647583, accuracy: 43.7 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 1.555449366569519, accuracy: 41.7 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 1.5535691976547241, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 1.4481, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 1.6233, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 1.6281, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 1.6512, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 1.4972, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 1.5458, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 1.5664, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 1.6600, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 1.4899, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 1.5456, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 1.5981839895248413, accuracy: 41.5 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 4.879145622253418, accuracy: 19.5 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 1.6701314449310303, accuracy: 37.2 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 1.5969300270080566, accuracy: 40.4 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 1.573581576347351, accuracy: 41.4 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 1.6984938383102417, accuracy: 35.8 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 1.573022723197937, accuracy: 41.3 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 1.5850342512130737, accuracy: 39.5 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 1.6063116788864136, accuracy: 40.5 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 1.5724648237228394, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 1.3685, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 1.6676, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 1.4108, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 1.5526, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 1.6875, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 1.4688, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 1.5497, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 1.7486, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 1.3721, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 1.6292, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 1.601051688194275, accuracy: 40.1 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 3.4396822452545166, accuracy: 22.9 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 1.688366413116455, accuracy: 35.5 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 1.5915921926498413, accuracy: 39.9 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 1.5981682538986206, accuracy: 43.2 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 1.5911664962768555, accuracy: 43.6 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 1.5913865566253662, accuracy: 42.3 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 1.5907286405563354, accuracy: 43.7 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 1.587972640991211, accuracy: 43.3 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 1.5880388021469116, accuracy: 44.7 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 1.5231, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 1.4697, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 1.5553, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 1.7647, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 1.6911, batch time: 0.13, accuracy:  36.72%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 1.5523, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 1.6719, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 1.5595, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 1.4704, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 1.6320, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 1.6054081916809082, accuracy: 41.3 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 2.8318653106689453, accuracy: 27.3 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 1.6030865907669067, accuracy: 41.4 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 3.2615582942962646, accuracy: 23.3 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 1.6147178411483765, accuracy: 41.3 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 1.6402767896652222, accuracy: 41.1 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 1.634031891822815, accuracy: 40.6 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 1.599043369293213, accuracy: 42.4 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 1.5951368808746338, accuracy: 42.5 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 1.5934745073318481, accuracy: 42.7 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 1.5720, batch time: 0.12, accuracy:  35.16%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 1.7300, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 1.6976, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 1.7906, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 1.5194, batch time: 0.12, accuracy:  44.53%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 1.6115, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 1.7495, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 1.6347, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 1.5205, batch time: 0.34, accuracy:  44.53%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 1.6310, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 1.6203348636627197, accuracy: 37.3 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 2.7921974658966064, accuracy: 24.4 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 1.6179025173187256, accuracy: 37.8 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 1.616909146308899, accuracy: 37.9 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 1.6539332866668701, accuracy: 42.0 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 1.711673378944397, accuracy: 32.7 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 1.7458586692810059, accuracy: 32.4 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 1.613244891166687, accuracy: 40.1 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 1.6124237775802612, accuracy: 38.5 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 1.6117161512374878, accuracy: 38.5 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 1.6630, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 1.5647, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 1.5192, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 1.6290, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 1.7034, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 1.6427, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 1.6855, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 1.5773, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 1.5960, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 1.6504, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 1.5946322679519653, accuracy: 40.5 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 1.8918410539627075, accuracy: 31.1 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 1.5945322513580322, accuracy: 40.5 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 2.683535099029541, accuracy: 27.7 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 2.1790060997009277, accuracy: 30.1 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 1.6205388307571411, accuracy: 39.4 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 1.59927499294281, accuracy: 40.6 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 1.5894432067871094, accuracy: 41.6 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 1.5896257162094116, accuracy: 42.4 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 1.6194053888320923, accuracy: 39.5 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 1.5493, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 1.6408, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 1.6434, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 1.6044, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 1.5216, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 1.5062, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 1.5377, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 1.5524, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 1.4943, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 1.7017, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 1.598144292831421, accuracy: 39.6 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 2.2343459129333496, accuracy: 28.0 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 1.5944578647613525, accuracy: 38.7 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 1.5944578647613525, accuracy: 38.7 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 1.6952348947525024, accuracy: 38.5 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 1.5902880430221558, accuracy: 37.8 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 1.6397336721420288, accuracy: 39.1 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 1.5885103940963745, accuracy: 39.3 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 1.583398461341858, accuracy: 40.1 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 1.583321452140808, accuracy: 38.2 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 1.5995, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 1.6094, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 1.5370, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 1.5729, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 1.5318, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 1.5744, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 1.6034, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 1.5802, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 1.5793, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 1.6557, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 1.6025323867797852, accuracy: 37.5 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 2.1996634006500244, accuracy: 29.2 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 1.5982718467712402, accuracy: 39.3 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 1.5962659120559692, accuracy: 40.3 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 1.7718273401260376, accuracy: 35.0 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 1.7925324440002441, accuracy: 35.5 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 1.5921214818954468, accuracy: 40.9 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 1.6014240980148315, accuracy: 38.5 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 1.590461254119873, accuracy: 39.6 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 1.602164626121521, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 1.4499, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 1.5317, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 1.5484, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 1.6089, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 1.5942, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 1.4729, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 1.5486, batch time: 0.12, accuracy:  35.94%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 1.5543, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 1.7137, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 1.5346, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 1.5922884941101074, accuracy: 39.6 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 2.0985794067382812, accuracy: 31.0 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 1.5903822183609009, accuracy: 40.0 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 1.9085148572921753, accuracy: 33.8 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 1.6067664623260498, accuracy: 39.0 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 1.6056865453720093, accuracy: 39.1 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 1.707491397857666, accuracy: 33.2 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 1.6007078886032104, accuracy: 42.3 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 1.6109645366668701, accuracy: 38.8 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 1.5825363397598267, accuracy: 40.8 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 1.4975, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 1.6732, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 1.5456, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 1.6211, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 1.5815, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 1.4387, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 1.4434, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 1.6179, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 1.5651, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 1.7344, batch time: 0.12, accuracy:  43.75%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 1.5926547050476074, accuracy: 38.2 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 2.669262409210205, accuracy: 26.4 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 1.5923389196395874, accuracy: 38.1 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 1.8316802978515625, accuracy: 32.0 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 1.5998406410217285, accuracy: 37.6 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 1.5974359512329102, accuracy: 37.7 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 1.589353084564209, accuracy: 38.0 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 1.5873632431030273, accuracy: 37.5 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 1.5866186618804932, accuracy: 37.6 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 1.585419774055481, accuracy: 38.6 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 1.6904, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 1.7074, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 1.6279, batch time: 0.12, accuracy:  40.62%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 1.6586, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 1.6229, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 1.5873, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 1.5406, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 1.7027, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 1.3441, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 1.6673, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 1.6299688816070557, accuracy: 39.6 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 2.2370052337646484, accuracy: 28.8 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 1.6915019750595093, accuracy: 38.3 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 1.7034757137298584, accuracy: 37.4 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 1.6531729698181152, accuracy: 37.8 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 1.6184358596801758, accuracy: 39.7 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 1.6164087057113647, accuracy: 39.2 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 1.6162378787994385, accuracy: 40.3 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.632664680480957, accuracy: 40.8 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 1.6389096975326538, accuracy: 38.7 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 1.7218, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 1.4705, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 1.5813, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 1.5587, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 1.4975, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 1.6876, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 1.6876, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 1.6509, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 1.6544, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 1.6275, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 1.579392910003662, accuracy: 40.9 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 2.5498011112213135, accuracy: 25.2 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 1.5772888660430908, accuracy: 41.4 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 2.795957326889038, accuracy: 25.4 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 1.5776175260543823, accuracy: 40.6 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 1.5719482898712158, accuracy: 41.3 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 1.573818564414978, accuracy: 41.1 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 1.5742229223251343, accuracy: 40.9 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 1.7190115451812744, accuracy: 35.6 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 1.5688148736953735, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 1.6010, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 1.5343, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 1.5865, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 1.4584, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 1.7007, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 1.6157, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 1.5486, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 1.4914, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 1.6991, batch time: 0.05, accuracy:  30.47%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 1.6244, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 1.602384328842163, accuracy: 40.7 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 2.6820766925811768, accuracy: 27.2 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 1.5990550518035889, accuracy: 40.0 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 1.5958309173583984, accuracy: 41.4 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 1.599061369895935, accuracy: 41.6 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 1.5954598188400269, accuracy: 40.3 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 1.6082953214645386, accuracy: 42.2 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 1.6353154182434082, accuracy: 39.3 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 1.5900973081588745, accuracy: 40.3 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 1.5891337394714355, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 1.6096, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 1.7460, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 1.5411, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 1.5986, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 1.6121, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 1.5872, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 1.7388, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 1.5762, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 1.4295, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 1.5041, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 1.6211274862289429, accuracy: 39.7 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 1.9135618209838867, accuracy: 31.1 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 1.6054728031158447, accuracy: 39.5 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 1.6035553216934204, accuracy: 39.9 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 1.5988694429397583, accuracy: 39.9 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 1.7073187828063965, accuracy: 37.5 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 1.5938467979431152, accuracy: 39.1 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 1.5995521545410156, accuracy: 41.0 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 1.623060703277588, accuracy: 41.5 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 1.6250351667404175, accuracy: 38.8 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 1.7074, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 1.7489, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 1.6814, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 1.5954, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 1.8505, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 1.6389, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 1.6277, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 1.4584, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 1.7217, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 1.6814, batch time: 0.12, accuracy:  34.38%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 1.599625587463379, accuracy: 40.6 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 2.0852928161621094, accuracy: 29.2 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 1.5965365171432495, accuracy: 40.4 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 1.6438337564468384, accuracy: 41.6 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 1.5935508012771606, accuracy: 43.9 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 1.5891599655151367, accuracy: 41.9 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 1.6250642538070679, accuracy: 38.0 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 1.5881940126419067, accuracy: 42.6 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 1.5887994766235352, accuracy: 42.3 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 1.5877294540405273, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 1.5039, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 1.5198, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 1.5159, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 1.6548, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 1.6032, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 1.6202, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 1.5202, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 1.5332, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 1.5149, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 1.5693, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 1.5691882371902466, accuracy: 40.3 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 1.925648808479309, accuracy: 30.6 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 1.5691633224487305, accuracy: 40.3 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 2.147526264190674, accuracy: 31.3 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 1.567470908164978, accuracy: 40.1 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 1.6090656518936157, accuracy: 36.9 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 1.58208429813385, accuracy: 38.4 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 1.5654462575912476, accuracy: 38.8 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 1.5647978782653809, accuracy: 38.9 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 1.5645220279693604, accuracy: 39.1 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 1.7927, batch time: 0.11, accuracy:  35.16%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 1.5074, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 1.5132, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 1.5187, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 1.5691, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 1.7501, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 1.4688, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 1.6976, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 1.6256, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 1.5134, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 1.6097166538238525, accuracy: 39.9 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 2.1401283740997314, accuracy: 27.6 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 1.6499446630477905, accuracy: 37.3 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 1.7761476039886475, accuracy: 36.0 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 1.621372938156128, accuracy: 38.7 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 1.6043506860733032, accuracy: 41.3 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 1.6156963109970093, accuracy: 38.2 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 1.6000893115997314, accuracy: 40.5 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 1.5978176593780518, accuracy: 41.0 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 1.5969325304031372, accuracy: 40.7 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 1.4824, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 1.6825, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 1.5727, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 1.6901, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 1.6084, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 1.5419, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 1.5528, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 1.6432, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 1.4986, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 1.6206, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 1.5488568544387817, accuracy: 40.5 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 1.910010814666748, accuracy: 33.9 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 1.5488544702529907, accuracy: 40.5 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 2.1286096572875977, accuracy: 29.3 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 1.5515639781951904, accuracy: 41.6 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 1.5665802955627441, accuracy: 41.0 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 1.5661028623580933, accuracy: 38.6 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 1.566400170326233, accuracy: 39.4 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 1.5442637205123901, accuracy: 40.4 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 1.5801515579223633, accuracy: 38.9 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 1.6327, batch time: 0.12, accuracy:  34.38%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 1.5204, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 1.4801, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 1.5341, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 1.5084, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 1.6546, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 1.6040, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 1.5779, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 1.5113, batch time: 0.12, accuracy:  42.97%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 1.5029, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 1.5972692966461182, accuracy: 39.6 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 2.4651107788085938, accuracy: 24.7 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 1.6622685194015503, accuracy: 36.9 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 2.470672369003296, accuracy: 34.6 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 1.5980192422866821, accuracy: 39.9 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 1.591980218887329, accuracy: 40.1 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 1.5918148756027222, accuracy: 41.0 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 1.6335928440093994, accuracy: 39.5 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 1.65834641456604, accuracy: 39.4 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 1.5873756408691406, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 1.6847, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 1.4893, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 1.5093, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 1.6128, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 1.5872, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 1.6281, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 1.7398, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 1.5843, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 1.5479, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 1.5383, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 1.6284140348434448, accuracy: 39.0 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 3.002169609069824, accuracy: 25.0 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 1.5920969247817993, accuracy: 42.3 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 1.592052698135376, accuracy: 42.3 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 2.2192764282226562, accuracy: 28.4 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 1.5898936986923218, accuracy: 42.8 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 1.5840718746185303, accuracy: 41.1 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 1.5976639986038208, accuracy: 42.5 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 1.6058204174041748, accuracy: 40.5 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 1.5949501991271973, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 1.7072, batch time: 0.11, accuracy:  37.50%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 1.5619, batch time: 0.11, accuracy:  40.62%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 1.7400, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 1.6012, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 1.6642, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 1.5690, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 1.4644, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 1.6562, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 1.5264, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 1.7745, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 1.6169928312301636, accuracy: 38.9 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 2.4870121479034424, accuracy: 26.0 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 1.5926095247268677, accuracy: 39.9 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 2.125793933868408, accuracy: 30.6 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 1.61167573928833, accuracy: 39.1 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 1.6430206298828125, accuracy: 36.8 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 1.6101845502853394, accuracy: 39.0 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 1.5888370275497437, accuracy: 39.8 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 1.5819780826568604, accuracy: 39.8 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 1.5808228254318237, accuracy: 40.7 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 1.6111, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 1.7283, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 1.7151, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 1.5020, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 1.7714, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 1.6066, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 1.6951, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 1.6849, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 1.5426, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 1.6228, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 1.5642781257629395, accuracy: 39.3 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 2.812563419342041, accuracy: 25.2 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 1.5631520748138428, accuracy: 39.4 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 1.5631520748138428, accuracy: 39.4 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 1.651100993156433, accuracy: 37.8 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 1.5639690160751343, accuracy: 40.4 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 1.5745021104812622, accuracy: 40.1 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 1.5610682964324951, accuracy: 40.7 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 1.5540205240249634, accuracy: 40.7 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 1.5532828569412231, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 1.7338, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 1.6700, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 1.5962, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 1.6047, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 1.5746, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 1.4923, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 1.7624, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 1.6029, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 1.6741, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 1.3609, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 1.621203899383545, accuracy: 37.7 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 2.0660269260406494, accuracy: 31.0 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 1.616702675819397, accuracy: 38.0 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 1.9320881366729736, accuracy: 34.7 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 1.6225978136062622, accuracy: 38.1 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 1.6401787996292114, accuracy: 36.2 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 1.6281743049621582, accuracy: 36.3 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 1.6203162670135498, accuracy: 38.1 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 1.6129463911056519, accuracy: 37.6 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 1.605570673942566, accuracy: 37.9 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 1.3672, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 1.5812, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 1.5591, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 1.5989, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 1.6470, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 1.5612, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 1.6754, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 1.6818, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 1.5331, batch time: 0.06, accuracy:  41.41%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 1.6144, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 1.5486351251602173, accuracy: 39.9 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 2.0315470695495605, accuracy: 30.7 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 1.54827880859375, accuracy: 40.0 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 1.6094163656234741, accuracy: 37.3 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 1.5457830429077148, accuracy: 37.2 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 1.577651858329773, accuracy: 40.3 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 1.573391318321228, accuracy: 38.4 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 1.5370491743087769, accuracy: 40.1 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 1.536558985710144, accuracy: 40.9 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 1.5349866151809692, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 1.4197, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 1.6787, batch time: 0.11, accuracy:  35.16%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 1.6295, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 1.3604, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 1.3897, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 1.6096, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 1.5420, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 1.6219, batch time: 0.11, accuracy:  39.84%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 1.5860, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 1.6397, batch time: 0.11, accuracy:  39.06%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 1.5503779649734497, accuracy: 40.4 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 3.115642547607422, accuracy: 23.1 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 1.5449106693267822, accuracy: 40.0 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 1.539672613143921, accuracy: 41.2 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 1.9105429649353027, accuracy: 35.5 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 1.5432310104370117, accuracy: 40.1 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 1.5576393604278564, accuracy: 39.8 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 1.5393543243408203, accuracy: 42.0 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 1.526901125907898, accuracy: 41.1 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 1.5266411304473877, accuracy: 40.8 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 1.5430, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 1.3844, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 1.5852, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 1.4994, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 1.6177, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 1.6384, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 1.6103, batch time: 0.11, accuracy:  42.97%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 1.6887, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 1.5726, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 1.4436, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 1.5976120233535767, accuracy: 40.3 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 2.279919147491455, accuracy: 31.2 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 1.5944440364837646, accuracy: 40.6 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 1.869102120399475, accuracy: 34.3 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 1.590482234954834, accuracy: 39.8 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 1.6235038042068481, accuracy: 38.6 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 1.5872740745544434, accuracy: 41.9 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 1.583335041999817, accuracy: 41.2 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 1.580419659614563, accuracy: 39.7 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 1.581336498260498, accuracy: 39.6 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 1.4146, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 1.5502, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 1.6393, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 1.6089, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 1.5072, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 1.4745, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 1.6471, batch time: 0.05, accuracy:  30.47%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 1.5003, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 1.6216, batch time: 0.04, accuracy:  31.25%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 1.6497, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 1.583491563796997, accuracy: 36.8 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 2.462562084197998, accuracy: 25.8 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 1.5809590816497803, accuracy: 37.0 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 1.9398754835128784, accuracy: 36.6 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 1.577406406402588, accuracy: 38.7 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 1.6397266387939453, accuracy: 38.4 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 1.577120065689087, accuracy: 39.0 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 1.6128755807876587, accuracy: 38.6 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 1.579204797744751, accuracy: 38.2 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 1.5788196325302124, accuracy: 38.1 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 1.5286, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 1.4904, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 1.5881, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 1.3888, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 1.5176, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 1.5107, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 1.5188, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 1.4625, batch time: 0.13, accuracy:  35.94%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 1.5029, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 1.8284, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 1.4948737621307373, accuracy: 41.2 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 2.1516683101654053, accuracy: 32.3 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 1.493711233139038, accuracy: 41.9 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 3.9969303607940674, accuracy: 27.2 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 1.4921931028366089, accuracy: 45.3 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 1.4902231693267822, accuracy: 44.3 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 1.5640746355056763, accuracy: 42.3 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 1.4913134574890137, accuracy: 43.8 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 1.4834078550338745, accuracy: 45.0 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 1.4829673767089844, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 1.4676, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 1.5429, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 1.5989, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 1.5430, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 1.5111, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 1.5812, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 1.4844, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 1.4518, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 1.4799, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 1.6122, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 1.5536377429962158, accuracy: 41.2 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 2.487112522125244, accuracy: 23.4 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 1.5517101287841797, accuracy: 40.2 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 1.5517101287841797, accuracy: 40.2 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 1.550693154335022, accuracy: 41.8 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 1.5915868282318115, accuracy: 38.5 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 1.5496708154678345, accuracy: 42.0 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 1.548321008682251, accuracy: 40.6 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 1.5476093292236328, accuracy: 41.3 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 1.5450139045715332, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 1.5736, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 1.6038, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 1.5482, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 1.5592, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 1.6748, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 1.4701, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 1.6431, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 1.5129, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 1.5099, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 1.5537, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 1.550355076789856, accuracy: 41.5 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 1.9491209983825684, accuracy: 30.8 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 3.4793896675109863, accuracy: 23.1 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 1.8642107248306274, accuracy: 38.2 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 1.5782091617584229, accuracy: 39.7 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 1.5426751375198364, accuracy: 43.9 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 1.537451982498169, accuracy: 42.1 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 1.5384725332260132, accuracy: 41.1 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 1.5340385437011719, accuracy: 41.8 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 1.5326875448226929, accuracy: 41.9 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 1.5244, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 1.4685, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 1.5509, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 1.4710, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 1.3981, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 1.5557, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 1.4786, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 1.5765, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 1.4976, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 1.5631, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 1.5625014305114746, accuracy: 40.2 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 2.11225962638855, accuracy: 26.1 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 3.278250217437744, accuracy: 22.9 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 1.9980134963989258, accuracy: 25.7 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 1.5695692300796509, accuracy: 39.7 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 1.5745611190795898, accuracy: 38.0 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 1.5655714273452759, accuracy: 40.8 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 1.5611032247543335, accuracy: 41.0 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 1.5634160041809082, accuracy: 40.3 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 1.5795012712478638, accuracy: 39.3 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 1.5157, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 1.4944, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 1.5338, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 1.5778, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 1.5847, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 1.4787, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 1.3869, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 1.5247, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 1.5250, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 1.5460, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 1.532516360282898, accuracy: 44.3 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 2.262632369995117, accuracy: 32.0 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 1.5289875268936157, accuracy: 42.7 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 2.5150625705718994, accuracy: 31.1 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 1.5361266136169434, accuracy: 42.2 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 1.5806201696395874, accuracy: 42.8 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 1.5293991565704346, accuracy: 43.0 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 1.5277210474014282, accuracy: 43.6 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 1.5308773517608643, accuracy: 42.6 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 1.5295490026474, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 1.5384, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 1.4945, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 1.7850, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 1.4643, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 1.6289, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 1.5350, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 1.3930, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 1.4506, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 1.5657, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 1.4392, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 1.5316649675369263, accuracy: 43.9 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 1.9708657264709473, accuracy: 32.1 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 3.320551872253418, accuracy: 23.3 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 1.9952362775802612, accuracy: 30.4 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 1.5856446027755737, accuracy: 42.7 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 1.5434279441833496, accuracy: 43.8 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 1.5262253284454346, accuracy: 43.6 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 1.5262054204940796, accuracy: 43.8 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 1.5258285999298096, accuracy: 43.2 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 1.5268806219100952, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 1.5521, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 1.5320, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 1.4988, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 1.5094, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 1.5990, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 1.4502, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 1.4369, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 1.6167, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 1.5506, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 1.4824, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 1.5534619092941284, accuracy: 41.6 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 2.061434268951416, accuracy: 29.2 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 3.2185685634613037, accuracy: 23.5 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 5.873450756072998, accuracy: 21.0 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 1.5565394163131714, accuracy: 42.2 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 1.5613715648651123, accuracy: 41.8 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 1.5537232160568237, accuracy: 42.1 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 1.5560894012451172, accuracy: 40.6 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 1.5651482343673706, accuracy: 42.5 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 1.5511219501495361, accuracy: 42.4 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 1.5849, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 1.4927, batch time: 0.11, accuracy:  39.06%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 1.6165, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 1.5269, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 1.7731, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 1.3906, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 1.5494, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 1.5211, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 1.4653, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 1.6531, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 1.5635367631912231, accuracy: 41.4 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 2.0753579139709473, accuracy: 29.6 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 1.6813408136367798, accuracy: 32.6 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 2.550729513168335, accuracy: 26.0 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 1.586572289466858, accuracy: 39.8 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 1.5898137092590332, accuracy: 41.2 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 1.5821588039398193, accuracy: 39.2 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 1.5558375120162964, accuracy: 41.1 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 1.556718111038208, accuracy: 43.5 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 1.8991761207580566, accuracy: 41.6 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 1.6415, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 1.4839, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 1.6564, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 1.6437, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 1.3638, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 1.4499, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 1.4420, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 1.5135, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 1.5642, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 1.6987, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 1.5674638748168945, accuracy: 42.9 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 2.22602915763855, accuracy: 28.5 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 1.565887451171875, accuracy: 41.0 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 1.574607491493225, accuracy: 39.5 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 1.5798827409744263, accuracy: 41.0 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 1.5859227180480957, accuracy: 41.7 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 1.622248888015747, accuracy: 40.3 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 1.6205077171325684, accuracy: 41.0 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 1.5732321739196777, accuracy: 42.2 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 1.5825819969177246, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 1.5094, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 1.5846, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 1.3906, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 1.4951, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 1.4013, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 1.6626, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 1.5240, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 1.4380, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 1.5500, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 1.5566, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 1.5241798162460327, accuracy: 46.6 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 1.5369194746017456, accuracy: 45.3 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 1.9482598304748535, accuracy: 31.6 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 3.789482831954956, accuracy: 21.7 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 1.5978715419769287, accuracy: 42.3 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 1.6258405447006226, accuracy: 38.2 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 1.5206612348556519, accuracy: 46.7 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 1.5201892852783203, accuracy: 45.8 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 1.5183109045028687, accuracy: 46.4 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 1.5195132493972778, accuracy: 47.2 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 1.5668, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 1.4778, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 1.5561, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 1.6765, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 1.5458, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 1.4138, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 1.4187, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 1.4138, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 1.5338, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 1.3624, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 1.479212760925293, accuracy: 46.2 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 1.9111469984054565, accuracy: 32.3 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 1.7198117971420288, accuracy: 34.4 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 2.308168411254883, accuracy: 27.9 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 1.4777475595474243, accuracy: 46.2 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 1.4766931533813477, accuracy: 45.1 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 1.4798698425292969, accuracy: 46.2 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 1.4771227836608887, accuracy: 46.6 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 1.4790925979614258, accuracy: 44.8 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 1.4721208810806274, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 1.5874, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 1.6060, batch time: 0.12, accuracy:  32.03%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 1.4613, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 1.5085, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 1.7197, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 1.5428, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 1.5311, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 1.4973, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 1.4207, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 1.5819, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 1.5198575258255005, accuracy: 44.5 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.5317728519439697, accuracy: 45.2 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 3.644379138946533, accuracy: 22.3 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 2.0942223072052, accuracy: 29.7 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 1.5196659564971924, accuracy: 45.5 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 1.5477033853530884, accuracy: 45.5 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 1.5207762718200684, accuracy: 45.2 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 1.5164802074432373, accuracy: 45.4 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 1.5161727666854858, accuracy: 46.4 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 1.5229142904281616, accuracy: 43.7 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 1.4645, batch time: 0.06, accuracy:  50.78%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 1.3441, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 1.7828, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 1.3500, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 1.4916, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 1.4461, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 1.3631, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 1.5874, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 1.6122, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 1.4827, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 1.4673725366592407, accuracy: 46.4 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 1.4913840293884277, accuracy: 46.8 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 1.7129831314086914, accuracy: 36.5 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 1.8462185859680176, accuracy: 35.5 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 1.4788322448730469, accuracy: 44.0 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 1.4840482473373413, accuracy: 45.0 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 1.4591028690338135, accuracy: 47.8 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 1.4595283269882202, accuracy: 47.1 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 1.4584457874298096, accuracy: 46.5 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 1.4566469192504883, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 1.4731, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 1.6837, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 1.7053, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 1.4456, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 1.7374, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 1.7578, batch time: 0.06, accuracy:  42.97%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 1.4763, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 1.7192, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 1.5969, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 1.6025, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 1.533934235572815, accuracy: 43.4 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 1.5392472743988037, accuracy: 43.6 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 1.6952614784240723, accuracy: 35.3 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 1.6908811330795288, accuracy: 40.4 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 1.6143383979797363, accuracy: 39.4 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 1.6436156034469604, accuracy: 39.2 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 1.531591773033142, accuracy: 42.6 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 1.5291986465454102, accuracy: 43.5 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 1.5279920101165771, accuracy: 43.3 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 1.52726411819458, accuracy: 42.8 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 1.6186, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 1.4701, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 1.5406, batch time: 0.12, accuracy:  49.22%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 1.5956, batch time: 0.11, accuracy:  40.62%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 1.5808, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 1.4240, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 1.5575, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 1.5052, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 1.6682, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 1.5001, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 1.4692020416259766, accuracy: 44.9 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 1.480509877204895, accuracy: 44.1 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 1.6744426488876343, accuracy: 35.5 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 5.054831027984619, accuracy: 18.3 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 1.4687414169311523, accuracy: 44.7 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 1.4772645235061646, accuracy: 45.6 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 1.5438697338104248, accuracy: 43.2 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 1.464839220046997, accuracy: 45.1 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 1.4624627828598022, accuracy: 45.5 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 1.4626027345657349, accuracy: 46.5 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 1.5620, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 1.5454, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 1.4970, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 1.4666, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 1.3522, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 1.6179, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 1.5120, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 1.4275, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 1.6132, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 1.4821, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 1.5303022861480713, accuracy: 44.5 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 2.629267930984497, accuracy: 26.4 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 1.527565598487854, accuracy: 45.1 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 1.8996896743774414, accuracy: 43.0 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 1.5463402271270752, accuracy: 43.8 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 1.5430086851119995, accuracy: 42.2 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 1.597809910774231, accuracy: 40.6 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 1.520359992980957, accuracy: 44.1 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 1.5223989486694336, accuracy: 45.4 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 1.5213137865066528, accuracy: 44.6 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 1.5275, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 1.4446, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 1.5806, batch time: 0.11, accuracy:  40.62%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 1.5756, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 1.4904, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 1.6478, batch time: 0.11, accuracy:  41.41%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 1.4678, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 1.5246, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 1.3585, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 1.5831, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 1.4950065612792969, accuracy: 44.9 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 2.6725029945373535, accuracy: 26.9 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 1.468343734741211, accuracy: 45.5 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 1.468343734741211, accuracy: 45.5 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 1.5312659740447998, accuracy: 41.6 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 1.46719491481781, accuracy: 46.0 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 1.5152894258499146, accuracy: 43.5 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 1.46687912940979, accuracy: 46.3 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 1.4720715284347534, accuracy: 47.0 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 1.463212251663208, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 1.6265, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 1.8536, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 1.5647, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 1.5112, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 1.5456, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 1.5694, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 1.3650, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 1.6510, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 1.5175, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 1.4796, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 1.4968832731246948, accuracy: 45.4 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 2.1649417877197266, accuracy: 30.5 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 3.5273587703704834, accuracy: 24.9 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 2.2116174697875977, accuracy: 29.1 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 1.4873106479644775, accuracy: 45.3 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 1.8167824745178223, accuracy: 36.1 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 1.51666259765625, accuracy: 44.8 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 1.591949701309204, accuracy: 42.3 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 1.4746075868606567, accuracy: 46.6 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 1.473612666130066, accuracy: 46.3 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 1.4047, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 1.6156, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 1.4870, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 1.6977, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 1.5245, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 1.5224, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 1.4577, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 1.5914, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 1.4914, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 1.4699, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 1.5364960432052612, accuracy: 43.3 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 2.215916395187378, accuracy: 26.8 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 3.0352351665496826, accuracy: 21.7 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 5.595036506652832, accuracy: 23.0 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 1.535553216934204, accuracy: 43.0 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 1.5545217990875244, accuracy: 42.0 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 1.5321974754333496, accuracy: 43.3 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 1.5317655801773071, accuracy: 43.2 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 1.530508041381836, accuracy: 43.3 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 1.5318502187728882, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 1.5805, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 1.5265, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 1.4735, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 1.2982, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 1.5505, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 1.4952, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 1.4246, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 1.6535, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 1.5316, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 1.7609, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 1.514532208442688, accuracy: 46.3 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 2.408237934112549, accuracy: 29.4 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 1.5063902139663696, accuracy: 46.2 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 2.1730639934539795, accuracy: 30.5 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 1.532931923866272, accuracy: 44.8 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 1.5238806009292603, accuracy: 45.6 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 1.5011638402938843, accuracy: 46.9 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 1.5004005432128906, accuracy: 46.5 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 1.5003998279571533, accuracy: 47.0 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 1.504692554473877, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 1.5333, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 1.6201, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 1.3876, batch time: 0.12, accuracy:  51.56%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 1.4841, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 1.4951, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 1.7478, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 1.5985, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 1.5600, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 1.6695, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 1.6418, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 1.499066948890686, accuracy: 44.2 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 2.609215021133423, accuracy: 27.9 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 1.493335485458374, accuracy: 44.2 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 5.2171430587768555, accuracy: 21.7 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 1.4954414367675781, accuracy: 44.2 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 1.4891711473464966, accuracy: 43.6 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 1.5078696012496948, accuracy: 44.3 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 1.4960883855819702, accuracy: 46.1 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 1.4921185970306396, accuracy: 42.8 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 1.4891841411590576, accuracy: 42.4 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 1.4557, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 1.5012, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 1.6007, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 1.5117, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 1.5491, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 1.5011, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 1.4595, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 1.5210, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 1.7171, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 1.6412, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 1.570509672164917, accuracy: 43.5 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 1.5978776216506958, accuracy: 42.2 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 3.4003429412841797, accuracy: 24.1 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 1.8211619853973389, accuracy: 33.3 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 1.5721217393875122, accuracy: 42.0 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 1.5542532205581665, accuracy: 43.4 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 1.5563762187957764, accuracy: 44.1 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 1.5537360906600952, accuracy: 43.5 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 1.5538020133972168, accuracy: 44.1 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 1.552655816078186, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 1.6105, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 1.4784, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 1.4116, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 1.3872, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 1.3651, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 1.6465, batch time: 0.11, accuracy:  36.72%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 1.4862, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 1.5180, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 1.4231, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 1.5220, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 1.511666178703308, accuracy: 45.7 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 1.5300555229187012, accuracy: 45.7 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 3.4337549209594727, accuracy: 22.1 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 2.3381454944610596, accuracy: 30.8 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 1.5304158926010132, accuracy: 45.9 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 1.649071455001831, accuracy: 38.4 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 1.505765438079834, accuracy: 46.6 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 1.5051435232162476, accuracy: 46.2 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 1.507859706878662, accuracy: 45.3 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 1.5043662786483765, accuracy: 46.9 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 1.4211, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 1.4676, batch time: 0.06, accuracy:  47.66%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 1.4399, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 1.5553, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 1.5842, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 1.6092, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 1.4876, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 1.4192, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 1.4284, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 1.5408, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 1.5505367517471313, accuracy: 44.2 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 1.5643858909606934, accuracy: 43.2 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 3.4901180267333984, accuracy: 22.3 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 1.8032580614089966, accuracy: 35.5 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 1.6274724006652832, accuracy: 41.6 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 1.5458271503448486, accuracy: 43.6 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 1.538672924041748, accuracy: 44.2 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 1.5370829105377197, accuracy: 45.1 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 1.5395901203155518, accuracy: 45.5 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 1.5373107194900513, accuracy: 44.6 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 47.05%\n",
      "Loss on the train set: 1.50\n",
      "Accuracy on the test set: 43.50%\n",
      "Loss on the test set: 1.54\n",
      "Generalization error: 0.04396963\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
