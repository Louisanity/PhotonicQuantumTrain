{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.375923</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.823125</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.316813</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.657845</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.465098</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.869602</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.239578</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.438663</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.684887</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.505926</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.48843</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.229432</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.483618</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.916624</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.638595</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.113534</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.332709</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.463559</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.493155</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.864112</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.73798</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.844466</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.750669</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.742494</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.596835</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.55682</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.426626</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.252183</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.994069</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.665289</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.613062</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.339384</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.98246</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.606607</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.361591</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=13*sqrt(3)/27</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.24952</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.045858</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.663612</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.31711</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.550054</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.383171</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.227262</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.746309</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.74801</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.064652</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.202452</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.008065</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.949791</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.969748</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.187833</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.400681</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.021128</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.326282</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.442972</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.814768</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.822213</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.684269</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.879872</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.557013</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.314936</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.007785</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.58101</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.772583</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.858277</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.534776</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.342443</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.357174</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.747215</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.996354</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.328817</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.899875</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.215481</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.359951</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.394166</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.941697</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.508764</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.933274</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.999502</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.588932</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.087397</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.451144</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.947204</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.093182</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.513656</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.999186</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.191162</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.069831</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.125952</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.148181</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.243453</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.753249</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.280193</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.648681</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.357986</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.608987</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7626eef06400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.133584</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.571727</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.35351</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.929829</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.571274</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.777647</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.005415</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.419622</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.702351</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.734117</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.567135</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.404142</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.538947</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.072716</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.974436</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.307604</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.945063</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.144484</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.375883</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.965789</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.971776</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.480119</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.281633</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.104601</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.68071</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.331892</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.913644</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.98758</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.058172</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.53905</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.082771</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.003515</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.331856</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.467337</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.578348</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.498759</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.943064</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.561086</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.085808</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.853752</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.312653</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.487968</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.900413</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.657358</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.935466</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.06724</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.489031</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.587284</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.698725</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.92848</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.945592</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.064247</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.415362</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.597786</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.663888</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.692331</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.973392</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.052827</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.284462</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.830956</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.540854</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.230934</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.712907</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.475009</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.587608</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.43674</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.154262</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.319712</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.870982</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.998593</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.259498</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.102488</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.972632</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.946619</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.688816</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7626eee997c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 79.00%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=8)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  1984\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  2176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2763, batch time: 0.15, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.0169, batch time: 0.10, accuracy:  20.31%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 1.8650, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.9022, batch time: 0.05, accuracy:  28.91%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.4758, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.6684, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.4145, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.1993, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 0.9904, batch time: 0.11, accuracy:  70.31%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 0.9655, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 0.889579176902771, accuracy: 71.2 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 2.6720168590545654, accuracy: 39.8 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 0.8747097253799438, accuracy: 70.8 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.2582876682281494, accuracy: 59.1 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 0.9447258114814758, accuracy: 69.1 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.0283981561660767, accuracy: 63.1 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 0.8615178465843201, accuracy: 72.7 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 0.8623693585395813, accuracy: 72.4 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 0.8528354167938232, accuracy: 71.6 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 0.858849287033081, accuracy: 71.5 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 0.9837, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 0.7603, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.8245, batch time: 0.05, accuracy:  74.22%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.6807, batch time: 0.05, accuracy:  75.78%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.7526, batch time: 0.11, accuracy:  80.47%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.6523, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.6997, batch time: 0.09, accuracy:  77.34%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.6676, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.4189, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.9726, batch time: 0.10, accuracy:  77.34%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.6278984546661377, accuracy: 80.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.6270063519477844, accuracy: 81.5 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.609063982963562, accuracy: 81.2 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.6087407469749451, accuracy: 81.3 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 1.0778529644012451, accuracy: 65.8 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.5884011387825012, accuracy: 81.9 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.5885474681854248, accuracy: 82.2 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.5737073421478271, accuracy: 82.2 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.5740405917167664, accuracy: 82.0 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.56641685962677, accuracy: 82.8 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.6704, batch time: 0.05, accuracy:  76.56%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.5728, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.5181, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.6287, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.3718, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.4681, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.4635, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.5192, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.4993, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.4857, batch time: 0.04, accuracy:  85.16%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.43231654167175293, accuracy: 86.8 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 0.44626277685165405, accuracy: 86.2 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.4790601432323456, accuracy: 86.1 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.42582473158836365, accuracy: 87.2 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.48201996088027954, accuracy: 84.3 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.41076764464378357, accuracy: 87.8 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.41076672077178955, accuracy: 87.3 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.4023674726486206, accuracy: 87.6 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.3983556032180786, accuracy: 88.5 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.3978308439254761, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.5617, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.4815, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.2981, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.4400, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.5426, batch time: 0.10, accuracy:  78.91%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.4319, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.4539, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.4731, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.4670, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.4688, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.432997465133667, accuracy: 85.5 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 0.43830129504203796, accuracy: 85.0 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.510287344455719, accuracy: 83.8 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.42087310552597046, accuracy: 85.7 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.49009236693382263, accuracy: 83.9 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.4890143573284149, accuracy: 85.3 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.40333735942840576, accuracy: 86.7 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.39867347478866577, accuracy: 87.2 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.3992007076740265, accuracy: 87.1 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.3931370973587036, accuracy: 87.4 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.4175, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.5164, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.3463, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.4670, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.4033, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.4729, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.3124, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.3733, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.3469, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.2586, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.41619759798049927, accuracy: 86.2 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 0.4162694215774536, accuracy: 86.1 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.39137908816337585, accuracy: 87.0 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.3823234736919403, accuracy: 87.7 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.6142259836196899, accuracy: 80.0 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.4289730489253998, accuracy: 85.8 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.39531049132347107, accuracy: 87.7 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.4531124234199524, accuracy: 86.0 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.4047812819480896, accuracy: 86.9 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.3454197347164154, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.4724, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.2892, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.3702, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.3671, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.2792, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.3319, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.1877, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.3214, batch time: 0.06, accuracy:  91.41%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.2600, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.3072, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.3270338177680969, accuracy: 90.0 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.3275165855884552, accuracy: 90.4 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.32559022307395935, accuracy: 89.9 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.31848496198654175, accuracy: 90.4 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.5646516680717468, accuracy: 81.3 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.34072574973106384, accuracy: 89.3 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.4271009862422943, accuracy: 85.3 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.317301869392395, accuracy: 90.3 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.3094644248485565, accuracy: 90.7 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.30648353695869446, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.5265, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.2176, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.2760, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.3306, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.3106, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.2847, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.3971, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.3508, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3554, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.2896, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.33460989594459534, accuracy: 89.8 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.33375799655914307, accuracy: 90.0 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.3162543773651123, accuracy: 90.6 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.3133508265018463, accuracy: 91.0 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.34625953435897827, accuracy: 90.2 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.3325575292110443, accuracy: 90.4 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.29574054479599, accuracy: 91.4 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.29518014192581177, accuracy: 91.6 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.2946881353855133, accuracy: 91.5 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.28948795795440674, accuracy: 92.0 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.4525, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.3253, batch time: 0.04, accuracy:  86.72%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.2120, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.3782, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.2943, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.2309, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.2722, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.2220, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.2350, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2332, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.3103483021259308, accuracy: 90.6 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.32822656631469727, accuracy: 90.8 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.32117849588394165, accuracy: 89.7 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.3060113191604614, accuracy: 91.2 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.3923538327217102, accuracy: 87.1 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.27147868275642395, accuracy: 92.0 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.273164838552475, accuracy: 91.6 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.25545400381088257, accuracy: 92.3 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.25602445006370544, accuracy: 92.4 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.2512657940387726, accuracy: 92.7 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.2505, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.1906, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.2086, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.3338, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.3116, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.2071, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.2216, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.2481, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.2048, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.1688, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.2741091549396515, accuracy: 91.5 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.38699430227279663, accuracy: 88.1 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.2674696445465088, accuracy: 91.8 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.41649243235588074, accuracy: 87.0 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.25645455718040466, accuracy: 92.2 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.2549590766429901, accuracy: 92.1 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.254410058259964, accuracy: 92.1 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.25916844606399536, accuracy: 91.4 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.2521129250526428, accuracy: 91.7 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.2570929527282715, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.3940, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.3183, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.1895, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.5344, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.2916, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.2601, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.2198, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.1657, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.1696, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.1994, batch time: 0.17, accuracy:  92.19%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.2229420691728592, accuracy: 92.7 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.23934818804264069, accuracy: 92.4 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.2689545750617981, accuracy: 89.7 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.21256105601787567, accuracy: 93.0 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.2977619767189026, accuracy: 89.0 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.20479518175125122, accuracy: 93.7 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.20781749486923218, accuracy: 93.5 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.20109035074710846, accuracy: 93.1 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.201884925365448, accuracy: 93.4 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.19704687595367432, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.2377, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.2795, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.2257, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.4111, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.3699, batch time: 0.05, accuracy:  84.38%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.3234, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.2681, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.2498, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.2415, batch time: 0.07, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.1482, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.2759476602077484, accuracy: 92.4 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.27072426676750183, accuracy: 91.9 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.27070939540863037, accuracy: 91.9 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.2643408179283142, accuracy: 91.6 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.2828467786312103, accuracy: 91.6 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.2616282105445862, accuracy: 92.3 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.2529565095901489, accuracy: 92.7 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.24668274819850922, accuracy: 92.3 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.2490658462047577, accuracy: 92.5 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.24130208790302277, accuracy: 92.4 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.2564, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.3088, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.3247, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.4446, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.1645, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.3001, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.3728, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.3751, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.1384, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.3940, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.2430717647075653, accuracy: 92.6 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.30510303378105164, accuracy: 90.5 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.2363945096731186, accuracy: 92.1 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.39909064769744873, accuracy: 87.1 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.22665269672870636, accuracy: 92.8 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.217091366648674, accuracy: 93.4 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.217325821518898, accuracy: 93.4 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.21561911702156067, accuracy: 93.0 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.21361514925956726, accuracy: 93.4 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.2074422538280487, accuracy: 93.1 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.3207, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2535, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.2516, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.2821, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.3123, batch time: 0.07, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.1496, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.2754, batch time: 0.07, accuracy:  92.19%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.2084, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.3101, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.1652, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.22317016124725342, accuracy: 92.6 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.2458081692457199, accuracy: 92.4 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.22103168070316315, accuracy: 92.9 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.20977838337421417, accuracy: 93.6 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.5722537040710449, accuracy: 83.6 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.1969970166683197, accuracy: 93.6 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.2599954903125763, accuracy: 90.3 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.18945975601673126, accuracy: 93.8 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.19463683664798737, accuracy: 93.5 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.1956881880760193, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.2329, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.1689, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.2641, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.2924, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.3069, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.4098, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.1375, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.2838, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.1434, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.1564, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.19394972920417786, accuracy: 94.2 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.20634841918945312, accuracy: 93.7 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.20597650110721588, accuracy: 94.5 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.18559595942497253, accuracy: 95.2 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.18812188506126404, accuracy: 94.9 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.28147339820861816, accuracy: 90.3 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.2287977635860443, accuracy: 93.6 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.1740902066230774, accuracy: 95.3 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.17199450731277466, accuracy: 95.1 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.1725487858057022, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.2418, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.3532, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.2868, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.1974, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.3787, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.2630, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.1768, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.2352, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.3996, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.1585, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.28307104110717773, accuracy: 90.8 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.31233134865760803, accuracy: 90.0 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.2882477939128876, accuracy: 90.6 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.2619730830192566, accuracy: 91.6 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.27917182445526123, accuracy: 91.0 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.24219484627246857, accuracy: 92.1 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.2411380261182785, accuracy: 91.8 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.2299298793077469, accuracy: 92.4 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.2281503826379776, accuracy: 92.4 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.2266107201576233, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.2341, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.2213, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.3256, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.2353, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.2297, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.2766, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.3022, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.3716, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.4557, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.2161, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.21399149298667908, accuracy: 93.9 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.24433451890945435, accuracy: 92.8 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.2994444966316223, accuracy: 90.8 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.8152279257774353, accuracy: 84.5 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.19841551780700684, accuracy: 94.9 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.19365085661411285, accuracy: 95.0 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.19316335022449493, accuracy: 94.7 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.1900000274181366, accuracy: 95.2 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.18985360860824585, accuracy: 95.3 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.1970261037349701, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.1878, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.3784, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.2449, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.3642, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.2081, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.2994, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.1572, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.2659, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.1350, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.2651, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.2344682216644287, accuracy: 92.9 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.2336043417453766, accuracy: 92.4 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.24039751291275024, accuracy: 92.7 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.21703003346920013, accuracy: 93.1 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.31203988194465637, accuracy: 88.9 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.20764745771884918, accuracy: 93.8 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.20699429512023926, accuracy: 93.4 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.20365580916404724, accuracy: 94.1 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.20558032393455505, accuracy: 93.9 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.2008875012397766, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.3363, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.2250, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.1028, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.1784, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.2197, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.2373, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.1818, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.2133, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.1912, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.2135, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.17147038877010345, accuracy: 94.7 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.205747589468956, accuracy: 94.1 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.16997715830802917, accuracy: 94.4 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.17399488389492035, accuracy: 94.2 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.2036653459072113, accuracy: 93.4 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.1611730456352234, accuracy: 95.1 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.1630610078573227, accuracy: 94.4 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.17302893102169037, accuracy: 94.6 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.15536503493785858, accuracy: 95.2 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.20717798173427582, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.2649, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.1447, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.2020, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.2061, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.1835, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.1962, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.1610, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.2102, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.1479, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.2719, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.2437431514263153, accuracy: 92.8 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.36779332160949707, accuracy: 88.6 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.29360032081604004, accuracy: 90.6 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.20669971406459808, accuracy: 93.0 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.27659833431243896, accuracy: 90.5 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.9805996417999268, accuracy: 72.8 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.21555127203464508, accuracy: 92.7 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.1988985538482666, accuracy: 93.9 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.19650015234947205, accuracy: 93.8 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.19529280066490173, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.1286, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.1407, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.1428, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.2419, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.2024, batch time: 0.29, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.1705, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.2729, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.3340, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.1648, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.1518, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.17723439633846283, accuracy: 94.4 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.18365901708602905, accuracy: 94.3 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.2436528354883194, accuracy: 91.6 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.17446184158325195, accuracy: 94.2 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.1837359219789505, accuracy: 94.4 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.21732448041439056, accuracy: 92.8 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.16938921809196472, accuracy: 94.4 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.16762763261795044, accuracy: 94.8 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.16517354547977448, accuracy: 94.7 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.16752497851848602, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.2089, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.2926, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.2542, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.3684, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.2667, batch time: 0.08, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.2958, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.1858, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.2730, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.2292, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.3838, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.19128040969371796, accuracy: 93.6 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 1.6233783960342407, accuracy: 60.2 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.17716985940933228, accuracy: 93.9 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.1735389679670334, accuracy: 94.6 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.2301303595304489, accuracy: 92.6 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.18180111050605774, accuracy: 93.8 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.16765668988227844, accuracy: 94.2 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.17075876891613007, accuracy: 94.4 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.22619900107383728, accuracy: 92.8 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.3152098059654236, accuracy: 89.8 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.4998, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.2358, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.1534, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.1386, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.1619, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.2598, batch time: 0.08, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.1611, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.1848, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.1759, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.1936, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.15371859073638916, accuracy: 95.3 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.16240765154361725, accuracy: 94.5 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.15278910100460052, accuracy: 95.2 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.15019600093364716, accuracy: 95.1 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.1489296853542328, accuracy: 95.4 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.15661072731018066, accuracy: 95.3 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.17320312559604645, accuracy: 93.9 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.14984825253486633, accuracy: 95.2 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.1384381800889969, accuracy: 96.1 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.13741673529148102, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.1169, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.2239, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.1847, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.2079, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.1176, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.1131, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.2416, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.2527, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.1392, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.1445, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.1548389047384262, accuracy: 95.6 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 2.8086769580841064, accuracy: 53.3 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.15185773372650146, accuracy: 95.7 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.15109694004058838, accuracy: 95.9 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.37687554955482483, accuracy: 88.0 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.14962513744831085, accuracy: 95.9 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.15253782272338867, accuracy: 95.6 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.14813412725925446, accuracy: 95.8 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.14604757726192474, accuracy: 95.7 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.14561231434345245, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.1774, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.2099, batch time: 0.04, accuracy:  92.19%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.1506, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.2002, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.2846, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1472, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.2560, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.1177, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.1941, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.1098, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.15739907324314117, accuracy: 95.0 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.1736937165260315, accuracy: 94.8 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.16893191635608673, accuracy: 94.7 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.30886200070381165, accuracy: 90.2 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.14670605957508087, accuracy: 95.8 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.14327868819236755, accuracy: 95.7 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.1412832885980606, accuracy: 95.8 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.14061231911182404, accuracy: 95.8 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.14361943304538727, accuracy: 95.6 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.1388498842716217, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.1978, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.1471, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.1976, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.2162, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.1655, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.3256, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.2162, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.2188, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.1385, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.1671, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.15382170677185059, accuracy: 95.7 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.22200198471546173, accuracy: 93.2 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.1410549134016037, accuracy: 95.1 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.1396505981683731, accuracy: 95.7 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.1508924514055252, accuracy: 95.5 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.13502393662929535, accuracy: 95.7 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.1345759481191635, accuracy: 96.1 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.13068625330924988, accuracy: 96.3 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.13056379556655884, accuracy: 96.3 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.12846994400024414, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.2550, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.1942, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.1481, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.2332, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.1797, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.2502, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.1139, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.1252, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.0900, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.1849, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.16901297867298126, accuracy: 94.4 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 4.711574077606201, accuracy: 42.3 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 10.13670539855957, accuracy: 26.8 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.2189730405807495, accuracy: 93.6 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.16241352260112762, accuracy: 94.6 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.22897650301456451, accuracy: 93.5 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.20378541946411133, accuracy: 93.9 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 4.2389960289001465, accuracy: 47.7 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.14051933586597443, accuracy: 95.4 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.1373007446527481, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.2491, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.1261, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.2134, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.0627, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.0549, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.3319, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.1636, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.2158, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.1621, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.1384, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.1384943425655365, accuracy: 95.9 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.14493447542190552, accuracy: 95.7 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.13565759360790253, accuracy: 95.9 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.1328701376914978, accuracy: 96.0 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.35638320446014404, accuracy: 90.2 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.12013933062553406, accuracy: 96.5 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.12277502566576004, accuracy: 96.0 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.11274012178182602, accuracy: 96.3 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.1134004220366478, accuracy: 96.5 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.11451844871044159, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.1756, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.1177, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.1734, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.1768, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.1440, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.1695, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.2819, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.1600, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.1742, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.1817, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.16725224256515503, accuracy: 95.1 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 8.00590705871582, accuracy: 35.9 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.1591254323720932, accuracy: 95.0 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.15803644061088562, accuracy: 94.9 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.28378450870513916, accuracy: 91.8 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.14832057058811188, accuracy: 95.4 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.14501743018627167, accuracy: 95.4 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.14420589804649353, accuracy: 95.4 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.1489405632019043, accuracy: 95.3 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.14457876980304718, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.1860, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.2221, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.1599, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.2410, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.1451, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.0866, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.1276, batch time: 0.08, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.0816, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.1222, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.2410, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.1550031155347824, accuracy: 95.9 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 2.977532148361206, accuracy: 61.6 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.1509590446949005, accuracy: 95.9 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.15390890836715698, accuracy: 95.5 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.1463562548160553, accuracy: 95.7 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.14184583723545074, accuracy: 96.1 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.1386701911687851, accuracy: 96.3 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.1360410749912262, accuracy: 96.4 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.1365898847579956, accuracy: 96.5 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.13464120030403137, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.1527, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.1198, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.1299, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.1762, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.1500, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.0630, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.1711, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.1235, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.2094, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.0964, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.1638656109571457, accuracy: 95.5 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 2.9684090614318848, accuracy: 54.2 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.17387641966342926, accuracy: 94.6 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.14627428352832794, accuracy: 95.9 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 5.726997375488281, accuracy: 54.1 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.13387513160705566, accuracy: 96.2 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.1321568489074707, accuracy: 96.3 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.12924903631210327, accuracy: 96.2 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.12319328635931015, accuracy: 96.6 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.12179539352655411, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.1913, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.2580, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.1388, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.0761, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.1273, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.0907, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.1755, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.1754, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.1797, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.1735, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.12638548016548157, accuracy: 96.0 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 3.0363943576812744, accuracy: 53.6 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.12483952939510345, accuracy: 96.2 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.15987224876880646, accuracy: 95.0 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.12231214344501495, accuracy: 95.6 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.1746903508901596, accuracy: 94.1 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.1983896940946579, accuracy: 92.7 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.11337245255708694, accuracy: 96.6 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.11386388540267944, accuracy: 95.8 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.11014215648174286, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.2676, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.1123, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.0823, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.0765, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.2969, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.0730, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.1837, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.1688, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.1369, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.2661, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.14714163541793823, accuracy: 95.4 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.33772245049476624, accuracy: 89.0 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.3306066393852234, accuracy: 88.7 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.14107196033000946, accuracy: 96.0 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.2606615722179413, accuracy: 91.9 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.13667337596416473, accuracy: 96.2 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.1426500529050827, accuracy: 95.6 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.13676974177360535, accuracy: 96.2 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.13230273127555847, accuracy: 95.8 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.13448840379714966, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.0827, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.1513, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.1549, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.1931, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.1525, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.3591, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.1488, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.1541, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.2682, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.1080, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.18802489340305328, accuracy: 93.8 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.1801658570766449, accuracy: 94.2 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.1710030734539032, accuracy: 94.7 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.1709580421447754, accuracy: 94.7 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.1684577912092209, accuracy: 94.9 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.16221880912780762, accuracy: 95.4 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.161937415599823, accuracy: 96.0 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.15429875254631042, accuracy: 95.8 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.14901652932167053, accuracy: 96.2 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.14494812488555908, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.2363, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.0983, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.1889, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.2181, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.2052, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.2843, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.0941, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.1316, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.1684, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.1732, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.1567627340555191, accuracy: 94.7 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.1509086787700653, accuracy: 95.2 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.21515774726867676, accuracy: 93.8 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.14818021655082703, accuracy: 95.4 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.12800683081150055, accuracy: 95.9 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.12483511865139008, accuracy: 96.1 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.138270765542984, accuracy: 95.7 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.12010883539915085, accuracy: 96.2 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.11889338493347168, accuracy: 96.5 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.12163080275058746, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.1231, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.2259, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.1051, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.2388, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.4249, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.3637, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.0970, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.1252, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.1444, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.1032, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.1543944925069809, accuracy: 94.9 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 2.0083024501800537, accuracy: 52.9 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.15065635740756989, accuracy: 94.6 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.153243288397789, accuracy: 95.5 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.19868823885917664, accuracy: 93.0 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.14375528693199158, accuracy: 95.5 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.7173211574554443, accuracy: 79.3 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.14088059961795807, accuracy: 96.0 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.14082632958889008, accuracy: 95.9 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.13952504098415375, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.2385, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.1469, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.1440, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.1744, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.1188, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.1993, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.2294, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.1614, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.0654, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.2586, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.15628518164157867, accuracy: 96.2 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 1.2512797117233276, accuracy: 70.6 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.15069541335105896, accuracy: 96.4 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.1449836939573288, accuracy: 96.7 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.14634159207344055, accuracy: 95.7 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.34148237109184265, accuracy: 90.7 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.13791906833648682, accuracy: 96.0 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.1339910328388214, accuracy: 95.8 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.13195359706878662, accuracy: 96.1 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.12999172508716583, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.1300, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.1260, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.1072, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.1940, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.1450, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.1641, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.1343, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.1848, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.0806, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.2534, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.11290886998176575, accuracy: 96.9 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.12268746644258499, accuracy: 96.8 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.2546456456184387, accuracy: 91.2 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.15984362363815308, accuracy: 95.4 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.09795072674751282, accuracy: 96.9 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.09505157172679901, accuracy: 97.0 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.09916669130325317, accuracy: 97.0 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.09408243745565414, accuracy: 97.0 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.09971682727336884, accuracy: 97.5 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.08984829485416412, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.1458, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.1159, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.0915, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.1682, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.2161, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.1945, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.2129, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.1404, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.1975, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.1447, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.11926499754190445, accuracy: 96.4 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.14736050367355347, accuracy: 95.6 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.11883516609668732, accuracy: 96.6 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.1177813857793808, accuracy: 96.7 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.15015514194965363, accuracy: 95.5 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.10908006131649017, accuracy: 97.2 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.10887997597455978, accuracy: 97.1 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.10712296515703201, accuracy: 97.3 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.10835258662700653, accuracy: 97.3 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.10719470679759979, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.2968, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.1554, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.1505, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.2266, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.1643, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.1005, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.2216, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.1097, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.0799, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.1519, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.17185108363628387, accuracy: 94.4 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.16475962102413177, accuracy: 94.5 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.1538127064704895, accuracy: 95.0 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.14980699121952057, accuracy: 95.5 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.14512334764003754, accuracy: 95.9 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.20998847484588623, accuracy: 92.9 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.16679464280605316, accuracy: 94.4 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.2768559157848358, accuracy: 92.2 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.5070407390594482, accuracy: 84.1 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.15648908913135529, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.1214, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.1648, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.0546, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.1624, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.1340, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.0690, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.1700, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.0755, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.1109, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.0947, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.13210099935531616, accuracy: 95.9 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.15898080170154572, accuracy: 95.4 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.12090296298265457, accuracy: 96.7 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.12035216391086578, accuracy: 96.4 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.12850886583328247, accuracy: 96.2 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.11730986088514328, accuracy: 96.7 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.11594919860363007, accuracy: 96.6 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.11864544451236725, accuracy: 96.5 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.11290767043828964, accuracy: 96.5 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.1123596578836441, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.2623, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.1787, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.2179, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.2866, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.1452, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.1407, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.1712, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.1250, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.1031, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.1672, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.1289869099855423, accuracy: 96.3 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.13169364631175995, accuracy: 96.4 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.15965548157691956, accuracy: 95.4 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.12348631769418716, accuracy: 97.2 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.1713142842054367, accuracy: 95.4 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.2229447215795517, accuracy: 93.0 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.2653260827064514, accuracy: 90.8 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.14490766823291779, accuracy: 95.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.12011180073022842, accuracy: 96.7 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.11866971850395203, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.1858, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.0929, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.2006, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.1157, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.1654, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.1644, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.0992, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.2060, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.1740, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.1241, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.15238867700099945, accuracy: 94.8 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.168355330824852, accuracy: 95.0 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.14586304128170013, accuracy: 95.6 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.1438843309879303, accuracy: 95.5 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.21105802059173584, accuracy: 93.6 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.45638492703437805, accuracy: 86.9 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.13157284259796143, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.12900416553020477, accuracy: 95.8 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.12839938700199127, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.13685426115989685, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.0776, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.1108, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.1596, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.0735, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.2519, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.0758, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.1290, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.0950, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.1347, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.11250300705432892, accuracy: 96.9 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.10920139402151108, accuracy: 96.6 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.106357641518116, accuracy: 96.7 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.10605776309967041, accuracy: 96.7 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.26449811458587646, accuracy: 91.4 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.10322948545217514, accuracy: 97.0 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.10627726465463638, accuracy: 96.9 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.10679692029953003, accuracy: 96.5 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.09988318383693695, accuracy: 96.7 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.09747142344713211, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.0990, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.2582, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.0720, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.0943, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.0826, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.1196, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.0960, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.1438, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.1410, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.1249, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.1434832066297531, accuracy: 95.0 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.16253851354122162, accuracy: 94.7 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.12937749922275543, accuracy: 95.7 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.12605425715446472, accuracy: 95.5 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.2894912362098694, accuracy: 90.0 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.11070939898490906, accuracy: 96.0 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.10851014405488968, accuracy: 95.8 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.10500579327344894, accuracy: 96.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.10285327583551407, accuracy: 96.3 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.10417166352272034, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.1388, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.1206, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.1343, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.1891, batch time: 0.32, accuracy:  90.62%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.1230, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.2568, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.0740, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.0833, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.1433, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.1298, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.12991827726364136, accuracy: 95.6 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.20211906731128693, accuracy: 93.4 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.148055300116539, accuracy: 95.0 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.1055360808968544, accuracy: 96.4 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.1076638475060463, accuracy: 95.9 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.24623675644397736, accuracy: 92.7 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.1323050856590271, accuracy: 95.2 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.1252370923757553, accuracy: 95.9 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.12764368951320648, accuracy: 95.3 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.1028948724269867, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.1766, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.1104, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.1381, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.1213, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.0941, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.1581, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.1854, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.2060, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.1058, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.1074, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.1410071700811386, accuracy: 95.1 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 2.282843589782715, accuracy: 58.3 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.13477931916713715, accuracy: 96.0 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.23250186443328857, accuracy: 91.9 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.1261054277420044, accuracy: 96.3 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.1899169683456421, accuracy: 93.9 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.29892808198928833, accuracy: 91.0 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.24437269568443298, accuracy: 90.9 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.11494351178407669, accuracy: 96.9 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.1120850145816803, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.0800, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.1191, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.1281, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.1115, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.1234, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.1319, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.1673, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.0992, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.1683, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.1315, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.09581296145915985, accuracy: 96.6 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.6825227737426758, accuracy: 68.8 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.09568952769041061, accuracy: 96.5 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.15196239948272705, accuracy: 94.3 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.08761181682348251, accuracy: 97.3 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.08495189994573593, accuracy: 97.1 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.08348914235830307, accuracy: 97.4 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.08415310829877853, accuracy: 97.1 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.08150037378072739, accuracy: 97.5 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.08371731638908386, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.1205, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.2668, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.1939, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.1276, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.1351, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1825, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.1900, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.0796, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.2176, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.0790, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.10915261507034302, accuracy: 96.4 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 0.15282085537910461, accuracy: 94.8 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.10484827309846878, accuracy: 96.8 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.10236585140228271, accuracy: 96.7 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.2102627456188202, accuracy: 92.8 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.09574557095766068, accuracy: 97.1 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.09893239289522171, accuracy: 96.5 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.0926862359046936, accuracy: 97.3 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.09289345145225525, accuracy: 97.5 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.09141805768013, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.1032, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.0889, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.1529, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.1305, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.1313, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.0998, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.1259, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.2028, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.0907, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.1441, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.12726669013500214, accuracy: 95.8 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.14983677864074707, accuracy: 94.8 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.12191889435052872, accuracy: 96.1 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.10798777639865875, accuracy: 96.5 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.12943729758262634, accuracy: 95.5 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.18573637306690216, accuracy: 93.7 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.14745864272117615, accuracy: 94.8 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.3504010736942291, accuracy: 90.0 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.3278030753135681, accuracy: 89.8 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.09540434181690216, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.1848, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.1225, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.0734, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.0604, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0928, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1381, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.1399, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.1221, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.0876, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.0649, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.11146904528141022, accuracy: 96.5 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 2.322894811630249, accuracy: 61.9 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.10284572839736938, accuracy: 96.6 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.09411097317934036, accuracy: 96.8 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.09106035530567169, accuracy: 97.1 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.0808023065328598, accuracy: 97.9 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.08037567883729935, accuracy: 97.6 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.0857013389468193, accuracy: 96.9 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.07833048701286316, accuracy: 97.5 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.07587525248527527, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.1377, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.2182, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.0758, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.1357, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.0655, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.0975, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.1936, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.2590, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.1895, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.1076, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.12699489295482635, accuracy: 95.4 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.12293925881385803, accuracy: 95.7 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.12308961898088455, accuracy: 95.7 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.11416343599557877, accuracy: 96.6 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.11416473239660263, accuracy: 96.6 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.1517299860715866, accuracy: 95.3 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.14768533408641815, accuracy: 95.0 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.10821546614170074, accuracy: 96.4 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.1022244393825531, accuracy: 96.7 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.10028570890426636, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.1545, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.1732, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.1347, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.1231, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.0867, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.1844, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.1694, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.0951, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.1195, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.2255, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.10690170526504517, accuracy: 96.2 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.12755811214447021, accuracy: 95.3 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.14886334538459778, accuracy: 94.8 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.2830701768398285, accuracy: 91.9 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.14075641334056854, accuracy: 95.0 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.08292535692453384, accuracy: 97.3 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.07831259071826935, accuracy: 97.1 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.07538876682519913, accuracy: 97.5 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.07699642330408096, accuracy: 97.5 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.07314646244049072, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.0874, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.1556, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.0917, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.1059, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.0863, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.1184, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.1252, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.0501, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.2400, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.11006564646959305, accuracy: 96.1 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 2.5075671672821045, accuracy: 67.2 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.09958003461360931, accuracy: 96.7 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.09881500154733658, accuracy: 96.8 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.20220966637134552, accuracy: 92.7 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.1715807020664215, accuracy: 93.3 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.09008527547121048, accuracy: 96.7 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.08971142768859863, accuracy: 96.8 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.0897165834903717, accuracy: 97.3 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.08662654459476471, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.1462, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.1091, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.1214, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.1789, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.2539, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.0909, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.0897, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.1074, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.0844, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.1082, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.09338168799877167, accuracy: 97.5 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.9236723184585571, accuracy: 64.3 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.09034602344036102, accuracy: 97.6 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.09015323966741562, accuracy: 97.5 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.15944114327430725, accuracy: 94.3 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.09314095228910446, accuracy: 97.6 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.12581215798854828, accuracy: 95.5 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.09300931543111801, accuracy: 97.6 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.0995124876499176, accuracy: 97.4 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.08519717305898666, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.0554, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.1222, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.1526, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.0437, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.1152, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.1336, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.0746, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.1107, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.0696, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.1427, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.09652750939130783, accuracy: 96.7 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.13203226029872894, accuracy: 95.3 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.09160732477903366, accuracy: 97.0 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.11794307827949524, accuracy: 96.0 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.112745761871338, accuracy: 80.7 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.08303716778755188, accuracy: 96.9 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.07791881263256073, accuracy: 97.2 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.08140897005796432, accuracy: 97.2 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.07770860940217972, accuracy: 97.3 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.08364477753639221, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.1159, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.1252, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.1872, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.0804, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.0888, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.1447, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.1354, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.2009, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.0710, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.0775, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.0905328169465065, accuracy: 97.4 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 1.1200958490371704, accuracy: 78.1 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.08120150864124298, accuracy: 97.6 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.08464407920837402, accuracy: 97.7 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.10019771009683609, accuracy: 96.9 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.0902261883020401, accuracy: 97.5 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.07666846364736557, accuracy: 97.7 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.07498334348201752, accuracy: 98.1 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.0751434862613678, accuracy: 98.0 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.0776529461145401, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.1591, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.1100, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.0776, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.0721, batch time: 0.32, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.1338, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.2323, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.1243, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1470, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.0832, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.1067, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.1110760048031807, accuracy: 95.9 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.17053675651550293, accuracy: 94.9 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.1088380217552185, accuracy: 96.1 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.09842777252197266, accuracy: 96.1 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.14504577219486237, accuracy: 95.0 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.2763262689113617, accuracy: 90.5 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.10834359377622604, accuracy: 96.7 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.23512467741966248, accuracy: 91.7 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.12524569034576416, accuracy: 95.3 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.1598818302154541, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.1445, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.0617, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.1709, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.0699, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.0359, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.1717, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.1796, batch time: 0.08, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.1254, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.1367, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.1999, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.1579791158437729, accuracy: 94.8 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 2.784309148788452, accuracy: 63.5 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.22970083355903625, accuracy: 92.4 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.13816425204277039, accuracy: 95.8 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.13074538111686707, accuracy: 96.0 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.20376865565776825, accuracy: 93.7 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.16414614021778107, accuracy: 94.5 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.1310732513666153, accuracy: 96.7 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.11637368053197861, accuracy: 97.0 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.11582253873348236, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.0838, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.1240, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.1411, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.0931, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.2065, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.1645, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.1309, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.0919, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.1861, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.13002222776412964, accuracy: 95.3 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.1865558922290802, accuracy: 93.6 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.1181240826845169, accuracy: 95.9 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.10850996524095535, accuracy: 96.5 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.3922230303287506, accuracy: 87.9 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.10179083049297333, accuracy: 96.8 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.10583256185054779, accuracy: 96.2 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.09527873247861862, accuracy: 97.0 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.09671194851398468, accuracy: 97.0 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.09262911975383759, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.2081, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.1038, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.1112, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.1554, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.0680, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.1238, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.1146, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.1047, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.0717, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.1732, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.09657495468854904, accuracy: 96.9 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.6455082297325134, accuracy: 83.7 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.09520521759986877, accuracy: 97.0 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.1718902587890625, accuracy: 93.9 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.08943779766559601, accuracy: 97.3 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.08173486590385437, accuracy: 97.9 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.08312399685382843, accuracy: 97.4 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.08023731410503387, accuracy: 98.3 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.078731007874012, accuracy: 98.2 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.07715872675180435, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.1731, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.0815, batch time: 0.12, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.1652, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.1585, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.2122, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.0725, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.1824, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.1368, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.1292, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.1360, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.10723110288381577, accuracy: 96.3 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 3.133826494216919, accuracy: 59.7 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.1693916916847229, accuracy: 94.3 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.09230555593967438, accuracy: 96.5 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.10212194174528122, accuracy: 96.7 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.11349702626466751, accuracy: 96.4 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.6568388938903809, accuracy: 86.9 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.08424057066440582, accuracy: 97.2 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.07726961374282837, accuracy: 97.2 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.07979100197553635, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.1088, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.1249, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.4656, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.1731, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.1413, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.1644, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.0856, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.1459, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.0460, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.1914, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.12155531346797943, accuracy: 96.4 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.13289445638656616, accuracy: 95.5 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.12062730640172958, accuracy: 96.6 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.11566831171512604, accuracy: 96.6 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.11383341997861862, accuracy: 96.4 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.12993158400058746, accuracy: 95.8 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.11124709993600845, accuracy: 96.6 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.11092080175876617, accuracy: 96.4 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.150148406624794, accuracy: 95.3 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.12292985618114471, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.1130, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.2063, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.0938, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.1394, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.0978, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.0849, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.1266, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.1355, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.1257, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.1981, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.12648184597492218, accuracy: 96.2 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.12924306094646454, accuracy: 96.4 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.11689763516187668, accuracy: 96.3 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.1134641245007515, accuracy: 96.9 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.13815414905548096, accuracy: 96.2 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.1028842106461525, accuracy: 97.5 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.10674169659614563, accuracy: 96.7 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.09701450169086456, accuracy: 97.3 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.09650599956512451, accuracy: 97.5 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.0951690524816513, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.0889, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.0904, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.1721, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.1530, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.1287, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.1586, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.1232, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.0910, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.1719, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.1493, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.08695528656244278, accuracy: 96.9 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 3.0664849281311035, accuracy: 62.7 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 1.2091851234436035, accuracy: 74.2 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.10411633551120758, accuracy: 96.7 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.40228378772735596, accuracy: 88.1 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.08015772700309753, accuracy: 97.4 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.07617513090372086, accuracy: 97.8 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.07317128777503967, accuracy: 98.0 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.07097310572862625, accuracy: 98.5 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.07223264127969742, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.1390, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.1116, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.1694, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.0682, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.0652, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.1162, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.0661, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.1563, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.0657, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.0522, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.10686880350112915, accuracy: 96.6 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.19199025630950928, accuracy: 93.7 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.11563542485237122, accuracy: 96.7 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.1472683846950531, accuracy: 95.3 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.10135232657194138, accuracy: 96.7 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.09489221125841141, accuracy: 97.1 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.09782715886831284, accuracy: 96.7 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.0945870503783226, accuracy: 97.1 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.09377673268318176, accuracy: 97.2 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.08919884264469147, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.1420, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.0793, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.1788, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.0410, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.1128, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1025, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.1896, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.1606, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.1640, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.0465, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.08356499671936035, accuracy: 96.8 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.08545006811618805, accuracy: 97.1 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.21397162973880768, accuracy: 93.4 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.07789460569620132, accuracy: 97.5 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.08199611306190491, accuracy: 96.8 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.07245007157325745, accuracy: 97.7 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.0747172012925148, accuracy: 97.5 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.06843563169240952, accuracy: 97.8 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.06778564304113388, accuracy: 98.3 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.06813351809978485, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.0847, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.0822, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.1341, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.1282, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.0756, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.2042, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.0612, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.0773, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.2490, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.1440, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.10320065915584564, accuracy: 97.1 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.11446496099233627, accuracy: 96.5 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.1262161135673523, accuracy: 96.3 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.09616231173276901, accuracy: 97.3 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.1037866622209549, accuracy: 97.0 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.12404976785182953, accuracy: 96.2 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.09060908854007721, accuracy: 97.7 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.09019070118665695, accuracy: 97.9 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.08739076554775238, accuracy: 97.8 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.09173060953617096, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.0405, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.0572, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.0609, batch time: 0.33, accuracy:  98.44%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.1384, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.0693, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.2371, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.1205, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.0247, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.1576, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.1068, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.09943646192550659, accuracy: 96.9 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.10585536062717438, accuracy: 96.5 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.07489382475614548, accuracy: 98.2 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.07385977357625961, accuracy: 98.3 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.07980356365442276, accuracy: 97.7 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.08583121001720428, accuracy: 97.2 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.08465199917554855, accuracy: 97.4 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.07935390621423721, accuracy: 97.7 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.06944768875837326, accuracy: 98.1 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.08221974223852158, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.0933, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.0794, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1687, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.0459, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.0601, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.1395, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.0962, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.0526, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.0811, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.11387881636619568, accuracy: 96.3 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.13085328042507172, accuracy: 95.5 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.17595843970775604, accuracy: 94.7 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.10492383688688278, accuracy: 96.9 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.11228039860725403, accuracy: 96.5 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.09116840362548828, accuracy: 97.6 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.09061852097511292, accuracy: 96.7 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.08559507131576538, accuracy: 97.4 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.0837102010846138, accuracy: 97.4 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.08383458852767944, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.2448, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.1843, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.1156, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.0493, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.1746, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.1305, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.1077, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.1133, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.0805, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.09584666788578033, accuracy: 96.3 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.10924644768238068, accuracy: 95.4 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.08810883015394211, accuracy: 97.0 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.0837918296456337, accuracy: 96.8 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.18294107913970947, accuracy: 93.9 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.10260511189699173, accuracy: 95.9 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.0742841511964798, accuracy: 97.3 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.07276890426874161, accuracy: 97.6 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.071413554251194, accuracy: 97.2 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.06951802968978882, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.0929, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.0818, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.0801, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.0903, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.0781, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.1054, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.0829, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.1150, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.0967, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.0491, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.10089398920536041, accuracy: 96.8 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.464729905128479, accuracy: 84.2 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.12192276865243912, accuracy: 95.4 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.09527082741260529, accuracy: 96.8 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.09396800398826599, accuracy: 97.0 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 3.923752784729004, accuracy: 62.1 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.08222202956676483, accuracy: 97.5 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.07325538992881775, accuracy: 97.9 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.07651575654745102, accuracy: 97.9 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.0710262730717659, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.2110, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.1040, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.1017, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.0529, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.0659, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.0755, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.2249, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.1473, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.1316, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.1104, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.10163459926843643, accuracy: 96.6 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.10803203284740448, accuracy: 96.5 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.17400029301643372, accuracy: 94.1 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.21667952835559845, accuracy: 93.9 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.1047171875834465, accuracy: 96.4 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.09424872696399689, accuracy: 97.5 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.09188917279243469, accuracy: 97.4 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.08655591309070587, accuracy: 97.6 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.0870036855340004, accuracy: 98.0 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.08538109064102173, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.0704, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.2522, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.1088, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.0949, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.1485, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.3516, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.1483, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.1036, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.0917, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.0340, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.07198957353830338, accuracy: 97.8 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.07551068812608719, accuracy: 97.5 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.07154155522584915, accuracy: 97.7 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.12106006592512131, accuracy: 95.3 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.06666035950183868, accuracy: 97.9 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.06496553122997284, accuracy: 98.1 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.1425965428352356, accuracy: 95.2 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.06211725249886513, accuracy: 97.9 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.06107852980494499, accuracy: 98.2 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.05830129608511925, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.1868, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.1131, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.1450, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.1401, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.2197, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1221, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.0656, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.0823, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.0779, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.0506, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.07105180621147156, accuracy: 97.4 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.08643180131912231, accuracy: 97.0 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.09811244904994965, accuracy: 96.6 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.12293573468923569, accuracy: 95.9 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.06081855669617653, accuracy: 98.1 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.05937652289867401, accuracy: 98.2 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.05731583759188652, accuracy: 98.2 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.05668715387582779, accuracy: 98.2 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.05473790317773819, accuracy: 97.8 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.05750469118356705, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.1196, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.1213, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.1090, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.0481, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.0667, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.0665, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.1036, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.0823, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.1260, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.1659, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.06925152987241745, accuracy: 98.2 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.07633717358112335, accuracy: 98.1 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.0682300254702568, accuracy: 98.2 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.06487058848142624, accuracy: 98.3 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.08693338930606842, accuracy: 97.8 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.06121804192662239, accuracy: 98.3 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.0655113086104393, accuracy: 98.1 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.05847873538732529, accuracy: 98.3 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.05899566784501076, accuracy: 98.5 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.05893748998641968, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.1078, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.1028, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.0591, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.1347, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.0767, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.1133, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.0671, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.0270, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.0696, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.1312, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.09395673125982285, accuracy: 97.0 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.09618809819221497, accuracy: 96.9 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.18159273266792297, accuracy: 94.7 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.14003229141235352, accuracy: 95.1 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.1777389794588089, accuracy: 94.7 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.07686947286128998, accuracy: 97.6 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.0736001655459404, accuracy: 97.8 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.07226104289293289, accuracy: 98.0 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.07130361348390579, accuracy: 98.2 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.06932129710912704, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.2514, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.0994, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.1161, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.0929, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.1263, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.1107, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.0637, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.1148, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.1420, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.1244, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.09771469235420227, accuracy: 97.4 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.10266325622797012, accuracy: 97.0 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.26611506938934326, accuracy: 91.6 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.1294015794992447, accuracy: 95.4 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.09996221959590912, accuracy: 96.6 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.08920975029468536, accuracy: 97.3 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.08529508113861084, accuracy: 97.7 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.08565220981836319, accuracy: 97.9 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.08421184122562408, accuracy: 97.9 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.0836314931511879, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.0351, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.1233, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.0938, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.0558, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.1227, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.1231, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.0483, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.1049, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.0740, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.0769229456782341, accuracy: 96.9 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.07085534930229187, accuracy: 97.2 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.06977849453687668, accuracy: 97.7 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.06823801249265671, accuracy: 97.6 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.08327705413103104, accuracy: 97.4 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.0672902837395668, accuracy: 97.5 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.07101865112781525, accuracy: 97.7 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.06462261825799942, accuracy: 97.9 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.0641934722661972, accuracy: 97.7 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.06143619865179062, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.0950, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.1233, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.0865, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.1648, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.0924, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.0600, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.0864, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.0933, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.1737, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.0302, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.08791293948888779, accuracy: 97.0 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.101234070956707, accuracy: 96.3 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.099166139960289, accuracy: 97.1 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.07709881663322449, accuracy: 97.3 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.07481064647436142, accuracy: 97.2 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.3318329155445099, accuracy: 89.5 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.08566636592149734, accuracy: 97.1 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.0789232850074768, accuracy: 97.3 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.0828014388680458, accuracy: 97.3 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.06840787082910538, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.0870, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.0473, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.0661, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.1050, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.0627, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.0420, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.0347, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.1578, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.1156, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.1548, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.08538799732923508, accuracy: 97.0 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.1529272198677063, accuracy: 95.3 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.07406461983919144, accuracy: 98.1 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.07067953795194626, accuracy: 98.0 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.0647309198975563, accuracy: 98.0 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.08980179578065872, accuracy: 96.8 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.058373190462589264, accuracy: 97.9 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.05334389582276344, accuracy: 97.9 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.054037731140851974, accuracy: 98.4 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.05330512672662735, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.1571, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.0689, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.1583, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.1205, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.2125, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.0889, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.0602, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.0586, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.0645, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.0247, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.08593564480543137, accuracy: 97.3 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.09430570900440216, accuracy: 97.6 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.09058583527803421, accuracy: 97.6 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.10455329716205597, accuracy: 96.7 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.0758526623249054, accuracy: 98.1 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.07573460042476654, accuracy: 97.9 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.0704389438033104, accuracy: 98.0 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.06880129873752594, accuracy: 98.2 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.06612268090248108, accuracy: 98.6 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.06446521729230881, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.0830, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.0551, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.0676, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.0743, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.1712, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.1520, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.1041, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.0528, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.1159, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.11314145475625992, accuracy: 96.6 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.12110684812068939, accuracy: 96.4 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.09463828802108765, accuracy: 97.2 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.0941738486289978, accuracy: 96.9 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.19029103219509125, accuracy: 94.5 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.16256171464920044, accuracy: 94.4 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.0857873186469078, accuracy: 97.1 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.08490338176488876, accuracy: 97.0 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.08227541297674179, accuracy: 97.7 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.0824032574892044, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.0869, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.1871, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.1166, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.0455, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.1023, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.1338, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.1662, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.0842, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.1587, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.1081, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.0767209604382515, accuracy: 97.8 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.07793397456407547, accuracy: 97.9 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.07342428714036942, accuracy: 97.8 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.06431753933429718, accuracy: 98.1 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.059890784323215485, accuracy: 98.6 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.060524869710206985, accuracy: 98.7 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.10860586911439896, accuracy: 96.3 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.0898989886045456, accuracy: 97.2 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.055451709777116776, accuracy: 98.9 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.05455179139971733, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.2195, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.0675, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.0476, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.1273, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.0946, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.1038, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.0859, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.1214, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.0397, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.0923, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.08693092316389084, accuracy: 97.3 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.09075815975666046, accuracy: 96.9 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.0856497660279274, accuracy: 97.1 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.08336054533720016, accuracy: 97.2 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.07803768664598465, accuracy: 97.4 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.0815582275390625, accuracy: 97.2 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.08064628392457962, accuracy: 96.9 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.3386582136154175, accuracy: 91.3 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.08589465916156769, accuracy: 97.4 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.08419635146856308, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.0827, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.0563, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.1467, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.0264, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.0206, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.0392, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.1281, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.1736, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.0791, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.1279, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.0905907079577446, accuracy: 97.0 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.09470908343791962, accuracy: 97.0 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.1434440314769745, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.1020873486995697, accuracy: 96.3 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.09564527869224548, accuracy: 96.6 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.08212084323167801, accuracy: 97.2 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.08038325607776642, accuracy: 96.9 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.07942328602075577, accuracy: 97.2 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.07919696718454361, accuracy: 97.3 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.0782274454832077, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.0651, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.0618, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.1464, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.0610, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.1414, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.1126, batch time: 0.25, accuracy:  94.53%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.0911, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.0706, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.0709, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.08223240077495575, accuracy: 97.6 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.0837780013680458, accuracy: 97.2 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.07996882498264313, accuracy: 97.9 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.07589764893054962, accuracy: 97.7 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.09693454205989838, accuracy: 97.5 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.14043940603733063, accuracy: 95.5 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.15779536962509155, accuracy: 94.6 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.06327341496944427, accuracy: 98.2 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.06408819556236267, accuracy: 97.8 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.05936671048402786, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.2124, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.1084, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.1624, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.1094, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.1132, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.0582, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.1421, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.0321, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.0904, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.1145, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.07362616062164307, accuracy: 97.7 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.07743639498949051, accuracy: 97.9 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.11870460957288742, accuracy: 96.7 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.21179832518100739, accuracy: 92.4 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.06885967403650284, accuracy: 97.8 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.06758952140808105, accuracy: 98.0 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.0679018422961235, accuracy: 98.3 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.06515229493379593, accuracy: 98.1 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.0661022737622261, accuracy: 98.0 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.06626994907855988, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.1249, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.0465, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.0823, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.1113, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.0249, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.0647, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.1847, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.0848, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.0862, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.0440, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.09639964997768402, accuracy: 97.1 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.1169435903429985, accuracy: 96.8 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.08523284643888474, accuracy: 97.8 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.08069237321615219, accuracy: 97.5 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.08916164189577103, accuracy: 97.4 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.07300122082233429, accuracy: 98.0 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.06960520148277283, accuracy: 98.0 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.06691336631774902, accuracy: 98.0 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.06738054752349854, accuracy: 98.1 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.07023551315069199, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.2124, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.0686, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.0463, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.0925, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.0818, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.0955, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.0808, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.0738, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.1478, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.1371, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.06287980824708939, accuracy: 98.0 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.10674989968538284, accuracy: 96.4 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.08874338865280151, accuracy: 96.8 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.1422000676393509, accuracy: 94.4 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.05603746697306633, accuracy: 98.6 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.05019741877913475, accuracy: 98.4 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.049108054488897324, accuracy: 98.8 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.04756733402609825, accuracy: 98.7 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.04722737893462181, accuracy: 98.8 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.0481034591794014, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.1669, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.0800, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.0819, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.0379, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.0568, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.0950, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.0805, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.1085, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.0360, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.0339, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.09016256779432297, accuracy: 97.2 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.09639375656843185, accuracy: 96.6 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.08647485822439194, accuracy: 97.4 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.1038133054971695, accuracy: 96.3 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.11768955737352371, accuracy: 96.1 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.09515630453824997, accuracy: 97.1 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.13786812126636505, accuracy: 95.3 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.06669087707996368, accuracy: 97.6 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.06266394257545471, accuracy: 98.1 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.05856838822364807, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.1312, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.0891, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.0626, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.1146, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.0995, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.0263, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.0795, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.1251, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.1254, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.1205, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.0882904902100563, accuracy: 96.4 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.07934108376502991, accuracy: 97.2 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.0712743028998375, accuracy: 97.3 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.0689711943268776, accuracy: 97.2 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.10475928336381912, accuracy: 96.9 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.07305006682872772, accuracy: 97.4 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.05785466730594635, accuracy: 98.3 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.055345021188259125, accuracy: 98.0 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.05798245221376419, accuracy: 98.4 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.054919932037591934, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.0473, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.0923, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.0983, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.0754, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.0534, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.0510, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.0726, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.2051, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.1389, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.0449, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.09543735533952713, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.09229806065559387, accuracy: 96.8 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.0962037444114685, accuracy: 96.8 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.08468517661094666, accuracy: 97.5 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.30050259828567505, accuracy: 90.5 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.128890261054039, accuracy: 95.7 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.10929782688617706, accuracy: 96.3 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.07205227017402649, accuracy: 97.9 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.06973924487829208, accuracy: 98.0 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.06677334755659103, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.0372, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.0881, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.1483, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.0785, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.0597, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.1168, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.0695, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.0472, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.0667, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.1778, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.06980745494365692, accuracy: 98.5 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.07324818521738052, accuracy: 98.0 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.0815359503030777, accuracy: 98.1 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.2938205301761627, accuracy: 91.5 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 1.0157066583633423, accuracy: 78.0 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.061479825526475906, accuracy: 98.7 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.05859523266553879, accuracy: 98.5 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.05607840418815613, accuracy: 98.7 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.05523543804883957, accuracy: 98.4 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.0532945841550827, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.0380, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.1437, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.0916, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.0765, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.1072, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.0388, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.0681, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.0953, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.1122, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.0668, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.08039626479148865, accuracy: 97.0 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.3950609862804413, accuracy: 88.7 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.13859878480434418, accuracy: 94.9 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.10765097290277481, accuracy: 96.1 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.06708641350269318, accuracy: 97.7 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.06269823759794235, accuracy: 97.8 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.0600302629172802, accuracy: 98.0 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.0596095509827137, accuracy: 98.0 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.06264049559831619, accuracy: 97.8 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.0560220330953598, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.0711, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.2060, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.1100, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.0983, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.0870, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.0381, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.0318, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.1916, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.0753, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.0702, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.08594804257154465, accuracy: 97.6 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.10061482340097427, accuracy: 97.1 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.1371941864490509, accuracy: 95.8 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.6050114631652832, accuracy: 84.9 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.07218658179044724, accuracy: 98.2 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.06477377563714981, accuracy: 98.2 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.06351399421691895, accuracy: 98.4 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.061197854578495026, accuracy: 98.5 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.06104966625571251, accuracy: 98.3 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.05947885289788246, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.0684, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.1453, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.1502, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.0771, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.0539, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.0757, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.0349, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.0983, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.0262, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.0638, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.07117102295160294, accuracy: 97.4 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.07059811055660248, accuracy: 97.9 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.13262639939785004, accuracy: 95.1 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.06586966663599014, accuracy: 98.0 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.19459299743175507, accuracy: 94.1 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.06154311075806618, accuracy: 97.8 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.060839053243398666, accuracy: 97.9 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.06049259752035141, accuracy: 97.4 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.05646757036447525, accuracy: 97.8 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.05562413111329079, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.0856, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.0626, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.1018, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.0716, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.1640, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.0721, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.0416, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.1636, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.0582, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.05681341513991356, accuracy: 98.7 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.14456172287464142, accuracy: 95.2 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.06943900883197784, accuracy: 98.1 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.3666362166404724, accuracy: 91.2 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.04898796230554581, accuracy: 99.1 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.04860347509384155, accuracy: 99.0 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.04881925508379936, accuracy: 99.0 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.04784535989165306, accuracy: 99.2 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.0629524290561676, accuracy: 98.4 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.04537240043282509, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.0395, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.1590, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.0797, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.0804, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.0311, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.0532, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.0146, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.0584, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.1650, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.0168, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.0634535402059555, accuracy: 97.8 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.14402814209461212, accuracy: 95.1 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.1208699494600296, accuracy: 96.0 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.14885428547859192, accuracy: 95.5 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.06371811032295227, accuracy: 97.7 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.13634097576141357, accuracy: 95.2 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.05333591252565384, accuracy: 98.0 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.059331659227609634, accuracy: 98.0 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.13203579187393188, accuracy: 95.4 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.041665609925985336, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.0803, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.0417, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.0676, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.0534, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.0692, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.1062, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.1020, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.0348, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.1576, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.0522, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.0891752615571022, accuracy: 96.8 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.10231447964906693, accuracy: 96.9 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.07925993204116821, accuracy: 97.4 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.07756111025810242, accuracy: 97.8 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.09922566264867783, accuracy: 96.4 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.30453184247016907, accuracy: 90.4 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.06661656498908997, accuracy: 97.8 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.0678306519985199, accuracy: 97.4 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.06536002457141876, accuracy: 98.0 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.06077869236469269, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.0248, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.0599, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.0564, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.1139, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.0240, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.1847, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.1186, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.2162, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.1534, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.1758, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.09371676295995712, accuracy: 97.3 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.10802161693572998, accuracy: 96.6 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.08538629114627838, accuracy: 97.5 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.08056438714265823, accuracy: 97.6 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.08539825677871704, accuracy: 97.4 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.07756555080413818, accuracy: 97.9 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.07452801614999771, accuracy: 98.0 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.07295204699039459, accuracy: 98.2 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.07452906668186188, accuracy: 98.0 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.07437080889940262, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.1080, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.0953, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.0635, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.0637, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.1287, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.0551, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.0867, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.0901, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.0622, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.1730, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.08662841469049454, accuracy: 97.5 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.22384768724441528, accuracy: 91.0 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.14234097301959991, accuracy: 95.1 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.08936940133571625, accuracy: 97.0 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.07987206429243088, accuracy: 97.3 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.0749727264046669, accuracy: 97.1 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.07413802295923233, accuracy: 97.5 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.07321026921272278, accuracy: 97.6 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.07195910811424255, accuracy: 97.7 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.07087046653032303, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.1032, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.0619, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.0230, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.0833, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.1011, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.0525, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.1439, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.1053, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.1193, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.1113, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.076018787920475, accuracy: 97.2 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.07627611607313156, accuracy: 97.4 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.10505900532007217, accuracy: 96.5 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.07284063845872879, accuracy: 97.4 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.06709751486778259, accuracy: 98.0 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.06430014222860336, accuracy: 97.9 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.0671587586402893, accuracy: 98.0 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.0629325658082962, accuracy: 98.1 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.06230146437883377, accuracy: 98.2 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.06206323578953743, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.1648, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.0702, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.0822, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.0631, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.0774, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.1460, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.0571, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.1314, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.1248, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.2143, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.06226147338747978, accuracy: 97.7 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.11026855558156967, accuracy: 95.5 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.11119566857814789, accuracy: 95.4 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.13526099920272827, accuracy: 94.9 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.05314413458108902, accuracy: 98.5 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.05174826458096504, accuracy: 98.3 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.05140503868460655, accuracy: 98.2 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.05187159404158592, accuracy: 98.3 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.04988931119441986, accuracy: 98.5 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.047931376844644547, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.0801, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.0571, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.1348, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.0637, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.1602, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.0901, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.0942, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.0991, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.1057, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.0832, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.07348445802927017, accuracy: 97.7 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.06839229166507721, accuracy: 97.6 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.06394877284765244, accuracy: 98.0 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.06357324123382568, accuracy: 97.9 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.08632895350456238, accuracy: 97.1 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.12560033798217773, accuracy: 95.7 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.0667211040854454, accuracy: 97.3 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.07736478000879288, accuracy: 96.9 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.06102436035871506, accuracy: 97.8 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.07981927692890167, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.1521, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.0372, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.1047, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.0576, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.0453, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.1413, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.1007, batch time: 0.28, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.0978, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.0137, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.1180, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.08688988536596298, accuracy: 97.1 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.13029707968235016, accuracy: 95.1 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.15474392473697662, accuracy: 94.0 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.06738317757844925, accuracy: 97.8 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.14742721617221832, accuracy: 95.2 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.07317459583282471, accuracy: 97.5 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.09759093821048737, accuracy: 96.4 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.1470690220594406, accuracy: 94.9 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.07277581840753555, accuracy: 96.6 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.06184559687972069, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.0664, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.1235, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.0544, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.0317, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.0315, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.1377, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.0791, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.0475, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.0559, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.0871, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.07032383978366852, accuracy: 97.4 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.07164476811885834, accuracy: 97.5 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.08506103605031967, accuracy: 97.0 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.1342059075832367, accuracy: 95.2 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.06538910418748856, accuracy: 97.5 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.060064926743507385, accuracy: 98.0 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.08108676224946976, accuracy: 97.1 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.06865641474723816, accuracy: 97.4 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.05337763577699661, accuracy: 98.0 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.05350910872220993, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.0295, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.0607, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.0467, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.1668, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.1441, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.1222, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.0310, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.0605, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.0742, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.0710, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.11591055989265442, accuracy: 96.4 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.11466049402952194, accuracy: 96.6 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.07554642856121063, accuracy: 97.8 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.06850162148475647, accuracy: 97.7 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.1186312735080719, accuracy: 96.1 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.2350548654794693, accuracy: 93.8 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.06444699317216873, accuracy: 98.0 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.06581509113311768, accuracy: 97.7 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.06386169791221619, accuracy: 97.9 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.06343549489974976, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.1006, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.2157, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.1479, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.1530, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.1188, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.0574, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.0739, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.1834, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.0888, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.0990, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.10258989781141281, accuracy: 96.9 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.1088806539773941, accuracy: 97.1 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.09552459418773651, accuracy: 97.0 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.08500562608242035, accuracy: 97.5 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.11890152841806412, accuracy: 96.3 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.11276151984930038, accuracy: 96.5 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.08993399888277054, accuracy: 97.2 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.10008799284696579, accuracy: 97.2 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.07273764908313751, accuracy: 97.9 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.06973833590745926, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.0782, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.3149, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.0363, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.1220, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.0595, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.2284, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.1518, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.1069, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.0537, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.0356, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.08430381119251251, accuracy: 96.8 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.08112276345491409, accuracy: 96.9 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.07395994663238525, accuracy: 96.9 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.07146158069372177, accuracy: 97.5 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.17887046933174133, accuracy: 93.2 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.06694088876247406, accuracy: 97.7 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.059746213257312775, accuracy: 98.0 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.058858372271060944, accuracy: 97.5 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.05940671265125275, accuracy: 97.7 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.056212928146123886, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.1132, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.1214, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.1274, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.1442, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.0690, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.0552, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.1457, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.0834, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.0544, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.1400, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.10171272605657578, accuracy: 96.4 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.11825821548700333, accuracy: 95.9 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.09136762470006943, accuracy: 97.3 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.0861787274479866, accuracy: 97.2 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.0918593630194664, accuracy: 97.1 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.12486264109611511, accuracy: 95.1 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.10752031207084656, accuracy: 95.5 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.07183177769184113, accuracy: 98.0 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.07163512706756592, accuracy: 98.0 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.0708184689283371, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.0561, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.0894, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.0430, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.0770, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.0670, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.0376, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.0552, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.0600, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.0384, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.0240, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.06401795148849487, accuracy: 97.8 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.06348024308681488, accuracy: 97.6 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.059606604278087616, accuracy: 97.5 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.31841713190078735, accuracy: 90.7 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.06635057181119919, accuracy: 97.6 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.04568611830472946, accuracy: 98.7 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.045275118201971054, accuracy: 98.7 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.046145882457494736, accuracy: 98.6 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.047915440052747726, accuracy: 98.5 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.043129000812768936, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.0492, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.1747, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.0349, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.0964, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.1671, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.1256, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.0784, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.1354, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.1414, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.0746, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.055608347058296204, accuracy: 97.9 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.0990820899605751, accuracy: 96.5 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.07708185911178589, accuracy: 97.4 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.120733343064785, accuracy: 95.6 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.04582612216472626, accuracy: 98.6 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.044375885277986526, accuracy: 98.5 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.0439021922647953, accuracy: 98.3 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.04218459874391556, accuracy: 98.7 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.04345349594950676, accuracy: 98.5 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.04185592383146286, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.0625, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.0676, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.0896, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.0896, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.0191, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.0955, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.0452, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.0983, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.2019, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.0620, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.05562097579240799, accuracy: 98.4 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.06133275106549263, accuracy: 97.6 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.07031569629907608, accuracy: 97.5 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.05185318738222122, accuracy: 98.2 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.05456560105085373, accuracy: 98.4 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.08088777214288712, accuracy: 97.2 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.049576036632061005, accuracy: 98.8 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.045680005103349686, accuracy: 98.8 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.050511911511421204, accuracy: 98.4 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.04511576145887375, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.0448, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.0448, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.0917, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.0897, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.0578, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.0634, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.0576, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.0841, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.0693, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.0550, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.0988052561879158, accuracy: 96.4 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.08043286204338074, accuracy: 97.1 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.0643259659409523, accuracy: 97.9 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.056090496480464935, accuracy: 98.1 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.0627441331744194, accuracy: 97.7 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.08368203043937683, accuracy: 97.5 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.10237973183393478, accuracy: 96.4 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.06849411129951477, accuracy: 97.9 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.06098100543022156, accuracy: 97.9 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.04436353221535683, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.1144, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.0204, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.1285, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.1263, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.1921, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.0661, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.1047, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.0830, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.1382, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.0299, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.06614063680171967, accuracy: 97.8 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.06620106101036072, accuracy: 97.7 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.07258766144514084, accuracy: 97.6 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.13543781638145447, accuracy: 95.2 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.059819310903549194, accuracy: 98.1 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.057579558342695236, accuracy: 98.2 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.052590664476156235, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.05079063028097153, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.05159694701433182, accuracy: 98.6 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.05014749616384506, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.0095, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.1392, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.1168, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.0613, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.0772, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.0640, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.0284, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.0820, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.0696, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.0440, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.059916459023952484, accuracy: 98.4 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.08753407001495361, accuracy: 97.6 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.05601063743233681, accuracy: 98.5 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.06262601166963577, accuracy: 98.3 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.05470733344554901, accuracy: 98.6 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.05277245491743088, accuracy: 98.5 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.05489390715956688, accuracy: 98.1 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.0541183166205883, accuracy: 98.2 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.050985563546419144, accuracy: 98.4 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.06227870285511017, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.0633, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.1159, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.0921, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.0937, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.0258, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.1227, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.0873, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.0657, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.0411, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.0620, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.04248501732945442, accuracy: 98.6 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.10627533495426178, accuracy: 95.6 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.15493659675121307, accuracy: 94.2 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.1919855773448944, accuracy: 93.6 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.0348723903298378, accuracy: 99.1 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.033982545137405396, accuracy: 99.2 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.03296786919236183, accuracy: 99.2 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.03462440147995949, accuracy: 99.3 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.03725630044937134, accuracy: 99.0 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.03179788589477539, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.0778, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.0808, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.0611, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.0697, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.0695, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.0688, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.3076, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.0374, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.0432, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.0618, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.12364045530557632, accuracy: 96.0 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.12564122676849365, accuracy: 95.7 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.10623227804899216, accuracy: 95.7 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.08221283555030823, accuracy: 97.4 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.08333947509527206, accuracy: 96.9 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.07853232324123383, accuracy: 96.7 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.14774277806282043, accuracy: 94.8 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.0631718710064888, accuracy: 97.8 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.0570366345345974, accuracy: 97.9 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.05473124980926514, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.0390, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.0788, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.0560, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.0831, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.0861, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.0722, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.1186, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.1021, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.0999, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.1166, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.059192437678575516, accuracy: 97.2 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.057129714637994766, accuracy: 98.2 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.049620967358350754, accuracy: 98.1 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.04527350515127182, accuracy: 98.3 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.0744391679763794, accuracy: 97.4 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.04806943237781525, accuracy: 98.0 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.11598575115203857, accuracy: 96.1 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.08125142753124237, accuracy: 96.9 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.050488825887441635, accuracy: 98.1 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.034323692321777344, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.1200, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.0774, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.1223, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.0398, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.0888, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.0600, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.0752, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.0449, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.0271, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.1586, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.05801906809210777, accuracy: 98.1 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.0903092622756958, accuracy: 97.3 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.057492464780807495, accuracy: 98.5 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.1295596957206726, accuracy: 95.6 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.050947800278663635, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.04518774151802063, accuracy: 99.1 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.04862425848841667, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.04920244589447975, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.04383425787091255, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.04192104563117027, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.1035, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.0988, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.1106, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.0687, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.0701, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.0675, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.1203, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.0829, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.0878, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.0783, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.082524873316288, accuracy: 96.9 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.1294395625591278, accuracy: 95.9 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.09503179043531418, accuracy: 96.2 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.19119858741760254, accuracy: 93.0 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.10200504958629608, accuracy: 96.1 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.046502407640218735, accuracy: 98.2 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.046457596123218536, accuracy: 98.5 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.045663170516490936, accuracy: 98.4 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.0419379398226738, accuracy: 99.0 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.040854573249816895, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.0441, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.0590, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.1283, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.0837, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.0706, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.0950, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.0824, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.0847, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.0288, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.1575, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.07200983166694641, accuracy: 97.7 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.07401429861783981, accuracy: 97.5 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.05934362858533859, accuracy: 98.1 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.05581682547926903, accuracy: 98.0 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.11313669383525848, accuracy: 95.8 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.309783011674881, accuracy: 90.8 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.06163793057203293, accuracy: 97.6 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.045636631548404694, accuracy: 98.5 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.04913858324289322, accuracy: 98.3 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.04384259507060051, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.0828, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.0831, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.0759, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.0903, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.0308, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.0754, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0197, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.0103, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.0507, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.2542, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.06174857169389725, accuracy: 98.0 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.27672961354255676, accuracy: 91.3 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.07753744721412659, accuracy: 97.4 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.0764339417219162, accuracy: 97.3 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.04801149293780327, accuracy: 98.2 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.0452948734164238, accuracy: 98.0 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.04565661773085594, accuracy: 98.4 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.0464438870549202, accuracy: 98.3 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.04471795633435249, accuracy: 98.2 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.048626597970724106, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.1343, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.1149, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.0917, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.0747, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.0671, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.1175, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.1387, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.0780, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.0285, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.1043, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.078782819211483, accuracy: 97.7 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.29729151725769043, accuracy: 91.6 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.10484425723552704, accuracy: 96.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.1232643872499466, accuracy: 95.8 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.06655216217041016, accuracy: 97.7 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.06188419833779335, accuracy: 97.9 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.06363396346569061, accuracy: 97.9 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.058936744928359985, accuracy: 98.4 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.05744858458638191, accuracy: 98.3 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.059111617505550385, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.0765, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.0945, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.1109, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.1134, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.0402, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.1601, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.0773, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.1729, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.0634, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.0456, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.06896182149648666, accuracy: 97.1 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.06878859549760818, accuracy: 97.2 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.07010846585035324, accuracy: 97.4 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.062478020787239075, accuracy: 97.4 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.06288030743598938, accuracy: 97.0 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.3321928381919861, accuracy: 92.7 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.05519304424524307, accuracy: 98.0 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.050538014620542526, accuracy: 98.1 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.04914560541510582, accuracy: 98.2 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.04826199635863304, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.1198, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.1144, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.0457, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.0783, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.0667, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.0420, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.0788, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.0189, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.0783, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.0469, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.05924547463655472, accuracy: 97.7 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.08276842534542084, accuracy: 97.1 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.10889623314142227, accuracy: 95.9 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.06296465545892715, accuracy: 97.4 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.04735230654478073, accuracy: 98.2 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.04580629616975784, accuracy: 98.3 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.04452887177467346, accuracy: 98.4 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.04351469874382019, accuracy: 98.5 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.04235082119703293, accuracy: 98.6 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.04168020933866501, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.0799, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.0522, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.1324, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.0713, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.0647, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.0730, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.0466, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.0308, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.0554, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.0992, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.05922833830118179, accuracy: 97.7 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.1416795700788498, accuracy: 95.7 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.056707192212343216, accuracy: 97.8 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.07303538173437119, accuracy: 97.5 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.0735771581530571, accuracy: 97.3 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.04552841931581497, accuracy: 98.8 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.04326499253511429, accuracy: 98.8 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.06596464663743973, accuracy: 97.8 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.047013070434331894, accuracy: 98.6 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.04408254101872444, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.0840, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.0956, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.0434, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.0634, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.1029, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.0173, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.0336, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.0578, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.0724, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.0640, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.08722340315580368, accuracy: 96.5 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.1495727300643921, accuracy: 94.8 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.06409121304750443, accuracy: 98.0 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.10321120917797089, accuracy: 96.0 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.06469830870628357, accuracy: 97.9 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.07983935624361038, accuracy: 97.2 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.07241987437009811, accuracy: 97.4 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.06150960922241211, accuracy: 97.8 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.39106664061546326, accuracy: 86.5 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.05011582747101784, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.0980, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.0443, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.0956, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.0771, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.0438, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.1268, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.0511, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.1409, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.0636, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.0569, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.04827404022216797, accuracy: 98.0 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.21594874560832977, accuracy: 93.5 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.0585881844162941, accuracy: 97.9 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.07957873493432999, accuracy: 96.9 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.06104010343551636, accuracy: 97.8 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.03516659513115883, accuracy: 98.6 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.03411708399653435, accuracy: 98.9 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.034608837217092514, accuracy: 98.6 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.03244800493121147, accuracy: 98.8 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.03207520768046379, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.1181, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.0548, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.0784, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.1374, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.1447, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.0782, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.0913, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.0953, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.1147, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.1215, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.047860436141490936, accuracy: 98.8 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.04797763377428055, accuracy: 98.9 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.0606226846575737, accuracy: 98.2 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.24307411909103394, accuracy: 92.6 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.05150145664811134, accuracy: 98.7 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.0418771356344223, accuracy: 99.2 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.042838118970394135, accuracy: 98.7 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.039934299886226654, accuracy: 99.2 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.038513533771038055, accuracy: 99.3 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.03792503848671913, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.0667, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.0586, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.0596, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.0954, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.0574, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.1394, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.1552, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.0204, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.0487, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.0402, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.05003435164690018, accuracy: 98.2 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.05004594102501869, accuracy: 98.2 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.049365632236003876, accuracy: 98.3 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.04369308054447174, accuracy: 98.7 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.04271218553185463, accuracy: 98.6 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.06457121670246124, accuracy: 97.3 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.1293674111366272, accuracy: 95.3 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.040315136313438416, accuracy: 98.7 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.03910640999674797, accuracy: 98.7 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.0400712676346302, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.0383, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.0614, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.0725, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.0902, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.1414, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.0842, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.0197, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.0614, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.1784, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.0424, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.0616471990942955, accuracy: 97.7 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.06164660304784775, accuracy: 97.7 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.05954601988196373, accuracy: 98.0 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.2112114429473877, accuracy: 92.5 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.06331992149353027, accuracy: 97.9 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.05587543919682503, accuracy: 98.2 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.07125650346279144, accuracy: 97.9 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.05199429392814636, accuracy: 98.6 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.05107726901769638, accuracy: 98.7 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.05102221667766571, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.0219, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.0629, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.1860, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.1656, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.0982, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.0567, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.0688, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.0554, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.0423, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.0814, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.05409667268395424, accuracy: 98.2 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.054095130413770676, accuracy: 98.0 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.05586257949471474, accuracy: 98.3 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.08562842011451721, accuracy: 96.8 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.04539043456315994, accuracy: 98.6 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.04303189367055893, accuracy: 98.8 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.04353904351592064, accuracy: 98.8 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.0428556352853775, accuracy: 98.8 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.042465031147003174, accuracy: 98.9 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.042444199323654175, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.1875, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.0276, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.1004, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.0656, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.0470, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.0741, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.1166, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.0792, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.0579, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.0610, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.1015063226222992, accuracy: 96.4 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.2423815131187439, accuracy: 92.6 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.0863497331738472, accuracy: 96.9 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.06542064249515533, accuracy: 97.8 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.07305466383695602, accuracy: 97.4 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.05598883330821991, accuracy: 98.1 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.050331003963947296, accuracy: 98.2 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.050776407122612, accuracy: 98.2 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.04901598021388054, accuracy: 98.4 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.04879152774810791, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.0892, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.0955, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.1236, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.0298, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.0389, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.0411, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.1018, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.1622, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.0706, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.0514412485063076, accuracy: 98.2 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 0.22193433344364166, accuracy: 93.0 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.08799264580011368, accuracy: 96.9 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.07473602890968323, accuracy: 96.9 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.04346665367484093, accuracy: 98.2 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.04272782430052757, accuracy: 98.3 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.0413697212934494, accuracy: 98.4 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.04165713116526604, accuracy: 98.5 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.03910678252577782, accuracy: 98.7 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.03976283594965935, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.0257, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.0633, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.1051, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.0219, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.0574, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.0443, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.0617, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.0941, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.1536, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.0654, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.04898456111550331, accuracy: 98.3 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.048411957919597626, accuracy: 98.3 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.05685636028647423, accuracy: 97.9 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.05865764245390892, accuracy: 97.9 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.0398075170814991, accuracy: 99.0 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.039681706577539444, accuracy: 98.5 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.036224860697984695, accuracy: 99.3 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.035821639001369476, accuracy: 99.3 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.03405722230672836, accuracy: 99.3 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.03745822235941887, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.1858, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0772, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.1360, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.0384, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.0377, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.0780, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.0657, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.0616, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.0292, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.0795, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.05188290774822235, accuracy: 98.2 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.14384783804416656, accuracy: 94.9 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.09621371328830719, accuracy: 96.9 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.11990393698215485, accuracy: 96.5 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.1334199458360672, accuracy: 96.1 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.045089878141880035, accuracy: 98.4 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.042760465294122696, accuracy: 98.6 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.04112353175878525, accuracy: 98.5 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.04123080149292946, accuracy: 98.7 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.041590310633182526, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.0924, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.1163, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.0260, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.0629, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.0534, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.0462, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.0659, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.0594, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.0890, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.06057603657245636, accuracy: 97.9 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.15586216747760773, accuracy: 94.5 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.07551772147417068, accuracy: 97.2 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.06833752244710922, accuracy: 97.6 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.057031456381082535, accuracy: 97.8 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.0540301650762558, accuracy: 98.1 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.05161468684673309, accuracy: 98.5 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.05169123783707619, accuracy: 98.6 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.04883872717618942, accuracy: 98.6 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.04886534810066223, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.1237, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.0943, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.0310, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.1558, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.1110, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.1497, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.0651, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.0613, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.0765, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.0556257925927639, accuracy: 98.0 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.1222943589091301, accuracy: 95.7 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.054841723293066025, accuracy: 97.8 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.0833895280957222, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.04362253472208977, accuracy: 98.4 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.0698968693614006, accuracy: 97.0 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.032169733196496964, accuracy: 99.3 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.03167956322431564, accuracy: 99.3 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.03631090372800827, accuracy: 98.8 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.031398236751556396, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.0668, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.1018, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.0432, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.0380, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.0818, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.0715, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.0517, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.1026, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.1238, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.05250885710120201, accuracy: 98.4 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.1467157006263733, accuracy: 94.6 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.0560494139790535, accuracy: 97.9 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.046401627361774445, accuracy: 98.9 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.044383369386196136, accuracy: 98.8 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.04367443546652794, accuracy: 98.8 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.042898572981357574, accuracy: 99.0 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.041510771960020065, accuracy: 98.9 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.044545434415340424, accuracy: 98.5 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.04254714399576187, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.0608, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.1195, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.1111, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.0900, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.0580, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.0839, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.0866, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.0443, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.0801, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.0192, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.05240042880177498, accuracy: 98.1 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.05417037755250931, accuracy: 97.8 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.11426543444395065, accuracy: 96.1 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.06613313406705856, accuracy: 97.1 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.042338740080595016, accuracy: 98.4 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.03933367133140564, accuracy: 98.6 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.038355764001607895, accuracy: 98.8 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.03631066903471947, accuracy: 98.7 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.03637799993157387, accuracy: 98.8 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.035816412419080734, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.1205, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.0491, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.0842, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.0567, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.0787, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.1165, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.1140, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.1069, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.0377, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.1037, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.03756574168801308, accuracy: 98.8 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.0403861403465271, accuracy: 98.6 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.035538386553525925, accuracy: 98.7 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.03467260301113129, accuracy: 99.0 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.1585889756679535, accuracy: 95.5 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.1315593272447586, accuracy: 95.8 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.03732806071639061, accuracy: 99.1 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.0808277279138565, accuracy: 97.3 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.04048602283000946, accuracy: 98.9 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.030549556016921997, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.0666, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.0875, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.0662, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.0813, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.0553, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.0432, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.1792, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.0444, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.0479, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.06332352012395859, accuracy: 98.3 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.06385321170091629, accuracy: 98.2 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.10620376467704773, accuracy: 96.5 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.05555642023682594, accuracy: 98.5 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.0599968247115612, accuracy: 98.5 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.048947811126708984, accuracy: 98.9 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.04466467350721359, accuracy: 99.2 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.043011970818042755, accuracy: 99.0 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.042655616998672485, accuracy: 99.0 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.046400632709264755, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.0926, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.0234, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.0463, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.1183, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.1219, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.0662, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.0329, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.0531, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.0465, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.06509710103273392, accuracy: 97.9 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.0644775778055191, accuracy: 98.2 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.0696784034371376, accuracy: 97.6 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.15950071811676025, accuracy: 95.5 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.05864308401942253, accuracy: 98.3 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.057088565081357956, accuracy: 98.7 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.059935037046670914, accuracy: 98.2 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.05410713329911232, accuracy: 98.4 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.053667355328798294, accuracy: 98.5 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.05319983512163162, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.0185, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.0972, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.0762, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.1168, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.0536, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.0556, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.0408, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.0329, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.0821, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.0164, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.06760995835065842, accuracy: 97.1 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.06778460741043091, accuracy: 97.2 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.1343366652727127, accuracy: 94.9 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.057017866522073746, accuracy: 98.0 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.054134562611579895, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.049987584352493286, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.048426758497953415, accuracy: 98.3 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.046725790947675705, accuracy: 98.6 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.04612605646252632, accuracy: 98.6 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.04497404396533966, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.0633, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.1239, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.1047, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.0652, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.0927, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.0898, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.0843, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.0485, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.0704, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.0595, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.0634598508477211, accuracy: 97.4 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.22661158442497253, accuracy: 92.5 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.11360032111406326, accuracy: 95.6 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.0476740300655365, accuracy: 97.9 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.04488150402903557, accuracy: 98.1 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.04235987365245819, accuracy: 98.5 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.04242263734340668, accuracy: 98.7 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.03929590433835983, accuracy: 98.3 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.03917707875370979, accuracy: 98.8 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.03899182751774788, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.0447, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.0365, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.0529, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.1136, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.0497, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.0701, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.0338, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.0511, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.1056, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.1788, batch time: 0.07, accuracy:  94.53%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.06456944346427917, accuracy: 97.8 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.07594764232635498, accuracy: 97.7 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.09935915470123291, accuracy: 96.0 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.06182830035686493, accuracy: 98.1 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.056200627237558365, accuracy: 98.0 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.05433424934744835, accuracy: 98.3 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.05459447205066681, accuracy: 98.4 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.05427514761686325, accuracy: 98.3 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.05465150251984596, accuracy: 98.1 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.05355783924460411, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.0248, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.0895, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.1152, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.0257, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.0557, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.0797, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.0147, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.0739, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.0414, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.0843, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.041224803775548935, accuracy: 98.5 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.1783386766910553, accuracy: 94.6 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.04205116257071495, accuracy: 98.7 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.06993519514799118, accuracy: 97.5 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.038525886833667755, accuracy: 98.9 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.03634648770093918, accuracy: 98.6 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.0357995443046093, accuracy: 98.8 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.04065996780991554, accuracy: 98.9 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.03289705514907837, accuracy: 99.1 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.031684596091508865, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.0863, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.0527, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.0552, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.0851, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0894, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.0589, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0308, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.1375, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.1235, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.1005, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.04691929742693901, accuracy: 98.3 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 0.049795106053352356, accuracy: 98.3 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.061601001769304276, accuracy: 98.2 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.13200005888938904, accuracy: 95.6 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.05434337258338928, accuracy: 97.6 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.032402560114860535, accuracy: 99.0 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.03102705627679825, accuracy: 99.1 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.02927607111632824, accuracy: 99.3 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.028871210291981697, accuracy: 99.3 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.028380585834383965, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.0533, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.1112, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.0467, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.1131, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.0626, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.0260, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.0496, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.0542, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.1415, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.0576, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.04655057191848755, accuracy: 98.7 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.08357426524162292, accuracy: 97.0 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.06928287446498871, accuracy: 97.5 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.08458144962787628, accuracy: 97.3 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.03922140225768089, accuracy: 98.7 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.03476806730031967, accuracy: 99.0 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.03652911260724068, accuracy: 99.0 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.03287273645401001, accuracy: 99.1 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.03345026075839996, accuracy: 99.1 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.030896330252289772, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.0520, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.1550, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.1407, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.0325, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.0576, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.0733, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.1072, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.0743, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.1011, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.06774189323186874, accuracy: 97.7 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.06835128366947174, accuracy: 97.6 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.10497736930847168, accuracy: 96.2 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.06062765792012215, accuracy: 98.4 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.08184210956096649, accuracy: 96.7 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.05260026082396507, accuracy: 97.9 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.07210521399974823, accuracy: 97.6 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.04269411787390709, accuracy: 99.0 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.041902173310518265, accuracy: 99.0 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.04157743230462074, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.1066, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.1590, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.1066, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.0520, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.1252, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.0336, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.0984, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.1185, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.0908, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.1219, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.07265635579824448, accuracy: 97.1 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.09207089990377426, accuracy: 97.0 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.07101871073246002, accuracy: 97.3 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.05827058106660843, accuracy: 98.3 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.05781029909849167, accuracy: 98.5 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.053476765751838684, accuracy: 98.6 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.05151670053601265, accuracy: 98.6 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.0572347566485405, accuracy: 98.2 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.06088864803314209, accuracy: 97.9 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.05514751747250557, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.0413, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.1011, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.0369, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.1147, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.0859, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.1466, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.0187, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.0789, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.0310, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.0485, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.09150758385658264, accuracy: 96.7 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 0.08035245537757874, accuracy: 96.7 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.06880585849285126, accuracy: 97.5 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.05378749966621399, accuracy: 98.3 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.0864495262503624, accuracy: 97.1 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.13200946152210236, accuracy: 95.6 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.16786159574985504, accuracy: 94.6 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.05848320946097374, accuracy: 97.8 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.20144331455230713, accuracy: 94.2 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.08954505622386932, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.0295, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.0657, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.0814, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.0261, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.0861, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.1208, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.0269, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.0628, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.0817, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.0258, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.08290235698223114, accuracy: 97.3 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.08373076468706131, accuracy: 97.3 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.13984346389770508, accuracy: 95.7 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.08766890317201614, accuracy: 97.1 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.09295377880334854, accuracy: 97.1 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.06735144555568695, accuracy: 97.8 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.06491521745920181, accuracy: 97.9 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.06746120005846024, accuracy: 97.8 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.070183664560318, accuracy: 98.1 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.06402668356895447, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.0813, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.0978, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.0814, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.1610, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.1021, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.0483, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.0591, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.0761, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.1309, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.0771, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.04299316927790642, accuracy: 98.3 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.06881751865148544, accuracy: 97.2 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.074944406747818, accuracy: 97.6 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.09093533456325531, accuracy: 96.6 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.036457739770412445, accuracy: 98.8 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.030437996610999107, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.03113817237317562, accuracy: 98.9 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.029841983690857887, accuracy: 99.4 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.027699952945113182, accuracy: 99.3 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.03007401153445244, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.0804, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.0341, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.0802, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.0781, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.0319, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.0679, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.2211, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.0820, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.0173, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.0293, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.0540892630815506, accuracy: 97.9 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.06940895318984985, accuracy: 97.6 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.04669740051031113, accuracy: 98.4 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.038384370505809784, accuracy: 98.7 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.06254937499761581, accuracy: 98.0 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.03668525069952011, accuracy: 98.9 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.041844889521598816, accuracy: 98.5 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.06214927136898041, accuracy: 97.6 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.2935428321361542, accuracy: 90.8 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.03294523060321808, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.0353, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.1421, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.0783, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.0923, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.0410, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.0790, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.0655, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.0959, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.08455017954111099, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.08932813256978989, accuracy: 97.2 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.07950533181428909, accuracy: 97.8 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.07280254364013672, accuracy: 98.3 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.09890534728765488, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.072719506919384, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.16372598707675934, accuracy: 95.3 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.12008123099803925, accuracy: 96.8 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.055233508348464966, accuracy: 98.1 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.09250320494174957, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.0547, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.1372, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.1092, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.0955, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.1260, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.1388, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.1204, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.0399, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.0897, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.0253, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.06638653576374054, accuracy: 97.7 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.336323618888855, accuracy: 90.7 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.07858201861381531, accuracy: 97.3 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.05586075037717819, accuracy: 98.5 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.0818382054567337, accuracy: 97.2 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.04985031485557556, accuracy: 98.6 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.04983006790280342, accuracy: 98.8 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.047517310827970505, accuracy: 98.7 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.05002461373806, accuracy: 98.5 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.045082900673151016, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.0835, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.0413, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.1622, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.1559, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.0662, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.0622, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.1011, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.0812, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.0168, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.0332, batch time: 0.44, accuracy:  99.22%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.04838896915316582, accuracy: 98.5 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.06825928390026093, accuracy: 97.7 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.048647765070199966, accuracy: 98.3 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.06078629940748215, accuracy: 98.1 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.04284302890300751, accuracy: 98.4 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.04194209724664688, accuracy: 98.5 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.04122358560562134, accuracy: 98.8 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.041401322931051254, accuracy: 99.0 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.039374466985464096, accuracy: 99.2 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.04155083745718002, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.1446, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.0859, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.0300, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.0835, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.0621, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.1202, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.0685, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0735, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.0425, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.0872, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.06589766591787338, accuracy: 97.7 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.09493301808834076, accuracy: 97.0 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.2151048183441162, accuracy: 92.5 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.15375778079032898, accuracy: 94.6 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.09116675704717636, accuracy: 95.9 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.045215241611003876, accuracy: 98.1 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.042642589658498764, accuracy: 98.7 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.04032793641090393, accuracy: 99.0 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.04014485701918602, accuracy: 98.9 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.03945185989141464, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.0553, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.0586, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.0551, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.1122, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.0839, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.0626, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.0111, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.0315, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.0856, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.1196, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.05942762270569801, accuracy: 98.0 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.09014750272035599, accuracy: 97.2 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.0799163430929184, accuracy: 96.8 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.04679524153470993, accuracy: 98.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.04456392675638199, accuracy: 98.4 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.04120069742202759, accuracy: 98.6 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.03971923887729645, accuracy: 98.5 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.03662342205643654, accuracy: 98.9 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.03699008375406265, accuracy: 99.0 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.03699229285120964, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.0175, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.0786, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.1119, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.0833, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.1761, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.0513, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.1007, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.0583, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.0408, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.07674682140350342, accuracy: 97.4 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.06851828843355179, accuracy: 97.7 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.08073591440916061, accuracy: 97.2 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.06299447268247604, accuracy: 97.7 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.09786705672740936, accuracy: 96.3 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.08516724407672882, accuracy: 97.4 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.0985349640250206, accuracy: 96.7 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.06722157448530197, accuracy: 97.7 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.07007443904876709, accuracy: 97.0 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.052774254232645035, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.0647, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.1314, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.0347, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.0585, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.0599, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.0236, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.0259, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.0897, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.0760, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.1356, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.0534432977437973, accuracy: 98.0 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.07938196510076523, accuracy: 96.6 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.0898704007267952, accuracy: 96.4 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.04743388667702675, accuracy: 98.3 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.07711424678564072, accuracy: 97.2 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.04453907907009125, accuracy: 98.3 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.041323985904455185, accuracy: 98.6 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.039816323667764664, accuracy: 98.4 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.040701981633901596, accuracy: 98.5 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.03855814412236214, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.0276, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.0468, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.0373, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.0492, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.0862, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.0942, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.0577, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.0494, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.0548, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.0358, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.04537677392363548, accuracy: 98.6 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.05019645020365715, accuracy: 98.8 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.04182744398713112, accuracy: 98.7 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.03863475099205971, accuracy: 98.7 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.048996951431035995, accuracy: 98.6 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.05649557709693909, accuracy: 98.5 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.06656849384307861, accuracy: 97.5 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.03257431089878082, accuracy: 99.0 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.031125884503126144, accuracy: 99.4 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.03306762874126434, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.0708, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.0575, batch time: 0.35, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.0992, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.0701, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.0592, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.0468, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.0596, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.1435, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.0593, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.0279, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.06816408783197403, accuracy: 97.4 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.07193373888731003, accuracy: 97.5 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.06646640598773956, accuracy: 97.4 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.06024805083870888, accuracy: 97.9 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.10012101382017136, accuracy: 96.1 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.08202636241912842, accuracy: 97.0 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.07332178950309753, accuracy: 97.5 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.05637107789516449, accuracy: 98.3 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.05148658528923988, accuracy: 98.4 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.05326808616518974, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.0641, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.1211, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.0377, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.1205, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.1099, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.0547, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.0390, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.0628, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.0434, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.0294, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.04530007019639015, accuracy: 98.6 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.04426182433962822, accuracy: 98.5 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.04126007482409477, accuracy: 99.0 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.04050009697675705, accuracy: 99.0 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.05474580451846123, accuracy: 97.8 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.07697539031505585, accuracy: 97.3 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.036952219903469086, accuracy: 98.7 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.033786553889513016, accuracy: 99.1 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.032296471297740936, accuracy: 99.2 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.031851980835199356, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.0454, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.0866, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.0608, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.0504, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.0284, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.1080, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.1058, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.0434, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.0865, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.1098, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.06390729546546936, accuracy: 97.8 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 0.06593706458806992, accuracy: 97.8 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.05944957584142685, accuracy: 97.7 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.05594588816165924, accuracy: 98.1 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.05313868075609207, accuracy: 98.0 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.05159247666597366, accuracy: 98.3 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.07854197919368744, accuracy: 97.1 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.06888306885957718, accuracy: 97.5 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.06952620297670364, accuracy: 97.6 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.04336019977927208, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.0898, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.0220, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.0672, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.0831, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.0058, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.0292, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.0936, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.0403, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.0427, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.0593, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.05171485245227814, accuracy: 97.8 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.05197874829173088, accuracy: 98.2 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.04837346822023392, accuracy: 98.3 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.04837346822023392, accuracy: 98.3 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.044378943741321564, accuracy: 98.7 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.043436355888843536, accuracy: 98.7 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.04451841488480568, accuracy: 98.7 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.04267532378435135, accuracy: 98.9 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.04368092492222786, accuracy: 99.0 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.0457199402153492, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.0833, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.0979, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.0189, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.1598, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.0697, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.0555, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.1025, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.0689, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.1348, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.0716, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.0958743691444397, accuracy: 96.1 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.09974639862775803, accuracy: 96.0 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.09703295677900314, accuracy: 96.0 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.07081584632396698, accuracy: 97.0 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.09804927557706833, accuracy: 95.7 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.06830218434333801, accuracy: 97.5 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.05804629996418953, accuracy: 98.0 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.05715464428067207, accuracy: 98.4 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.05696359649300575, accuracy: 98.2 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.05590775981545448, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.0821, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.0769, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.0904, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.0767, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.1087, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.0241, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.0677, batch time: 0.36, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.0915, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.0364, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.0861, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.04980340227484703, accuracy: 97.9 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.10907402634620667, accuracy: 96.1 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.06483300775289536, accuracy: 97.3 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.07093071192502975, accuracy: 97.5 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.040174443274736404, accuracy: 98.6 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.03788544610142708, accuracy: 98.7 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.038304466754198074, accuracy: 98.7 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.0362948477268219, accuracy: 98.7 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.04053135961294174, accuracy: 98.6 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.035525403916835785, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.0314, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.0619, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0269, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.1037, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.1132, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.1504, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.0714, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0247, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.0615, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.09646444767713547, accuracy: 96.4 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.2020413726568222, accuracy: 93.6 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.0748886987566948, accuracy: 97.3 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.12486488372087479, accuracy: 95.9 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.07485216110944748, accuracy: 97.2 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.13892851769924164, accuracy: 95.6 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.04977007210254669, accuracy: 98.1 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.04455672949552536, accuracy: 98.3 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.0424884669482708, accuracy: 98.7 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.03923008590936661, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.0843, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.0622, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.0322, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.0525, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.0904, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.1170, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.0556, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.0709, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.0240, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.1896, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.055568620562553406, accuracy: 98.4 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.05326834321022034, accuracy: 98.3 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.05082172155380249, accuracy: 98.2 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.05042979493737221, accuracy: 98.1 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.10734669864177704, accuracy: 95.8 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.04487496241927147, accuracy: 98.7 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.04272449389100075, accuracy: 98.7 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.04263000562787056, accuracy: 98.7 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.04182176664471626, accuracy: 98.7 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.03956032916903496, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.0988, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.0436, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.0154, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.0115, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.0239, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.0832, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.0234, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.0687, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.0297, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.0430, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.04553379863500595, accuracy: 98.7 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.1365392953157425, accuracy: 95.7 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.062494706362485886, accuracy: 97.9 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.10380639880895615, accuracy: 96.8 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.04075663164258003, accuracy: 98.9 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.03722301498055458, accuracy: 99.2 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.037484124302864075, accuracy: 99.2 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.03736957162618637, accuracy: 99.2 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.03584884852170944, accuracy: 99.2 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.03867502138018608, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.0227, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.0991, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.0983, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.0484, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.0696, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.0928, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.0597, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.1298, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.0558, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.1194, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.06877158582210541, accuracy: 97.8 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.06390251219272614, accuracy: 97.3 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.06618474423885345, accuracy: 97.6 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.05587342381477356, accuracy: 98.1 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.054484136402606964, accuracy: 98.0 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.0897001102566719, accuracy: 96.7 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.9898555874824524, accuracy: 80.1 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.04689500108361244, accuracy: 98.3 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.043087929487228394, accuracy: 98.7 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.04305431619286537, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.0394, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.1184, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.0603, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.0741, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.1018, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.0496, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.0355, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.2059, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.0560, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.1800, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.06540150940418243, accuracy: 97.9 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.06563549488782883, accuracy: 97.9 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.06074577569961548, accuracy: 98.5 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.06064922362565994, accuracy: 98.3 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.08037040382623672, accuracy: 97.6 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.0891513004899025, accuracy: 97.0 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.04598236829042435, accuracy: 98.5 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.04615746811032295, accuracy: 98.9 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.04394477978348732, accuracy: 98.8 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.04411309212446213, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.1009, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.0652, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.0892, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.0402, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.0837, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.0858, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.0538, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.0458, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.0915, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.08343233913183212, accuracy: 97.1 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.0788320004940033, accuracy: 97.4 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.08350618183612823, accuracy: 96.8 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.06198202073574066, accuracy: 97.9 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.09277178347110748, accuracy: 96.5 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.07744396477937698, accuracy: 96.4 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.06348852813243866, accuracy: 97.3 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.15171164274215698, accuracy: 95.4 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.06497114896774292, accuracy: 97.5 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.1122344508767128, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.0538, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.0561, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.0375, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.0685, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0865, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.0952, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.0286, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.0970, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.0849, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.0595, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.04736366868019104, accuracy: 98.2 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.07110808044672012, accuracy: 97.1 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.04952356591820717, accuracy: 98.0 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.0368778221309185, accuracy: 99.1 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.034310806542634964, accuracy: 98.9 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.03593827784061432, accuracy: 99.1 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.04454726725816727, accuracy: 98.0 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.02774958498775959, accuracy: 99.1 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.025534218177199364, accuracy: 99.0 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.025614717975258827, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.0556, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.0268, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.0408, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.1332, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.0560, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.1226, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.0635, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.0276, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.0693, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.1143, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.07553555071353912, accuracy: 97.0 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.06876184046268463, accuracy: 97.7 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.07188834249973297, accuracy: 97.5 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.05811206251382828, accuracy: 97.6 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.07089217007160187, accuracy: 97.2 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.057894185185432434, accuracy: 97.8 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.05838485434651375, accuracy: 98.4 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.0493035726249218, accuracy: 98.6 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.05171594023704529, accuracy: 98.7 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.07644380629062653, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.0233, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.0661, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.0993, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.0589, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.0236, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.1607, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.1142, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.1036, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.0707, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.0560, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.04067797213792801, accuracy: 98.8 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.041147299110889435, accuracy: 98.9 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.06679937243461609, accuracy: 97.5 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.06835497915744781, accuracy: 97.6 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.03288247063755989, accuracy: 98.8 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.030309202149510384, accuracy: 99.0 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.031114280223846436, accuracy: 99.2 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.03152073174715042, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.031059084460139275, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.02892271615564823, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.0859, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.0388, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.1014, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.1437, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.0899, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.0708, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.0470, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.0432, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.0820, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.1098, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.05943692848086357, accuracy: 97.9 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.052004847675561905, accuracy: 98.0 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.06953545659780502, accuracy: 97.5 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.048451732844114304, accuracy: 98.3 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.05498267710208893, accuracy: 98.1 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.04150817170739174, accuracy: 98.4 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.038407303392887115, accuracy: 98.6 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.034489456564188004, accuracy: 99.1 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.03017837181687355, accuracy: 99.3 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.02953866682946682, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.0604, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.1709, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.0914, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.0875, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.0562, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.0371, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.0236, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.1007, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.2460, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.04730059951543808, accuracy: 98.0 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 4.941147804260254, accuracy: 43.1 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.04354000464081764, accuracy: 98.8 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.04192183539271355, accuracy: 98.8 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.20243054628372192, accuracy: 93.1 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.059839069843292236, accuracy: 97.9 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.04280063137412071, accuracy: 99.1 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.08717608451843262, accuracy: 96.5 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.03551327437162399, accuracy: 99.0 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.03493226319551468, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.0468, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.0521, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.0881, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.0549, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.0402, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.0687, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.1010, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.0415, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.1049, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.1803, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.10022823512554169, accuracy: 96.5 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.10039082169532776, accuracy: 96.4 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.09513343125581741, accuracy: 97.0 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.0870271846652031, accuracy: 96.9 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.06624516099691391, accuracy: 97.4 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.05271415039896965, accuracy: 98.3 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.05062155798077583, accuracy: 98.4 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.050013910979032516, accuracy: 98.4 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.048526063561439514, accuracy: 98.3 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.04598642885684967, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.1377, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.0378, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.0577, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.0766, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.0642, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.0439, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.0202, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.0488, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.0684, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.0952, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.057639092206954956, accuracy: 98.5 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.058840855956077576, accuracy: 98.2 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.09349893033504486, accuracy: 96.6 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.05625386908650398, accuracy: 98.6 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.10208532214164734, accuracy: 96.4 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.07533319294452667, accuracy: 97.3 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.05123720318078995, accuracy: 98.4 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.04873795434832573, accuracy: 98.7 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.0485045500099659, accuracy: 98.7 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.04740423709154129, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.1195, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.0630, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.0208, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.0756, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.0987, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.0188, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.0512, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.0593, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.0351, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.04767153784632683, accuracy: 98.1 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.16570177674293518, accuracy: 94.1 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.0507204569876194, accuracy: 97.8 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.07097085565328598, accuracy: 97.2 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.06977352499961853, accuracy: 97.8 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.03580925986170769, accuracy: 98.6 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.035000767558813095, accuracy: 98.8 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.034872353076934814, accuracy: 98.5 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.033775508403778076, accuracy: 98.6 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.03303380310535431, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.2334, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.0637, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.1276, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.0722, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.0631, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.0487, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.0333, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.0996, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.0212, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.0977, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.052212052047252655, accuracy: 98.3 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 2.550276517868042, accuracy: 65.5 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.04657357186079025, accuracy: 98.6 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.045603152364492416, accuracy: 98.7 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.0752033144235611, accuracy: 97.4 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.09376905858516693, accuracy: 96.6 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.04977257549762726, accuracy: 98.1 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.07954365760087967, accuracy: 97.3 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.06378386169672012, accuracy: 97.7 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.18757416307926178, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.0470, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.0469, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.0404, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.1229, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.0840, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.0835, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.0623, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.0817, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.0516, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.05353932082653046, accuracy: 97.9 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.057130202651023865, accuracy: 97.8 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.08181706815958023, accuracy: 96.8 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.05085653066635132, accuracy: 98.1 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.08052615076303482, accuracy: 96.8 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.06813210248947144, accuracy: 98.0 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.3254057765007019, accuracy: 90.0 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.04912787303328514, accuracy: 98.2 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.04514429345726967, accuracy: 98.5 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.045629698783159256, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.1079, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.0637, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.0419, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.0709, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.0306, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.0233, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.0465, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.0156, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.0768, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.06221171095967293, accuracy: 97.8 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.05792229622602463, accuracy: 98.1 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.0601261742413044, accuracy: 98.2 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.047193218022584915, accuracy: 98.5 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.07324033975601196, accuracy: 97.5 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.10021016001701355, accuracy: 95.7 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.16828814148902893, accuracy: 94.3 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.03983341157436371, accuracy: 99.2 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.03941444307565689, accuracy: 99.1 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.03975322097539902, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.0467, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.0857, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.1615, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.0521, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.0823, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.0419, batch time: 0.42, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.0795, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.0728, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.0768, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.0665, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.049984101206064224, accuracy: 98.3 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 0.05096612125635147, accuracy: 98.2 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.04247555136680603, accuracy: 98.4 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.05396805703639984, accuracy: 97.9 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.0569470077753067, accuracy: 98.0 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.04061765596270561, accuracy: 98.5 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.032369714230298996, accuracy: 99.1 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.06236104294657707, accuracy: 97.6 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.029768122360110283, accuracy: 98.7 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.042909346520900726, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.0132, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.0973, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.0941, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.0336, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.0738, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.0446, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.0835, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.0427, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.0872, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.0398, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.03909432888031006, accuracy: 98.6 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.04313390702009201, accuracy: 98.5 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.06459594517946243, accuracy: 97.8 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.028181202709674835, accuracy: 99.2 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.04493780434131622, accuracy: 97.8 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.025096474215388298, accuracy: 99.4 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.024423543363809586, accuracy: 99.3 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.022433344274759293, accuracy: 99.3 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.023313291370868683, accuracy: 99.3 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.02253379486501217, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.0446, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.1235, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.0951, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.0571, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.0709, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.0757, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.0548, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.0416, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.0483, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.0472, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.06777557730674744, accuracy: 97.9 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.06907278299331665, accuracy: 98.0 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.09152119606733322, accuracy: 96.9 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.06880269199609756, accuracy: 97.7 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.05297047272324562, accuracy: 98.2 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.04900224134325981, accuracy: 98.2 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.04803408682346344, accuracy: 98.2 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.04564565047621727, accuracy: 98.4 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.043469224125146866, accuracy: 98.5 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.04498976469039917, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.0140, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.1015, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.0145, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.1453, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.0567, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.0735, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.0522, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.1445, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.0350, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.049524903297424316, accuracy: 97.8 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.045349881052970886, accuracy: 98.2 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.07014904916286469, accuracy: 97.3 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.04285530373454094, accuracy: 98.6 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.056722622364759445, accuracy: 97.9 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.2918347716331482, accuracy: 89.4 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.31896063685417175, accuracy: 89.0 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.0384889654815197, accuracy: 98.7 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.037522055208683014, accuracy: 98.5 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.042724814265966415, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.0239, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.0291, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.0339, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.1219, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.1061, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.0226, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.1200, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.0797, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.1603, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.0816, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.04975830763578415, accuracy: 98.1 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 0.05287011340260506, accuracy: 97.9 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.04468770697712898, accuracy: 98.8 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.04425195977091789, accuracy: 98.7 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.10364972800016403, accuracy: 96.7 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.040450990200042725, accuracy: 99.2 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.0410604402422905, accuracy: 99.2 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.039013367146253586, accuracy: 99.0 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.03801102191209793, accuracy: 99.4 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.03732152283191681, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.0164, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.0390, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.0748, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.0187, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.0702, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.0511, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.0628, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.0426, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.0519, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.1057, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.07586157321929932, accuracy: 97.2 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.07411140203475952, accuracy: 97.2 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.0726538673043251, accuracy: 97.3 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.07254423201084137, accuracy: 97.3 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.1085805669426918, accuracy: 96.3 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.0877363458275795, accuracy: 96.8 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.06013057753443718, accuracy: 98.0 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.05567583441734314, accuracy: 98.3 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.05427826568484306, accuracy: 98.3 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.05570092424750328, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.0308, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.0325, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.0387, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.0838, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.0629, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.0446, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.0846, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.0565, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.1424, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.0635, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.051864393055438995, accuracy: 98.1 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.0928979367017746, accuracy: 96.7 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.12766288220882416, accuracy: 95.2 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.09450005739927292, accuracy: 96.9 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.07535608112812042, accuracy: 97.0 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.05304812267422676, accuracy: 98.4 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.13902635872364044, accuracy: 95.1 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.03810179978609085, accuracy: 98.9 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.038828037679195404, accuracy: 98.9 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.03729270026087761, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.1163, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.1274, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.0589, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.0488, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.0158, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.0874, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.0406, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.0532, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.1137, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.0943, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.05132928490638733, accuracy: 97.8 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.05074462294578552, accuracy: 97.7 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.10557872802019119, accuracy: 96.4 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.10583143681287766, accuracy: 96.4 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.08160952478647232, accuracy: 97.2 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.040540337562561035, accuracy: 98.6 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.040307413786649704, accuracy: 98.6 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.03585390746593475, accuracy: 98.6 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.03626555949449539, accuracy: 98.6 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.034305229783058167, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.0593, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.0521, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.0760, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.0285, batch time: 0.37, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.0191, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0629, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.0454, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.0312, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.1509, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.0674, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.027729380875825882, accuracy: 99.0 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.16629798710346222, accuracy: 94.2 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.04435524716973305, accuracy: 98.4 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.0608050711452961, accuracy: 97.7 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.01901059038937092, accuracy: 99.4 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.01768532022833824, accuracy: 99.5 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.015901001170277596, accuracy: 99.6 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.015216873027384281, accuracy: 99.6 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.016898399218916893, accuracy: 99.4 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.0140693299472332, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0715, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.0219, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.0268, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.1226, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.0311, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.0256, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.0728, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.0914, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.0333, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.0428, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.028424696996808052, accuracy: 99.1 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.02837420254945755, accuracy: 99.0 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.037895385175943375, accuracy: 99.0 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.12416653335094452, accuracy: 96.1 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.022558169439435005, accuracy: 99.3 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.022016823291778564, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.022465847432613373, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.020047303289175034, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.020535707473754883, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.017727622762322426, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.0446, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.0733, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.0156, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.0748, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.0870, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.0635, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.0434, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.0526, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.0652, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.0685, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.041705645620822906, accuracy: 98.5 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 2.344291925430298, accuracy: 73.7 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.05648206174373627, accuracy: 97.7 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.03700103238224983, accuracy: 99.0 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.031880177557468414, accuracy: 99.0 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.03137091174721718, accuracy: 98.9 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.030021907761693, accuracy: 98.9 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.02949119731783867, accuracy: 99.1 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.0299528855830431, accuracy: 99.0 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.028576215729117393, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.0502, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.0633, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.0458, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.0441, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.0448, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.0158, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.1096, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.0684, batch time: 0.37, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.0455, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.0722, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.047412652522325516, accuracy: 97.9 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.04757203534245491, accuracy: 97.8 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.06653869897127151, accuracy: 97.1 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.035758521407842636, accuracy: 98.8 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.03197053447365761, accuracy: 99.4 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.08616504073143005, accuracy: 97.1 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.03084898181259632, accuracy: 99.0 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.028301529586315155, accuracy: 99.2 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.029891785234212875, accuracy: 99.2 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.027322065085172653, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.0985, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.0645, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.0718, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.0755, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.0392, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.1446, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.0678, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.0303, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.0894, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.0647, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.09535904228687286, accuracy: 96.6 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.7134739756584167, accuracy: 84.5 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.10010110586881638, accuracy: 96.3 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.07993056625127792, accuracy: 97.0 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.31657519936561584, accuracy: 91.2 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.10989853739738464, accuracy: 96.2 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.05856368690729141, accuracy: 97.6 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.055380597710609436, accuracy: 97.8 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.05385025963187218, accuracy: 97.7 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.05221586674451828, accuracy: 98.1 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9080109000205994, 0.6745071411132812, 0.5965717434883118, 0.4569703936576843, 0.4962361752986908, 0.3632756769657135, 0.31983333826065063, 0.33773085474967957, 0.2502496540546417, 0.3268689215183258, 0.3910798132419586, 0.1881592571735382, 0.17923879623413086, 0.23468224704265594, 0.23602499067783356, 0.20178388059139252, 0.22276410460472107, 0.2933639883995056, 0.12821371853351593, 0.1999405324459076, 0.08632693439722061, 0.12902003526687622, 0.2851587235927582, 0.2774178683757782, 0.31896069645881653, 0.12044165283441544, 0.22810661792755127, 0.1659553498029709, 0.20459838211536407, 0.2180968075990677, 0.21686771512031555, 0.20007765293121338, 0.23653586208820343, 0.18435977399349213, 0.18297278881072998, 0.14365573227405548, 0.14089739322662354, 0.10317806154489517, 0.10293370485305786, 0.10783382505178452, 0.19829177856445312, 0.18485097587108612, 0.1498844176530838, 0.07288859039545059, 0.2406650334596634, 0.1704312115907669, 0.0954568013548851, 0.10934330523014069, 0.16870562732219696, 0.15462557971477509, 0.10168325901031494, 0.15447969734668732, 0.12098101526498795, 0.13605694472789764, 0.08153343200683594, 0.14907971024513245, 0.10513702780008316, 0.1851262003183365, 0.05246446281671524, 0.1911516934633255, 0.12349998950958252, 0.10481095314025879, 0.1329692304134369, 0.07528301328420639, 0.08077666908502579, 0.06825534254312515, 0.168135866522789, 0.12924981117248535, 0.10804552584886551, 0.08844833076000214, 0.0918668657541275, 0.06944562494754791, 0.10813559591770172, 0.028049184009432793, 0.19523926079273224, 0.1261049062013626, 0.048318710178136826, 0.08002257347106934, 0.1169232577085495, 0.04440048336982727, 0.054302237927913666, 0.026517128571867943, 0.10052759200334549, 0.07449967414140701, 0.08601550757884979, 0.10498291999101639, 0.1065954938530922, 0.25140443444252014, 0.10466309636831284, 0.1015271544456482, 0.13457967340946198, 0.1265038698911667, 0.11115331202745438, 0.08614270389080048, 0.15477381646633148, 0.046773966401815414, 0.1547774225473404, 0.09313737601041794, 0.06356161087751389, 0.1470845639705658, 0.23732085525989532, 0.015118279494345188, 0.11898602545261383, 0.09009384363889694, 0.13046927750110626, 0.1235329732298851, 0.09191172569990158, 0.02353603206574917, 0.1602686494588852, 0.1153724268078804, 0.06401291489601135, 0.02029639109969139, 0.08292149752378464, 0.0877017229795456, 0.07429325580596924, 0.055892813950777054, 0.029918495565652847, 0.08225082606077194, 0.034651707857847214, 0.07470609247684479, 0.03968147188425064, 0.1303323656320572, 0.08217742294073105, 0.043614424765110016, 0.01059186551719904, 0.12571436166763306, 0.11042173951864243, 0.09752624481916428, 0.04015352949500084, 0.11764699965715408, 0.07263850420713425, 0.03502091392874718, 0.05840170010924339, 0.07788807898759842, 0.10173159837722778, 0.07376605272293091, 0.09693087637424469, 0.11909724026918411, 0.12214308232069016, 0.10119558125734329, 0.04302841052412987, 0.10142426192760468, 0.03550693020224571, 0.08020403236150742, 0.08113443106412888, 0.05012311786413193, 0.13449051976203918, 0.020026296377182007, 0.0679592713713646, 0.04873254522681236, 0.08190519362688065, 0.1179700568318367, 0.10596153885126114, 0.10832162946462631, 0.0688374787569046, 0.007781307213008404, 0.030531365424394608, 0.07890044152736664, 0.09113086760044098, 0.057500697672367096, 0.11409760266542435, 0.01741054840385914, 0.05919349193572998, 0.05447535961866379, 0.030746150761842728, 0.0334070585668087, 0.088854119181633, 0.020940562710165977, 0.09895730763673782, 0.05452515929937363, 0.0654049962759018, 0.02530817687511444, 0.08933047950267792, 0.06601922959089279, 0.1339714527130127, 0.110054150223732, 0.06529226899147034, 0.0980798676609993, 0.08029096573591232, 0.12549468874931335, 0.03911895677447319, 0.0637049525976181, 0.039451826363801956, 0.046581070870161057, 0.023232895880937576, 0.03953280299901962, 0.05557291954755783, 0.042004745453596115, 0.07817099988460541, 0.06657665222883224, 0.0597447045147419, 0.08371084928512573, 0.06115574389696121, 0.06506475061178207, 0.058026231825351715, 0.10804571956396103, 0.023365335538983345, 0.06853719055652618, 0.05821162462234497, 0.20859797298908234]\n",
      "[66.96428571428571, 80.35714285714286, 85.71428571428571, 83.03571428571429, 81.25, 88.39285714285714, 87.5, 89.28571428571429, 91.07142857142857, 91.07142857142857, 91.07142857142857, 93.75, 93.75, 93.75, 93.75, 94.64285714285714, 90.17857142857143, 91.07142857142857, 95.53571428571429, 92.85714285714286, 97.32142857142857, 95.53571428571429, 93.75, 93.75, 91.96428571428571, 97.32142857142857, 92.85714285714286, 95.53571428571429, 93.75, 91.96428571428571, 91.07142857142857, 93.75, 91.07142857142857, 96.42857142857143, 91.96428571428571, 95.53571428571429, 93.75, 96.42857142857143, 96.42857142857143, 94.64285714285714, 93.75, 95.53571428571429, 93.75, 97.32142857142857, 93.75, 93.75, 96.42857142857143, 96.42857142857143, 93.75, 93.75, 96.42857142857143, 94.64285714285714, 95.53571428571429, 96.42857142857143, 97.32142857142857, 94.64285714285714, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 96.42857142857143, 97.32142857142857, 96.42857142857143, 98.21428571428571, 98.21428571428571, 98.21428571428571, 95.53571428571429, 96.42857142857143, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 96.42857142857143, 98.21428571428571, 94.64285714285714, 96.42857142857143, 99.10714285714286, 97.32142857142857, 95.53571428571429, 99.10714285714286, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 93.75, 97.32142857142857, 91.07142857142857, 96.42857142857143, 94.64285714285714, 93.75, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 97.32142857142857, 94.64285714285714, 97.32142857142857, 97.32142857142857, 94.64285714285714, 91.96428571428571, 100.0, 95.53571428571429, 95.53571428571429, 95.53571428571429, 94.64285714285714, 96.42857142857143, 99.10714285714286, 93.75, 97.32142857142857, 96.42857142857143, 100.0, 97.32142857142857, 95.53571428571429, 96.42857142857143, 99.10714285714286, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 94.64285714285714, 98.21428571428571, 99.10714285714286, 100.0, 96.42857142857143, 95.53571428571429, 96.42857142857143, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 96.42857142857143, 95.53571428571429, 97.32142857142857, 96.42857142857143, 94.64285714285714, 96.42857142857143, 97.32142857142857, 99.10714285714286, 96.42857142857143, 98.21428571428571, 99.10714285714286, 93.75, 99.10714285714286, 97.32142857142857, 98.21428571428571, 97.32142857142857, 94.64285714285714, 97.32142857142857, 95.53571428571429, 97.32142857142857, 100.0, 99.10714285714286, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 100.0, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 100.0, 96.42857142857143, 98.21428571428571, 97.32142857142857, 99.10714285714286, 97.32142857142857, 96.42857142857143, 95.53571428571429, 95.53571428571429, 97.32142857142857, 97.32142857142857, 96.42857142857143, 94.64285714285714, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 97.32142857142857, 97.32142857142857, 98.21428571428571, 96.42857142857143, 98.21428571428571, 97.32142857142857, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 99.10714285714286, 91.96428571428571]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.7851460576057434, 0.5637038350105286, 0.5420746207237244, 0.34920734167099, 0.38214829564094543, 0.19616656005382538, 0.390805184841156, 0.264143168926239, 0.19532908499240875, 0.1894717663526535, 0.22778603434562683, 0.13902343809604645, 0.19654493033885956, 0.18423175811767578, 0.19679059088230133, 0.1936047077178955, 0.1268329620361328, 0.16474607586860657, 0.11724834144115448, 0.20386622846126556, 0.04713213071227074, 0.0887191891670227, 0.2593144476413727, 0.2441752701997757, 0.048412106931209564, 0.12650121748447418, 0.1063842624425888, 0.11777462810277939, 0.21091096103191376, 0.17820271849632263, 0.15553784370422363, 0.18019436299800873, 0.09419118613004684, 0.0698174238204956, 0.1437043845653534, 0.0773288831114769, 0.18263664841651917, 0.15894773602485657, 0.1342155784368515, 0.07758193463087082, 0.0761612206697464, 0.10287091881036758, 0.08002384752035141, 0.06210542470216751, 0.07750963419675827, 0.29903700947761536, 0.13122527301311493, 0.08047519624233246, 0.09786634892225266, 0.03710215911269188, 0.07893260568380356, 0.20678620040416718, 0.13928858935832977, 0.07576180249452591, 0.13929857313632965, 0.049123551696538925, 0.06043660640716553, 0.04826120287179947, 0.1379205733537674, 0.10722009092569351, 0.10731107741594315, 0.13895076513290405, 0.14214272797107697, 0.04032004997134209, 0.031011288985610008, 0.12665481865406036, 0.019322287291288376, 0.03232140094041824, 0.1072009950876236, 0.07903237640857697, 0.2582106590270996, 0.057585638016462326, 0.07120381295681, 0.17948104441165924, 0.02759365737438202, 0.07343725860118866, 0.09247636049985886, 0.036617279052734375, 0.026302780956029892, 0.08696263283491135, 0.08046130836009979, 0.17218017578125, 0.11985071748495102, 0.1403731405735016, 0.08510155230760574, 0.07173147052526474, 0.04333014041185379, 0.10304577648639679, 0.08710026741027832, 0.08567804843187332, 0.14678451418876648, 0.061581600457429886, 0.09153060615062714, 0.07141439616680145, 0.06489415466785431, 0.027232874184846878, 0.07124467194080353, 0.1579284518957138, 0.030184103175997734, 0.05412973091006279, 0.06742018461227417, 0.08510424941778183, 0.15274827182292938, 0.08394268900156021, 0.06305151432752609, 0.056311435997486115, 0.05288488790392876, 0.05147498473525047, 0.0630447119474411, 0.029992956668138504, 0.12276951223611832, 0.11408579349517822, 0.2478996217250824, 0.09730955213308334, 0.09814775735139847, 0.15089812874794006, 0.031817249953746796, 0.03880956396460533, 0.034264300018548965, 0.10150768607854843, 0.058996137231588364, 0.07140914350748062, 0.0987752228975296, 0.024511173367500305, 0.0315927118062973, 0.08458546549081802, 0.05902286618947983, 0.12580014765262604, 0.07357534021139145, 0.05594825744628906, 0.12097673118114471, 0.05977540463209152, 0.042559172958135605, 0.03602229803800583, 0.10455860942602158, 0.10860250145196915, 0.05071258172392845, 0.05889898166060448, 0.06102382391691208, 0.07412650436162949, 0.10382433235645294, 0.07210692018270493, 0.04509314149618149, 0.1060018390417099, 0.059130582958459854, 0.07708600908517838, 0.056486643850803375, 0.0528167188167572, 0.029062164947390556, 0.10040052980184555, 0.04673455283045769, 0.05828046798706055, 0.07255307585000992, 0.04519138112664223, 0.08186684548854828, 0.04611990600824356, 0.08237038552761078, 0.054950959980487823, 0.08831409364938736, 0.06820104271173477, 0.038018275052309036, 0.12234993278980255, 0.08238237351179123, 0.040849048644304276, 0.0322626456618309, 0.03353416547179222, 0.05538661405444145, 0.11490869522094727, 0.13324418663978577, 0.02504158392548561, 0.10135437548160553, 0.06468857079744339, 0.1409846991300583, 0.04971366748213768, 0.03275028616189957, 0.03990314155817032, 0.026818962767720222, 0.09649360924959183, 0.030868304893374443, 0.07813842594623566, 0.02931353636085987, 0.040195100009441376, 0.08059387654066086, 0.060914237052202225, 0.08855114132165909, 0.07271069288253784, 0.09324382990598679, 0.04651874303817749, 0.08334646373987198, 0.0387013740837574, 0.12071596086025238, 0.08144911378622055, 0.09773600846529007, 0.058309342712163925, 0.11344309151172638, 0.05000309273600578, 0.051452379673719406, 0.07206863909959793, 0.04083022475242615, 0.03631418198347092]\n",
    "# acc_list_epoch_ = [66.96428571428571, 83.92857142857143, 87.5, 91.96428571428571, 90.17857142857143, 94.64285714285714, 91.07142857142857, 93.75, 95.53571428571429, 94.64285714285714, 93.75, 95.53571428571429, 93.75, 93.75, 93.75, 94.64285714285714, 96.42857142857143, 95.53571428571429, 93.75, 91.07142857142857, 98.21428571428571, 96.42857142857143, 93.75, 93.75, 98.21428571428571, 98.21428571428571, 96.42857142857143, 96.42857142857143, 91.96428571428571, 93.75, 93.75, 93.75, 97.32142857142857, 97.32142857142857, 96.42857142857143, 97.32142857142857, 96.42857142857143, 94.64285714285714, 95.53571428571429, 96.42857142857143, 98.21428571428571, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 91.07142857142857, 96.42857142857143, 97.32142857142857, 96.42857142857143, 98.21428571428571, 96.42857142857143, 92.85714285714286, 95.53571428571429, 98.21428571428571, 91.96428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 95.53571428571429, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 98.21428571428571, 99.10714285714286, 97.32142857142857, 100.0, 99.10714285714286, 95.53571428571429, 96.42857142857143, 90.17857142857143, 99.10714285714286, 97.32142857142857, 91.96428571428571, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 99.10714285714286, 98.21428571428571, 97.32142857142857, 93.75, 94.64285714285714, 96.42857142857143, 96.42857142857143, 96.42857142857143, 97.32142857142857, 94.64285714285714, 97.32142857142857, 96.42857142857143, 96.42857142857143, 97.32142857142857, 96.42857142857143, 97.32142857142857, 97.32142857142857, 99.10714285714286, 95.53571428571429, 95.53571428571429, 98.21428571428571, 98.21428571428571, 97.32142857142857, 96.42857142857143, 93.75, 95.53571428571429, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 96.42857142857143, 91.96428571428571, 95.53571428571429, 97.32142857142857, 94.64285714285714, 100.0, 99.10714285714286, 99.10714285714286, 96.42857142857143, 97.32142857142857, 98.21428571428571, 94.64285714285714, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 96.42857142857143, 97.32142857142857, 99.10714285714286, 97.32142857142857, 97.32142857142857, 94.64285714285714, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 97.32142857142857, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 94.64285714285714, 97.32142857142857, 99.10714285714286, 94.64285714285714, 95.53571428571429, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 95.53571428571429, 97.32142857142857, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 97.32142857142857, 100.0, 96.42857142857143, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 96.42857142857143, 97.32142857142857, 94.64285714285714, 99.10714285714286, 98.21428571428571, 95.53571428571429, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 96.75%\n",
      "Loss on the train set: 0.09\n",
      "Accuracy on the test set: 94.17%\n",
      "Loss on the test set: 0.22\n",
      "Generalization error: 0.1351644\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
