{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.492</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.676478</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.879767</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.536453</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.973369</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.641156</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.50981</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.960218</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.590428</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.944307</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.395221</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.016244</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.165684</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.448032</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.155592</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.048195</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.265372</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.605574</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.557851</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.97055</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.346572</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.941831</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.334304</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.014667</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.080352</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.431262</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.047275</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.179334</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.225886</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.395775</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.383434</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.694004</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.480882</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.187104</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.546609</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.989501</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.301317</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.593888</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.474511</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.014817</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.943962</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.533657</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.745594</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.856135</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.405757</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.951038</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.5633</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.535198</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.014366</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.089475</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.881353</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.19945</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.024444</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.688208</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.92933</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.958501</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.105998</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.417948</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.558414</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.374064</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.361465</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.804449</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.501925</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.506755</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.125309</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.563782</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.486122</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.467423</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.83358</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.52172</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.059527</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.325737</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.511688</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.173474</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.25769</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.733142</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.521906</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.589791</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.414601</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.865766</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.634975</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.812616</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.01931</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.864526</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.346088</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.684632</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.197346</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.373141</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.989842</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.003807</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.662068</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.552581</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.299367</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.902475</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.827303</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.045322</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7015728bd460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.935495</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.086976</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.53935</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.491045</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.997942</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.0461</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.920089</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.836344</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.65038</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.67607</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.528403</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.319238</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.886622</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.375988</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.988646</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.883559</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.883982</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.66974</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.576045</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.053767</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.84718</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.216001</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.743236</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.498887</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.278861</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.622929</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.711217</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.793776</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.051267</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.690336</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.082069</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.97846</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.689683</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.141286</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.499804</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.156906</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.276885</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.0174</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.448616</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.256477</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.107714</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.748223</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.921937</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.298758</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.42759</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.21546</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.410234</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.012992</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.916834</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.895156</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.755181</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.85657</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.403618</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.847449</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.712813</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.4445</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.512125</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.006363</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.020134</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.972813</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.083599</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.717451</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.09684</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.765796</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.573895</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.517544</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.64931</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.751215</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.097338</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.83691</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.261452</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.28419</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.448913</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.441046</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.473149</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x70156df93910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 67.83%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=6)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  1116\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  1308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.1476, batch time: 0.30, accuracy:  19.53%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.0181, batch time: 0.13, accuracy:  14.06%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 1.7625, batch time: 0.17, accuracy:  28.12%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 1.7701, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.4019, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.4898, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.4715, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.0364, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.1418, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 0.8857, batch time: 0.10, accuracy:  68.75%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 0.8753722310066223, accuracy: 72.2 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 1.4924150705337524, accuracy: 52.0 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 0.8658526539802551, accuracy: 73.2 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 0.852556049823761, accuracy: 72.5 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 0.8591431975364685, accuracy: 72.4 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 0.8819530010223389, accuracy: 72.5 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 0.8198192715644836, accuracy: 73.9 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 0.8198791146278381, accuracy: 74.4 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 0.8197836875915527, accuracy: 75.1 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 0.8558279275894165, accuracy: 71.9 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 0.8957, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 0.6483, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.6816, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.6723, batch time: 0.10, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.4999, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.5923, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.4785, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.5545, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.6029, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.4520, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.569095253944397, accuracy: 81.7 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 0.5949293971061707, accuracy: 81.0 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.5876964926719666, accuracy: 81.3 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.7100721001625061, accuracy: 78.3 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.5784825086593628, accuracy: 82.6 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.5477437376976013, accuracy: 82.2 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.5430845618247986, accuracy: 82.5 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.5422157645225525, accuracy: 82.4 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.5464215278625488, accuracy: 81.7 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.5348180532455444, accuracy: 82.5 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.6037, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.4086, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.5119, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.5554, batch time: 0.05, accuracy:  78.91%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.6006, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.4519, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.4274, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.4378, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.4936, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.4325, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.4422028362751007, accuracy: 87.6 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 0.4658053517341614, accuracy: 87.5 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.44422608613967896, accuracy: 87.5 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.4349172115325928, accuracy: 88.2 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.5004565715789795, accuracy: 85.7 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.5035048723220825, accuracy: 87.0 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.44579827785491943, accuracy: 88.2 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.4468629062175751, accuracy: 87.0 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.42008787393569946, accuracy: 88.9 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.42397794127464294, accuracy: 88.9 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.5363, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.4968, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.3085, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.5354, batch time: 0.11, accuracy:  82.03%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.3731, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.3159, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.2937, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.4653, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.4072, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.3241, batch time: 0.09, accuracy:  86.72%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.42407235503196716, accuracy: 89.0 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 0.5224292874336243, accuracy: 85.4 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.41813021898269653, accuracy: 89.0 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.4124751389026642, accuracy: 88.8 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.46946942806243896, accuracy: 87.3 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.4045775532722473, accuracy: 88.7 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.40452226996421814, accuracy: 89.1 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.3990216851234436, accuracy: 89.2 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.4091903269290924, accuracy: 88.6 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.3971344232559204, accuracy: 89.1 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.5004, batch time: 0.10, accuracy:  84.38%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.4651, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.4140, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.4312, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.6325, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.4129, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.4003, batch time: 0.06, accuracy:  89.84%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.3598, batch time: 0.11, accuracy:  86.72%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.4344, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.3742, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.38222217559814453, accuracy: 88.9 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 0.41207343339920044, accuracy: 88.3 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.4127078652381897, accuracy: 88.2 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 1.013599157333374, accuracy: 71.7 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.7700482606887817, accuracy: 78.3 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.3508421778678894, accuracy: 90.3 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.3407510817050934, accuracy: 91.0 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.34076157212257385, accuracy: 90.8 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.33927613496780396, accuracy: 90.8 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.3439774215221405, accuracy: 90.9 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.3921, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.3322, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.5124, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.2300, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.3337, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.3909, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.2768, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.4009, batch time: 0.09, accuracy:  86.72%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.2050, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.2588, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.3095278739929199, accuracy: 90.9 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.32073846459388733, accuracy: 89.9 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.5942885279655457, accuracy: 83.0 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.37251055240631104, accuracy: 88.0 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.2934655249118805, accuracy: 90.8 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.28686287999153137, accuracy: 91.3 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.2890062928199768, accuracy: 91.2 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.28383347392082214, accuracy: 91.0 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.28322461247444153, accuracy: 91.2 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.3318890631198883, accuracy: 88.6 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.3383, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.2426, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.4312, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.2947, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.3345, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.2722, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.4248, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.3463, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.3158, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.3049, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.3027103543281555, accuracy: 90.9 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.3498436212539673, accuracy: 89.4 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.2986980974674225, accuracy: 91.3 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.29571402072906494, accuracy: 91.5 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.33942726254463196, accuracy: 89.9 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.37466591596603394, accuracy: 88.1 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.2876102030277252, accuracy: 90.9 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.28312063217163086, accuracy: 90.8 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.282803475856781, accuracy: 90.9 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.29546448588371277, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.3416, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.3002, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.2795, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.4018, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.2172, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.3218, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.3837, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.3431, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.3902, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2436, batch time: 0.07, accuracy:  92.97%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.30485641956329346, accuracy: 91.0 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 1.341431736946106, accuracy: 64.0 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.3594326376914978, accuracy: 89.3 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.2937089800834656, accuracy: 91.2 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.3392582833766937, accuracy: 89.7 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.5251682996749878, accuracy: 84.7 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.8338441252708435, accuracy: 80.3 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.28262951970100403, accuracy: 91.8 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.2827616333961487, accuracy: 92.1 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.28389573097229004, accuracy: 91.8 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.2884, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.2335, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.2002, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.3670, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.3143, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.2511, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.3096, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.4464, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.3756, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.2736, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.27869975566864014, accuracy: 90.9 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.3656054735183716, accuracy: 88.1 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.2852458357810974, accuracy: 91.4 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.26388007402420044, accuracy: 91.5 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.254811555147171, accuracy: 91.9 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.25124040246009827, accuracy: 92.4 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.264985591173172, accuracy: 92.3 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.24867688119411469, accuracy: 92.2 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.25092846155166626, accuracy: 92.6 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.24966686964035034, accuracy: 92.3 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.3601, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.2914, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.3080, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.2673, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.2387, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.3326, batch time: 0.06, accuracy:  89.84%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.2800, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.1798, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.3284, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.3444, batch time: 0.04, accuracy:  87.50%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.2708662748336792, accuracy: 91.8 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.32358601689338684, accuracy: 89.7 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.2638028860092163, accuracy: 93.1 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.2594134509563446, accuracy: 93.2 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.28326794505119324, accuracy: 91.4 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.2512216866016388, accuracy: 93.3 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.2498207986354828, accuracy: 92.9 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.24408841133117676, accuracy: 93.2 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.24841363728046417, accuracy: 93.4 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.24275565147399902, accuracy: 93.6 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.2609, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.3094, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.3245, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.3268, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.2294, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.3018, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.2783, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.2112, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.2891, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.2193, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.24391137063503265, accuracy: 92.4 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.2528839707374573, accuracy: 92.2 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.23819296061992645, accuracy: 92.9 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.23819296061992645, accuracy: 92.9 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.23283876478672028, accuracy: 93.8 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.2301352471113205, accuracy: 93.8 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.23049403727054596, accuracy: 93.4 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.23132750391960144, accuracy: 93.9 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.23030908405780792, accuracy: 94.0 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.23380765318870544, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.2618, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.2643, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.2052, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.3631, batch time: 0.06, accuracy:  89.84%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.3809, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.2802, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.2860, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.2392, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.2880, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.2561, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.2671377956867218, accuracy: 92.1 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 3.0088725090026855, accuracy: 47.6 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.2567344307899475, accuracy: 91.4 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.24616339802742004, accuracy: 92.8 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.2914077043533325, accuracy: 89.9 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.23658263683319092, accuracy: 92.5 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.23070299625396729, accuracy: 92.7 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.2299790382385254, accuracy: 92.9 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.22664333879947662, accuracy: 93.6 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.2257368564605713, accuracy: 92.8 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.2186, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2266, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.2164, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.2021, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.2722, batch time: 0.04, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.1664, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.2120, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.2334, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.2010, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.2176, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.2182532101869583, accuracy: 93.1 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.22659526765346527, accuracy: 93.2 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.21631498634815216, accuracy: 93.2 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.23734880983829498, accuracy: 93.1 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.20884571969509125, accuracy: 93.0 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.2043510377407074, accuracy: 93.3 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.20702369511127472, accuracy: 93.2 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.242243692278862, accuracy: 92.1 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.1997578740119934, accuracy: 93.0 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.20074108242988586, accuracy: 93.2 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.3190, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.2485, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.1794, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.1682, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.1490, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.2631, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.1735, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.2723, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.2383, batch time: 0.06, accuracy:  93.75%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.2613, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.20049716532230377, accuracy: 93.4 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.20983049273490906, accuracy: 93.1 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.20036408305168152, accuracy: 93.9 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.2958407998085022, accuracy: 90.6 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.2250940352678299, accuracy: 93.2 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.19655373692512512, accuracy: 93.4 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.19006028771400452, accuracy: 93.5 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.1885288953781128, accuracy: 93.1 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.18855290114879608, accuracy: 93.5 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.19088847935199738, accuracy: 93.9 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.1085, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.1648, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.2344, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.2297, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.2098, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.1874, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.2703, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.2109, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.2409, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.1083, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.19987264275550842, accuracy: 93.2 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 4.353035926818848, accuracy: 41.1 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.20781558752059937, accuracy: 93.0 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.18996603786945343, accuracy: 94.0 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.21237005293369293, accuracy: 92.9 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.18802517652511597, accuracy: 93.9 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.1862267106771469, accuracy: 94.4 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.18396510183811188, accuracy: 94.3 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.18273970484733582, accuracy: 94.4 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.1822829246520996, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.1898, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.4268, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.2490, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.2281, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.2784, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.2563, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.2318, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.2779, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.2257, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.2003, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.22119919955730438, accuracy: 93.5 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.26954108476638794, accuracy: 92.4 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.3479735553264618, accuracy: 89.5 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.26183515787124634, accuracy: 93.0 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.20746679604053497, accuracy: 94.0 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.20481926202774048, accuracy: 93.6 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.20351512730121613, accuracy: 93.8 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.20565323531627655, accuracy: 94.0 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.2204527109861374, accuracy: 93.7 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.2056032121181488, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.2598, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.1403, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.2409, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.2376, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.1853, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.1764, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.1575, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.3777, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.2780, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.1722, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.1733221560716629, accuracy: 94.4 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.186350017786026, accuracy: 93.9 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.1704486459493637, accuracy: 94.6 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.16955655813217163, accuracy: 94.7 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.17546451091766357, accuracy: 94.3 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.19381387531757355, accuracy: 94.3 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.1673985868692398, accuracy: 95.0 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.16427990794181824, accuracy: 95.0 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.16435666382312775, accuracy: 95.0 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.1632901430130005, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.2458, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.2064, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.1834, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.3962, batch time: 0.11, accuracy:  85.94%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.1462, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.2430, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.1556, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.2657, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.2516, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.3272, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.20870964229106903, accuracy: 93.2 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 1.1342949867248535, accuracy: 62.8 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.20057758688926697, accuracy: 92.8 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.22743287682533264, accuracy: 92.8 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.2123810052871704, accuracy: 93.1 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.22608663141727448, accuracy: 93.2 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.20095790922641754, accuracy: 93.4 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.23032797873020172, accuracy: 92.0 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.2093912661075592, accuracy: 92.7 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.23304541409015656, accuracy: 91.4 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.1741, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.1799, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.1285, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.2280, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.1305, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.2714, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.2865, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.2675, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.2114, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.1552, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.2194051444530487, accuracy: 93.7 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.23394440114498138, accuracy: 93.4 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.2315068244934082, accuracy: 93.1 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.21469776332378387, accuracy: 93.9 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.29110226035118103, accuracy: 91.4 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.2114599198102951, accuracy: 93.8 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.21104779839515686, accuracy: 93.7 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.21109771728515625, accuracy: 94.0 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.20461265742778778, accuracy: 93.9 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.20315811038017273, accuracy: 94.0 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.1903, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.1739, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.3046, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.1984, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.1047, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.1061, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.2156, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.2136, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.2613, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.2214, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.18929077684879303, accuracy: 94.8 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.21301837265491486, accuracy: 94.3 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.1891831010580063, accuracy: 94.6 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.18621234595775604, accuracy: 94.8 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.4569990932941437, accuracy: 84.7 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.3888486623764038, accuracy: 86.9 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.2056012749671936, accuracy: 93.3 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.20211181044578552, accuracy: 93.8 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.17665445804595947, accuracy: 94.9 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.17879725992679596, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.1847, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.1595, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.2302, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.2149, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.1941, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.1763, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.3475, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.1869, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.1452, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.2853, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.18998797237873077, accuracy: 94.0 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 1.1263970136642456, accuracy: 64.6 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.1819092333316803, accuracy: 94.4 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.180172860622406, accuracy: 94.2 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.1778174787759781, accuracy: 94.1 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.20039048790931702, accuracy: 93.8 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.27387624979019165, accuracy: 91.1 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.18383774161338806, accuracy: 94.2 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.1740073263645172, accuracy: 94.3 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.17342129349708557, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.2524, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.2353, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.1647, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.1950, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.2984, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.1758, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.2721, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.1282, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.1495, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.2348, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.20824748277664185, accuracy: 93.7 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 1.1638253927230835, accuracy: 66.3 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.20094221830368042, accuracy: 93.9 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.19424955546855927, accuracy: 94.2 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.20218539237976074, accuracy: 94.0 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.4476569890975952, accuracy: 85.9 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.20314998924732208, accuracy: 93.6 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.23614375293254852, accuracy: 92.8 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.18480724096298218, accuracy: 94.9 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.18319405615329742, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.1447, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.1591, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.1030, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.0972, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.1305, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.1825, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.1788, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.1503, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.1687, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.2508, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.1861751824617386, accuracy: 94.2 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 1.215330719947815, accuracy: 67.9 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.1808193475008011, accuracy: 94.3 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.28676673769950867, accuracy: 92.5 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.18268868327140808, accuracy: 94.1 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.22928452491760254, accuracy: 93.2 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.18312974274158478, accuracy: 94.2 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.1742110401391983, accuracy: 94.4 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.17363400757312775, accuracy: 94.4 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.1720028519630432, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.1896, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.1584, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.2771, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.2529, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.1543, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1743, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.1976, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.2845, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.3119, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.1494, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.18837618827819824, accuracy: 93.8 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.21071229875087738, accuracy: 93.2 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.18773341178894043, accuracy: 94.0 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.18243689835071564, accuracy: 93.8 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.1796126812696457, accuracy: 93.9 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.1718815714120865, accuracy: 94.2 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.17098954319953918, accuracy: 94.3 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.16891218721866608, accuracy: 94.3 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.18020214140415192, accuracy: 94.3 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.17375224828720093, accuracy: 93.8 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.2035, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.1982, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.1395, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.1497, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.1960, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.1934, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.2052, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.1628, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.3317, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.2756, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.18782305717468262, accuracy: 94.4 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.1932317018508911, accuracy: 94.5 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.18553759157657623, accuracy: 94.6 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.18417853116989136, accuracy: 94.9 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.20048710703849792, accuracy: 93.6 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.19783486425876617, accuracy: 94.0 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.17910003662109375, accuracy: 94.5 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.20219849050045013, accuracy: 93.1 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.17198225855827332, accuracy: 95.3 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.1707303524017334, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.1437, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.2499, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.3057, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.2063, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.2421, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.2511, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.1644, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.2618, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.1442, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.1518, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.17178918421268463, accuracy: 94.7 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.3952445685863495, accuracy: 87.4 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.1694200485944748, accuracy: 94.1 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.20634932816028595, accuracy: 93.8 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.22042547166347504, accuracy: 93.1 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.1960856020450592, accuracy: 92.6 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.17610719799995422, accuracy: 95.1 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.17154841125011444, accuracy: 93.8 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.16002494096755981, accuracy: 94.7 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.15929065644741058, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.1077, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.1210, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.2039, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.1732, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.1596, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.1562, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.1545, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.2166, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.1517, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.1606, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.17468863725662231, accuracy: 94.9 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.1779923290014267, accuracy: 94.5 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.1790415495634079, accuracy: 95.0 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.16932560503482819, accuracy: 94.9 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.1702904850244522, accuracy: 95.2 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.16726917028427124, accuracy: 95.0 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.16641366481781006, accuracy: 95.5 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.16349440813064575, accuracy: 95.5 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.16351553797721863, accuracy: 95.3 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.1605686992406845, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.1886, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.0863, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.3379, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.1636, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.2501, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.2216, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.2123, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.1315, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.2356, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.1318, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.1504388004541397, accuracy: 95.2 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.8896971940994263, accuracy: 80.4 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.1442415416240692, accuracy: 94.8 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.1520916074514389, accuracy: 95.5 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.13691851496696472, accuracy: 95.9 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.1381736546754837, accuracy: 95.7 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.2150932401418686, accuracy: 93.1 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.13013331592082977, accuracy: 96.7 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.1272711306810379, accuracy: 96.3 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.12522166967391968, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.1655, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.1437, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.1071, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.1429, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.2402, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.0983, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.2647, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.1900, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.1013, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.3172, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.12277205288410187, accuracy: 96.1 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 1.1025246381759644, accuracy: 70.1 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.11604078114032745, accuracy: 96.8 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.11441093683242798, accuracy: 96.6 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.13396571576595306, accuracy: 95.4 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.13215689361095428, accuracy: 95.2 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.1222274899482727, accuracy: 96.4 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.12314886599779129, accuracy: 96.3 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.1061922237277031, accuracy: 96.9 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.10464993864297867, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.1313, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.1198, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.2299, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.2128, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.1996, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.1242, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.0788, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.2447, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.1409, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.1870, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.18551714718341827, accuracy: 94.2 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 0.8859043717384338, accuracy: 70.8 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.16712483763694763, accuracy: 95.4 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.16993169486522675, accuracy: 95.0 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.16100867092609406, accuracy: 95.0 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.15902097523212433, accuracy: 95.1 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.15711678564548492, accuracy: 95.4 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.1463090181350708, accuracy: 95.4 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.15002603828907013, accuracy: 95.2 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.1551143229007721, accuracy: 95.3 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.2581, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.0848, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.2696, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.1775, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.3142, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.1573, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.2411, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.2704, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.2691, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.1717, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.14919613301753998, accuracy: 95.7 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 0.44662678241729736, accuracy: 83.0 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.13657887279987335, accuracy: 95.9 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.14049912989139557, accuracy: 95.7 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.16289682686328888, accuracy: 95.0 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.17442646622657776, accuracy: 94.2 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.1261541247367859, accuracy: 96.3 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.12282621115446091, accuracy: 96.2 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.12251786142587662, accuracy: 96.7 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.12278012186288834, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.0636, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.2297, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.1653, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.2687, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.1576, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.1751, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.0863, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.1591, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.1357, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.1559, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.13770149648189545, accuracy: 95.7 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.4597458839416504, accuracy: 84.5 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.13105347752571106, accuracy: 95.9 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.12170501798391342, accuracy: 96.4 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.12520833313465118, accuracy: 96.0 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.14503109455108643, accuracy: 95.9 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.1948505938053131, accuracy: 93.7 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.11136709898710251, accuracy: 96.7 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.10974553227424622, accuracy: 96.5 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.10870945453643799, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.1101, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.1467, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.3023, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.2979, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.1429, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.1828, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.2114, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.1893, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.2167, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.2662, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.15017083287239075, accuracy: 95.0 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 0.17293964326381683, accuracy: 94.4 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.14840637147426605, accuracy: 95.1 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.14671246707439423, accuracy: 95.2 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.17070168256759644, accuracy: 94.6 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.13933685421943665, accuracy: 95.0 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.13715551793575287, accuracy: 95.4 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.13264144957065582, accuracy: 95.2 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.13256821036338806, accuracy: 95.3 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.13000422716140747, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.1805, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.1034, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.0605, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.1490, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.2058, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.1801, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.1177, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.1833, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.1357, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.2256, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.1681288182735443, accuracy: 94.8 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.3576638996601105, accuracy: 88.0 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.16646692156791687, accuracy: 95.0 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.16060511767864227, accuracy: 95.0 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.158364400267601, accuracy: 95.3 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.15752066671848297, accuracy: 95.0 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.16271564364433289, accuracy: 95.0 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.15534469485282898, accuracy: 94.7 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.1533375084400177, accuracy: 95.2 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.15155261754989624, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.0794, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.1532, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.1739, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.1645, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.1084, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.1107, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.1403, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.2355, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.1760, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.2605, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.15913183987140656, accuracy: 95.1 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.19239848852157593, accuracy: 94.4 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.16277220845222473, accuracy: 95.0 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.13477365672588348, accuracy: 95.1 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.13914138078689575, accuracy: 95.2 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.14063800871372223, accuracy: 95.1 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.13274841010570526, accuracy: 95.6 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.12794971466064453, accuracy: 95.6 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.12721404433250427, accuracy: 95.3 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.12503308057785034, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.3622, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.1838, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.1123, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.1259, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.1452, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.0606, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.2612, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.1987, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.1218, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.2700, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.16267874836921692, accuracy: 95.3 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.1617240607738495, accuracy: 95.2 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.16174010932445526, accuracy: 94.5 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.16559283435344696, accuracy: 94.8 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.14326630532741547, accuracy: 95.7 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.13952691853046417, accuracy: 95.6 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.14429925382137299, accuracy: 95.5 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.14124144613742828, accuracy: 95.6 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.13672122359275818, accuracy: 96.3 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.1351013332605362, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.1732, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.1608, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.1848, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.1785, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.1138, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.1782, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.1375, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.1652, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.1154, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.15561705827713013, accuracy: 94.4 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.1587340533733368, accuracy: 94.8 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.1527741253376007, accuracy: 95.0 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.15222902595996857, accuracy: 95.0 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.15246520936489105, accuracy: 95.4 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.1860884130001068, accuracy: 94.4 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.15603473782539368, accuracy: 95.0 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.1531984508037567, accuracy: 94.7 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.14541538059711456, accuracy: 95.3 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.16328515112400055, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.2300, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.1891, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.1896, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.0903, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.1519, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.1337, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.1409, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.1173, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.12232082337141037, accuracy: 95.5 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.1831640750169754, accuracy: 94.4 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.11329063773155212, accuracy: 96.3 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.11008796095848083, accuracy: 96.4 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.10672160983085632, accuracy: 96.4 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.11535164713859558, accuracy: 96.4 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.14437440037727356, accuracy: 94.5 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.1012384444475174, accuracy: 96.7 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.10094276070594788, accuracy: 96.8 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.1003582626581192, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.1038, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.1852, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.1281, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.1940, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.1160, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.2217, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.0989, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.0880, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.1509, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.1475, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.14161808788776398, accuracy: 96.2 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.2534427046775818, accuracy: 92.6 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.1784971058368683, accuracy: 94.1 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.14154036343097687, accuracy: 96.2 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.1387767195701599, accuracy: 96.3 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.12952736020088196, accuracy: 96.8 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.13483451306819916, accuracy: 96.5 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.17138072848320007, accuracy: 95.5 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.12284009158611298, accuracy: 96.6 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.12020755559206009, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.1194, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.1971, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.1271, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.1642, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.1178, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.2607, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.2682, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.2022, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.1142, batch time: 0.21, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.1187, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.13707014918327332, accuracy: 96.2 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 1.136306881904602, accuracy: 70.6 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.13368578255176544, accuracy: 96.5 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.13017694652080536, accuracy: 96.8 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.1271989792585373, accuracy: 95.8 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.134743332862854, accuracy: 96.3 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.13891521096229553, accuracy: 96.0 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.1205797865986824, accuracy: 96.3 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.11953636258840561, accuracy: 96.6 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.11789176613092422, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.1641, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.1347, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.1531, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.1434, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.2561, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.2123, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.1261, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.1064, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.1380, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.1454, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.13617278635501862, accuracy: 95.6 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.1360388547182083, accuracy: 95.2 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.14292994141578674, accuracy: 95.4 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.15125976502895355, accuracy: 95.3 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.13023605942726135, accuracy: 95.7 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.12716664373874664, accuracy: 96.3 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.1269426792860031, accuracy: 96.0 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.12711699306964874, accuracy: 96.0 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.1262955367565155, accuracy: 96.2 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.12587331235408783, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.1402, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.1389, batch time: 0.08, accuracy:  95.31%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.1951, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.1315, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.1059, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.1691, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.0589, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.1947, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.1230, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.0792, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.15682965517044067, accuracy: 95.0 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.1590675413608551, accuracy: 94.7 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.1532425880432129, accuracy: 95.0 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.1445527821779251, accuracy: 95.6 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.16738179326057434, accuracy: 94.5 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.16487525403499603, accuracy: 94.5 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.14287887513637543, accuracy: 95.9 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.1326846033334732, accuracy: 95.7 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.13225287199020386, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.12788988649845123, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.1532, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.2537, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.2134, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.1646, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.2269, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.1081, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.1668, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.1677, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.1028, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.1759, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.13343805074691772, accuracy: 95.3 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.14784888923168182, accuracy: 94.9 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.12857945263385773, accuracy: 95.2 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.12772798538208008, accuracy: 95.4 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.12432623654603958, accuracy: 95.3 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.12174316495656967, accuracy: 95.9 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.1207718476653099, accuracy: 96.0 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.13905028998851776, accuracy: 95.4 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.12300252169370651, accuracy: 95.9 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.15024295449256897, accuracy: 95.1 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.1653, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.1392, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.1760, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.1265, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.1762, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.1539, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.0636, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.3636, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.1489, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.3166, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.11898456513881683, accuracy: 95.7 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.1306430697441101, accuracy: 95.6 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.17439913749694824, accuracy: 94.6 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.11973337084054947, accuracy: 96.2 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.11973235011100769, accuracy: 96.6 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.1322418749332428, accuracy: 95.8 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.10567699372768402, accuracy: 96.5 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.1039324626326561, accuracy: 96.6 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.1045771911740303, accuracy: 96.5 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.10476793348789215, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.1428, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.2392, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.2101, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.2604, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.2835, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.1572, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.0509, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.1390, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.2819, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.1084, batch time: 0.09, accuracy:  95.31%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.16291426122188568, accuracy: 94.9 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.902370274066925, accuracy: 75.6 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.1510930061340332, accuracy: 95.1 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.1510208547115326, accuracy: 95.0 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.14767231047153473, accuracy: 95.7 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.13937808573246002, accuracy: 95.7 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.17009933292865753, accuracy: 94.8 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.1519552320241928, accuracy: 95.1 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.1321956366300583, accuracy: 95.8 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.13035964965820312, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.1877, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.1356, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.1657, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.2513, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.2473, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.0589, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.1427, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.1538, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.3680, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.2972, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.1759241223335266, accuracy: 94.5 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.22096744179725647, accuracy: 92.8 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.16518661379814148, accuracy: 94.7 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.1615568995475769, accuracy: 94.9 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.16097095608711243, accuracy: 95.4 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.16571614146232605, accuracy: 94.7 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.1552673578262329, accuracy: 95.3 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.1593165248632431, accuracy: 95.2 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.14913779497146606, accuracy: 95.5 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.18826642632484436, accuracy: 94.1 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.2540, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.1351, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.2127, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.1903, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.1656, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.1440, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.1466, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.1309, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.2041, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.1105, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.1463315635919571, accuracy: 96.4 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.32917967438697815, accuracy: 88.8 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.13981567323207855, accuracy: 95.9 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.19205327332019806, accuracy: 93.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.1320558488368988, accuracy: 96.2 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.13670040667057037, accuracy: 95.9 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.12807826697826385, accuracy: 96.9 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.25415003299713135, accuracy: 91.2 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.1487763673067093, accuracy: 95.2 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.17497488856315613, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.1250, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.2438, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.1014, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.1049, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.3594, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1361, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.1600, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.1452, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.1837, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.2401, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.11670251190662384, accuracy: 96.5 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 1.85930597782135, accuracy: 69.5 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.1143483892083168, accuracy: 96.8 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.18751050531864166, accuracy: 94.8 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.11811947077512741, accuracy: 96.1 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.1340423971414566, accuracy: 95.3 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.10402965545654297, accuracy: 96.7 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.1029001995921135, accuracy: 96.9 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.10234175622463226, accuracy: 97.4 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.10279799997806549, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.1290, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.2053, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.1961, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.1407, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.2278, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.2286, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.3238, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.1694, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.2496, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.1241, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.13607990741729736, accuracy: 95.5 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.2698388397693634, accuracy: 91.5 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.12841466069221497, accuracy: 95.9 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.17898689210414886, accuracy: 94.1 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.16191723942756653, accuracy: 94.9 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.1300496608018875, accuracy: 95.7 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.1346171498298645, accuracy: 95.6 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.15045736730098724, accuracy: 95.2 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.11905936151742935, accuracy: 96.0 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.11873013526201248, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.1641, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.1368, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.1225, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.1659, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0967, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.1492, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.1386, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.0625, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.0688, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.0683, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.12916859984397888, accuracy: 95.9 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.14782723784446716, accuracy: 95.2 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.16142921149730682, accuracy: 94.3 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.12240903079509735, accuracy: 96.1 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.12221800535917282, accuracy: 95.9 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.14660575985908508, accuracy: 95.1 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.11929450929164886, accuracy: 96.2 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.11768695712089539, accuracy: 96.2 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.11472134292125702, accuracy: 96.5 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.11272037029266357, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.2018, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.1638, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.1499, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.1792, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.1106, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.1199, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.2846, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.1927, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.1680, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.0740, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.12241413444280624, accuracy: 96.6 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.8635281920433044, accuracy: 78.0 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.11728160828351974, accuracy: 96.9 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.11597645282745361, accuracy: 96.8 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.11398791521787643, accuracy: 96.7 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.11315792053937912, accuracy: 96.8 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.1404099464416504, accuracy: 95.7 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.15184801816940308, accuracy: 95.0 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.11029724776744843, accuracy: 97.0 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.10861551761627197, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.0753, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.0944, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.0714, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.1653, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.1785, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.0979, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.0889, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.1104, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.1726, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.2407, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.1438153088092804, accuracy: 94.9 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.6627270579338074, accuracy: 86.4 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.1302536129951477, accuracy: 95.8 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.1325097680091858, accuracy: 96.0 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.1371588408946991, accuracy: 95.4 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.1244451031088829, accuracy: 96.2 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.16999974846839905, accuracy: 94.9 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.11871598660945892, accuracy: 96.6 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.16555938124656677, accuracy: 95.1 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.1301567256450653, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.0488, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.2178, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.0999, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.1260, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.2319, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.2169, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.1307, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.1494, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.1348, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.1718, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.12885552644729614, accuracy: 96.6 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.14734679460525513, accuracy: 95.2 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.15033166110515594, accuracy: 95.7 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.12278888374567032, accuracy: 96.6 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.12454641610383987, accuracy: 97.3 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.13146260380744934, accuracy: 96.2 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.12075605243444443, accuracy: 96.8 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.13415546715259552, accuracy: 95.9 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.12284546345472336, accuracy: 96.5 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.1248658150434494, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.1785, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.0658, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.1456, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.2327, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.0955, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.1227, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.1682, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.1557, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.1606, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.1166, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.13567616045475006, accuracy: 96.0 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.36436110734939575, accuracy: 90.4 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.12846912443637848, accuracy: 96.3 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.12801222503185272, accuracy: 95.8 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.18441390991210938, accuracy: 94.1 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.1367674171924591, accuracy: 95.6 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.13478410243988037, accuracy: 95.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.11375663429498672, accuracy: 96.8 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.11403710395097733, accuracy: 96.7 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.11221115291118622, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.1080, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.0920, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.1878, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.2873, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.0582, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.1566, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.2148, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.0912, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.0965, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.1777, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.12741141021251678, accuracy: 95.9 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.9809855222702026, accuracy: 78.7 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.14945513010025024, accuracy: 94.9 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.1278766691684723, accuracy: 96.2 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.11240095645189285, accuracy: 96.7 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.149859219789505, accuracy: 95.0 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.11970847845077515, accuracy: 96.7 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.10764025151729584, accuracy: 96.9 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.10694726556539536, accuracy: 96.8 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.10645444691181183, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.0912, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.1735, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.1621, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.1596, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.1424, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.1999, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.1535, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.1640, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.1545, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.2003, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.13330435752868652, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.8706490993499756, accuracy: 74.3 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.12676167488098145, accuracy: 96.4 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.12603338062763214, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.1634574681520462, accuracy: 94.9 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.1218278780579567, accuracy: 96.5 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.12085406482219696, accuracy: 96.9 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.11981281638145447, accuracy: 96.8 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.12075202912092209, accuracy: 96.7 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.11879182606935501, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.2276, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.1225, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.0940, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.1191, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.1534, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.2237, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.1440, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.1203, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.0714, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.1018, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.17039643228054047, accuracy: 93.9 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.1728104203939438, accuracy: 94.2 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.18722882866859436, accuracy: 94.0 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.15563984215259552, accuracy: 94.8 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.1665705293416977, accuracy: 94.5 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.14958646893501282, accuracy: 95.0 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.20659495890140533, accuracy: 92.7 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.14556631445884705, accuracy: 95.2 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.20246805250644684, accuracy: 93.0 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.14234524965286255, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.2182, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.1800, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.1715, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.1731, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.0813, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.1991, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.0547, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.2153, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.1330, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.1643, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.13786573708057404, accuracy: 96.1 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.18991364538669586, accuracy: 93.6 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.1333526074886322, accuracy: 96.5 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.13188017904758453, accuracy: 96.2 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.16696101427078247, accuracy: 94.4 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.14042961597442627, accuracy: 96.1 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.12762168049812317, accuracy: 96.7 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.12187382578849792, accuracy: 96.9 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.12212365120649338, accuracy: 96.6 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.11877612769603729, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.1601, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.2847, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.2505, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.0915, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.1559, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.2563, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.1346, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.0902, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.1236, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.1535, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.13578243553638458, accuracy: 96.2 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.8329691290855408, accuracy: 75.7 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.14403288066387177, accuracy: 95.7 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.1267314851284027, accuracy: 96.6 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.12265817075967789, accuracy: 96.9 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.15424753725528717, accuracy: 95.2 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.11910178512334824, accuracy: 96.6 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.11328495293855667, accuracy: 97.0 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.11865905672311783, accuracy: 96.5 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.1362280398607254, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.1610, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.0950, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.2639, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.1226, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.1017, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.1044, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.1199, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.1700, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.1089, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.1940, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.11854386329650879, accuracy: 95.7 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.12469479441642761, accuracy: 95.7 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 0.11717046797275543, accuracy: 96.1 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.11408942192792892, accuracy: 96.1 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.15012408792972565, accuracy: 95.1 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.16364698112010956, accuracy: 94.5 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.10581310838460922, accuracy: 96.6 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.10360748320817947, accuracy: 96.6 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.10357293486595154, accuracy: 96.7 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.10222256183624268, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.0590, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.1311, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.1716, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.1238, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.1907, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.2106, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.0803, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.1915, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.0905, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.1549, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.12480396777391434, accuracy: 96.2 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.4542238712310791, accuracy: 85.4 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.11935582756996155, accuracy: 96.2 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.11014197021722794, accuracy: 96.1 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.10658717155456543, accuracy: 96.3 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.1596435159444809, accuracy: 95.3 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.1551905870437622, accuracy: 95.1 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.16168971359729767, accuracy: 94.1 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.12998153269290924, accuracy: 95.3 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.13671736419200897, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.1948, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.1614, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.1357, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.2183, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.1776, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.1676, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.0965, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.1131, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.1100, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.1244, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.10559249669313431, accuracy: 96.7 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.9705253839492798, accuracy: 77.5 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.10475675761699677, accuracy: 96.9 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.09746453166007996, accuracy: 97.1 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.09616882354021072, accuracy: 97.2 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.1043296679854393, accuracy: 96.9 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.10423598438501358, accuracy: 96.5 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.09350498765707016, accuracy: 97.2 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.09039981663227081, accuracy: 97.2 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.08801067620515823, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.1576, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.1386, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.1048, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.2089, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.2271, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.2775, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.1091, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.2047, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.1585, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.1259, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.11165681481361389, accuracy: 96.6 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.3143354654312134, accuracy: 90.6 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.10977362096309662, accuracy: 96.7 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.14433050155639648, accuracy: 95.6 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.10608282685279846, accuracy: 96.5 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.1466020792722702, accuracy: 95.7 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.10053801536560059, accuracy: 96.9 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.10182793438434601, accuracy: 96.6 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.0980999693274498, accuracy: 97.0 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.0990661010146141, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.1281, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.1417, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.0567, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.1463, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.2456, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.1444, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.1138, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.1716, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.1673, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.1024, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.14839428663253784, accuracy: 95.9 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.1606558859348297, accuracy: 95.5 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.14005213975906372, accuracy: 96.4 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.12941357493400574, accuracy: 96.8 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.1329793483018875, accuracy: 96.0 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.16534198820590973, accuracy: 94.4 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.12660925090312958, accuracy: 96.6 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.12509821355342865, accuracy: 96.8 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.12317288666963577, accuracy: 96.9 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.12221871316432953, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.1468, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.0776, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.1108, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.1802, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.1338, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.1554, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.0745, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.1593, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.1915, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.1390751302242279, accuracy: 96.0 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 1.1367155313491821, accuracy: 74.4 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.1338501274585724, accuracy: 95.8 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.12870894372463226, accuracy: 95.8 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.1352258026599884, accuracy: 95.2 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.13559463620185852, accuracy: 95.8 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.13911421597003937, accuracy: 95.0 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.12366324663162231, accuracy: 96.0 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.1459181010723114, accuracy: 95.2 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.12731753289699554, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.1936, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.1359, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.2177, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.2350, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.0902, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1617, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.1649, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.1326, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.2004, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.1315, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.17169708013534546, accuracy: 94.4 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.8836015462875366, accuracy: 76.0 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.15028464794158936, accuracy: 94.9 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.13804328441619873, accuracy: 95.5 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.13906297087669373, accuracy: 95.6 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.14255808293819427, accuracy: 95.2 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.13985641300678253, accuracy: 95.3 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.13019639253616333, accuracy: 95.9 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.1355608105659485, accuracy: 95.5 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.19708776473999023, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.1244, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.0983, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.1250, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.1607, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.0980, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.2265, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.0640, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.1658, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.1679, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.2136, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.12765586376190186, accuracy: 95.6 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.16139400005340576, accuracy: 94.3 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.1535828858613968, accuracy: 94.6 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.12381276488304138, accuracy: 95.5 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.12242929637432098, accuracy: 95.6 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.1156984344124794, accuracy: 95.9 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.11347895115613937, accuracy: 96.5 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.11313329637050629, accuracy: 96.2 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.11336389183998108, accuracy: 96.3 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.11230529099702835, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.2146, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.1552, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.1626, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.1658, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.1376, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.1490, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.0861, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.1050, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.2205, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.1802, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.1085071712732315, accuracy: 96.4 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 1.107913613319397, accuracy: 72.8 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.12289562076330185, accuracy: 96.0 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.10517759621143341, accuracy: 96.3 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.10373759269714355, accuracy: 96.0 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.10944507271051407, accuracy: 95.7 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.10631219297647476, accuracy: 96.0 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.1633584201335907, accuracy: 94.3 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.1442945897579193, accuracy: 94.6 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.15705670416355133, accuracy: 94.9 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.1055, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.1865, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1545, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.1584, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.1560, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.1548, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.0911, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.1846, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.1400, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.2339, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.12806116044521332, accuracy: 95.7 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 1.2533156871795654, accuracy: 74.2 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.12966670095920563, accuracy: 95.6 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.12232743203639984, accuracy: 95.6 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.188391774892807, accuracy: 93.9 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.1498899906873703, accuracy: 95.0 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.11601591855287552, accuracy: 96.0 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.11563336104154587, accuracy: 96.2 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.10882177203893661, accuracy: 96.8 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.10839088261127472, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.2032, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.2165, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.1766, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.1914, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.1386, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.1307, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.0827, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.1491, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.0592, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.2153, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.1159188374876976, accuracy: 96.1 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.1485135704278946, accuracy: 95.1 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.12820841372013092, accuracy: 95.6 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.10777991265058517, accuracy: 97.0 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.11806181818246841, accuracy: 95.7 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.1733168363571167, accuracy: 93.9 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.1031893938779831, accuracy: 96.5 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.1009480208158493, accuracy: 96.8 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.10121402889490128, accuracy: 96.8 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.09889044612646103, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.0810, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.1331, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.1456, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.0828, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.1821, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.1205, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.1429, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.1172, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.1778, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.1098, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.13021397590637207, accuracy: 96.8 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.1603582203388214, accuracy: 96.0 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.13488875329494476, accuracy: 96.6 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.23646508157253265, accuracy: 92.7 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.12112037092447281, accuracy: 96.8 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.15519720315933228, accuracy: 94.7 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.11405645310878754, accuracy: 96.4 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.11354635655879974, accuracy: 96.6 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.11376332491636276, accuracy: 96.5 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.1141575425863266, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.2288, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.2475, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.1500, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.1472, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.1416, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.2378, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.1062, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.1240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.1387, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.1362, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.14486537873744965, accuracy: 95.2 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.14983096718788147, accuracy: 95.2 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.1375207006931305, accuracy: 96.1 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.1366199404001236, accuracy: 96.1 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.14053738117218018, accuracy: 95.8 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.15659917891025543, accuracy: 95.6 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.14015965163707733, accuracy: 96.0 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.1274871975183487, accuracy: 96.5 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.1273748278617859, accuracy: 96.3 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.12516576051712036, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.0148, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.1212, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.1500, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.1153, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.1051, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.1238, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.1528, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.1620, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.1439, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.2588, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.09870222955942154, accuracy: 96.7 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.09921955317258835, accuracy: 96.7 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.10829295963048935, accuracy: 96.6 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.11230126768350601, accuracy: 96.7 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.09061852097511292, accuracy: 96.9 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.08968155831098557, accuracy: 97.2 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.08973378688097, accuracy: 97.1 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.08709132671356201, accuracy: 97.5 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.0872545912861824, accuracy: 97.3 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.08645714074373245, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.1035, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.1811, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.1153, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.1249, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.1142, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1700, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.1316, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.2670, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.1812, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.2104, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.15870758891105652, accuracy: 95.1 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.15394999086856842, accuracy: 95.2 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.15119481086730957, accuracy: 95.7 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.14299654960632324, accuracy: 95.4 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.14322316646575928, accuracy: 95.0 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.1620607227087021, accuracy: 94.7 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.14340457320213318, accuracy: 95.6 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.15191197395324707, accuracy: 95.2 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.13655026257038116, accuracy: 95.7 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.13507522642612457, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.1922, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.1571, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.1989, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.1485, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.1453, batch time: 0.24, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.0875, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.1025, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.1339, batch time: 0.07, accuracy:  96.88%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.1175, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.1694, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.12149503827095032, accuracy: 96.0 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.12665298581123352, accuracy: 95.8 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.12248747050762177, accuracy: 95.3 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.11241091042757034, accuracy: 96.4 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.11081503331661224, accuracy: 96.5 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.10743388533592224, accuracy: 96.8 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.1315712034702301, accuracy: 95.4 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.10334568470716476, accuracy: 96.6 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.1402166783809662, accuracy: 95.0 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.1274166852235794, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.1005, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.2472, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.1492, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.0857, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.1561, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.1862, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.1591, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.0845, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.1399, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.1435, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.13219940662384033, accuracy: 95.6 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.1404171586036682, accuracy: 94.9 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.1166246235370636, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.11535456776618958, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.11738113313913345, accuracy: 96.0 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.14683139324188232, accuracy: 95.0 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.12344901263713837, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.10618247091770172, accuracy: 96.7 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.10569258779287338, accuracy: 96.6 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.10560353100299835, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.1006, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.1359, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.1116, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.1466, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.1097, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.0543, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.0998, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.1540, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.1394, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.1669, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.11870043724775314, accuracy: 96.5 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 3.861600875854492, accuracy: 43.8 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.10036056488752365, accuracy: 96.4 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.09813249856233597, accuracy: 97.0 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.10549882054328918, accuracy: 96.5 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.09358157217502594, accuracy: 97.2 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.09184964746236801, accuracy: 97.1 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.19228051602840424, accuracy: 93.4 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.08753634989261627, accuracy: 97.0 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.08716100454330444, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.2423, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.2020, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.1405, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.0936, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.1059, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.0431, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.1068, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.2038, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.1655, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.1257, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.14696352183818817, accuracy: 95.6 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.1574171483516693, accuracy: 95.0 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.1477111428976059, accuracy: 96.1 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.13919545710086823, accuracy: 96.2 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.14062078297138214, accuracy: 95.5 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.16183428466320038, accuracy: 95.3 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.14122679829597473, accuracy: 95.2 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.12604545056819916, accuracy: 95.7 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.11822739988565445, accuracy: 96.4 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.1685926467180252, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.1006, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.1890, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.0636, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.1359, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.1191, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.0687, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.2010, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.1478, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.1701, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.1104, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.10550601035356522, accuracy: 96.6 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 2.1108438968658447, accuracy: 57.5 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.10411833971738815, accuracy: 97.0 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.09929376095533371, accuracy: 97.4 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.10860677808523178, accuracy: 97.2 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.09582621604204178, accuracy: 97.1 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.11485933512449265, accuracy: 96.3 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.0980059802532196, accuracy: 96.9 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.12394969165325165, accuracy: 96.8 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.08660410344600677, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.0981, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.1365, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.1015, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.1816, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.1039, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.1882, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.1124, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.1675, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.2149, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.1397, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.11720436811447144, accuracy: 96.0 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.1233326718211174, accuracy: 96.1 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.15089643001556396, accuracy: 94.8 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.11036179214715958, accuracy: 96.3 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.10923485457897186, accuracy: 97.0 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.11299635469913483, accuracy: 96.5 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.10498131811618805, accuracy: 97.1 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.10226037353277206, accuracy: 97.0 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.1021246537566185, accuracy: 96.9 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.10339368134737015, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.0762, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.1692, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.0843, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.0689, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.2082, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.1525, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.1172, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.2034, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.1600, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.11026265472173691, accuracy: 96.3 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.12254572659730911, accuracy: 96.1 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.11642459034919739, accuracy: 96.3 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.1224595382809639, accuracy: 96.1 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.16024768352508545, accuracy: 94.7 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.104451984167099, accuracy: 96.7 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.09166073054075241, accuracy: 97.0 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.09258224070072174, accuracy: 97.3 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.09136316180229187, accuracy: 97.1 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.09464539587497711, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.2094, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.2908, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.0977, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.1126, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.1779, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.1666, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.1126, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.0703, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.1212, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.1412, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.15449468791484833, accuracy: 95.6 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.16370123624801636, accuracy: 95.4 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.17223654687404633, accuracy: 94.3 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.15041759610176086, accuracy: 95.5 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.20161308348178864, accuracy: 93.5 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.14406518638134003, accuracy: 95.8 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.14037758111953735, accuracy: 95.9 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.1383272111415863, accuracy: 96.0 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.13834872841835022, accuracy: 96.1 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.136834517121315, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.1112, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.0598, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.0890, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.1046, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.1590, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.1231, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.0572, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.1156, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.2119, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.1830, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.11736258864402771, accuracy: 97.1 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.13413815200328827, accuracy: 96.7 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.1254052221775055, accuracy: 96.4 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.11946489661931992, accuracy: 96.6 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.1118725910782814, accuracy: 96.9 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.10246893763542175, accuracy: 97.5 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.10216344147920609, accuracy: 97.3 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.10038630664348602, accuracy: 97.7 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.10009989887475967, accuracy: 97.5 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.09903456270694733, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.0817, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.1029, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.0995, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.1351, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.1766, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.1688, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.1461, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.1568, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.1372, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.0984, batch time: 0.37, accuracy:  94.53%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.11469393223524094, accuracy: 96.2 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.1574907898902893, accuracy: 95.2 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.11251165717840195, accuracy: 96.2 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.1105387806892395, accuracy: 96.1 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.11031674593687057, accuracy: 96.1 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.12009523808956146, accuracy: 96.3 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.10595756769180298, accuracy: 96.9 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.12407225370407104, accuracy: 95.2 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.12178882956504822, accuracy: 95.8 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.10762720555067062, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.1228, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.1816, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.1340, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.3059, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.1274, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.0885, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.0661, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.1091, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.1239, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.1264, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.13221697509288788, accuracy: 95.6 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.13297177851200104, accuracy: 95.9 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.14383818209171295, accuracy: 94.9 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.12171707302331924, accuracy: 96.4 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.12386922538280487, accuracy: 96.3 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.11720079183578491, accuracy: 96.2 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.12071101367473602, accuracy: 96.2 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.1163577288389206, accuracy: 96.0 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.11440873891115189, accuracy: 96.1 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.11420006304979324, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.1202, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.1141, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.1237, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.2758, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.1156, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.1694, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.0830, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.1595, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.1593, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.1508, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.12330370396375656, accuracy: 96.7 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.13967265188694, accuracy: 95.5 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.11939025670289993, accuracy: 96.5 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.15230251848697662, accuracy: 94.9 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.12039938569068909, accuracy: 96.2 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.1147221177816391, accuracy: 96.5 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.1437261402606964, accuracy: 95.3 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.12829013168811798, accuracy: 95.9 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.10646737366914749, accuracy: 97.1 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.4671862721443176, accuracy: 88.0 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.0581, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.1728, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.0878, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.0891, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.1918, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.0540, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.0585, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.1063, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.0440, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.1597, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.12442343682050705, accuracy: 96.0 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.16121135652065277, accuracy: 95.1 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.1253373622894287, accuracy: 96.1 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.245806023478508, accuracy: 92.1 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.12476993352174759, accuracy: 96.0 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.11161483824253082, accuracy: 96.0 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.1050131544470787, accuracy: 96.4 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.10153231769800186, accuracy: 96.7 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.10392773151397705, accuracy: 96.4 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.10107944905757904, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.1371, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.0706, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.0819, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.1079, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.0959, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.1315, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.1791, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.1232, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.1161, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.0751, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.11858639121055603, accuracy: 96.7 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.13870835304260254, accuracy: 95.9 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.12139160931110382, accuracy: 96.4 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.11415942013263702, accuracy: 96.8 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.13708816468715668, accuracy: 96.0 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.12374534457921982, accuracy: 96.6 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.10655662417411804, accuracy: 97.2 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.1279790997505188, accuracy: 96.5 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.11341787129640579, accuracy: 96.7 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.1185741201043129, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.1778, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.1362, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.0958, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.3532, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.1455, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.2264, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.1504, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.2242, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.1238, batch time: 0.26, accuracy:  95.31%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.1526908129453659, accuracy: 95.2 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.1843966543674469, accuracy: 93.8 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.14007382094860077, accuracy: 95.4 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.13848437368869781, accuracy: 95.4 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.161092147231102, accuracy: 95.1 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.13554497063159943, accuracy: 95.8 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.13706865906715393, accuracy: 96.0 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.13195380568504333, accuracy: 95.6 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.1317467838525772, accuracy: 96.0 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.13029958307743073, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.0873, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.1560, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.0498, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.1868, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.1727, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.1111, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.1437, batch time: 0.26, accuracy:  95.31%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.1989, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.1235, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.0916, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.09600040316581726, accuracy: 97.2 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.10920412838459015, accuracy: 96.6 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.09361399710178375, accuracy: 97.0 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.09099531918764114, accuracy: 97.4 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.20940883457660675, accuracy: 92.9 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.1369795948266983, accuracy: 95.5 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.09601150453090668, accuracy: 97.4 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.0803099051117897, accuracy: 97.8 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.08607133477926254, accuracy: 97.6 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.07828608900308609, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.1126, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.1412, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.2243, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.2000, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.1356, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.1568, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.0794, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.0889, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.1438, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.1412, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.11688573658466339, accuracy: 96.1 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 1.0904186964035034, accuracy: 70.7 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.11514174938201904, accuracy: 96.1 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.11136429011821747, accuracy: 96.1 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.1142219752073288, accuracy: 96.4 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.11500758677721024, accuracy: 96.6 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.10597378015518188, accuracy: 96.6 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.10722331702709198, accuracy: 96.4 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.10412728041410446, accuracy: 96.5 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.10343028604984283, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.1261, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.1203, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.0993, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.1055, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.0525, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.1707, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.1035, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.0621, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.0799, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.2563, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.14739200472831726, accuracy: 95.1 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.1038341522216797, accuracy: 73.2 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.17385664582252502, accuracy: 93.9 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.13639654219150543, accuracy: 95.2 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.1501876264810562, accuracy: 94.9 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.13143879175186157, accuracy: 95.8 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.15009020268917084, accuracy: 95.5 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.12420032173395157, accuracy: 95.9 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.12342803925275803, accuracy: 95.9 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.12692837417125702, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.2271, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.1913, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.1435, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.1385, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.1293, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.1057, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.1112, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.0943, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.1009, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.1272, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.13174861669540405, accuracy: 95.2 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 1.6763780117034912, accuracy: 62.8 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.12675870954990387, accuracy: 95.5 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.12680642306804657, accuracy: 95.9 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.17567844688892365, accuracy: 94.1 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.127031609416008, accuracy: 96.0 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.1134733110666275, accuracy: 96.0 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.1118166446685791, accuracy: 96.0 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.11033954471349716, accuracy: 96.1 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.10870344936847687, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.1702, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.1750, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.1802, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.2023, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.2251, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.1246, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.1338, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.0712, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.0764, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.0856, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.13549719750881195, accuracy: 96.5 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 1.165648341178894, accuracy: 69.7 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.13356365263462067, accuracy: 96.7 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.1284388154745102, accuracy: 96.5 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.1532972902059555, accuracy: 95.1 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.13133352994918823, accuracy: 95.9 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.12119893729686737, accuracy: 96.5 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.11943179368972778, accuracy: 96.8 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.11614600569009781, accuracy: 96.7 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.1147727370262146, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.1271, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.1931, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.1029, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.2638, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.0593, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.1326, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.0820, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.2573, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.2753, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.1220, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.12728580832481384, accuracy: 96.1 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.296919345855713, accuracy: 71.0 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.1279938817024231, accuracy: 95.8 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.12209229171276093, accuracy: 96.7 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.16630935668945312, accuracy: 94.9 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.1436571478843689, accuracy: 95.0 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.14175757765769958, accuracy: 95.1 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.1130526065826416, accuracy: 96.6 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.11428897082805634, accuracy: 96.8 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.11257481575012207, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.1196, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.2221, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.0562, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.1892, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.1174, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.0837, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.0481, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.0855, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.2182, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.2763, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.16284912824630737, accuracy: 95.7 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 1.107366681098938, accuracy: 71.9 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.15785151720046997, accuracy: 95.4 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.14310653507709503, accuracy: 95.6 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.1400618851184845, accuracy: 95.7 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.1595991849899292, accuracy: 95.1 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.2811063230037689, accuracy: 91.2 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.2452441304922104, accuracy: 91.7 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.13855421543121338, accuracy: 95.5 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.12977449595928192, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.0858, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.0939, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.1630, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.1707, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.1270, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.1614, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.0931, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.1166, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.2248, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.0611, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.10693378001451492, accuracy: 96.1 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.11193845421075821, accuracy: 96.2 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.10633327066898346, accuracy: 96.0 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.10440512746572495, accuracy: 96.6 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.12816521525382996, accuracy: 95.6 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.1012953519821167, accuracy: 96.8 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.10228442400693893, accuracy: 96.3 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.10235988348722458, accuracy: 96.4 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.10093523561954498, accuracy: 96.7 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.10062147676944733, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.1375, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.0902, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.1169, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.2685, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.0936, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.1039, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.1603, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.1223, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.0993, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.2041, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.10310635715723038, accuracy: 97.2 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.11417605727910995, accuracy: 96.6 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.17335501313209534, accuracy: 94.3 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.0993451252579689, accuracy: 96.9 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.10071562975645065, accuracy: 97.2 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.09681009501218796, accuracy: 97.5 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.0951787531375885, accuracy: 97.1 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.0938592478632927, accuracy: 97.7 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.09763240069150925, accuracy: 97.4 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.09248348325490952, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.0686, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.1486, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.0555, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.1337, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.0839, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.1131, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.1583, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.1136, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.1419, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.0871, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.0863337367773056, accuracy: 97.3 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.08894401788711548, accuracy: 97.2 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.13711877167224884, accuracy: 95.9 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.08453422784805298, accuracy: 97.6 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.22671809792518616, accuracy: 91.8 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.08030764013528824, accuracy: 98.0 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.07953587919473648, accuracy: 97.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.07720915973186493, accuracy: 97.7 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.07693707942962646, accuracy: 97.9 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.07722967118024826, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.1832, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.1126, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.1329, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.1240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.0925, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.1478, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.1260, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.1942, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.1225, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.1677, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.10677081346511841, accuracy: 96.8 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.11355838924646378, accuracy: 96.5 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.1066000908613205, accuracy: 96.8 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.10597891360521317, accuracy: 96.9 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.12264035642147064, accuracy: 96.4 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.11673379689455032, accuracy: 96.0 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.1314823031425476, accuracy: 95.7 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.10108035057783127, accuracy: 96.8 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.09897111356258392, accuracy: 97.1 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.09975095838308334, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.1754, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.0960, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.1480, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.2657, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.0812, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.1487, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.1131, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.1367, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.0965, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.2530, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.10048450529575348, accuracy: 96.5 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.8038501143455505, accuracy: 79.6 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.14952164888381958, accuracy: 93.6 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.1025506928563118, accuracy: 96.2 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.14042705297470093, accuracy: 95.3 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.11287669837474823, accuracy: 96.2 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.11772329360246658, accuracy: 95.6 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.09991618245840073, accuracy: 96.7 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.08006273955106735, accuracy: 97.3 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.07878845930099487, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.1980, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.0737, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.1880, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.0908, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.0819, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.1031, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.0937, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.2865, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.0986, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.11533790081739426, accuracy: 96.7 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.14694535732269287, accuracy: 95.5 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.11875417083501816, accuracy: 96.8 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.10448836535215378, accuracy: 97.0 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.11059640347957611, accuracy: 96.7 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.10184400528669357, accuracy: 97.2 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.10168851912021637, accuracy: 97.3 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.09655144065618515, accuracy: 97.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.09554100781679153, accuracy: 97.6 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.09369467198848724, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.0946, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.1334, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.1341, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.1460, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.1782, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.1240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.1636, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.1372, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.0830, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.0731, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.12152094393968582, accuracy: 97.2 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.6107943058013916, accuracy: 82.2 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.1625678390264511, accuracy: 94.8 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.11087776720523834, accuracy: 97.1 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.1318117380142212, accuracy: 95.7 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.10508017987012863, accuracy: 97.1 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.10551051795482635, accuracy: 97.0 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.11291304230690002, accuracy: 96.7 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.10301030427217484, accuracy: 97.6 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.10446535795927048, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.1347, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.0621, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.1038, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.0957, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.0958, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.1007, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.0977, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.1130, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.0459, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.1001, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.09317221492528915, accuracy: 97.0 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.5471405982971191, accuracy: 84.3 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.11849553138017654, accuracy: 96.2 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.10204806923866272, accuracy: 96.9 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.12390976399183273, accuracy: 95.5 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.08327817171812057, accuracy: 97.3 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.08235300332307816, accuracy: 97.5 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.08628817647695541, accuracy: 97.3 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.08058518916368484, accuracy: 97.6 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.08069717139005661, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.1446, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.1174, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.1222, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.1236, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.1254, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.2193, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.0925, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.2508, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.1543, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.1404, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.11480500549077988, accuracy: 95.9 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.6623272895812988, accuracy: 81.5 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.12384704500436783, accuracy: 95.8 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.15235352516174316, accuracy: 95.0 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.11164349317550659, accuracy: 96.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.10882926732301712, accuracy: 96.1 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.10650764405727386, accuracy: 96.3 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.10451161116361618, accuracy: 96.3 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.10477007180452347, accuracy: 96.4 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.10384781658649445, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.0929, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.1387, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.0819, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.1257, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.1623, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.1916, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.2121, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.0958, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.1702, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.0571, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.12379717826843262, accuracy: 95.5 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.13986286520957947, accuracy: 94.9 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.12236737459897995, accuracy: 95.8 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.1121729165315628, accuracy: 96.5 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.2033538520336151, accuracy: 93.4 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.11733638495206833, accuracy: 96.3 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.10241954773664474, accuracy: 97.0 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.09999121725559235, accuracy: 97.2 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.09930113703012466, accuracy: 97.3 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.09881646186113358, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.0825, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.1253, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.1410, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.0437, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.1589, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.2436, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.1663, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.1012, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.1705, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.2025, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.11128393560647964, accuracy: 97.0 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.689949095249176, accuracy: 83.4 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.11042463779449463, accuracy: 97.1 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.10948984324932098, accuracy: 96.9 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.1158405989408493, accuracy: 96.2 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.18331997096538544, accuracy: 94.6 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.10416220873594284, accuracy: 96.9 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.10262215882539749, accuracy: 96.6 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.10251908749341965, accuracy: 96.9 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.10144391655921936, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.1204, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.1073, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.1960, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.1543, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.1705, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.1941, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.0984, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.1262, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.1838, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.11305651068687439, accuracy: 97.0 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.4521805942058563, accuracy: 86.4 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.11244308948516846, accuracy: 96.8 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.11226470023393631, accuracy: 96.8 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.15047435462474823, accuracy: 94.9 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.11290092021226883, accuracy: 96.7 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.15999329090118408, accuracy: 95.2 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.1276359111070633, accuracy: 96.1 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.10300881415605545, accuracy: 97.2 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.10116471350193024, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.1071, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.1304, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.1944, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.0820, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.1306, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.1674, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.1465, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.0733, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.0916, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.1275344043970108, accuracy: 95.5 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.18874825537204742, accuracy: 93.4 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.14327584207057953, accuracy: 95.1 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.1422700136899948, accuracy: 95.8 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.12170295417308807, accuracy: 96.1 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.1167980432510376, accuracy: 95.8 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.12763366103172302, accuracy: 95.3 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.12565091252326965, accuracy: 95.5 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.11080990731716156, accuracy: 95.8 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.10821579396724701, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.2006, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.1247, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.0964, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.1667, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.2195, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.1307, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.2795, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.1747, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.1428, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.0915, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.12088284641504288, accuracy: 96.0 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.12516896426677704, accuracy: 95.9 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.11787334084510803, accuracy: 96.8 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.14500172436237335, accuracy: 95.4 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.10956043750047684, accuracy: 96.4 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.10573358088731766, accuracy: 96.6 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.10465172678232193, accuracy: 96.8 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.1041838601231575, accuracy: 96.9 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.10300860553979874, accuracy: 96.8 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.1034516990184784, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.1036, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.0537, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.2114, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.0516, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.2052, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.0888, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.0767, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.1922, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.0850, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.1747, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.10652189701795578, accuracy: 96.9 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.12835317850112915, accuracy: 96.0 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.10242944955825806, accuracy: 97.1 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.10390772670507431, accuracy: 96.7 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.0946941003203392, accuracy: 96.7 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.0900745615363121, accuracy: 97.2 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.0914916843175888, accuracy: 97.3 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.08854475617408752, accuracy: 97.1 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.08854617923498154, accuracy: 97.4 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.08762308955192566, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.1186, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.1885, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.2025, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.1103, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.1077, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.1630, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.0870, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.1714, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.1354, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.1201, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.12126287072896957, accuracy: 96.0 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 1.2614398002624512, accuracy: 70.7 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.14038300514221191, accuracy: 95.2 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.18156872689723969, accuracy: 94.5 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.11458803713321686, accuracy: 96.3 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.13197000324726105, accuracy: 95.4 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.11853574961423874, accuracy: 96.0 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.10556536912918091, accuracy: 97.0 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.10441682487726212, accuracy: 97.2 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.10474526882171631, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.1422, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.1724, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.0618, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.1584, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.0545, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.1837, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.0497, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.0709, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.2429, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.1862, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.08790663629770279, accuracy: 97.1 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.11376679688692093, accuracy: 96.2 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.08562206476926804, accuracy: 97.5 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.08282113820314407, accuracy: 97.4 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.1367829442024231, accuracy: 96.3 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.07723616808652878, accuracy: 97.8 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.07683120667934418, accuracy: 97.9 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.07607022672891617, accuracy: 97.7 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.07530258595943451, accuracy: 97.7 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.07708775252103806, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.0742, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.0601, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.0999, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.1824, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.0987, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.0814, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.1149, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.1632, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.0805, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.1230, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.1180056482553482, accuracy: 97.0 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.24038778245449066, accuracy: 91.4 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.1219448372721672, accuracy: 96.5 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.11789221316576004, accuracy: 96.6 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.11061924695968628, accuracy: 96.8 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.10696590691804886, accuracy: 96.7 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.10730975866317749, accuracy: 96.8 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.10492017865180969, accuracy: 96.9 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.10376919060945511, accuracy: 97.0 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.10538298636674881, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.0524, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.1001, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.3668, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.1002, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.0790, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.0955, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.0620, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.1136, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.1164, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.0567, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.07595092058181763, accuracy: 98.0 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.07586923241615295, accuracy: 97.9 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.07758894562721252, accuracy: 97.8 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.10147208720445633, accuracy: 96.4 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.07061874866485596, accuracy: 98.4 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.06657315045595169, accuracy: 98.2 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.066367007791996, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.06532420217990875, accuracy: 98.6 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.06575673073530197, accuracy: 98.3 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.06505434960126877, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.1077, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.1045, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.0460, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.0989, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.2984, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.2192, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.1452, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.1446, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.0808, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.11965538561344147, accuracy: 96.3 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.1440395712852478, accuracy: 95.4 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.12463527172803879, accuracy: 96.5 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.1500837355852127, accuracy: 95.2 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.10864754021167755, accuracy: 97.2 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.105051688849926, accuracy: 97.2 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.10612282902002335, accuracy: 97.3 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.10596726089715958, accuracy: 97.4 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.10483472794294357, accuracy: 97.4 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.10485319793224335, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.1582, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.1009, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.1757, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.0899, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.1578, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.1388, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.0887, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.0592, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.1309, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.0384, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.10322634875774384, accuracy: 96.5 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.10704731941223145, accuracy: 96.5 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.10149567574262619, accuracy: 96.9 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.10052122175693512, accuracy: 96.7 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.10971678793430328, accuracy: 96.2 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.11646301299333572, accuracy: 96.4 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.12402147054672241, accuracy: 95.9 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.09495184570550919, accuracy: 97.0 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.09300646185874939, accuracy: 97.1 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.09058714658021927, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.1317, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.1845, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.2244, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.0741, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.1409, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.1148, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.0448, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.1775, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.1368, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.1542, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.12174879014492035, accuracy: 96.0 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.12687191367149353, accuracy: 95.7 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.1245923861861229, accuracy: 95.9 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.10946125537157059, accuracy: 96.5 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.12131110578775406, accuracy: 96.5 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.12176155298948288, accuracy: 95.9 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.15517152845859528, accuracy: 93.8 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.17205679416656494, accuracy: 94.7 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.11144156754016876, accuracy: 96.6 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.12207477539777756, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.0809, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.1335, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.0910, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.1096, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.2170, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.1067, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.0278, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.0618, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.1902, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.1172, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.12322181463241577, accuracy: 96.3 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.14177867770195007, accuracy: 95.8 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.12041694670915604, accuracy: 96.1 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.10759291797876358, accuracy: 96.5 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.11178526282310486, accuracy: 96.4 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.10426072031259537, accuracy: 96.7 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.10138514637947083, accuracy: 96.9 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.10006867349147797, accuracy: 96.9 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.09978627413511276, accuracy: 97.1 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.09838095307350159, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.0733, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.0671, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.1436, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.0694, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.1250, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.0500, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.1199, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.1180, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.1094, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.09596700966358185, accuracy: 97.2 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.9836490154266357, accuracy: 72.7 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.10596839338541031, accuracy: 96.4 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.09319688379764557, accuracy: 97.0 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.09756969660520554, accuracy: 96.6 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.13142162561416626, accuracy: 95.0 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.09721408784389496, accuracy: 96.7 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.08644521236419678, accuracy: 97.2 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.08622109144926071, accuracy: 97.2 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.08462472259998322, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.0930, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.1884, batch time: 0.09, accuracy:  92.97%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.1062, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.0462, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.1105, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.1351, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.1283, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.1034, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.1393, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.11542627215385437, accuracy: 96.2 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.11542250216007233, accuracy: 96.2 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.10863474011421204, accuracy: 96.7 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.10680368542671204, accuracy: 96.9 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.11366245895624161, accuracy: 96.5 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.10265181958675385, accuracy: 96.9 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.09952977299690247, accuracy: 96.6 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.0981060117483139, accuracy: 96.7 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.09604212641716003, accuracy: 96.9 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.09586058557033539, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.1182, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.1535, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.1790, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.1467, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.0992, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.1405, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.1079, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.1607, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.0564, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.0970, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.1305059939622879, accuracy: 96.8 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.15446625649929047, accuracy: 95.8 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.1334790140390396, accuracy: 96.1 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.1418759673833847, accuracy: 95.4 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.13038749992847443, accuracy: 96.2 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.0953267440199852, accuracy: 97.4 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.08765723556280136, accuracy: 97.5 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.08647938072681427, accuracy: 97.6 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.08594651520252228, accuracy: 97.5 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.08700180053710938, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.1770, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.0844, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.1424, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.1676, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.2372, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.2171, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0971, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.1541, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.1496, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.1369, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.14935769140720367, accuracy: 95.2 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.158656507730484, accuracy: 94.7 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.1461307853460312, accuracy: 95.5 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.14547163248062134, accuracy: 95.3 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.15544943511486053, accuracy: 95.2 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.16294091939926147, accuracy: 94.1 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.15467952191829681, accuracy: 95.2 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.17168746888637543, accuracy: 93.9 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.13529330492019653, accuracy: 95.7 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.1335514932870865, accuracy: 95.5 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.1470, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.1348, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.1718, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.1643, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.1665, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.1817, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.1334, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.1662, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.1220, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.0917, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.0967748686671257, accuracy: 97.6 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.10639313608407974, accuracy: 97.1 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.09954560548067093, accuracy: 97.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.08828308433294296, accuracy: 98.0 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.10705242305994034, accuracy: 97.1 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.12141897529363632, accuracy: 96.0 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.10718489438295364, accuracy: 96.8 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.0879153162240982, accuracy: 98.0 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.10612764209508896, accuracy: 97.2 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.0924270749092102, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.0959, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.0752, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.0676, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.0937, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.0948, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.1118, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.1005, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.1499, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.0989, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.0927, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.13240540027618408, accuracy: 96.4 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.13698935508728027, accuracy: 96.4 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.14021380245685577, accuracy: 95.5 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.13443870842456818, accuracy: 96.1 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.12143666297197342, accuracy: 96.3 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.11361543834209442, accuracy: 96.9 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.11323750764131546, accuracy: 96.8 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.10929636657238007, accuracy: 97.1 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.10848541557788849, accuracy: 97.1 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.10679600387811661, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.1674, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.1628, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.0862, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.1169, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.1492, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.2311, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.1031, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.1563, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.2208, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.0873, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.12995120882987976, accuracy: 95.6 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.12831102311611176, accuracy: 95.4 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 0.13230890035629272, accuracy: 95.3 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.1387811303138733, accuracy: 95.4 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.1107282042503357, accuracy: 96.4 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.10791463404893875, accuracy: 96.2 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.10506539791822433, accuracy: 96.2 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.10388560593128204, accuracy: 96.6 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.10199572890996933, accuracy: 96.6 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.10070931166410446, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.0967, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.1940, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.1054, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.1012, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.1405, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.0877, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.0917, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.1463, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.1874, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.2850, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.146780863404274, accuracy: 95.0 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.16418831050395966, accuracy: 94.3 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.13570088148117065, accuracy: 95.9 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.11858344078063965, accuracy: 96.0 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.15892471373081207, accuracy: 94.6 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.10688629001379013, accuracy: 96.2 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.10299774259328842, accuracy: 96.4 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.09958731383085251, accuracy: 96.7 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.0991392433643341, accuracy: 97.1 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.09795687347650528, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.0937, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.1029, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.1920, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.1049, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.0959, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.1222, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.1463, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.1331, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.0986, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.09335269033908844, accuracy: 97.0 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.09711720794439316, accuracy: 96.8 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.10507258027791977, accuracy: 96.9 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.08767383545637131, accuracy: 97.4 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.09785427898168564, accuracy: 97.4 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.08498211950063705, accuracy: 97.4 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.08602898567914963, accuracy: 97.3 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.08150586485862732, accuracy: 97.5 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.0813557356595993, accuracy: 97.5 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.08035531640052795, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.1353, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.1699, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.1563, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.1449, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.1370, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.1919, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.0887, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.1159, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.0447, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.0988, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.11665026098489761, accuracy: 96.6 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.14048606157302856, accuracy: 95.6 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.11615480482578278, accuracy: 96.5 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.1156579777598381, accuracy: 96.2 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.16079312562942505, accuracy: 95.4 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.15638580918312073, accuracy: 95.4 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.1399359554052353, accuracy: 95.3 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.10931811481714249, accuracy: 96.8 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.10696019977331161, accuracy: 96.7 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.10747886449098587, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.2602, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.0771, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.1708, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.2798, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.1288, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.1491, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.0397, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.2218, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.1042, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.1092, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.09572834521532059, accuracy: 97.0 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.10594572126865387, accuracy: 96.8 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.09500520676374435, accuracy: 97.3 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.1748848706483841, accuracy: 93.8 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.08962666243314743, accuracy: 97.5 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.08618749678134918, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.08502579480409622, accuracy: 97.6 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.08395373821258545, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.08335869759321213, accuracy: 98.0 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.0827900618314743, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.1957, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.1222, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.2141, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.0774, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.2102, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.1891, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.1540, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.0965, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.0910, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.1025, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.11148270964622498, accuracy: 96.3 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.10608448088169098, accuracy: 96.5 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.12984251976013184, accuracy: 95.4 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.10456754267215729, accuracy: 96.6 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.14548297226428986, accuracy: 94.1 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.14478766918182373, accuracy: 94.6 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.09743711352348328, accuracy: 96.7 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.09351037442684174, accuracy: 96.9 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.09463918954133987, accuracy: 97.2 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.09126389026641846, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.1910, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.1811, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.1201, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.0698, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.2261, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.1297, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.1355, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.1043, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.0968, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.1640, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.12741833925247192, accuracy: 95.6 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.38560304045677185, accuracy: 87.3 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.11884644627571106, accuracy: 95.9 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.11086899787187576, accuracy: 96.1 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.12170019000768661, accuracy: 95.4 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.114348866045475, accuracy: 96.1 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.12546898424625397, accuracy: 95.6 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.09970023483037949, accuracy: 96.6 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.10050446540117264, accuracy: 96.8 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.10194046050310135, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.1262, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.0417, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.1250, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.0562, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.1683, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.0847, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.0815, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.1095, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.0819, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.0938, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.09996477514505386, accuracy: 96.8 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.10281333327293396, accuracy: 96.7 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.09638169407844543, accuracy: 96.8 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.08899474143981934, accuracy: 97.0 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.10517560690641403, accuracy: 96.2 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.08676628768444061, accuracy: 97.3 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.08117267489433289, accuracy: 97.5 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.07892333716154099, accuracy: 97.4 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.0782996192574501, accuracy: 98.0 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.08120105415582657, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.0741, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.2131, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.1765, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.0516, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.0549, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.3396, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.1578, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.0891, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.1468, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.0981, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.07889063656330109, accuracy: 97.2 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.2880690097808838, accuracy: 68.2 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.09189266711473465, accuracy: 96.6 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.07412643730640411, accuracy: 97.4 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.06979323923587799, accuracy: 97.7 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.08849135786294937, accuracy: 97.0 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.08963261544704437, accuracy: 96.7 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.06673362106084824, accuracy: 97.7 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.06493810564279556, accuracy: 97.8 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.06513025611639023, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.1405, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.0974, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.0650, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.0955, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.1226, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.1907, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.2152, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.1303, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.1672, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.0486, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.1257951557636261, accuracy: 95.7 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.2090681791305542, accuracy: 68.9 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.1190110519528389, accuracy: 95.6 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.11065278202295303, accuracy: 95.9 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.10666986554861069, accuracy: 96.3 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.10904446989297867, accuracy: 96.2 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.11383772641420364, accuracy: 96.0 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.10205639898777008, accuracy: 97.1 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.10546506941318512, accuracy: 96.5 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.14089705049991608, accuracy: 94.5 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.2131, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.2180, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.1419, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.1796, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.0520, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.1498, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.0954, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.0722, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.1216, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.1890, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.09106124192476273, accuracy: 98.0 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.811814546585083, accuracy: 80.0 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.12138699740171432, accuracy: 96.6 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.13703744113445282, accuracy: 95.4 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.09970715641975403, accuracy: 96.9 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.08395834267139435, accuracy: 97.6 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.07915844768285751, accuracy: 97.9 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.07883379608392715, accuracy: 97.9 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.07630106061697006, accuracy: 98.3 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.07455103099346161, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.0558, batch time: 0.33, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0696, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.0909, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.0934, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.1103, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.1432, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.0444, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.2027, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.0779, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.1157, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.08760476857423782, accuracy: 96.6 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.09562443196773529, accuracy: 96.7 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.08537448197603226, accuracy: 97.1 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.1075182557106018, accuracy: 96.1 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.08933145552873611, accuracy: 97.3 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.08088944107294083, accuracy: 97.4 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.07926280796527863, accuracy: 97.6 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.07897499948740005, accuracy: 97.2 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.07884741574525833, accuracy: 97.3 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.08300957083702087, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.1187, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.1286, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.1003, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.1265, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.1214, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.1725, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.1571, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.2145, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.0980, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.2084, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.1135747954249382, accuracy: 96.7 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.13415811955928802, accuracy: 96.0 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.11105279624462128, accuracy: 96.7 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.11001542210578918, accuracy: 96.4 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.14034192264080048, accuracy: 95.7 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.13480691611766815, accuracy: 95.3 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.10900570452213287, accuracy: 96.6 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.09683800488710403, accuracy: 97.3 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.0965176373720169, accuracy: 97.4 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.09788039326667786, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.1238, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.3429, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.1668, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.1447, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.1496, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.0973, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.1402, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.1141, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.1301, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.1260, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.11999017745256424, accuracy: 96.2 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.13088330626487732, accuracy: 95.2 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.12091391533613205, accuracy: 95.3 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.11261060833930969, accuracy: 96.1 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.09947305917739868, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.09791554510593414, accuracy: 96.8 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.09709881991147995, accuracy: 96.7 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.0961286798119545, accuracy: 96.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.09682299196720123, accuracy: 96.5 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.09499985724687576, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.1432, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.0612, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.0480, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.1536, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.1024, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.1878, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.1426, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.1148, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.0841, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.1092, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.10926584899425507, accuracy: 96.0 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.11451877653598785, accuracy: 95.9 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.13915614783763885, accuracy: 94.7 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.12379416078329086, accuracy: 96.4 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.09566957503557205, accuracy: 96.9 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.09400369226932526, accuracy: 97.0 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.09460394084453583, accuracy: 97.1 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.09223882853984833, accuracy: 97.1 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.100435771048069, accuracy: 96.6 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.09095951169729233, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.1240, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.0644, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.1399, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.1897, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.1163, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.0652, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.0857, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.1599, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.0756, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.0970, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.08058694005012512, accuracy: 97.3 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.10355532169342041, accuracy: 96.1 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.09570135921239853, accuracy: 97.0 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.07731844484806061, accuracy: 97.7 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.07923568785190582, accuracy: 97.5 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.07443441450595856, accuracy: 97.6 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.0753137543797493, accuracy: 97.7 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.07755833864212036, accuracy: 97.7 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.07630183547735214, accuracy: 97.8 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.07245088368654251, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.1601, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.0978, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.1181, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.1107, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.1528, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.1292, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.1258, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.1409, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.2062, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.09908369183540344, accuracy: 96.9 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.7397484183311462, accuracy: 83.4 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.09312903881072998, accuracy: 97.1 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.09312903881072998, accuracy: 97.1 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.12069448083639145, accuracy: 95.6 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.08398522436618805, accuracy: 97.5 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.08167081326246262, accuracy: 97.6 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.07992468774318695, accuracy: 97.9 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.08000479638576508, accuracy: 97.7 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.08430379629135132, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.1413, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.1576, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.1059, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.1045, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.0885, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.2149, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.1269, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.2375, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.1363, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.1234, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.11090785264968872, accuracy: 96.5 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.137437641620636, accuracy: 95.3 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.12120553851127625, accuracy: 95.7 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.09934937953948975, accuracy: 96.8 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.11401015520095825, accuracy: 96.6 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.09541141986846924, accuracy: 96.9 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.09449070692062378, accuracy: 96.8 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.09354721009731293, accuracy: 97.1 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.0924946665763855, accuracy: 96.9 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.09205098450183868, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.1761, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.1956, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.1211, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.0639, batch time: 0.33, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.1340, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.1253, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.0915, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.0809, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.0698, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.10591428726911545, accuracy: 96.0 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.12255384773015976, accuracy: 95.7 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.10228361934423447, accuracy: 96.0 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.09650210291147232, accuracy: 97.0 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.18018724024295807, accuracy: 94.6 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.08972097933292389, accuracy: 96.4 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.08835651725530624, accuracy: 96.7 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.08577260375022888, accuracy: 97.1 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.08634831011295319, accuracy: 96.9 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.08331568539142609, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.1475, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.1396, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.2181, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.1204, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.1135, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.1844, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.0612, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.1818, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.0848, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.1924, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.13479144871234894, accuracy: 96.0 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.16630969941616058, accuracy: 94.5 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.2633334696292877, accuracy: 91.7 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.1358940750360489, accuracy: 95.3 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.1467561274766922, accuracy: 95.0 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.15373189747333527, accuracy: 95.1 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.11980042606592178, accuracy: 96.2 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.11761797219514847, accuracy: 96.3 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.11726405471563339, accuracy: 96.4 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.11776471138000488, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.1295, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.1429, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.1280, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.1100, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.0986, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.1337, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.2312, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.1755, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.0850, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.1043311208486557, accuracy: 96.6 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.13006597757339478, accuracy: 96.2 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.10181472450494766, accuracy: 96.7 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.09393226355314255, accuracy: 97.0 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.0937923863530159, accuracy: 97.0 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.09951493889093399, accuracy: 96.5 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.0943683385848999, accuracy: 97.0 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.09312734752893448, accuracy: 97.0 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.1044308990240097, accuracy: 96.8 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.11179967224597931, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.2081, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.1135, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.1251, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.1154, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.0760, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.1270, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.2224, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.1292, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.1420, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.08782299607992172, accuracy: 97.5 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.12210900336503983, accuracy: 96.2 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.09748610854148865, accuracy: 96.9 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.1175030767917633, accuracy: 95.9 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.07794903963804245, accuracy: 98.1 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.07659589499235153, accuracy: 98.0 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.07509387284517288, accuracy: 98.2 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.07304685562849045, accuracy: 98.1 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.07361681014299393, accuracy: 98.0 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.07192259281873703, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.1165, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.0671, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.2121, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.1421, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.1121, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.1442, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.1259, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.1870, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.0875, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.1726, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.11103462427854538, accuracy: 95.9 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.13769234716892242, accuracy: 95.4 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.20352570712566376, accuracy: 92.5 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.19595935940742493, accuracy: 92.6 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.11108013242483139, accuracy: 95.4 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.10170524567365646, accuracy: 96.1 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.10308235883712769, accuracy: 96.1 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.10744417458772659, accuracy: 96.0 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.1066407784819603, accuracy: 95.8 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.08968287706375122, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.1559, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.1934, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.0806, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.1484, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0907, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.1703, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0726, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.1656, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.1328, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.1228, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.12642799317836761, accuracy: 96.3 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 1.153025507926941, accuracy: 73.6 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.1164209395647049, accuracy: 96.6 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.11559546738862991, accuracy: 96.8 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.21631009876728058, accuracy: 93.2 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.10665886104106903, accuracy: 96.9 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.10435714572668076, accuracy: 97.1 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.10211480408906937, accuracy: 97.6 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.10093850642442703, accuracy: 97.4 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.10873003304004669, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.0798, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.1428, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.1206, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.1183, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.1468, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.1781, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.1618, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.1690, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.0750, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.10073021054267883, accuracy: 96.8 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 0.10534331202507019, accuracy: 96.4 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.27022770047187805, accuracy: 91.7 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.14897827804088593, accuracy: 95.3 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.09210360795259476, accuracy: 97.0 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.09015048295259476, accuracy: 97.1 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.09630731493234634, accuracy: 97.0 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.0929904654622078, accuracy: 96.8 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.09002920985221863, accuracy: 97.1 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.09271244704723358, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.2214, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.1027, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.1167, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1077, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.0630, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.0871, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.0956, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.0873, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.1167, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.12935252487659454, accuracy: 95.3 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.1407647728919983, accuracy: 95.4 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.13180723786354065, accuracy: 95.4 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.12417183071374893, accuracy: 95.2 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.18720857799053192, accuracy: 93.9 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.09873712062835693, accuracy: 96.8 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.09928295016288757, accuracy: 96.5 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.10375471413135529, accuracy: 96.7 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.09586754441261292, accuracy: 96.7 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.0965380072593689, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.0769, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.1422, batch time: 0.34, accuracy:  93.75%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.0916, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.0459, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.0807, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.0565, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.1349, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.1296, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.1780, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.0741, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.10625627636909485, accuracy: 96.4 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 1.697179913520813, accuracy: 66.3 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.0968887209892273, accuracy: 97.3 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.08914647996425629, accuracy: 97.4 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.2906194031238556, accuracy: 91.6 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.11926378309726715, accuracy: 96.1 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.14773307740688324, accuracy: 95.3 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.09024618566036224, accuracy: 97.3 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.08117280900478363, accuracy: 97.5 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.07679491490125656, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.1298, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.1119, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.2089, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.0401, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.0812, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.1197, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.1411, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.1274, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.1351, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.1095, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.11335980147123337, accuracy: 96.6 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 0.13245037198066711, accuracy: 96.2 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.11413883417844772, accuracy: 95.7 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.09232143312692642, accuracy: 96.5 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.13581815361976624, accuracy: 95.0 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.13919177651405334, accuracy: 95.1 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.09049772471189499, accuracy: 96.9 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.08688206225633621, accuracy: 96.6 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.08783704787492752, accuracy: 97.2 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.08604997396469116, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.0789, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.1093, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.0918, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.1236, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.1077, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.0801, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.1543, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.1825, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.0807, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.1390, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.10957356542348862, accuracy: 96.4 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 2.1173205375671387, accuracy: 60.5 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.15996943414211273, accuracy: 94.9 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.10391633212566376, accuracy: 97.0 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.11422749608755112, accuracy: 96.8 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.10435982793569565, accuracy: 97.0 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.10262900590896606, accuracy: 97.0 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.10101893544197083, accuracy: 96.8 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.11303667724132538, accuracy: 97.1 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.10125225782394409, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.0837, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.0675, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.1318, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.2587, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.0993, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.0384, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.1735, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.0571, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.0682, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.09459825605154037, accuracy: 96.9 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.10833820700645447, accuracy: 95.9 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.09230536967515945, accuracy: 96.4 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.08992074429988861, accuracy: 96.7 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.0884428471326828, accuracy: 97.2 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.09676604717969894, accuracy: 97.5 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.15941020846366882, accuracy: 94.2 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.07879138737916946, accuracy: 98.1 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.0808892622590065, accuracy: 97.9 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.0798942819237709, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.0580, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.1905, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.0572, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.1209, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.0480, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.0869, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.1154, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.1471, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.1340, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.1355, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.1588042825460434, accuracy: 94.8 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 1.0984910726547241, accuracy: 71.1 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.21259647607803345, accuracy: 93.0 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.15216244757175446, accuracy: 95.1 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.18356306850910187, accuracy: 93.8 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.1623113602399826, accuracy: 95.4 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.20802468061447144, accuracy: 93.5 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.17834028601646423, accuracy: 94.6 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.23199462890625, accuracy: 93.1 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.13747847080230713, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.0371, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.1573, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.0554, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.1255, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.1715, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.0768, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.0986, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.1202, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.2454, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.10371427983045578, accuracy: 96.5 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.1020422950387001, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.1349010467529297, accuracy: 95.2 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.09803543984889984, accuracy: 96.7 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.1213766559958458, accuracy: 95.7 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.0949978306889534, accuracy: 97.1 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.09556169807910919, accuracy: 97.1 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.09274531900882721, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.09440100193023682, accuracy: 97.0 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.0917343720793724, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.1496, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.1051, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.0947, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.1677, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.0858, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.1247, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.1444, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.2014, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.1552, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.0930, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.12254022806882858, accuracy: 96.4 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.15065327286720276, accuracy: 95.1 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.1328166127204895, accuracy: 95.7 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.10641492158174515, accuracy: 96.4 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.17801028490066528, accuracy: 93.9 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.1103290319442749, accuracy: 96.6 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.09906189888715744, accuracy: 96.8 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.09878844767808914, accuracy: 96.5 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.0957237184047699, accuracy: 96.8 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.09558437764644623, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.0982, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.1477, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.1067, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.1817, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.1105, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.1858, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.1017, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.1411, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.0916, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.1540, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.12511345744132996, accuracy: 95.9 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.1422877311706543, accuracy: 95.0 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.1439107060432434, accuracy: 95.3 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.139638289809227, accuracy: 94.9 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.11771053075790405, accuracy: 96.1 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.11600219458341599, accuracy: 96.5 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.12320692837238312, accuracy: 95.9 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.11727108061313629, accuracy: 96.5 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.11120688915252686, accuracy: 96.9 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.1105225458741188, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.1642, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.0749, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.1119, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.0329, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.1036, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.0846, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.0883, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0632, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.1855, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.0715, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.10705944150686264, accuracy: 96.2 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 1.1652370691299438, accuracy: 73.7 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.10246489942073822, accuracy: 96.4 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.09614287316799164, accuracy: 97.1 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.09321790188550949, accuracy: 97.3 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.08768080174922943, accuracy: 97.4 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.0845174714922905, accuracy: 97.6 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.08217988908290863, accuracy: 97.6 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.0826016515493393, accuracy: 97.7 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.08024278283119202, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.0990, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.1679, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.2178, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.1545, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.0813, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.0480, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.1465, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.1226, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.1460, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.0638, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.15180858969688416, accuracy: 94.8 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.17593011260032654, accuracy: 94.0 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.13942855596542358, accuracy: 96.0 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.14005807042121887, accuracy: 95.8 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.12157828360795975, accuracy: 96.0 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.11516885459423065, accuracy: 96.5 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.11203505843877792, accuracy: 96.3 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.11073402315378189, accuracy: 96.7 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.10917150974273682, accuracy: 96.5 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.10641805827617645, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.1726, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.1308, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.2276, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.0757, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.1159, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.1255, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.0968, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.1399, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.1095, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.1051, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.07796922326087952, accuracy: 97.8 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.08442900329828262, accuracy: 97.1 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 0.08603187650442123, accuracy: 97.5 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.08554022014141083, accuracy: 97.3 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.07255418598651886, accuracy: 97.9 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.07201290130615234, accuracy: 97.8 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.07108494639396667, accuracy: 98.0 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.0708417296409607, accuracy: 98.2 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.06889163702726364, accuracy: 97.9 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.06815234571695328, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.1578, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.1780, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.1258, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.1132, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.0703, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.1835, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.1069, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.1372, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.1081, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.1051, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.08069726824760437, accuracy: 97.5 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.09814772009849548, accuracy: 96.6 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.11376193910837173, accuracy: 95.9 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.09714487195014954, accuracy: 96.7 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.08916465938091278, accuracy: 97.0 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.3185218572616577, accuracy: 92.0 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.07116131484508514, accuracy: 97.6 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.06607742607593536, accuracy: 97.9 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.06649460643529892, accuracy: 97.9 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.06734064966440201, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.0640, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.1070, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.1701, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.1271, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.1471, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.1188, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.2413, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.0867, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.1203, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.1688, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.11398489028215408, accuracy: 96.6 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.11699765175580978, accuracy: 96.4 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.11546430736780167, accuracy: 96.7 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.10980378091335297, accuracy: 96.9 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.1260700672864914, accuracy: 95.6 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.13870808482170105, accuracy: 96.1 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.13571973145008087, accuracy: 95.7 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.10573455691337585, accuracy: 97.0 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.1049007698893547, accuracy: 96.8 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.10273484140634537, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.1042, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.1774, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.1192, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.1056, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.1194, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.0990, batch time: 0.12, accuracy:  96.09%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.0833, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.1785, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.0997, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.0889, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.10402501374483109, accuracy: 97.0 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 0.12157370150089264, accuracy: 96.5 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.10797911137342453, accuracy: 97.0 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.09815777838230133, accuracy: 97.2 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.19713912904262543, accuracy: 93.0 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.10865534096956253, accuracy: 96.4 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.08924785256385803, accuracy: 97.3 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.08335497230291367, accuracy: 97.4 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.08330156654119492, accuracy: 97.6 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.08170472830533981, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.1354, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.1302, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.1132, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.1794, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.0705, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.0762, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.2547, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.1283, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.1206, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.0900, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.10504338145256042, accuracy: 97.1 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 0.9591041207313538, accuracy: 77.1 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.10944396257400513, accuracy: 96.7 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.09266681224107742, accuracy: 97.2 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.09365812689065933, accuracy: 97.0 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 0.0948696956038475, accuracy: 97.3 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 0.12699207663536072, accuracy: 96.2 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 0.10725189745426178, accuracy: 97.3 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.09080012142658234, accuracy: 97.5 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.10922083258628845, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.0904, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.0886, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.1231, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.1505, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.0660, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.2128, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.0139, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.1397, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.1614, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.1891, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.11940795928239822, accuracy: 96.2 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 1.0126363039016724, accuracy: 77.3 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.16260485351085663, accuracy: 94.8 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.11142969876527786, accuracy: 96.3 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.10643507540225983, accuracy: 96.4 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.15236826241016388, accuracy: 94.6 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.12912635505199432, accuracy: 95.8 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.10520331561565399, accuracy: 96.4 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.12735605239868164, accuracy: 95.0 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.0929170474410057, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.0925, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.0769, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.1854, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.0760, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.2448, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.0893, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.2402, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.0962, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.0898, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.0863, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.10959436744451523, accuracy: 96.7 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.2705775499343872, accuracy: 91.2 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.3352035880088806, accuracy: 88.7 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.23157347738742828, accuracy: 91.2 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.1028248518705368, accuracy: 96.6 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.10075587034225464, accuracy: 97.3 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.10692881792783737, accuracy: 96.6 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.10534591227769852, accuracy: 97.2 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.09998492896556854, accuracy: 97.1 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.17215977609157562, accuracy: 94.4 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.1435, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.0677, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.1373, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.1728, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.0724, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.0920, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.0577, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.0471, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.0996, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.08589645475149155, accuracy: 97.4 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.08852767199277878, accuracy: 97.5 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.08474770188331604, accuracy: 97.4 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.08095982670783997, accuracy: 97.4 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.10817595571279526, accuracy: 96.5 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.264399915933609, accuracy: 92.2 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.07554160058498383, accuracy: 97.2 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.07313872873783112, accuracy: 97.9 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.07987978309392929, accuracy: 97.8 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.07156157493591309, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.1190, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.1020, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.1189, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.1599, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.2109, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.0805, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.1276, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.1847, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.1274, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.1501, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.12895888090133667, accuracy: 95.7 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.1400298923254013, accuracy: 94.9 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.13966000080108643, accuracy: 95.6 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.12404080480337143, accuracy: 95.4 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.1884179413318634, accuracy: 94.1 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.11983151733875275, accuracy: 95.8 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.11983189731836319, accuracy: 95.8 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.11566514521837234, accuracy: 96.1 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.11662177741527557, accuracy: 96.3 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.11548620462417603, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.1497, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.1220, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0665, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.1653, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.2887, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.1732, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.0551, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.0772, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0868, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.0625, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.05756005272269249, accuracy: 98.3 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 3.4235198497772217, accuracy: 62.2 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.07631029933691025, accuracy: 97.5 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.05325058102607727, accuracy: 98.5 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.058547016233205795, accuracy: 98.6 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.10228662937879562, accuracy: 96.7 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.05015261843800545, accuracy: 98.6 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.04799766466021538, accuracy: 99.1 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.04773208871483803, accuracy: 98.9 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.0472392775118351, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.2832, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.3027, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.1302, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.0576, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.0689, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.1688, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.0997, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.1076, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.1479, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.1614, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.11032071709632874, accuracy: 96.5 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.1352519392967224, accuracy: 95.6 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.11032071709632874, accuracy: 96.5 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.10676848888397217, accuracy: 96.5 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.09932949393987656, accuracy: 97.1 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.11325480788946152, accuracy: 96.7 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.10984518378973007, accuracy: 96.4 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.09461929649114609, accuracy: 97.0 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.09427460283041, accuracy: 97.2 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.09174145758152008, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.1346, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.1792, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.0701, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.2034, batch time: 0.07, accuracy:  95.31%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.1125, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.1360, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.1499, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.1331, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.0692, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.1683, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.0992596223950386, accuracy: 97.5 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.6599045395851135, accuracy: 80.6 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.10808577388525009, accuracy: 97.2 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.09765250980854034, accuracy: 97.4 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.16964103281497955, accuracy: 95.7 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.10362742841243744, accuracy: 97.1 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.09289833158254623, accuracy: 97.8 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.08569894731044769, accuracy: 97.9 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.08534502238035202, accuracy: 98.2 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.08275450766086578, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.0402, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.0551, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.1211, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.1031, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.0805, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.1811, batch time: 0.09, accuracy:  93.75%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.0766, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.1097, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.1611, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.0604, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.12998679280281067, accuracy: 95.7 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.20631776750087738, accuracy: 93.6 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.20298738777637482, accuracy: 93.3 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.3411533534526825, accuracy: 90.6 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.1216910108923912, accuracy: 96.3 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.12052300572395325, accuracy: 96.1 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.1134074255824089, accuracy: 96.5 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.11602342128753662, accuracy: 96.6 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.10969860106706619, accuracy: 97.0 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.10845465213060379, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.1645, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.0646, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.1565, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.0759, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.0811, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.0733, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.1507, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.1277, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.1786, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.0910, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.11142884939908981, accuracy: 96.3 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.13038749992847443, accuracy: 95.6 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.12276741117238998, accuracy: 95.8 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.12653140723705292, accuracy: 95.7 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.10085906833410263, accuracy: 96.6 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.09841407835483551, accuracy: 96.6 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.0969584658741951, accuracy: 97.0 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.09669822454452515, accuracy: 96.8 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.10012032836675644, accuracy: 96.7 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.0995929092168808, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.0559, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.0983, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.1050, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.1515, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.1986, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.0808, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.1308, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.1062, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.1528, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.08611798286437988, accuracy: 97.0 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.2641198933124542, accuracy: 90.5 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.09957548975944519, accuracy: 96.3 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.08178676664829254, accuracy: 97.3 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.08095797151327133, accuracy: 97.6 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.14338427782058716, accuracy: 95.3 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.07390300929546356, accuracy: 98.0 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.07487165927886963, accuracy: 97.9 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.07210837304592133, accuracy: 98.0 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.07081970572471619, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.0636, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.0640, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.0988, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.1572, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0771, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.1219, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.0718, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.0537, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.1076, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.1539, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.12117834389209747, accuracy: 95.9 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 1.7330797910690308, accuracy: 64.2 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.11546140164136887, accuracy: 96.6 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.11546140164136887, accuracy: 96.6 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.12658005952835083, accuracy: 95.7 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.12399598211050034, accuracy: 96.1 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.16472584009170532, accuracy: 94.8 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.10656249523162842, accuracy: 96.8 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.10737523436546326, accuracy: 96.9 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.10575982928276062, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.1445, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.0961, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.1275, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.1133, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.0888, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.0786, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.1769, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.1359, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.0838, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.08858421444892883, accuracy: 97.0 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.11737190932035446, accuracy: 95.4 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.1266067773103714, accuracy: 95.8 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.08265987038612366, accuracy: 96.9 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.10669989883899689, accuracy: 95.7 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.10889369249343872, accuracy: 96.0 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.07689502090215683, accuracy: 97.1 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.07628442347049713, accuracy: 97.5 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.07946072518825531, accuracy: 97.3 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.07446053624153137, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.1267, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.0546, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.1375, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.1445, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.1735, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.0587, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.1406, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.1653, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.0882, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.0913, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.10947941988706589, accuracy: 95.7 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.12218161672353745, accuracy: 96.4 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.2105661779642105, accuracy: 93.0 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.10176800936460495, accuracy: 97.4 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.11414122581481934, accuracy: 96.2 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.10087002068758011, accuracy: 96.7 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.09290101379156113, accuracy: 97.4 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.08735936135053635, accuracy: 97.4 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.08562958240509033, accuracy: 97.5 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.08431033045053482, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.1174, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.0412, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.1021, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.1009, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.1842, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.1258, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.0903, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.1615, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.1256, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.1716, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.10684004426002502, accuracy: 96.8 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 1.0264743566513062, accuracy: 74.3 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.10070671141147614, accuracy: 96.9 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.08838286250829697, accuracy: 96.9 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.09463679790496826, accuracy: 96.9 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.08576511591672897, accuracy: 97.1 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.14115317165851593, accuracy: 94.7 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.08702405542135239, accuracy: 97.1 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.08596192300319672, accuracy: 97.1 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.08297683298587799, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.0907, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.1096, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.1167, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.0772, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.1260, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.0892, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.0748, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.1193, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.1270, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.1490, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.1187235489487648, accuracy: 96.9 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.692186713218689, accuracy: 68.3 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.13029693067073822, accuracy: 95.8 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.10894956439733505, accuracy: 97.1 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.11961980164051056, accuracy: 96.3 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.10100844502449036, accuracy: 97.3 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.0975923165678978, accuracy: 97.5 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.09361457079648972, accuracy: 97.7 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.09389703720808029, accuracy: 97.4 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.09678390622138977, accuracy: 97.5 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.1081, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.2264, batch time: 0.04, accuracy:  91.41%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.0543, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.0787, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.1653, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.0822, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.1156, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.1054, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.0779, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.1214, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.11535376310348511, accuracy: 96.2 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.14338119328022003, accuracy: 95.0 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.1670963317155838, accuracy: 94.6 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.10602902621030807, accuracy: 96.4 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.1479616016149521, accuracy: 95.1 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.1964292973279953, accuracy: 93.5 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.14302437007427216, accuracy: 95.4 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.314572811126709, accuracy: 90.1 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.12451887875795364, accuracy: 96.2 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.09179014712572098, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.2109, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.1960, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.1470, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.0419, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.1455, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.0835, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.0613, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.1131, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.1355, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.1369902491569519, accuracy: 95.5 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.16947422921657562, accuracy: 95.0 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.1324184089899063, accuracy: 96.0 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.1830315738916397, accuracy: 94.8 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.11928541213274002, accuracy: 96.3 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.11358676850795746, accuracy: 96.5 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.1096193715929985, accuracy: 96.3 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.11131103336811066, accuracy: 96.6 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.1104682981967926, accuracy: 96.1 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.10278325527906418, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.1249, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.1588, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.1235, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.1171, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.0600, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.1071, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.0947, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.1544, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.1996, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.1694, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.097260482609272, accuracy: 97.2 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.10796863585710526, accuracy: 97.5 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.08755141496658325, accuracy: 97.4 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.08745212107896805, accuracy: 97.3 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.11561338603496552, accuracy: 96.6 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.08519716560840607, accuracy: 97.4 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.08282508701086044, accuracy: 97.3 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.08013883978128433, accuracy: 97.1 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.08550240099430084, accuracy: 97.3 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.07920033484697342, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.1618, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.0868, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.1275, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.1363, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.1612, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.0369, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.1290, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.0862, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.1584, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.1130, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.10035998374223709, accuracy: 97.1 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.10314927250146866, accuracy: 96.5 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.19567619264125824, accuracy: 92.8 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.09847372770309448, accuracy: 96.8 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.1337657868862152, accuracy: 95.8 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.13140739500522614, accuracy: 95.7 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.10703301429748535, accuracy: 96.3 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.08625123649835587, accuracy: 97.2 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.0841122642159462, accuracy: 97.6 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.08340749144554138, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.1042, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.1551, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.0504, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.2389, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.1018, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.1593, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.0965, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.0477, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.1431, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.0938, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.09936435520648956, accuracy: 97.2 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.11801762878894806, accuracy: 96.1 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.13558919727802277, accuracy: 95.7 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.0911354348063469, accuracy: 97.7 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.12743660807609558, accuracy: 96.1 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.0913681834936142, accuracy: 97.5 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.08836117386817932, accuracy: 97.9 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.0889330580830574, accuracy: 97.8 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.08762707561254501, accuracy: 97.9 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.08630821853876114, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.1215, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.1962, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.1071, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.1505, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.0967, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.1205, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.0742, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.0830, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.0885, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.1180, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.11242619156837463, accuracy: 96.2 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.1244114488363266, accuracy: 96.3 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.11995922774076462, accuracy: 96.4 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.10244439542293549, accuracy: 97.3 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.1145862489938736, accuracy: 97.1 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.15750327706336975, accuracy: 94.5 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.09624560177326202, accuracy: 97.5 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.09350491315126419, accuracy: 97.6 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.09396784007549286, accuracy: 97.2 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.08978643268346786, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.1251, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.1666, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.1644, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.1060, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.1389, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.1765, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.0531, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.1317, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.1160, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.1357, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.09837765246629715, accuracy: 97.3 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.201085090637207, accuracy: 73.0 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.15006907284259796, accuracy: 95.5 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.09396599233150482, accuracy: 97.5 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.10795781761407852, accuracy: 96.8 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.09220750629901886, accuracy: 97.2 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.09120683372020721, accuracy: 97.5 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.08923055231571198, accuracy: 97.4 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.08955775946378708, accuracy: 97.4 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.08916512131690979, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.0882, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.1669, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.1903, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.0781, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.0677, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.1950, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.0981, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.1063, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.0968, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.1252, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.15983223915100098, accuracy: 94.7 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.17382235825061798, accuracy: 94.2 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.1447015255689621, accuracy: 95.1 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.13725131750106812, accuracy: 95.0 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.14390194416046143, accuracy: 95.1 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.13320595026016235, accuracy: 94.8 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.1166941300034523, accuracy: 95.8 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.1071862056851387, accuracy: 96.3 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.10290689766407013, accuracy: 96.5 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.09945443272590637, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.1400, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.0987, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.1422, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.2033, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.0918, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.1845, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.1166, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.1261, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.3194, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.1148, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.10186009109020233, accuracy: 96.8 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.1472848802804947, accuracy: 95.7 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.14873428642749786, accuracy: 94.5 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.08692952245473862, accuracy: 97.3 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.1521071046590805, accuracy: 95.4 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.42419618368148804, accuracy: 88.5 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.07784947007894516, accuracy: 97.5 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.07594984769821167, accuracy: 97.5 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.0751015841960907, accuracy: 97.6 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.07495813071727753, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.1716, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.0959, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.1160, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.0961, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.1010, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.1360, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.0949, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.2143, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.0560, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.1125, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.10387866199016571, accuracy: 96.4 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.11281502991914749, accuracy: 96.5 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.14064142107963562, accuracy: 95.3 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.10139289498329163, accuracy: 96.5 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.10433519631624222, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.1740957796573639, accuracy: 93.6 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.0937509536743164, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.09512708336114883, accuracy: 96.4 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.09229740500450134, accuracy: 96.6 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.09365658462047577, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.1645, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.0908, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.1211, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.1258, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.1237, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.1130, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.0679, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.0748, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.1485, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.1562, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.12681840360164642, accuracy: 95.8 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 2.4545321464538574, accuracy: 57.6 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.15701721608638763, accuracy: 94.4 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.11120130121707916, accuracy: 96.0 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.10471151769161224, accuracy: 96.6 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.09366633743047714, accuracy: 96.7 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.12043997645378113, accuracy: 95.6 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.09802591800689697, accuracy: 96.3 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.08966536819934845, accuracy: 97.4 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.09075885266065598, accuracy: 97.0 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.1929, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.0585, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.2128, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.1296, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.1976, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.0498, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.0936, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.2023, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.0691, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.1115, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.11711033433675766, accuracy: 96.1 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.3015928566455841, accuracy: 90.7 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.11403154581785202, accuracy: 96.1 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.1139766275882721, accuracy: 96.1 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.1254558116197586, accuracy: 95.5 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.15830786526203156, accuracy: 94.6 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.1401352882385254, accuracy: 95.0 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.13147710263729095, accuracy: 95.8 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.1160435825586319, accuracy: 95.8 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.11259128898382187, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.0553, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.1162, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.1000, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.1632, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.1549, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.1942, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.1071, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.0533, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.0902, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.0718, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.11175239831209183, accuracy: 96.6 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.11415687203407288, accuracy: 96.6 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.11149103194475174, accuracy: 96.4 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.09852872043848038, accuracy: 96.6 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.1130647212266922, accuracy: 95.5 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.10944995284080505, accuracy: 96.7 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.1041312962770462, accuracy: 96.7 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.12445459514856339, accuracy: 96.0 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.1106453388929367, accuracy: 95.8 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.12300119549036026, accuracy: 96.4 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.1006, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.0277, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.1127, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.0530, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.1263, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.1363, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.0844, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.1370, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.1238, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.1114, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.12526191771030426, accuracy: 96.0 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.13699498772621155, accuracy: 95.9 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.12709760665893555, accuracy: 95.8 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.10676635801792145, accuracy: 96.3 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.11998136341571808, accuracy: 96.2 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.10722428560256958, accuracy: 96.3 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.12476949393749237, accuracy: 95.0 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.15539269149303436, accuracy: 94.3 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.09296812862157822, accuracy: 96.9 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.09210880100727081, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.1305, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.1367, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.0536, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.1295, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.1226, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.1211, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.0831, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.0690, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.0831, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.0960, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.12031631171703339, accuracy: 96.5 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.12458501756191254, accuracy: 96.1 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.14383012056350708, accuracy: 95.8 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.11767397075891495, accuracy: 96.6 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.11685626953840256, accuracy: 96.6 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.11135820299386978, accuracy: 96.6 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.10984721034765244, accuracy: 96.9 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.10844738036394119, accuracy: 96.9 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.10766032338142395, accuracy: 96.9 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.11420337110757828, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0501, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.1589, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.0472, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.1227, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.0997, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.0829, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.1763, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.0483, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.1853, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.0671, batch time: 0.35, accuracy:  97.66%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.1200665757060051, accuracy: 95.6 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.12938475608825684, accuracy: 95.6 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.12008463591337204, accuracy: 95.9 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.13914553821086884, accuracy: 95.1 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.11197637766599655, accuracy: 95.8 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.11248978972434998, accuracy: 95.7 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.12033776193857193, accuracy: 95.5 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.11050429940223694, accuracy: 96.0 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.10725148767232895, accuracy: 95.9 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.10792319476604462, accuracy: 96.2 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.1635, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.0870, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.2275, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.0729, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.1655, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.1466, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.0588, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.0862, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.0718, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.1247, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.10228374600410461, accuracy: 97.1 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.13802829384803772, accuracy: 95.9 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.10526065528392792, accuracy: 96.9 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.10188957303762436, accuracy: 95.8 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.08671081811189651, accuracy: 96.8 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.08567914366722107, accuracy: 96.9 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.08260275423526764, accuracy: 96.9 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.0824725329875946, accuracy: 96.8 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.08565492182970047, accuracy: 96.5 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.08069037646055222, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.0832, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.1442, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.0998, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.1118, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.0819, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.1220, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.1078, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.1878, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.1072, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.0770, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.1140429899096489, accuracy: 96.7 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.12191783636808395, accuracy: 96.5 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.10848165303468704, accuracy: 96.9 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.1053321361541748, accuracy: 96.4 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.13102370500564575, accuracy: 95.7 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.09985819458961487, accuracy: 96.6 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.09801619499921799, accuracy: 96.7 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.09750178456306458, accuracy: 96.6 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.09537769109010696, accuracy: 97.2 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.09441269189119339, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.1012, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.1340, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.1508, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.0969, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.1568, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.0606, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.1453, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1794, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.0642, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.1744, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.11751978099346161, accuracy: 96.2 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.13479623198509216, accuracy: 95.1 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.1442451924085617, accuracy: 95.8 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.10958674550056458, accuracy: 96.7 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.12135147303342819, accuracy: 96.7 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.10743635147809982, accuracy: 97.0 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.13597342371940613, accuracy: 95.7 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.14839622378349304, accuracy: 95.6 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.10124079883098602, accuracy: 97.4 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.09815235435962677, accuracy: 97.3 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8209543824195862, 0.569908082485199, 0.47447773814201355, 0.47477486729621887, 0.4353739619255066, 0.5826711654663086, 0.2877562940120697, 0.4013645052909851, 0.2225179374217987, 0.33950161933898926, 0.2903220057487488, 0.49120229482650757, 0.20108194649219513, 0.3234591484069824, 0.25634661316871643, 0.19305704534053802, 0.159584179520607, 0.10803405940532684, 0.3146834969520569, 0.42672279477119446, 0.2098093181848526, 0.11270250380039215, 0.14509892463684082, 0.21829625964164734, 0.20195505023002625, 0.09173639863729477, 0.09042441099882126, 0.07212033122777939, 0.10636652261018753, 0.19417926669120789, 0.35509827733039856, 0.30824992060661316, 0.3251679241657257, 0.13291485607624054, 0.19968871772289276, 0.10426042228937149, 0.16511258482933044, 0.22546391189098358, 0.1739763468503952, 0.09398037195205688, 0.20122407376766205, 0.12382755428552628, 0.19865278899669647, 0.1349467784166336, 0.12989994883537292, 0.06888603419065475, 0.09633957594633102, 0.18321354687213898, 0.04858927056193352, 0.27095746994018555, 0.14233091473579407, 0.10544240474700928, 0.1721782684326172, 0.26323646306991577, 0.21007616817951202, 0.15426969528198242, 0.25816360116004944, 0.18001416325569153, 0.09700645506381989, 0.14942744374275208, 0.19022634625434875, 0.09203512221574783, 0.23868203163146973, 0.24434325098991394, 0.13247935473918915, 0.12829598784446716, 0.1937071830034256, 0.12534937262535095, 0.1755979061126709, 0.14418789744377136, 0.2553664445877075, 0.13220344483852386, 0.09514462947845459, 0.17489007115364075, 0.13553892076015472, 0.16515783965587616, 0.1066073402762413, 0.07556786388158798, 0.09540241211652756, 0.2493865191936493, 0.10860536992549896, 0.2392311990261078, 0.10228139907121658, 0.11648065596818924, 0.10464657843112946, 0.20511145889759064, 0.1887892782688141, 0.17829854786396027, 0.13724298775196075, 0.13710297644138336, 0.11658189445734024, 0.16602100431919098, 0.27266713976860046, 0.15897324681282043, 0.2166173756122589, 0.1202271431684494, 0.14893043041229248, 0.24346983432769775, 0.09241961687803268, 0.15104399621486664, 0.20162680745124817, 0.19103486835956573, 0.33376625180244446, 0.13708926737308502, 0.27690669894218445, 0.14739875495433807, 0.08141983300447464, 0.0809498056769371, 0.2039482593536377, 0.15423153340816498, 0.11323476582765579, 0.1207616925239563, 0.12551890313625336, 0.12984618544578552, 0.10081768780946732, 0.16494426131248474, 0.18515647947788239, 0.06331188976764679, 0.18314318358898163, 0.092238649725914, 0.06989477574825287, 0.16833312809467316, 0.19881048798561096, 0.16321802139282227, 0.18679417669773102, 0.11422427743673325, 0.08983288705348969, 0.170362189412117, 0.1640503704547882, 0.12566564977169037, 0.049666259437799454, 0.0886533334851265, 0.10765577107667923, 0.16104698181152344, 0.14730119705200195, 0.04078051075339317, 0.2211667001247406, 0.12083147466182709, 0.10412175953388214, 0.2040768414735794, 0.04258347302675247, 0.031055526807904243, 0.090552918612957, 0.11913339793682098, 0.1266590803861618, 0.260132372379303, 0.10053645819425583, 0.1126975268125534, 0.12470614910125732, 0.09245692193508148, 0.13500848412513733, 0.15611696243286133, 0.2033982127904892, 0.0650714784860611, 0.10365717113018036, 0.11105133593082428, 0.12788167595863342, 0.1020352691411972, 0.087188720703125, 0.11930359899997711, 0.12163420766592026, 0.11809451133012772, 0.11363698542118073, 0.12208149582147598, 0.19458438456058502, 0.1821899116039276, 0.23149144649505615, 0.16922542452812195, 0.18841437995433807, 0.14149680733680725, 0.05666738748550415, 0.08195338398218155, 0.14864452183246613, 0.0825103372335434, 0.07646162807941437, 0.13783077895641327, 0.14349278807640076, 0.0729328989982605, 0.15942907333374023, 0.17781414091587067, 0.1294446885585785, 0.10768438130617142, 0.07545588165521622, 0.12174785137176514, 0.06100711226463318, 0.07152868807315826, 0.0844496414065361, 0.172089621424675, 0.32973548769950867, 0.13906560838222504, 0.08728330582380295, 0.10557123273611069, 0.09492848068475723, 0.07592916488647461, 0.21234767138957977, 0.07325727492570877, 0.0365074947476387, 0.08365508168935776, 0.08068794012069702, 0.1183849424123764]\n",
      "[68.75, 84.82142857142857, 81.25, 83.92857142857143, 87.5, 89.28571428571429, 89.28571428571429, 88.39285714285714, 91.07142857142857, 90.17857142857143, 88.39285714285714, 87.5, 91.96428571428571, 84.82142857142857, 94.64285714285714, 96.42857142857143, 97.32142857142857, 97.32142857142857, 91.07142857142857, 90.17857142857143, 93.75, 96.42857142857143, 95.53571428571429, 96.42857142857143, 94.64285714285714, 97.32142857142857, 95.53571428571429, 98.21428571428571, 96.42857142857143, 94.64285714285714, 92.85714285714286, 89.28571428571429, 90.17857142857143, 95.53571428571429, 92.85714285714286, 97.32142857142857, 95.53571428571429, 91.07142857142857, 92.85714285714286, 97.32142857142857, 93.75, 95.53571428571429, 97.32142857142857, 94.64285714285714, 96.42857142857143, 99.10714285714286, 96.42857142857143, 93.75, 99.10714285714286, 90.17857142857143, 96.42857142857143, 95.53571428571429, 91.96428571428571, 91.96428571428571, 92.85714285714286, 95.53571428571429, 94.64285714285714, 96.42857142857143, 97.32142857142857, 94.64285714285714, 94.64285714285714, 95.53571428571429, 91.07142857142857, 92.85714285714286, 95.53571428571429, 95.53571428571429, 93.75, 95.53571428571429, 93.75, 94.64285714285714, 91.07142857142857, 97.32142857142857, 98.21428571428571, 93.75, 94.64285714285714, 94.64285714285714, 97.32142857142857, 98.21428571428571, 97.32142857142857, 91.96428571428571, 95.53571428571429, 93.75, 95.53571428571429, 95.53571428571429, 93.75, 95.53571428571429, 91.96428571428571, 93.75, 94.64285714285714, 97.32142857142857, 95.53571428571429, 94.64285714285714, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 95.53571428571429, 94.64285714285714, 97.32142857142857, 93.75, 92.85714285714286, 91.96428571428571, 92.85714285714286, 92.85714285714286, 91.07142857142857, 95.53571428571429, 96.42857142857143, 98.21428571428571, 93.75, 95.53571428571429, 95.53571428571429, 96.42857142857143, 94.64285714285714, 96.42857142857143, 98.21428571428571, 95.53571428571429, 92.85714285714286, 97.32142857142857, 95.53571428571429, 97.32142857142857, 97.32142857142857, 95.53571428571429, 94.64285714285714, 95.53571428571429, 92.85714285714286, 95.53571428571429, 96.42857142857143, 94.64285714285714, 96.42857142857143, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 90.17857142857143, 97.32142857142857, 98.21428571428571, 92.85714285714286, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 96.42857142857143, 92.85714285714286, 97.32142857142857, 95.53571428571429, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 93.75, 98.21428571428571, 95.53571428571429, 97.32142857142857, 96.42857142857143, 97.32142857142857, 98.21428571428571, 93.75, 96.42857142857143, 98.21428571428571, 97.32142857142857, 94.64285714285714, 93.75, 96.42857142857143, 93.75, 96.42857142857143, 94.64285714285714, 94.64285714285714, 98.21428571428571, 98.21428571428571, 96.42857142857143, 97.32142857142857, 96.42857142857143, 96.42857142857143, 93.75, 96.42857142857143, 96.42857142857143, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 95.53571428571429, 96.42857142857143, 98.21428571428571, 97.32142857142857, 95.53571428571429, 88.39285714285714, 93.75, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 93.75, 99.10714285714286, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [1.5527082681655884, 0.821916937828064, 0.4357883930206299, 0.520495593547821, 0.6002520322799683, 0.5129491090774536, 0.3472384810447693, 0.3953164517879486, 0.23690354824066162, 0.42198827862739563, 0.33050450682640076, 0.24789150059223175, 0.252990186214447, 0.4449290931224823, 0.2395581752061844, 0.32155272364616394, 0.28324517607688904, 0.2699401080608368, 0.3565397262573242, 0.1410621851682663, 0.30839377641677856, 0.2693183720111847, 0.16812007129192352, 0.22309091687202454, 0.21632036566734314, 0.3089526295661926, 0.27928388118743896, 0.11085422337055206, 0.12934847176074982, 0.21440613269805908, 0.1600201576948166, 0.20735681056976318, 0.19754192233085632, 0.2421455681324005, 0.14874911308288574, 0.18399100005626678, 0.20026187598705292, 0.26662006974220276, 0.21613572537899017, 0.11081840842962265, 0.31454911828041077, 0.13199084997177124, 0.250933974981308, 0.17277786135673523, 0.13233669102191925, 0.14024347066879272, 0.13897578418254852, 0.2828730046749115, 0.2180139720439911, 0.2962564527988434, 0.0894770696759224, 0.1765693873167038, 0.0669313594698906, 0.20110082626342773, 0.11875273287296295, 0.08693380653858185, 0.15636780858039856, 0.1658804565668106, 0.17704692482948303, 0.11214101314544678, 0.2388426810503006, 0.16706597805023193, 0.1911080777645111, 0.12050791829824448, 0.24391670525074005, 0.12245609611272812, 0.07410384714603424, 0.18450026214122772, 0.08971917629241943, 0.1351558268070221, 0.1634756475687027, 0.05411200597882271, 0.10361556708812714, 0.1336205154657364, 0.1923748254776001, 0.08211904764175415, 0.09500335156917572, 0.08312954008579254, 0.24714629352092743, 0.15412068367004395, 0.13937871158123016, 0.1378481388092041, 0.11307946592569351, 0.19941632449626923, 0.15815149247646332, 0.17232845723628998, 0.07265500724315643, 0.14370258152484894, 0.21024581789970398, 0.17081165313720703, 0.08635182678699493, 0.11471913009881973, 0.1288972645998001, 0.19918100535869598, 0.09654117375612259, 0.09373673051595688, 0.2614876627922058, 0.23236151039600372, 0.21459685266017914, 0.07146948575973511, 0.22483015060424805, 0.28991079330444336, 0.2633385956287384, 0.12008941918611526, 0.22572211921215057, 0.22020819783210754, 0.12657393515110016, 0.22693565487861633, 0.23916466534137726, 0.11261292546987534, 0.09873270243406296, 0.14024558663368225, 0.11159996688365936, 0.13792987167835236, 0.09651073068380356, 0.11880241334438324, 0.10103648900985718, 0.12666024267673492, 0.13419181108474731, 0.11094494163990021, 0.08628032356500626, 0.1052437424659729, 0.15799567103385925, 0.11133521050214767, 0.17966176569461823, 0.14704196155071259, 0.1437619924545288, 0.077719546854496, 0.14343860745429993, 0.11744453758001328, 0.1045406386256218, 0.07188886404037476, 0.05408835411071777, 0.11756821721792221, 0.09619205445051193, 0.2231816053390503, 0.18925367295742035, 0.11313091218471527, 0.11806601285934448, 0.22790531814098358, 0.12394194304943085, 0.11876077204942703, 0.11331097036600113, 0.09428982436656952, 0.18541596829891205, 0.08310209214687347, 0.07435284554958344, 0.12460290640592575, 0.17960171401500702, 0.16887222230434418, 0.13874074816703796, 0.15458311140537262, 0.06102018803358078, 0.15877528488636017, 0.05251716822385788, 0.20162203907966614, 0.07203029841184616, 0.060983698815107346, 0.08277744054794312, 0.10553168505430222, 0.07920272648334503, 0.11486774682998657, 0.22829769551753998, 0.1515415608882904, 0.10009436309337616, 0.11327189952135086, 0.21349883079528809, 0.05268169194459915, 0.1491495668888092, 0.1158331036567688, 0.11639727652072906, 0.10863836854696274, 0.09098844975233078, 0.17787528038024902, 0.1303773820400238, 0.07944361865520477, 0.12400998175144196, 0.06296124309301376, 0.09333069622516632, 0.23743629455566406, 0.10137560218572617, 0.13208378851413727, 0.18596573173999786, 0.09350971132516861, 0.10947806388139725, 0.22633123397827148, 0.1336974799633026, 0.10390913486480713, 0.09000981599092484, 0.1306539922952652, 0.2695833444595337, 0.06498425453901291, 0.06081300228834152, 0.08573383092880249, 0.17408928275108337, 0.14662852883338928, 0.15242242813110352, 0.09418928623199463, 0.10331504791975021, 0.050542742013931274]\n",
    "# acc_list_epoch_ = [46.42857142857143, 69.64285714285714, 84.82142857142857, 83.92857142857143, 81.25, 86.60714285714286, 84.82142857142857, 91.96428571428571, 91.96428571428571, 85.71428571428571, 90.17857142857143, 92.85714285714286, 90.17857142857143, 88.39285714285714, 91.07142857142857, 89.28571428571429, 90.17857142857143, 89.28571428571429, 87.5, 94.64285714285714, 91.96428571428571, 92.85714285714286, 94.64285714285714, 91.96428571428571, 91.07142857142857, 94.64285714285714, 89.28571428571429, 96.42857142857143, 93.75, 93.75, 96.42857142857143, 92.85714285714286, 91.96428571428571, 91.96428571428571, 94.64285714285714, 93.75, 91.07142857142857, 93.75, 93.75, 97.32142857142857, 94.64285714285714, 94.64285714285714, 93.75, 93.75, 95.53571428571429, 97.32142857142857, 93.75, 92.85714285714286, 94.64285714285714, 94.64285714285714, 97.32142857142857, 93.75, 97.32142857142857, 95.53571428571429, 96.42857142857143, 97.32142857142857, 95.53571428571429, 94.64285714285714, 93.75, 96.42857142857143, 91.96428571428571, 93.75, 95.53571428571429, 95.53571428571429, 92.85714285714286, 96.42857142857143, 97.32142857142857, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 99.10714285714286, 97.32142857142857, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 97.32142857142857, 92.85714285714286, 94.64285714285714, 95.53571428571429, 95.53571428571429, 97.32142857142857, 92.85714285714286, 97.32142857142857, 95.53571428571429, 96.42857142857143, 94.64285714285714, 93.75, 95.53571428571429, 97.32142857142857, 95.53571428571429, 97.32142857142857, 94.64285714285714, 95.53571428571429, 96.42857142857143, 88.39285714285714, 93.75, 92.85714285714286, 99.10714285714286, 94.64285714285714, 91.96428571428571, 95.53571428571429, 97.32142857142857, 94.64285714285714, 91.07142857142857, 95.53571428571429, 95.53571428571429, 91.07142857142857, 94.64285714285714, 96.42857142857143, 93.75, 95.53571428571429, 96.42857142857143, 98.21428571428571, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 97.32142857142857, 95.53571428571429, 97.32142857142857, 96.42857142857143, 96.42857142857143, 95.53571428571429, 96.42857142857143, 97.32142857142857, 96.42857142857143, 95.53571428571429, 97.32142857142857, 97.32142857142857, 96.42857142857143, 98.21428571428571, 94.64285714285714, 96.42857142857143, 96.42857142857143, 92.85714285714286, 97.32142857142857, 97.32142857142857, 94.64285714285714, 97.32142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 95.53571428571429, 92.85714285714286, 97.32142857142857, 95.53571428571429, 98.21428571428571, 94.64285714285714, 98.21428571428571, 92.85714285714286, 99.10714285714286, 98.21428571428571, 96.42857142857143, 96.42857142857143, 97.32142857142857, 94.64285714285714, 94.64285714285714, 95.53571428571429, 96.42857142857143, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 95.53571428571429, 96.42857142857143, 97.32142857142857, 95.53571428571429, 93.75, 95.53571428571429, 97.32142857142857, 96.42857142857143, 99.10714285714286, 96.42857142857143, 91.96428571428571, 95.53571428571429, 91.96428571428571, 92.85714285714286, 96.42857142857143, 97.32142857142857, 92.85714285714286, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 94.64285714285714, 98.21428571428571, 97.32142857142857, 98.21428571428571, 91.96428571428571, 94.64285714285714, 97.32142857142857, 97.32142857142857, 95.53571428571429, 97.32142857142857]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 96.98%\n",
      "Loss on the train set: 0.10\n",
      "Accuracy on the test set: 95.00%\n",
      "Loss on the test set: 0.21\n",
      "Generalization error: 0.10584016\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
