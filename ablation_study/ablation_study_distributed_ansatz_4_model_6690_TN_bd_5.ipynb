{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 73.83%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "    \n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "    \n",
    "    return repeated_states\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(126 * 70, 1).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=5)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  775\n",
      "# of trainable parameter in full model:  775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3031, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3017, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3067, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3013, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3009, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3036, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3036, batch time: 0.09, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3012, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3036, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3020, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3020, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3021, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3032, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3016, batch time: 0.06, accuracy:  19.53%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3033, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3029, batch time: 0.03, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3037, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  17.19%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3031, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3019, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3020, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3017, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3020, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3019, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3019, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3032, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3023, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3032, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3035, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3017, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3031, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3019, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3018, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.2995, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3030, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.06, accuracy:  18.75%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3035, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3013, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3032, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3022, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3021, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3041, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  15.62%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3010, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3015, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3031, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3018, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  0.78%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.84%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3008, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  13.28%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.04, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.02, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3031, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3015, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.2994, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.97%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  18.75%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  20.31%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.91%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  17.97%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  4.69%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.91%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  17.19%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  3.12%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.02, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  17.19%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  16.41%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  16.41%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.12, accuracy:  11.72%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  3.91%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  17.97%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  4.69%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.12, accuracy:  6.25%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  13.28%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  13.28%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  5.47%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.08, accuracy:  3.91%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.07, accuracy:  3.91%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  3.12%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.94%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  9.38%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  6.25%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  18.75%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3034, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  12.50%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  15.62%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.11, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.06%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  16.41%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  6.25%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  4.69%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  4.69%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  11.72%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.09, accuracy:  7.81%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.09, accuracy:  6.25%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  5.47%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  6.25%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  5.47%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  10.16%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  16.41%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.10, accuracy:  14.06%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  14.84%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  6.25%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.03%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  8.59%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  7.81%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.06, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  5.47%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.06, accuracy:  15.62%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.07, accuracy:  14.84%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.11, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  13.28%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  3.12%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.81%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.08, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.07, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  5.47%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  4.69%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.91%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  5.47%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  13.28%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.84%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  16.41%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  16.41%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.84%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  13.28%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.07, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.03, accuracy:  6.25%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.06, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3029, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3016, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.04, accuracy:  17.19%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  14.06%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.03, accuracy:  5.47%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  15.62%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.03, accuracy:  15.62%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  12.50%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  5.47%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  14.84%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.02, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.08, accuracy:  7.03%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.05, accuracy:  11.72%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.06, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  14.06%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.05, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  12.50%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.03%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  3.12%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  11.72%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.05, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  10.16%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.94%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  7.81%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  6.25%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  6.25%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  11.72%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  16.41%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.06, accuracy:  7.03%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  17.97%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.02, accuracy:  17.97%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.03, accuracy:  7.81%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  11.72%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.05, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.04, accuracy:  9.38%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.04, accuracy:  14.06%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.03, accuracy:  12.50%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAADN3UlEQVR4nO39eZxlVXU2jj93rqFr6Hmgm+4GGZRRUVscIRCB168CGjWECBqHbwwkUaIx5BeHoAlG32jiK4Ekr4D5GsdEISqSIKPIoAwtItJC0yN0N/RQVV3THc/vj3vXPmvvs890x1NV6/l8+lNdt+4994x7r/2sZz0r5TiOA4FAIBAIBIIEI93rHRAIBAKBQCAIgwQsAoFAIBAIEg8JWAQCgUAgECQeErAIBAKBQCBIPCRgEQgEAoFAkHhIwCIQCAQCgSDxkIBFIBAIBAJB4iEBi0AgEAgEgsQj2+sdaAdqtRqee+45DA0NIZVK9Xp3BAKBQCAQRIDjODh8+DDWrFmDdDqYQ5kXActzzz2HdevW9Xo3BAKBQCAQNIFdu3Zh7dq1ge+ZFwHL0NAQgPoBDw8P93hvBAKBQCAQRMHExATWrVun5vEgzIuAhdJAw8PDErAIBAKBQDDHEEXOIaJbgUAgEAgEiYcELAKBQCAQCBIPCVgEAoFAIBAkHhKwCAQCgUAgSDwkYBEIBAKBQJB4SMAiEAgEAoEg8ZCARSAQCAQCQeIhAYtAIBAIBILEQwIWgUAgEAgEiYcELAKBQCAQCBIPCVgEAoFAIBAkHhKwCAQCgUAgSDwkYBEIBAIAB6dKuO7urXh+YrbXuyIQCCyQgEUgEAgAfPPnO/HZHz2JG+7b3utdEQgEFkjAIhAIBAAOz1YaP8s93hOBQGCDBCwCgUAAoFpzAACVqtPjPREIBDZIwCIQCARwA5ayBCwCQSIhAYtAIBDADViqtVqP90QgENggAYtAIBAAqDkNhqUmDItAkERIwCIQCAQAKsSwSEpIIEgkJGARCAQCADUS3UpKSCBIJCRgEQgEArAqIUkJCQSJhAQsAoFAAClrFgiSDglYBAKBAEDVkZSQQJBkSMAiEAgEEIZFIEg6JGARCAQCiIZFIEg6JGARCAQC8IBFUkICQRIhAYtAIBDANY6TlJBAkExIwCIQCASQlJBAkHRIwCIQCARgTrcSsAgEiYQELAKBQADWS6gqGhaBIImQgEUgEAggZc0CQdIhAYtAIBBANCwCQdIhAYtAIBBAypoFgqRDAhaBQCAAQJmgqqSEBIJEIlbAcvXVV+MVr3gFhoaGsGLFClxwwQXYsmWL9p7Z2VlcdtllWLp0KRYtWoS3ve1t2LdvX+B2HcfBJz7xCaxevRr9/f04++yz8dRTT8U/GoFAIGgStQbDUhaGRSBIJGIFLHfffTcuu+wyPPDAA7jttttQLpfxxje+EVNTU+o9H/7wh/H9738f3/nOd3D33Xfjueeew1vf+tbA7X7uc5/Dl770JVx33XV48MEHMTg4iHPOOQezs7PNHZVAIBDEhJQ1CwTJRspxnKafzhdeeAErVqzA3Xffjde//vUYHx/H8uXL8fWvfx2/8zu/AwB48skn8eIXvxj3338/XvWqV3m24TgO1qxZgz/7sz/DRz7yEQDA+Pg4Vq5ciRtvvBG/+7u/G7ofExMTGBkZwfj4OIaHh5s9HIFAsIBxzhfvwZZ9hwEA267+X0ilUj3eI4Fg/iPO/N2ShmV8fBwAsGTJEgDAww8/jHK5jLPPPlu95/jjj8eRRx6J+++/37qNbdu2Ye/evdpnRkZGsGnTJt/PFItFTExMaP8EAoGgFVTZ2k1IFoEgeWg6YKnVavjQhz6E17zmNTjxxBMBAHv37kU+n8fo6Kj23pUrV2Lv3r3W7dDrK1eujPyZq6++GiMjI+rfunXrmj0MgUAgAKCngsQ8TiBIHpoOWC677DI8/vjj+OY3v9nO/YmEK6+8EuPj4+rfrl27ur4PAoFgfoEHLKJjEQiSh6YClssvvxw/+MEPcOedd2Lt2rXq9VWrVqFUKmFsbEx7/759+7Bq1Srrtuh1s5Io6DOFQgHDw8PaP4FAIGgFPEgRt1uBIHmIFbA4joPLL78c3/ve93DHHXdg48aN2t9PO+005HI53H777eq1LVu2YOfOnTj99NOt29y4cSNWrVqlfWZiYgIPPvig72cEAoGg3dACFiltFggSh1gBy2WXXYavfe1r+PrXv46hoSHs3bsXe/fuxczMDIC6WPa9730vrrjiCtx55514+OGH8Z73vAenn366ViF0/PHH43vf+x4AIJVK4UMf+hA+85nP4L/+67/wy1/+EpdccgnWrFmDCy64oH1HKhAIBAHgolux5xcIkodsnDdfe+21AIAzzjhDe/2GG27Au9/9bgDAF7/4RaTTabztbW9DsVjEOeecg3/6p3/S3r9lyxZVYQQAf/7nf46pqSl84AMfwNjYGF772tfi1ltvRV9fXxOHJBAIBPFRq0nAIhAkGS35sCQF4sMiEAhaxalX/Q/GpssAgLs/egbWLx3s8R4JBPMfXfNhEQgEgvkC3kNIGBaBIHmQgEUgEAhgaFikSkggSBwkYBEIBAKIcZxAkHRIwCIQCAQQ4ziBIOmQgEUgEAhgljULwyIQJA0SsAgEggWPWs0Br5cUDYtAkDxIwCIQCBY8qoa7g1QJCQTJgwQsAoFgwcPUrEjAIhAkDxKwCASCBY+aybBIlZBAkDhIwCIQCBY8hGERCJIPCVgEAsGChydgEdGtQJA4SMAiEAgWPLwMi6SEBIKkQQIWgUCw4OGpEhKGRSBIHCRgEQgECx4mwyJOtwJB8iABi6Cr+PqDO/HgMwd6vRsCgQYzQClLSkggSBwkYBF0Dc+8MIm//N4v8bH/fKzXuyIQaDDjE2FYBILkQQIWQdcwWaxoPwWCpMDUsJRFwyIQJA4SsAi6BvK2kNWrIGmoGhSLGMcJBMmDBCyCroECFYlXBEmDGZ+IcZxAkDxIwCLoGlTAIpOBIGEQ4ziBIPmQgEXQNdCkYOoFBIJew1vWLCkhgSBpkIBF0DWIhkWQVHhEt3KPCgSJgwQsgq6hpjQsMhkIkgUxjhMIkg8JWARdQ0VEt4KEwmMcJ1VCAkHiIAGLoGuoSkpIkFAIwyIQJB8SsAi6Bj4JSKWQIEkw05RiHCcQJA8SsAi6hgqrvJBKIUGSIFVCAkHyIQGLoGvgq1gR3gqSBPFhEQiSDwlYBF0DnwRkAStIEjwBi6QsBYLEQQIWQdfAJwVJCQmSBPN+rEhELRAkDhKwCLoGPilIFYYgSZCUkEDgxWy5in+5Zyu2vjDZ610BIAGLoIuQKiFBUiEpIYHAi/95Yh/+9pYn8YXbftPrXQEgAYugi9ACFkkJCRIEb1mzpIQEgkNTJQDA5Gylx3tShwQsgq5BNCyCpMJMAUnKUiCop4SA5CwwYwcs99xzD9785jdjzZo1SKVSuOmmm7S/p1Ip67/Pf/7zvtv81Kc+5Xn/8ccfH/tgBMlGpSZVQoJkwiO6FQ2LQIDZcn2gnrMBy9TUFE455RRcc8011r/v2bNH+3f99dcjlUrhbW97W+B2TzjhBO1z9957b9xdEyQcwrAIkgpTUyVVQgIBMFupMyxJYRyzcT9w3nnn4bzzzvP9+6pVq7Tfb775Zpx55pk46qijgnckm/V8VjC/IKJbQVJBAXQ+k0apWhPRrUAAlhJKSPzeUQ3Lvn378MMf/hDvfe97Q9/71FNPYc2aNTjqqKNw8cUXY+fOnb7vLRaLmJiY0P4Jko+KiG4FCQUF0/lsfUiUlJBA4KaEksKIdzRg+epXv4qhoSG89a1vDXzfpk2bcOONN+LWW2/Ftddei23btuF1r3sdDh8+bH3/1VdfjZGREfVv3bp1ndh9QZvBWZWkUIwCAeDejwUKWJKypBQIeohiOVkpoY4GLNdffz0uvvhi9PX1Bb7vvPPOw9vf/nacfPLJOOecc3DLLbdgbGwM3/72t63vv/LKKzE+Pq7+7dq1qxO7L2gzhGERJBXegEXuT4GANCxOQsbr2BqWqPjJT36CLVu24Fvf+lbsz46OjuLYY4/F008/bf17oVBAoVBodRcFXUZNc7rt4Y4IBAZUwJLLAJCUkEAALKCU0Fe+8hWcdtppOOWUU2J/dnJyElu3bsXq1as7sGeCXkFrfpiQB0AgANwBmRiWpFDgAkEvMatSQj3ekQZiByyTk5PYvHkzNm/eDADYtm0bNm/erIlkJyYm8J3vfAfve9/7rNs466yz8OUvf1n9/pGPfAR33303tm/fjvvuuw8XXnghMpkMLrroori7J0gwqkwXIBOCIEmoGSkhcboVCHiVUDLG69gpoYceeghnnnmm+v2KK64AAFx66aW48cYbAQDf/OY34TiOb8CxdetW7N+/X/2+e/duXHTRRThw4ACWL1+O1772tXjggQewfPnyuLsnSDA4rSgMiyBJoPgkLwyLQKCQNOO42AHLGWecESrA+cAHPoAPfOADvn/fvn279vs3v/nNuLshmIOoSpWQIKEg9q+QrWtYhGERCJhxXEICFuklJOgaRMMiSCpEwyIQeFEkhiUhz4MELIKuQU8J9XBHBAIDRKgUcg0NS4dv0HK1hv/7k2fw6z1iejmfcGiqhGvv2oq947OR3v+tn+/EfVv3h7+xR5gpC8MiWKCQlJAgqTBTQp2+P+/begCf+eGv8be3/Lqj3yPoLr790C783a1P4vqfbgt9766D0/jYf/4SH/n2L7qwZ81hQVnzCwQc0ktIkFQohoWlhDpplnV4tgwAODRd6th3CLqPw7OVxs9y6HvHZ+geCH9vL+A4jhuwCMMiWGiQbs2CpKJmaFgAoNxB8zh6FqgKQzA/QA7JUe4deu9spZoYJ1mOctVRqfukMOISsAi6hoqkhAQJBfUOyrOApZP3KAVItIIVzA9QarESocqMKtEcByglsCqNKoQAYVgECxA8DZSQ+18gAMBTQhn1WrmDiXv6PmFY5hdoURalFxUvnU/ifcCD6aQsMCVgEXQNwrAIkgrT6RYAqh1MCdH3FYVhmVegcS1KLyr+niTeB8Vy8pzJJWARdA2iYREkFXQ/ZjNppFL11zrKsDiufkEwfxCHYanU5g7DkpThWgIWQdcgVUKCpILuzUwayKU7bx5XZeLMpKxeBa2DWLlKhGCXC3OTGLjyICopC0wJWARdgzAsgqTCDVjSyKTrFEsUWr9ZcBGjCG/nD4hZiRKE6hqW5N0DPIhKSlAtAYugaxCnW0FSQfdmJgVkM42ApQsMC5DMyUrQHKhKKEovKh4QJz0lJFVCggWHiqSEBAkFUfmZdApZxbB0skqIpwOSN1kJmsO8YlhEdCtYyKjWkvcACAQAY1jSaWQz9WGxkwyLpITmJ7g2KQyVhLNsOsPSwx1hkIBF0DXwBatoWARJQo2JbrNd0LDwZyGJk5WgOcRhWDiDl0SWzbwvk8CKS8Ai6Bo4w5JEK2rBwgUF0OlUimlYOjeJ6AxL8iYrQXNwGZaYVUIJDFrNfUrCIlMCFkHXoBvH9XBHBAIDNNFkMylk051PCYnodn6iWQ1LEo3jzEA6CWl8CVgECt97dDfu3PJ8x7Zfk7JmX9z71H78x8O7e70bCxY0GKdTqS6lhLwBy+PPjuP//uSZREwMAhe/2DWGG3+6LVJKRPUSimQcF49le3TnIXz1vu2x2GnHcfDV+7bj0Z2HIn/G3Sc9iErCkJ3t9Q4IkoHnD8/iw9/6BYb7snjsU+d05DukSsgfH/rWZuyfLOJ1xyzDyuG+Xu/OgoPrw5JyfVi6nBK66vtP4GfbD+Ilq4fx6hct69h3C+LhEzc/jl/sHscp60bx0iMXB763Ess4Ll6V0Cdu/hV++Wx9P05dNxr6fgB4/NkJfPK/foWTjhjB9//4tZE+o/apIikhQULxwuEiAOBwsdKx79AYFglYNEzMlAEAh2fLPd6ThQkVsKRSyFGVUJcZlgNTxcbPUse+VxAfB6fr12NiNnxsbLaX0EyEgIXGhkPT0e8P+sxEE+OKpIQEicXYdP2GdpzO3Zgaw5KAaD0pcBxHtZcvVeS89AJuWTNnWDoYsHCGpbGSnS7Vf051cNEgiA+auKP48lSU6DaChiVmLyHaZhy9SyVGAGVCqoQEiQUFLEA0hXszqErAYgWfGDt17gXBqLGUUC7TBeM4i8vpZCNQmSolT4C5kEETd5Rns6pEtxECkIo3aA0CpZniVJXR/pSauJc9DEsCxmwJWAQAgLEZl2bsWMDi8JRQR75iToKfbwlYegMKGtPpLlUJGcZxjuMohmVaGJZEoVgmu/3oQtpIKaFaPA0LBR9xqsrcFFUTAYsRRCVhkSkBiwCAzrB0KnfPV5VJuPmTAr7SamYlJGgdqqw53SUfFhYMFctVFCs1tQ/CsCQH1Zqbro1yP8SpEuIBUDFGSihOwNJKSshMPXXwcYgMCVgEAIDxGZYS6tCdWRHRrRUljWGR89IL1FTzwy6VNWsalppiVwBguiQMS1JQZCxDLIYlwhhaiVklpBiWGK64ysiuiTFdUkKCxGKMKc87xrA4wrDYoKWEEmjRvRBQZSmhTFeM49z/z5armtB2qigMS1LAJ+0o46JKwcT1YYmgYaFxIlZKyBHRrWAeouui2wTc/EmBaFh6D54SUqLbTjY/NMqahWFJJvikHeXZpMAgSrWl7sMSXdAbT3TrpqjitkPx+LAkYMyWgEUAABjjKaEOMCyO42g3fBLoxaSAD1yiYekNVC8hXtbcySohwzhuigUpomFJDuIGLHyMC0sLxTGOcxxHBdDxRLf8+2IGLEZglARWXAIWAQBgnItuO6BhMYNzmZddcO8V0bD0BnTLc+O4Tq4oPQwLSwNJlVByoKWEYqZ5wtIwlRjND/m9WIyQPnI/x/c/3qDrSQlJwCJICg51WMNiPixJuPmTAkkJ9R50f3LjuE4Gj6boVhiWZIKnRaIwbnqAEJISitFLKG7fIdvn4jMsZkoo1sc7AglYBHAcx0gJdYBhqZm/S8BCkICl96DTzo3joph/Nf99bAIqVTXdimhYkgM9JRSXYQkJQni35hDWpFKLzsZw1GLsjwmx5hckErPlGkqVeNRnXJgMi2hYXHDdSkmqhHqCmsWav5MMS82w5ueVQVIllBwUy/FSKppOL2QcrVjcjv3fG68EWn1O09S0xrAkgRWXgEWgudwCnSmtNR9eYVhc8IlRNCy9AU0I6ZTrdNvJFaXZ/FAYlmSiFYalHHL/lGIEIc2mhPh9FmcxVKnW1HcO5DMAJGARJAS8pBkIf9CagTn4L2SGZXy6jOvu3ornxmYA6AGiMCy9Ad2e2bRrHNcpA0XA9GGpaazKdKna04D+l7vHcf292xKRAug1ZivNVwlVw0S3ht4lKGWjsTGxRLfNMSzcnG4gn/Vsq1eIHbDcc889ePOb34w1a9YglUrhpptu0v7+7ne/G6lUSvt37rnnhm73mmuuwYYNG9DX14dNmzbhZz/7WdxdEzQJM2DpRDmnh2Hp/b3fM/znI7vx2R89iX+55xkAomFJAuj+zKRTyFKVULdSQgbDAgDTMWj/duOqH/wKV/3gCTy0/WDP9iEpmClFN44zrRvCAl5ze0EOtnxcmIkhyo6jqdH2hd1//fn68zAnGZapqSmccsopuOaaa3zfc+6552LPnj3q3ze+8Y3AbX7rW9/CFVdcgU9+8pN45JFHcMopp+Ccc87B888/H3f3BE1g3EwJdWCgNhmVhZwSOjxbn5yoHUJJApaeg/uwKGv+LqaEzMqgXpY2T8zo9+dCBp+4wzQsHhY5hnEcEByI6GXN0ccIPs7GGdfpuPPZNEuRRv54x5CN+4HzzjsP5513XuB7CoUCVq1aFXmbX/jCF/D+978f73nPewAA1113HX74wx/i+uuvx1/8xV/E3UVBTHgYlg5Q4eZqIgn0Yq9A1SeU/uEDiRjH9Qa25oedDB5rZi8hI0DpZWkzMQNxJsb5itkYvYTMADfs/jHfH6RjidvZ2fYdccZ10sn0ZdNoxO9zk2GJgrvuugsrVqzAcccdhw9+8IM4cOCA73tLpRIefvhhnH322e5OpdM4++yzcf/991s/UywWMTExof0TNI8xYyXViYFaNCwu6NiLKmARhqXXUL2EWPPDboluS5UaJs2ApYcMC92DoqfSBa5xA5A4xnFAcGlzs2XNWoqqiZRQXy6jquaSwIq3PWA599xz8W//9m+4/fbb8Xd/93e4++67cd5556FatZ/k/fv3o1qtYuXKldrrK1euxN69e62fufrqqzEyMqL+rVu3rt2HsaDATeMASQl1GjRuEJuiNz9cuOelV+D3ItewdNQ4zrj/D07pz+B0DxkWmkiF7QOKPCUUcj+YmqewlKJ5foOqf+KUQGv75PCAJfr9TMFTXy6DdCrl2VavEDslFIbf/d3fVf8/6aSTcPLJJ+Poo4/GXXfdhbPOOqst33HllVfiiiuuUL9PTExI0NICxj2i285XCS3geEVRqzQY8pWsMCzdB59YMhrD0p2UEAAcMAKWqR6WNtPEVuyh8DcpiNNLyEy5xDGOM7/Lu229SshxHKQagUQQtCqhWBqWRkool3YDlgQM2h0vaz7qqKOwbNkyPP3009a/L1u2DJlMBvv27dNe37dvn68OplAoYHh4WPsnaB490bAkIFrvFcwVrGhYegsePGQyvKy5iwzLZD1goTlouofmcfT8y70Yr5dQXNEtjQP5bNrzXd73un9znOjXho+7ccr0rSmhBIzZHQ9Ydu/ejQMHDmD16tXWv+fzeZx22mm4/fbb1Wu1Wg233347Tj/99E7vngCucVwnHT7Nm30hp4ToXJREw5IIVA2GJdOFsmZz04cbmpWlg3kAvWVYVEAtGpZYPiwe0W1oL6H69oYK9URHVIal/t5o14aPu80xLBmklYYl8sc7htgBy+TkJDZv3ozNmzcDALZt24bNmzdj586dmJycxEc/+lE88MAD2L59O26//Xacf/75eNGLXoRzzjlHbeOss87Cl7/8ZfX7FVdcgX/913/FV7/6Vfz617/GBz/4QUxNTamqIUFnQQzLksZg2QkfFvOBSwK92CvQsdOEoKeEFu556RU425dOAzlV1tzBlJDP/b9sUQFAb8uaSyK6VZiNo2HxjHHRfFgW9TUCliDRrSnQjZiu08zpmhXdNli/JLDisTUsDz30EM4880z1O2lJLr30Ulx77bV47LHH8NWvfhVjY2NYs2YN3vjGN+LTn/40CoWC+szWrVuxf/9+9fs73/lOvPDCC/jEJz6BvXv34tRTT8Wtt97qEeIKOgPyW1i+qIAXDhe7UiWUBHqxV6DgTaqEkgHOpGTTaSW67ZYPC8fyoQKe3Hu4p2XNNLFJWXNrVUJBiw/HcdT7FymGJSAlZAQ/URkWvstxUnwzFLBk05hJUJVQ7IDljDPOgBMw2fz3f/936Da2b9/uee3yyy/H5ZdfHnd3BG0AMSzLhgrAng5VCYnoVqFmMizS/LCn0BiWFFzjuC453XIsH2owLD1KCdVqjno2JWAxRLehGpbo3Y35GDvUFyEl5HHFjRbQVjWGJb5xXF8uo8S9SWBYpJfQAsdsuaqi6WWLGimhTohuYzzM8x304FvLmoVh6ToogEyngFTKNY7rZErIl2FppIR61bGZCzNFdKvb5YdW/cQwjuP31qJCrv5dsTQsUVNCzRnHUbDal0sjs5CqhATJxkQjHZRJp7BkgDQsHRDdGs/KQk4JmQwL914RDUv3QYM6WZB3g2GxrVbzmTRGBuqTV68YFn7MwvbF82GJ4+ZtY1iCGK1mU0KtWvPzKqEkDNkSsCxwHGqkg0b6c8hlO2eYJQyLC1fDUh8UhGHpLZTLbWM0pMClkxoWmkj6cxn12kAhg8FGZ9xeMSx80pWUkJkSitdLKCjA4WzNoihVQmZKqBmGpUnRbboLzs9RIQHLAsdYw+V2tD+nqiNEdNtZ0Oq6XHVQqzm6hkUClq6D7kWivjPdSAk1vnOw4AYsg/ksBvL133tV1qzrqcQ4riVr/oAJnv6WSafUNe9ESqjaNMPi9hJKUpWQBCwBmClV8dkfPYkrv/uYRyHtOA7+v/u34+Edh3q0d17cteV53PTos9a/ffNnO3H/Vm9PJ+ojNDKQY9URXQhY5vm8XKs5uP7ebfjl7nHr3wilai3RDMtUsYLr7t6KnQemu/q9d215Ht97dHdXvquiGJb6yJwjhqVJpnG2XMW/3LMVW1+Y9H0P3f8DebfuYSCfwWBjtd2Mcdx9T+/Ht3++K/bnOPizH5QS+s2+w/i/P3kmsP9Nu1FtPFOPP+t9pjoFLm6l+6Fac/AVy354GJaAQY7ObTadQiFHAUs047j6fkWtEmrNOK7ArPmTUCUkAUsAUinguru34hs/26WMnQhP7JnAx2/+Ff5/3/tlj/bOiz/5xqP48Lc345Bh8719/xT+4ru/xEf/4xeez5CGZbgvx7rUdr5KKAnReifx8M5DuOoHT+Cvv/8rz9/4aqlYqWnnO2m9hG7e/Bw++6Mn8aU7nurq9/7pNzfjim//Agcmix3/rprSsNTv/1a7Nf/PE/vwt7c8iS/e9hvf99DzQKtrABgstMawXPHtX+DP//Mx7D7UfHCpaVgCjv/vfvQkPvPDX+Mnv9nv+55246HtB3HVD57Ap/7L+0x1CjMlbhxXPzcPbjuAT//gCXz6B09o7/Va84czLLlMGn05crqNwbBELHtv1pqfmnEO5JlxXAKGJglYAtCXy6gcs9lvZ2KmfkHNxoG9Qq3mYGK2AsfxDnYHpuqDvmnBD7iRel8uzVaWHWBYjAAlCfnQTuLwbLnx0zvxaAxLJdkMy76JWQDApOU4OgXHcTA+U67fy13QctC9SeLCQgSr9CCMN8YE27U3v5MYlfr/GcPShA8L+SkdmvI+51HB779iwPHTdx0uNv9dcaGOr0tjruM4mo6HAhKaC8aNLvdxGBYaY7OZFPqy9TlmJlDDYjIsEQMWzek2+v2882A96F23eMCtEkrAIlMClhAsbqj2yb6eQDdjs4Nau8FXQ+ZzQoO+LYInajKfzSBHK8sOBBMLTcNCqxnboMUf/FK1plHvSdOwkMapkwJUE5UmaexmoUS3jYG5r7FIaTbdQZNc0IRVszAsA1zD0oTTLQUbky245FZq0RgW+q5OVlJ5v7P+Xd0ac03RMR1r0eJQDcQzjqO/ZdNpdb8FG8e1QcMS8Rl2HAc7GingDcsG3F5CCVhkSsASgpFGqe8hg52gBzbqjdNp8IfLDAaoRLJSczxRNj10hSxz+OyENX91YQUsNFDYmKTqHGJYSOPUyc7FJrp9PqpGSijKBBIE18HY/x5XDAvTsAzm3SqhuAxLreY6p7ZSEq0FzwE6iVLV//7uFOhe6JZuxhzb6fvpvJgBjdl7KujcUDCby6RUSijouJrtJcTH3ajj+oGpEiaLFaRSwLolA1IlNJcw2t9gWAwassyi7SDn326BDy4mdcdpdVOs5TIsaZdh6YSGxdEnhYTNy20HDTA2ZoI/+MVKVdewJMyHhdKI3WRYuI6nGyt4t6yZApZwTUEQ6JkKGuCVhqXAy5qz6vepUiXWuMKZqFZs/StGMO37fcSwdPG+KKlFYncGD/N7VMBEgYsxiHmqhAIZKq5hCa8SMu+lyAyLE39s2b5/CgCwZqQfhWwGjcciEYtMCVhCMNpICZn5yqT5FfDo3KTu+IrLvNHpc/lMWvlPdLKsOddgcZJAL3YSzTIs1ZqTiJUMwWVYuj8xAd1hWGqGhoU0BTZGMgpUSijgs3T/+zEsjhNvYuaTUSuNE/k+B41rdF16wbB0i9U2v6fm1K+bYliMv3s1LEEpIaZhyYVrpsznIHovIR6wRPvMdpYOAtxyfwlY5gAoYDEFqzw/nYS0UCDDwlZc5r7qKaHOOXzSw5tvCBqTIODqJIIYFv7glyo1z0otSWmh8R5oWPjxd+N76X7PGCkhIHr5KEdJaVjCU0Iaw5LPoj+XQWN+iFUpVGb72QrDUo64ECtHOMZ2g39nJ9LWJkjYSmMWUGeyaJHnZViCGRftb8SwpNMqQI7FsETuJRSfrdxxoM6wrF86CAAsJRTp4x2FBCwhGOmva1jMgIU/2EkQ3paMVToHX3GZ+0qfK2TTyHfQh6VmBCzzn2HxX4GatLsZoCRJeNsLhqXrGhbDOK7AJqhmFiOlav0zQRMEPWIaw1Kol5AONAKmOF4s/Dy1xLBoPiz+3+9qWLqpbWJjbhdYbRorh1glV6XqMixmyiyO0y2l8LIZ5sMScL7NdE5zott4DMvGRsAiDMscwqhPlRAfIJLGsJj3VRSGJc9Et52x5m8ELJQSSsDN30kohsUy4fJgrVipebxXyglIMQL1/aRUaK8Ylm5oemgcJ4YlnU6pwLqpgCVClZBiWIwqIaCuZQHiMSw8yG1JwxLRh6WXGhagO2MufceiPnvAUnP059vrdBtQ9UNVQpoPS8D90tiWEuhGFd02wbCQhmX90npKSES3cwgkujV9WPiNGpWe6yQ4fethWNjAZyrRi1rA0jlrfpqkSdg731NCgRoWxwhYPCmhZJybidmyCn67uZIuaaLbzn8vTSxU1gy4PX6aYU+LUVJCpGExfFiAupYFiFfto2lYWqkSMjQsfsJfpWHpallzbwIWzoKZNgRB425wSqgx7mZSkUS3dH2jdHbm4IujKMy54zjY3kgJbVjWSAmRNb8ELMmHy7AkPCUUtUrITAlRwJJJt2xJHgRTwzLfrfldHxZLSshYxSZVw8LToN312+gyw0IVbBk3YGmlUkgxLD77zicRLWAhhqXxc7LJlFArZnt8nx3Hf9LtBcOiByzdSwn15dwKykqtpgUpfNyNUyVEz3w2nVbBcRBrQsHGokJ4+sj2ufq+hl+rQ9NlHJ6tlzQfuaQhulXdmiVgSTxGB0jDYjeOA5KXEjL1IVPFoCqhhoYll3EZlo70Eqpvk6qEkhCtdxJBDAtPhxXL1cRqWHiQ3isNSycbEBLo6zjD0op5XFhKiC8oBg1r/vpP0rDESAmx578VhsXcZ1tps+M4KpDs7n3BF4mdH3Pp2vflMm4Hb5YSAgztYEiZs/a3qhsk071WqtZ8zye9TumpZqqEojxLxK6sHu5T+5UWp9u5A78qoW4/PGEIoianSuGi23wmrYKJTqym6VleiFVC5spEK2uu1jwsQnIYFjdI71VZczd9WGglCYBVbjRRJRRS8stfN5sf8tfiaFE0hqVNVUKAPWDh7+mqhkVLxXQvJdTPF3MGIxrMsAQELGwBR2we4H9cdM6JhWvGhyXKs+TqVwbVaxmpEpo7GKUqoZmyNvFUEpYS0nxYjPtyOkB0S14C3DiuI72EDIYlCfRiJ8E1H+b14L/Plt1VFVHDSWmAyL2Hukv9s8qGLjrdagFLCykhovb90lmcYRssBDAszWpY2uTDAthLm3XfoG5WCfUqJZRxF3M1xzdw8jR4DfRhaTAsabeXEP9OE7Stob6YAUvMZ8n0YAEgxnFzCcSwVGuO1qMjyVVC5o2lpYSMCF4xLFlmHNeBycmsEprvKaFKABXLf+fXhiaqxKSEpnuUEmL3cjc0LGZZMwBVahrUkM4PxXYxLE1qWFrpJeRJT4YELL3TsHSPYSnk0sqhu1ytaUFKMYBhCQoQKDDMZdP1qrRMcIBM21pUiJkS4ovsCNeKPFg2MIZFqoTmEPpyGeXLwAfwskXD8swLk/jnu7dqLcnbhVsf34MfPrbH9++BPixsf8x948ZxuQ5WCdGDo1JCCbj5Owl+fJ7Gj+z08smFJiq/8//z7QfxtQd2tI2dGpsu4bq7t2LP+IzP3znD0puVdDe+t2ZlWFpICaleQvbP8kPSGJbG9W+mSog//3H6EJUqNfzrPc9gy97DjX02UkJVS8PUgLGmk+h2oQMFq5xhKVcdX9Gt2ZMquJdQo2qSOoSHMHqmhiVqSiyu0y0xLFpKSHxY5hZs9vwVi4bl7//nN7j6R0/if57Y29bvPzxbxuVffxQf+tajvjd0cJUQL2v2qRLSmh92QMOiemfQzd/2r0gUdIbFnyrWA5ZGSshnYPnod36Bv7rpcWx9YbIt+/idh3bjsz96El/5yTbr3w8lQMPSDYalYgtYWvJhqX/Gl2Fhz+dIfw75ho6BUkI0KZntQIJQblJ0e89vXsDf3PJrXP2jXwPwBoj2lFCPNCxdZ1gaKSHWyb5idle3MCwU7AYx1apKqDHmFkI0U2ZZc9RFsdb5PMKztPtgPWChCiEAierWnA1/i2C0P499E0WjzJM9PI2b9sBUEQBwaEqvKGoVOw5MqxtvsljRrMMJRZ8qIcdxgjUs3Jo/3Q2Gpb7vSYjWOwmNYTEGCj6IUDCZTacUk+d3/vdN1O+vw7PNU/4cNCH6ba9XGhZtEuhGL6FAhqWJlBDzYXEcBymWagK8KaHr3vUyZNJpxT6uW1yfLHY2Jo8o4JNRnFTSwcZYRdfanNRsAYu2OOpiuTv/3m54X80qhkU31TS9agjc3G2yGHzvVowFnPKn8k0jmmXNTVQJhTxLtZqjFinLFuXV60mqEpKAJQJGLG63PHqmG5sCg3bbRlOpGf8uE7qGhb1erWmTja/TbSajBsxOTE5u88Pk5EM7iUrAKpQHaxSw5FiVls0vYbZcVRR1u84dBUZ+ZexalVBXfVi6u4KngVgva244irbQSwio738uYw9YKED6reNXan8nOp4qNqKAB7kz5SqqNUcLwPxADB8JhU12Nakalk6k3U3oZc3Mh4WxIDaGpcCaZ/qBggfSDWaZz4v1/ZQSarBw1ZqDcrWmxgw/6GXNwddqslRRc8dwwzAVYAFLAqR1khKKAHK71TQsPNpv3MD08LebrtxxwF1p+VGGtlwq4O1H4ttLiAnLqjWn7fTfQrPm59UTQdUDxG7kMimWJ/de4/EOeKLQtfdLAY71rErIPiF0Cm4A4b7WCsMSpvGwiXw5NjYcRncfmonMdppC7ahiYUofqXshgg9LycIqdANlH2ajU9CN45gPC78/NR+WRsCSo/f67yMteClQocDF79mmZ5QbDUa5N/WUUPA5Izf3/lxGY/HpuUhCZacELBGwuGEe50eRK4alERy0WxC2bX8EhoXdjNoK3shn+zMsLu0JtN88zmx+OO8ZloAqIX7sdH3y2TRyASkhrWKnTQOHslf3uRbjvaoS6rpxHIkl3fu/pYBFq3Ly7j89C2mf0XfFUAF9uTQqNQfPjdkF0UHfCUQvbSbPFtXQL8lVQhXvmNtJzDLRLQUWpjV/EMMSKLpl/leAy7b5nU96DvSAJfzZ0Kz5Q1hSGmNIs0mQKqE5BrqAXJuiR/v1G5smn/YzLG7A4qcOL7Lv1CZEk2ExBqAia6HOqet2C2+9DEsyIvZOIahKyHZ9cpk08gFVWjw90645nCYAv5WXzrB0byXdK+O4tFV0G/+4g0wc+Wt+DEs6ncL6JXWWZVvEtJB5DaOax1Fg49dOIEx02ysxdlcDlmxGZ1hCfFgonRgkclU+LIphCQ4KVFVRJq20bu1mWEi/MtKvByyZBGlYJGCJgBFLPyHTOI6LW9vtwrg9SkqoCYalVnMttrkPC9D+iUJpWLLudyTg/u8YAquE2IFP2jQslnPfieAhiGGp1Rw9SHK6VyXAV9Ld7CXEpSaFJhmWas0xSkn9U0LpAI0Jdcrl6eAgeAKWmAwLjVlmGsNW1pwEDUs3jeMKnl5C7jmxVglFYFjoWGjMDWVYuNFcxLYR5vMaFrDQGEMZBUKSqoQkYIkA5Xbr40sxW66iWHEdS9v5ME0VK3jhcFH7Lhu0KiE2IXo1LOxhYzdwwWBY2p0SqrIVgnptHkcswT4sLGCxaVgsq1qenmmX/oeuv6388nCx4ik979b16nZKyC1rtqSEYmolzBSKXzBY/z7/gIV0LFxwHwQzMIrqxaI0LBX7vWDVsPTMh6XLDIull1DZw7DYq4SA4DHUrBJyGRb7Z1SAk0kxF+bge9PTKiDkWo03FihmSiilGJbAj3cFErBEgOvDwlNCej41qHS4FZgrrGiiW/d1k2HRFO7sjflsGqlUylXDd4hhybOgKAk50U5BY1gCyppJHMkZFmtKaIZ7orRnH12GJThAcr+3+wFLV5xuraLb5nxYzAnedi3DRLeAWykUlWExv9d87v1AKUlXgB1BwxLg7tpJaGNuV0W3hg+Lj+g2joaFgpmsqWHxud95ZVlUfZX5/c1qWGjITkKhhAQsEWCtEjLoyaCOyK3AXGFFYlh4lZCZEuK20ix4IW1JtkNutypgYSmhJDwAnYJflZAfrZrPppHPBmlYuAC2XSkhR/upfV8jQFrMBq9uTU66cVznJyYb49HfZErIpOmDNCxBKaENjZRQ1NJm8zyZzKofaHwoVx0tRUwI17B0UdukVWZ2oaxZaVjcdLnZrJSPoaaGJbD5oWJYGuNuWJUQY6ijNuY0GdFyrRaoG6SU0Ei/pITmNEI1LBWTYWnfQ+wJWHzyln5Ot7SCsjXN4p2aifbLpf1X+a3AFN0C85th0b1E7NeGQ/dhsTEsPGBp1z76a1goQFq6qOB+b5c4YS0l1IWAhe5N3Yel2YBF319bSoteCmRYGimhXYemI52DpjUsRX08MLcT1vywG6Jo2/d2u0qItHdmEUMQwxKUznS7NdfvgahVQnWGJRr7Zz6vjhM85kqV0DzBKJU1T7sdm/VeQjWNgm2nC+OO/fFTQpqGpbFfSwfzns/zPkIE18Co3SmhxgOqMSxt/YpEwU/D4vfQ58NEt9zErV0aFlUZ4h8gLRl0V1vdqhTSRLdduEnoeclqTrfNVQmZZcG250ilhAIYltXDfchn0yhXHewZnw39XpMZiZoS4gxssVJTAQjFUknVsBS7IbptHHt/PqN6/piMtc31NwrDQuaQpnFcmA9LLp12BeEh84zteQ0a10nyMOpTJZQERjx2wHLPPffgzW9+M9asWYNUKoWbbrpJ/a1cLuNjH/sYTjrpJAwODmLNmjW45JJL8NxzzwVu81Of+hRSqZT27/jjj499MJ0CXcBStaY0B2YvIU7BdoJhCaOotSohS9nsEhWweBXueS1g6QzDQqeLi26TQDF2Cn49PPwGpFw2RMPSkZRQzbOvBBLgLRnIq/byvdCwdINhsZc1N8ewmBO8bdJyv89/O/XS5npaKEppsxkoRRXd8vLnUqXm+n00GjHaOodrGqOeaVi6W9ZMAYWHYdH0PFRVFMHpVmlYojIsbpDbH7Exp21hEzSu+zIsqTnMsExNTeGUU07BNddc4/nb9PQ0HnnkEXz84x/HI488gu9+97vYsmUL3vKWt4Ru94QTTsCePXvUv3vvvTfurnUMA/mMSmUcmqaeGzo9yVc0xQ6Ibo9duShw2zY/AMBdESwZrFP73AGTe7AQ8pnw1UEzoEk2v2CqhOyrUL9jzmdSIT4snUgJ1ffFdq3p+xYP5tQqsBcalq74sFhEsFFXsSa8KSFLlVAE0S3AhbfhAYtZWRY1JcQN5rg+gxpx2piMsqUyphvopg+L4zjWXkLmeeXjrlvWHO50G7dKiLaVy8RICalUp/d7bXB9WHQNCwXyCYhX4vcSOu+883DeeedZ/zYyMoLbbrtNe+3LX/4yXvnKV2Lnzp048sgj/Xckm8WqVavi7k5XkEqlMDKQwwuHixibLuGI0X5PwMKpwnY9TDOlKvZO1Ong41YN4Re7x33V8bqGxX2dVlCUErL1wchbU0Jt1rAwo6RUqp5PndcMi4+Gxe+Yw6qEuMtyu86by7B4v48C85H+fH31V+2eXkGz5u8Gw9I4rkymDSkhD8NiqRKKILoFmPA2QqUQnbO+XBqz5VokhqVWczDNFzDlqu6oerjo48PiXwHXKTiO01UflnLVURN0IeemhCaDUkKkYYnAsJRVABLV6bb5KqF8No1SpYaaE1xqTWPM4kEjJdSYHuZkSiguxsfHkUqlMDo6Gvi+p556CmvWrMFRRx2Fiy++GDt37vR9b7FYxMTEhPav06C0EJV76tb8NY0qjFJyN1uu4l/u2Yqnnz/s+dvzE7P4/H8/ib+66XEAdefBVcN96nM2lHyqhGhFsLTRfbNUdf1irBqWxoNja8AXFXc++Txu3vys9hpfVSbJObFT8NOt+A1IuYxrzW879x3RsASkhKhKaHQgpzV+s2G2XMW/3vOM9V6OgkNTJVx711bsbWg12jEh3vTos7hzy/OR3mtjWMxJ4ennD+O6u7eGmnV5ApYgH5YQhmXDMi/D8tS+w/iXe7Z6xgE6Z2T6FYVhmSlXNfPGUrWm9EODja7ASdGwVGuOtq90/Fv2Hsa/3vNM23pOzZaruObOp3HVD36lXuMMi9nywMYGFiI0kaW/KQ1LxF5CepVQtIAlk0qp/fd7nhzHcVNCJsMyl1NCcTA7O4uPfexjuOiiizA8POz7vk2bNuHGG2/ErbfeimuvvRbbtm3D6173Ohw+bB8Ar776aoyMjKh/69at69QhKJBdMUWhZpUQHyCidBK948nn8be3PIn//d+/8fzthvu245o7t+I/H9kNADhu5ZCK2v227Se6NTUsgEtjFqtehkVZUDfJsDiOg8u//gg+/K3NmpcHXyEkiWLsFPycbpthWEqVmqY1aFdqRjEslkFsYqZ+Pw/35RTz4Ddg3bXlefzNLb/G527d0tR+fOuhXfi7W5/EV+59RtsvoLn78NBUCR/+9mb8yTcejfR+W1mzchNtrOT/7tYt+OyPnsQPH9sTuC2TkbBqWCKIbgFgXUPDsvuQ20/oc/+9BX97y5O4a8sLxvfW95PGqSgMiynMLVVqagU+QBqWkCqh7uma9O+hyfozP3wCf3PLr/GTp16wfSw27tryPD7/31vwtQfqC+ZFhawmiDdbHtgYFrp36kGW/fyUWYoHiOvDEs84LpNOKYbIT8MyVaqq93t8WBJUJRQ7JRQV5XIZ73jHO+A4Dq699trA9/IU08knn4xNmzZh/fr1+Pa3v433vve9nvdfeeWVuOKKK9TvExMTHQ9aCka7eX7hHUcvO52tVOE4jioVtuFgoy/R4aLXoOvwbP21V25YglcdtQRvPmUN7nlqf2Pb9htOc1y0VQktcgOW2XINA3l3MOa6EpUSanJlW2ST61SpokrCaVLIZlIqpzqfU0K+VUJ+Gpasv4aFp4OA9p03VSVkCQrKLJjNhtDVEw23XnM/o4JWdpSG0psHxj/WyWIFjlPvhF2rOaGpl4otYCG2q8FIPt9IzT79/GTgtkzNh42Cd7UFwfs1mPeupGkRMGGca7peNNlEqRIyvVpKrEpoUaPJXmhZcw90TYA7Du5rXJdDFqPDZnBwqr6do5YN4ryTVuE1Ry9DKpVSgYVXw2IR3bIFYKXmaA7iBLeXEDEswUFBmYl0BxrXJiwo5YF4fS6q+j5PxOAWsmmtUzPg3qdJSAl1JGChYGXHjh244447AtkVG0ZHR3Hsscfi6aeftv69UCigUChY/9Yp5A2PDPNBPTjpUvaOU3/AqB7fBhqEbDcQDRpvOG45LjvzRQCAn20/qH3OhG9KqHFTDxVyyGVSKFddMVkpgGFptkpokj3QtlRImqeE5nHA4sew+AWCQQwLd1gG2nfegkS3fAUYtsKi122TWxQQ4+c+E60xLKYGpi/t/xwCdhEsH7SLlaqaEMOcZ82J1eZdo8qoLRMZRz6rjzm0L/wnQQUsDTo/inGcxwW74vqwkOjWzrDYg/FOwsY61vtd1a9Lu3SDtJ2XrBnGR89xK1UpZWMGCbZGl/zeqVQd5Cy3nxLRpsOrhGosHZZNp1UgG5b24y0nMmg86z7Pk1+FEMADlsCv6wranhKiYOWpp57Cj3/8YyxdujT2NiYnJ7F161asXr263bvXNCj4oDSK+QAdmNInlTC6jm50myiPBoRMjDLLokbTuq9TznWgkPHk5V0Ni/tE5VqsCOEDZcXCMmTTadeIKAERe6egVwl503VmOiCo+eGYsXpsW8DiE3wDes48rEqIXm9WR0Cfo2emVQ2L5kQaYZ+sZc1slpkt19QKNKy3TxTjOHo+wxiWPGN5zO2b30Pak1gMiyW9QdeSGBab6NlWyttp2BZQs5WqYrbbFrCw/kEcWR+Gxdb8UGdYfKp+FONs+rBY5gP2WjaTUum6sGvsjrkp9xn2eZ6IHTX1K0CyUkKxA5bJyUls3rwZmzdvBgBs27YNmzdvxs6dO1Eul/E7v/M7eOihh/Dv//7vqFar2Lt3L/bu3YtSyZ3QzzrrLHz5y19Wv3/kIx/B3Xffje3bt+O+++7DhRdeiEwmg4suuqj1I2wTzNWO+QAdnCpqv4eVNtMDZrfubtB/ATl1DsdxjCohnhKqf89gPssClpp2LLYqoWYZFv4Q2Up7M2l3xR5kEz3X4ceq0HnoNwbEXCatroNZouoJWNoturUFzewedAcs+z1RbXy+2YqekpqEvQxLM9vUPh8hYLGlhDJpPQ1Aaa/t+6cC79sootuq5ftsUIukivd8mOdFaVgGYmhYLOkNl2GJlhLqGsNSIfbCHasOTZfZvdMu0W3N8z0AfFNCQRoWwD9A8NWwBCwegPqCclHElBC/z3IBbT8Ad4wZsTAsSaoSip0Seuihh3DmmWeq30lLcumll+JTn/oU/uu//gsAcOqpp2qfu/POO3HGGWcAALZu3Yr9+/erv+3evRsXXXQRDhw4gOXLl+O1r30tHnjgASxfvjzu7nUMNJm4bdj1ixeXYQlKCZVZZExQQitLlYI5ePEBlQKIwULGsw2bD4trHNckw8ICFhvDkknzlFBTXzEnEOZ0m82kVIoOqPuw+KWEDk13KiUUkWEJ0TW1yrAUFcOiM39B3xkEfjxRAp6a5XkD6qxmuVrB86xb+lSpiv2TJSwfsqekPQxLQEoorErIHXO8AZhHK2OkhKJUCXkYlqqrYaEqoaRpWPpyGVRr9Z5He5kDcLsYFrd/kMGwpHXRbSadQrXmWH1YuDmmLysZo5cQ30YmncJAIW5KyG1q6zeu0xhjutwCrFtzAhiW2AHLGWecEbjCiLJq3r59u/b7N7/5zbi70XVwhsVxHLc3TqPGnWtYgHDDKQporAyLIcgCgnubBLW0pxTNQD7rSSuplBD7HsqpNuswysu7dS8SUwCWjAegU7AdO+CyI9l0CvlMGuWq263Zr/lhJ0S31ZrrM2EbVHk7+zBBoKthaW7SMFNCeqlo/PuQfyaKiSNdKjNFU8hlcLhYUcJOwo4DU74BSxyGJcjpFtB1cyTipwDCDMQ8otsIAYuHYSlX1XYGC0FVQux+7rI3D5X1lqv6dWm3hsVMCfGWIkA9ZTY+U7aWeOfYYsQvJcSfLyCMYWEpoXRKuRCHim7ZWOMuOuz7ozxYBiwpofmsYZmvKLCAhd9UQ40H+7Dx8Ic9QIphsfZ7sKWE/EvZPAGL46546YHiKaGikRIqMPpTrfKb1bCU7KJbnk9NEsXYKYQxLOlUShc7Z6NrWNqxqjVpfXOhwX0iMp3WsFR1hqVV63c+ocZhWMwUDT1zZi+fICO3KMZxfjomE/z+oGOi7ZvfQ3+nFfJ0uRoa2FoZlhoxLBSwBDO63WJYVNVaJo2+huhUZ1g6nBIyrtUiS0DHGxSGlSmrgEX5sPgvCrhjbTqdUoLoMA0LfXeaaVj8nifSaNlEt9KteQ6CMyz8JlzUZyepQlNCFX+GxRRkAW4+28qwGIMi3Vjcs2WAp4TMKiFrWXMbGJbQlFDvH4BOwd+Hpf4zk055qrP8UkJjRpVQOwK9sCZ9PMcelWFpWXRb8aZJm7kP42tY3ImGgwJ8k2HZHtDbx+PDEjgBhWlY3PtDaVd8Ahb6nRq1Ok44y2v1YVELnIz2vbbv4sfSafD7kcaxvZ1gWHxFt/pUOdTnDVgUM55OhxYvuOmjcB+WsjEfUDAZVgnGF4m5kHE9SMOSTpDRpwQsEUFpkyJjLQA30jYRlWGx3aDKxp4NoP0WTwaCmc+m3SMb6Xxj9d5n9EchetlqHNcGDYvNf0Q3juv9A9Ap+FUJ0eSYTqW06qwgDQsNJu1sQmgKe81t8hx7VNvwZkW3bllzzbNvzWipOA0fJWCh3fZjWPZ6GBb/gMV8FoOs+UMZFjZJFo1Fhl9Z83B/VnVaNhv1mQjyYVGiW1svoRbLzpsBjVXc6VVjWNrodAu49voE00tluC+n7Regp70zAVU/gE3D4v/+qjEfRGVYaMxNM6dbXx+WCFVCwrDMIegMi3/AQpF35IAlKCWk9TahYMOy4jEZlsaNSiXNtFpyWRp9lZa3WfM3XSXEGRbvSiyTTiXKiKhT8GVYmAeHGSjSBGUGE5RfJrfitgQsxsBlBkl2DYv9nqDXy1WnqUHN1bDok7Jtv6IgblmznwiWKrloJU+/B3mxhDFXQd9nIs1WxnVBrLetBoHOUyGbZhqH4AktyIdFWfNbbRfc12pOdyayMpvg+4zrArRTw9JICRmalawhOFpkY1iYoF6lYPxSQp5uzf6MTNmQCAyyKqEgzWiVfYdiWHye4fFAH5bG9hIwXkvAEhE02fM8byadUswHgZoMhkX8tHKJyrD0sYDJHCDMwYsGRAoeaLVEK0ZKFdFgzlf6YT0nwjDtZxxX9eZ3F0yVkFbWXP+ZSaW0FXS9lxBNTnYNy9JGx+32BCwhDAureIjKsADNBbrKW0T5sLSmkeD3brNlzYA3JXTSESMA6gyL30QRTXRb/xnmwAvowlt+br2iW/d6qRV4MwyLR8NiCViMXlfdmMgoiM9l02oc66ro1mBYaKFaqblBuq0qx0+TQqeMUkeuD4t/CpHGZrq+9Sol//ubnoN6iX6wIajqHWapEkoSIy4BS0RwhsUVTKU8fhq0Cg5lWKg8OkjDwqJ63XlTv+nM3+kGVwxLY7VkpoRsDEtYJB4Gv5439N9sOtXW1EZS4et0SykhU8OSDdewKIalAxoWP8aFVxj4alhiMhp++1Kq1lRXWbVtiyA4DPzejcSw+AQsBSP1cPLaEaRSdcv/g4aNASGoYk+9FpFhAdzURKlS07bt0bCwKhp3BR6NYaH7kItwbaJS87sI3XiOXdGt262Yp4RsqatmQAtNm08SB9cu0vnQjNoC/Kz4a1GqhPizCLgLUCC4UogzeeFlzQE+LMSIJ2CBKQFLRHAfloqFniQsaayCw8opieWw5biVCNCSEgK8wZCZzw5jWIj2VD4sxkofaI8PC5/IuHYjk6CIvVPwqxKihz6bTmmiynzGZVz8NCzUD6orDIumYQlm3TSGpYmAhU82k5Zy3Lj3YtwqIZvTLeA+LxT0rBrpw+pG13S/SiGPA62tSiiihgVwn82iEbDw73EcRyv7dTUOIaLbxrlebCmFpm1Uao7n3jCPqRuVQjwgsxnqhQmMo2K2FOx0SxhiAYtiy5l4O4hh4efPq2EJYFiYjT/dm0Hl6xrjE8CcO47DUkLzzOl2oYIPHFxjwsvf8pk007AED5SBDAtNFoxh4c6b5sPpt6qbLhkMCz3oZX+GpdUqockwa/7M/NewOI4+yNt8WMyy5rwPw1Kp1nC44bK6tJ0alkrwJNSMDwvQnBcLDyqo8SdHXLaPH0s0HxY742FOWiP9OaxfOgig7sVig5tm9TcC8wuQbODmcUWfgIWnGPIZpmEJ8WKhgIa8NybZYmOQreL99DLq+7vgxaJrWLzTVvurhII1LIN5V9xcrOqu5dl0OlDkqjnXNt4XzLDoKSH6fiBYeGuaVNa3732WZspV9Qwuliqh+QHyKqlTs+7Dw/UfttJhP8yqqDwgJWRE9RRwzAS0OAfc9MtU0WRYDOO4qj64Au3oJRTsw8JFt0mI2OPgubEZ/N2tT+Kvv/8r/M0Pn8CWvYet7zOPS+slxM5DwVPW7NK2U8UK/vHHT+GT//Ur9Z7FjYCFAr3ZchX/cs9W/GaffT+CECQO5caIsTUszaSEKjxgsTAsleD7ZNfBaVx391YV7PBgOw7D4lclRBgdyGPDsnrA4sewKN+jRkrFNmG5VH3ormmpaJvjrfkduSxzQmXjxH88vBs/eeoFbdu0oKGAhT+7tA3zu2zH1I5KoWKlin+95xnfe1kzjrN0E7QtEO/+zQv4z4d3W7f3rZ/vxE+f3u95PaqGJZ9N+zbEDWVYGucrlXLvucAqIYNhAcDcbv3nGV4+HyQCJgY3n0l7UmGAa3CYhCqhjnRrno9QN2fVZVhy6ZR2Yw/msyqAmYnRS4hcLAkVI2dJIOdN8+H082GhAYluQjMlFMSwNF8lxK3569twHNdVNTOHU0L/+pNncMNPt6vfn3p+Eje+55We95kTu03PYvVhYb9/6+e78MUf/0b9vmKooN5PA9E9v3kBf3vLk/jJU/vx/713U6xj8aaE7ELXXDoduUoIaO6+4RPiRCPoIOtzwG6uyHHNnU/jmz/fhUWFLH7/Vev1lFAU0a3P82bas48O5LBuST8A4NlDMz7HUn+u6ZkLKmuOwrAow8qqv4alZKQY1Oq7EYDsm5jFR77zCyweyOHRT7xRvZdEt4sHqWFi/fd0qj7epVJ1P5c6g+CuvKPodOLint/sx9/c8ms88MwBfOXdr/D8XWlYsikrw2Ibbz/8rc04OFXCKzcuwbolA+r1XQen8bH//CWWDObx8F+drY29fsZxpg9LIVvv/UWpOr2jMtOw2KpArQy6f8qmwthOQpRKsAoLdFy7Cu/+cA+WlEVXlUkQIy4MS0QoarZc0yg6fmMPah2RgwdKnrf3m+DMh8Svn5DHh8XRVet0s/r5sJgrfaD5lBAXgdFAxgc0rVtzAkRccUDlxUeM1ietQ9Pe9AVgY1jsTJPWJZuVNQPAE3smAACv2LAYl515NP7p4pepgYOuK7ERTz8/GftYvCkgFlSx/2czqY4zLDyNRMeUz7iBUljFGvXxomAnrg8LXVdTcGiuskf7cyoQ8QvM6JmiNKy1SiiG6NYdd6rad/Jzxo8xm04pNpgWRTQhHZoua5+jxQXpFijAyWXSSLEqNr++RYR2aFjIadVsQ0GgY+Q+LBw2Rnuisa2nX9CfD+qbc3Cq5BFPKx+WbDjDwrU0Wr+fTHB3ZNOWHwjWsJTVmMHnGgpKA0S37HO5ABFwUIUQADZeS8AyZ8BbvfOIlw9qA/lsYJNCQrXmWHtQEGxlzYB/PyE/1b5JJRbMlJClrNl1RGzu5uQiMHqI+cOcTrtUeBIegDigSf24VUMA/PURQQwLV+7zACXPnG6BOnsDAG992Vp89Jzj8fINSzwGTnT+9ozPxs7hB4luzXb28TQs8QKWSlWvCqKAJZcJrrTgoHuOUkdxfVhc0ywzYNGHx5GBHBMv2rdLzxSlYW3pkmZEt6VqTbvfbF41+UagYS6a+L0xzoJsYliWUEqo5Pa1AvQxjyNMsN0MVGm7z/Wy+bBonzeCqlrNTWvuMJyJubCbp/Ycxy0T9qaE9Hshn0lr7Vr0RVmwd1HZMr4HLQpoGzxoIlF0FIYlkwZ7lrzbD/JgAaSX0JyE8mFh0XQundYMhgYLGbUCC5pA/FwqCb4alpx9xePnw2JSz7SvwcZxjVxnsxqWCAwLPZxxy1V7DfKCCDMH9DAslkaI6bRRTp5NNfQ99d+fbuTy1y91qWxX/KZvCwB2HvQ3M7OhFCC65cZ1uRi9hOrbjRewmJMhrYrz2UxkPRWlMugY4ljz12pOZIZlpD+nesr4BVElg2Gxi27rP+OIbj0+LBVvwEITmmpyqhyE3fuUgjPHcRjDolcJ0bjDxzwOr4al9efYr+WA+51cw+KdtkrVmm/QbeqNuP8MF0/zYMkrurVoWPgiln1fRitrtmkU/VPx9qoib4Drim7DNSzZdNplfCwBFN0TIxaXW/69SVhgSsASEQXLwGFnWPQGgzaY6SKTzbA1PwTg6bZM8AQsjV9NhsVPdGv1YWlWw2JhWLi6XOvWPNcCFrI/b9hy+6X9zEFB7yXkDiK2lgj0kwaiDY2qFIAPajXtJwBsC+hvE3QsBFtVE7VRCGVYYmpGOMz3uymh6AwLiUXpfZpxXMhnD89WlPbAtCUvaM92BoVsJtTinL6vP+cvuo3lw8LHHV/RbWMyz1LqV08JcRNLSg8Vmd/NYiMlRJMb/27bMarjaYPolnvx2GDzYQH0wIIvBPl5N1spcJ0d7wvFx9UwhqWQzWgpM3NRRufQ2iuO9RwiuAyLv+aJa15IdBtUCcYXrEHM+aGAxocAVDVUEsZrCVgiIooPy2A+WpWQ+TdzhVK13NCAV4NCMBmbqsGwZMyARTmLen1Y3AE5/iDkOI7OsJChUlUPWOZq80MaTBXD4pP2C6oS4oOIVtZMNLzW8DKNVQ3fDwCe6ip+3/iV2fohSMNiGlVlQtKEfD/ipoTM91OlTy6bjnwv0j1H16ccQ8NC+fvBfEa7HoBuz07pojBjRVqoBDEscVJCXCfh58PCqxYBBKaESCvCFxaKYVEpofp+8ZJqAvd8IbSTYfFLs2o+LGzMXcmeD76A4Cyh2UqBj1GcfaHPc2dYgsl2F7Jpt3K0WtXT3ikEBtt2DYt/gGN7fzyGJbiXkEoJ+WhYksSIS8ASEbyErcIoWB7hDxSyvkEFhzdgMSYP3+6xekqH4GpR6n+3WUXzz5uN1ArsGMIcEYPA2xbw7zcf5rlaJVRWAQsxLD4algDKvMpKWm1iZ14ptH7pgJY2MFsa8MHNr8w27FjUfvHrFqMxm/l6XB8WP4aFi5DD9FS0YrYxLGH7cyjAMIsvRkYafw8zVqRnijQstgmLe/GEIVpZs6thqe+3/pzbUkI0affnMp5SVpoYzbJdQPd8cSuh2qFh8faR4iB9Uj6rp+GXDObVfvLj5Od918FpjTHmwRoP9FVJc9Y7LZqLR7OsmQcHqVQwK2kWQ9Dn+N84bGX3kRgW1nA2yJqfWDeyTTCRpAWmBCwR4UbTNbfdd1qP9gcbtDEQXCUUlhKqWm7o+j7YU0JFoqGpx0TjRlWN9nxSQqpbs8XpthlvBbM3CR0H349UinVrbp1J7ipokuLmgLZVR7QqITMllNJ+AlAmZQQz0GuFYTH7FZW1smZ9RdfJKiEPw1JsMCyZtGtiGHKj0H1HkxqfnMIYH2IcRiyrSx6wkKGWW7kUomHJR2FYAncNgC665eeW97DxaFjMakA23tBqeoqZSprMEo0BnEEg8ECtP+AY40IxLJE0LPy65D1VUfV91s/Vc2Oujb8vw6JM47yi3rwnJZTWGChzcRikBST2RxPdBmhYzAUEEI9hyaRSSntl17D4PwMA7yXUe5ZFApaIyLOVFT1c2UxKK7HTqoSCUkIVk2Fxb4I65WqnjPt8giHaH1rxqJRB1U0/8L8HiW5bseY3XRdNhoX2I0ndP+OgbKSEAPsAG1QlVGWTlRYoZnUNCwBsXGYELEZZs8aw7I8rujUYFi0lpKck41QJxfVhCdSwRGD7uKZMiW5jBFAkuLXl7zl7Sn8PZVhUlVDG931NOd2Wq2phor7L0H2olJAxTvDx5pBKCbmmkp6AJa2nJ/08XxTD0kXRbT6rByyj/TmrlYR53rexgJ6PU+MzZRxqlDa7HizegMVMCeWNgMVN4+tp1KrleVALXhvDYhXpWhiWKFVCNI9kglNCYxGrhIDeVwpJwBIR/KGmm8RUrOs+LNFTQpoTKrshzNp/v2CoaAQsFAd4GZb652fKVa2Er13W/GYjLsWwGOJft5nW3ApYaDAl0S1gF1ebqxitlxCjaQshGhZeIUSfAVjKjw0+z43PxCpt9uoQLCJOxbB0rkrITNlMsJRQLkJKiLs+q8AloEmgiaDBWksJNQS5QdqEGrMrGGj4ZFidS5sQ3RYNhgXg3a31FbjJONhTQsSweAOWbICGhR93UPuBuKDzVqzYWcsSuyf7tVRdzmolYV4fzkCaTDCJcpUHi6UKyRawcFFyxUjj5wJYSRpb82ybQaLbiqWs2fVhCU8JZTXRrXf7Kmj3qRJKawGLMCxzAvyhptVJzlCsD3INS2BKyCxr9goeAf929369hPpMhsV4iAqsyoh/p9WHpYlByGxcZzIsNEArI6I5yrD05zOKJbJplYI0LG7L97THOI7/BPQKIcBr4MQnQ8cBdh+KzrKUK2bA4mVYojRmM1+PK7r1MizelFCQ6JavlpWGJcb+KJdPy2DNJ8ZRlRLyD944+zCY92cfYvmw+FQJAW4PG7qWbpWQvmiataWEqJM7S2MTaDUeFLDkY6TsoqAYwI7w18xF4mh/3lo9aZ4rzkCaTDCJcmeUhsXLsORMDUsmjTwr+64arElQkG/rDRR0X/Exg6AaXAZa89fPQZp3a7ZsP4xh4Yfeax2LBCwRwVe+tDrJGr0XBllKKEjsZwYzfp19TQ0LfZefD4upYakagYIqua7UtP3jK316cJpxLDVXLhTN04NDNOlcZVhooOG0tI3VCOwlxES3NCFwIXIuyzUsOsNiBg7m4BYnLeRhWDSnWz8Ni/2eaKcPixLd+jSDNDGtBSy6piPK/iiXz7CUUCO/n8/6r1T5sSjjuICy5viiW/tChY630DhfZupXZ1iMlJCFYcmpBY53LCiriqSUmkDbYhzHr5ktjcKdbo1A0mYlEYVhofuaGBYSKdM4ypFmHklAXU+ot2vRWeQgRsNmWxHkdcJbwRCiWPPTV/MqIas1f4iGhQfWwrDMEaRYd13FsKRNH5aMr86Ew8uwMIGYUQLM4ZcSMjUsphNqRonx3MvNm8zpZc3NMyzmysVlAhrbTusT4ByLV7TVpTkpcHg0LFVvQMrLmnlgyl1G14z0a9sxu6aag5vpNxEEj+jWECkC7qoynGGJHiB49sN4vzKOy6QiGcfx7uDN+LAQ42DrUsuZB5NhsbEA/Fj6FcNiSQk1XorDsJhlzfz7VLokaxfd8nuUVtMqJZTPeASl7j3oNY5zvysdWNkSF34eMwT+7JnaItu4aF6f7RYNy4uWLwLgMix+fYQI/DmtMyykL9KrhICw7su65oh/LrKGxdLg0kSVMexcg8kxW66q4/ZlWFhgLQzLHAKtYFxHSFPDko2oYfFnWPgAF9Wav2io281eQibDArh9V7LplCb+ywdE4mEwo303JeRSkwAzIppjEYutUiEaw8Kvr3tNbLoVGsSOXDLgEWWaqzAPwxIjYAm05jcZljAflhgBggkzZVNkK+koKSFe1ul2zY3DsPjn74M0LLZAhFfdudV2raWEuNusJyWkGBY9hacm8BIZx3EfFqoS8hfdmmXNtpQQ7+JdDdAYRYXuMeN9pnhQxgPJES66tWhYhhpaj10HZ9Q9TuP3S9YMA3BNF2cDUkKAEbBwDQvzYaFnJUh/5aaEIjIslhSSYlgCNCxa92ifZ4nuh2w6hUUFey9kTcPSevavJUjAEgP0YE8q0a2FYcm5A5XfQBukYeE3mdk5k8qazc6kyl2zsaqje96s3+eDzMRM/RgKnsGqhSohn7Jmv9VHr+nFuHAnU2+DOQ6vrw4T3dbcwYq2kbOIbzcY6SDAy3TQTzKXMw2yguAxjrPobOheCGNYNM1IzJ5GfgFFPWAJF93yFSYdE2ePwn1YGnR4G6qEuB9S0Iq52ZSQGQyaKSFvk9NGSoidIxJY0kQ3WMh4xgBPLyE/DUtIqjAO/Jo5mt/rTQnlrVYSdK7WLRlAPpNGqVrDc2P1DttUHHBCI2DZYYhubVVCgB5gFLJmLyFK8+jPTJAmRWNYAphtWzdxJboNYFh4sYPfs8RTorZOzYCkhOYs6AadZhbW/GHnDAvgz7KYQk3r6tay+jJ7ARHclFD972ZKiG+LtuH2bDEClhYGIS/DQhoWffUR1Yjo4R2H8G/3b29b7f/4TBnX3b0VzzYGrrjQBs2sPin8cvc4rr93G2o1J9jplk1WFJxw9T/93xTcAl7RLZ3fF62oU9stMSxV26QUrUrIVta8edcYbvjpttBrFxSwhPXtAewaFs4OhpY1B7h8mloJgBsrWjQsrOourJoIiObDQqxuvfmh8dwb5dzKOM4QofLxZrJYQalS0xkW09XV1LBUvcFELkIXbxu+/dAu/OSpFzyvh6eE/ES3PikhVYiQxpGN4J8CekoJvXh1PWA5NF3G+HRZPcu2KiFAN4/jKaG6mai+OMxE0LDw5940Z5wtV/Ev92zF088ftvaWIyflKM0P02l/HxZXdG5PBwHQtDu9LpSQgCUGlIaFdTVNpVJYOphHKlV3XeQBjJ+OxXydm3b5mcYBAd2afXxY7A6J9cj8wFRROyZCSz4sIQxL3Cqhv/jPx/CJm3+FJ/ZMxN4XG777yG589kdP4p/v3trU53XRrT5IfvK/HsdVP3gCD+04FKhh4emAJQ1nycXMZZX+f+zKIc/3u11T9fO6YVl9QH720ExkIbPZ/FCrElKBblSGhdP59f9//KbH8dfffwKP7hoL3A/TW4SQzzIaO+CYpsI0LFFTQhan21wmjaG+LNIpYMVQn3rN/A51LI3AIJ9NB1L8zTAsxUrVl2HhQQSga90cx/GMN+MzZcW0DPVltV4z/Bhp4p4pWTQsLGUXNbW7Z3wGf/4fj+Hyrz/qCWT5sdkqu1Qw2NCP9ecyyGVSWDZUUOPijEXDksuksX5J/fnY1aiiI9HtskUFLB8qqL+FMSzc3DHNdCHFilfDEqS/cq+XO/aai4I7nnwef3vLk/jcrVs8gl6AOyk7vvd4FGv+sQCnZ0Iq5QqOe10oYU9aCaxwRbduSggA/unil+HgVAnLFtVv/kI2jWKl5suwmLS5zbTLlt82qV61PVpNqJSQGbC4D8baxf144XART+2b1I6JELXhnA0ehqVqD5xo4g0L1vdN1N0paXBtFWQQ1cz2qow5sWlYDrBtm1fOr7HgMSuH8PdvP0ULTj7828fi1CNH8ZZT13j2waNhaZxfWh3VnPq9YKtyMBHUDyZulZCt+eHBxvk4OFkK3A96FrLplLYPug9LNIZFpUhq3gnWhlrNUU63foLDf37XaZiYqajgMsgJmjMsQRoWm4jSD37NDwE3QPL6sLip4XLV8YxD4zMl1d177eK6sDufSaPcYFLoutN9RXo387vUJBtxcXNoqtz4/jJemCyqIJCOzz2u4JRQNpPGP7/rNJSrNSwqcLNOC0uYTatrp0zzGvfMQD6DpYN5vHC4iLHpsiu69dGwmNoejWExx7iAZ0Z1B2eshrkooPfsO1zE2sUDje/3ljUD9Wcgn/UGHHz89xvXxyklFMCw0PHUqk7PGRYJWGKAblDKgdJNsOmopdr7+nIZT+kwR1AvIXdStAUspEoPqRIyAhYemW9YOohHd47hN8/XAxbTgyFq/xYbiHlaVMhislixaFgaZbyN5y5oZVap1pSJWFxvDz+4TR/jb48/6Fy7RNuilX6xUvX0HdHK1g3TsLedtlZ777olA7jk9A3WfTADFvo5yMRys+VqcwGLpVLN9GGJ0/yQPHnMyjETFFAM9+dUkEPfHcU4jjMsJQvDEnStJ0sVpffyo8RfffQy7Xd34HfgOI6W9+calqAJq1kfFvM58GhYjG7NQD0dZI43Y9Nl1aWYUo+FXEZjjgFXiEyrcED3fAlj3kzw1NSOA9NawOLXJ0m9ZpgZvv7Y5epvFGDwcZEzQRSMjk+XUa25jNNgIauu+9hMiTEswVVCdE24qZ+HYQkQqo9Z0pBmeo2u6dh0yVoGnWukpCi9N+qVvFldtT0aFkoJ+QTshPp97k13dxuSEooBmtzNNuwm/JoUEjy9hCwalkCGJcTp1qwiSRsBCwA8te8wAG+PjFbMoEjbM9ywrve35g8f6CZmvSvnVkHnLW4lC2AGLCwl1BiEaaXPTaTyllV2nMnKBF0qswqsL5tRg1lQ003b8diMAsvGABmmVdA0LI1rRecjyNiKv98MGHJM1FkOuBenLcZx/Fr5pZwAV7/Sl0v7pgFMcAMx83wU2ao+F8A+qNL2WCkh7wKoaAQsvOqMNs3LVgnPjc/i+cP1lDCNB3qlWv3DaqKfcQNJrm+Kq2Hh4xYFTAQ/+3/ze3NZ75hrGxd5mozSHWPTZe1+Gchn1DGOTZc91ZYm6JrSPMDLvr0Miz/DRmnIEZaGMYM/2v+x6TJLCenHTuaEfpVCbvND/2cpqEqOIyor3mlIwBID9FCbKSETYaXNnl5CFp8OWzDk20vIp0rItOYHXL3DnvF6usUrunVznXHFrrRCG25MPooJMPYjSpUQUfVABwKWJrbHc7+a6LZcRa3mKNaN23TbrMvjpANMmIEeZ+OiOCxzUCUNfU43jjMYlhCtgmkcV6rU1PkKEgXS+wE3yCXkM/6VDRxTEYzj/O5j1aU2IH9vggsfzf0iNiefSQdO5rw9Qxh4P59QH5bGvqVSKcY61FhTv/q2HmvoihYP5NTKWmvPkSaGxZ3M1Xfy1IwhFA0DZ7tMgXio6Ja6NVu1ff4poVwmrYLhQ9Ml9ZxSawyaqMdnWErIT3RrtCzQegkZVUJBxnEqDWlhWOrdsN1+chOzZa13HcdASANErn3xrRIKSYna9q+XkIAlBkzRbdby8AD+gQXBmxLiE5r95gTgWdUTioZYzK/5IeDtAOwV3brvjXtz0uREAYuqEjL2I52KELAwnUn7AhZdpBgHnPnKpFOsc3ZNE/uVGD1cUCXu7ve1wrBkDWdRt/WCVwQcejyNczBgsZD37yUULO4D6sfPg5QwhoVYgmELw5KLoKfi7sp0TGaQ4CcgD3P4tIE/l+ZqtcQZloAJyxShB4HusyIra6Z7RzEsFT3ABHThLQUKKxvl77/YPQZAHwts/cSImTg07adhaYFhMUrww3xYbGZrhCAfljxLCY3NlLWWBKlUSv3t0BRPCflpWPRAxU3XVS0Mi/+5IX3K4kGuYXGPq1pzLTEcx9XemZWjVCnk10+Ij7t+92OYLT+BvrrXGhYJWGLAr6LGRNjkMWOmhCz6AWtZs1+VEDEsZpWQjWEx/D38fFiA+JVC5DpKzQHN1FTWCFiCMjPjbJBsm4al7OpM4sKvEmOmXNVW+cWySw8TdWzTsERJB5gwtT88b16w9FMJQtm4Z/g9aPY6iVclVNVWfNEZFiNg0az5/e9D3r/KpmHhr5s4FHGw1vaLp4TM71EalkzghEUfi9StmZU10/bJ4MvPhwWAxrjRPUF+Pb98dhyAPhbwcUBpWFhKiFiqspVhaUbDojMscTUsHAXLuMgDK2LQxqfLimEh3ZdKF82Uw43j0rroVmt+aJjBBbGDyvuHpWEynLmr6R5e+yeL2jYJimEJSQll0ymXOTeuVZQqIcDbeLVXkIAlBrwGS/YBp2CJ+Dk8xnGWlIEtJVRg1CenuU3RreOpEnL3c3Qgrw3QnoAl7b+CDIPSsPTrGhaTAqfnLphh4Smh+AGGDUp02wLD4jHnKle1Vb7GsGS9eew4tuwmzFQaX9WF6ab8jqc/r18rwA1eXIYlnoaF59RDRbcBDEuUzuHTFuM4k5HxM7MbV9R89JRQOs20Gz5lxlqVkGXCiuPDYhPdqoDF9GHJWgIWJrpdPVIPWOge2bDMzrCYGpZy1U15ut+VCtRp2MDvzR37p9U45TiOFlSGGceZsPlTqQVGNqUJa2lyJ2aRa1iIKfX1YWmcF/q7ujZVr4YlyDjOxmrwcbda08/H/slghmXaJyXEmTw/ttLVsIQxLDT2BL6t45CAJQb89B4mgvrMADyF06D4LX1c7CkhN/KnwatSrambaMBofmha8xP8qGBAHxDiVgrRg+PHsHh8WALuflvevFW0JrrVc+g87acxLEyAR+e2qmmU/EXVYfBzus1yDUvE4I40LP2WtFV8HxY9YNEYljDRraoS8mpYovQS4ue+5tT30Xy/3/WOSoeb8Ot8G9mHJYboVlWiVKpqEh7q0xkWG/tQUJN4VQXqK0fcqhxANyfU+ok1zns/a/BHExv3Q4nNsLDA8XCxoqwAPP4yVtGt/kxxkHZPZ1jcAIcHJR6Gpd9lkVwNS7A1v2JYyIelzDUsZsDiZdOpj5tNw1L/jKPSfABnWPw0LPZFAQ+i/ALo8YgalihjdjcQO2C555578OY3vxlr1qxBKpXCTTfdpP3dcRx84hOfwOrVq9Hf34+zzz4bTz31VOh2r7nmGmzYsAF9fX3YtGkTfvazn8XdtY7Dmz7xE90Gp4TowVhUIK2Hd3Vrd7plAUvZyxYUVEqo/rtayRn7yalgU8SWSbsmQXH7CU2ZGpbGw1EzgrAoTrdawNKmlFCxJdGtybDQYFXVVjilSk0FoHQ92sWw0ASnqq+YZ49bZh0vJWTrKmz6sATR27Wao1UOxGVYaJL3pIQi9xIy21zUlJaF75MNbrVGvIBFpap8vqfA993W/DCG6Nbmw0Lnys+HBXAn3SlmL0ApIQLvBm5jWFKplDo3JM7UNCwhPaZMmAs4Sgt5/GUsvdYCDTUN1+n6fnINS51BK1ZqavKnxd0IC2bCjeN8NCw2hsVHqM6rH7l2ii8quYaF9huwMCyqSsj+zPNx17eXUMwqoTlnzT81NYVTTjkF11xzjfXvn/vc5/ClL30J1113HR588EEMDg7inHPOwezsrO82v/Wtb+GKK67AJz/5STzyyCM45ZRTcM455+D555+Pu3sdhberaWtVQosK3gnNZVi8lyaXcYMJ2obWIdbwYbE5JAI6w2L6sPDvDnIYtWFaaVjqk6CHYTEEaUFVSNzcrX0aluZTQkEdcXkOucgEeLYqIZUea0LDYuaRuYal+ZSQ/z1I93vQStpT2msyLAG9TgD/lFBe07D4H5MZEJWqNa8Y1i9gmY42WJvwK/1XAUvOLWt2HG/eXy0kYpQ11xxXD7TIYFiUN4pFdMsFs2bAssFnHOBjj2IgGtvh5cVxq4TM8XD7/rrw1uMvY1xv0wPJhC1Y54HVYN4t+6e2HNQ8UHnNzJRdA04LiwPwlgUZ7Se3MnBZSfu9S4HfUCGrnec0XyjWatZ73lPWXAhjWOrbSKcYw8LuxWLFXWyFBe1ztkrovPPOw2c+8xlceOGFnr85joN/+Id/wF/91V/h/PPPx8knn4x/+7d/w3PPPedhYji+8IUv4P3vfz/e85734CUveQmuu+46DAwM4Prrr4+7ex1FwYi8fUW3VFLoM1DSg0sDj010a1t9pVIpTzDEKwfyWTNl0PibMTBuXGZfWanjIso7xsTOm7N5qoSM/SCzrSDF+aFOlDVbgryoMCcFnvbTzMsqNg2LN+XXioaFzluZVwnFFd0auidb/50oTrfmAFaqmFVCYQxLfZt8UgF0UWfQCt4MiMpMAEm3vd9zOD4TjQ43wUv/OUpsVc9ZTTOAUsLrGMZxgCsw9hPd8gUVXVd6jlIpYMVwQf19pD+HxYNuoMbZY34deIWN+V2xq4SMdKUvw1IJCliCyprtxnG8GogaIA4o0a0bkNHn/YwXlZOwp0rI20so58OwBLF6vArQlhYzGX0KWPwWBXTb1UW37v7QQpEWhemU29XaD0rwP9cYliBs27YNe/fuxdlnn61eGxkZwaZNm3D//fdbP1MqlfDwww9rn0mn0zj77LN9P1MsFjExMaH96wa8TcKaqxJSTos2waOlMRaHqY/hOWWzXNgmugWCNSwASwHEEN3OsIfGZFjMNEgmQpXQWAerhFrxYVH5a3aNpwx7eLNKqMZW2a0Zx/loWNLeQDYMpGGxlTVXDE+JYIbFmGyqegAXlWGp92dyJwrudBvcS8jLsNCx0PPld//YHEejIO+TCimyY8kZZaocsRgWNubQZhTDUjU0LFl3e3QuiRkpZNNaJYhZLainhBjDMqC73XK9TFwNS9HwOdnWKG3285ch8MDQ7sPi1Qy6jrz1faT0y3NjdaZ/0BDdlqo15bQc1q3Z7sOis9kZn6B2PEA3lWEBum2MMucbenb9FgUVppezVX/yxodhwXNaGcfNo4Bl7969AICVK1dqr69cuVL9zcT+/ftRrVZjfebqq6/GyMiI+rdu3bo27H04gjxLOEJTQo3Xh/ps+gGa0PyCIX3bNqGfmTIwJ8cNIQFLMw0QadLOsz47FZPpMauEgjQsM50Q3eoDfByYlRh6lZBeWmv6sADuykQJLpsJWAztD1/VqQAqYjDmSQlZjePCq4RsDMtULA2LG3Bzw6581t87wt1Pr109D5xpQA/TsISVdJpwU6b2iZY/i4D3OVIaFp/xw/wu8/mlcaNoLFpsGpYx5eab0QIzjx9TxidgYRU2gO75Er9KqH5tjmv0zlIMi1nVZTAxvIO97bmx+VOZrBNdY8WwNIJZLix2U0LRRLdBvYT8NCx0Hm1mhTwAtKWEzPuAAvLQKqF0Sru+ru1/9Ps/yiKzG5iTVUJXXnklxsfH1b9du3Z15Xu9jQLtp68QUCXkOI6nPNHKsPhMaAXm/wHoq7q0kWrxE/ctHsipQc8UEgPBfTD8QGmAgULGYnCm70eUbs3jLCXUTO8fG2jArNac2IJiTjED+qqOazZ0HxbvKttPVxQFdN5qTv0+aoVhcUW3NuM4XUdlXk8Ou/W4e+1Cq4SU7iOj6SioyR3fHxPT7Fhp0uKD96BR/uvZz4gVEiaUgNEnlVHI6ukt815TjGNEHZPJKijRrVnWbNGw0LXoy2Y0kafHj4kFizz1wCts+Hc148NCY9Zxq+oBy7b9U/Xx0HTu9mFc/FLwNg8iU4hMgZfSsDT0g1xYTPDvJdTQsOT01FCpWvMK1Smt7mPUZjMrVCLmmmO9580F8kCYcRwb/20OzWPT0Y0Tk1Il1Nbmh6tWrQIA7Nu3D6tXr1av79u3D6eeeqr1M8uWLUMmk8G+ffu01/ft26e2Z6JQKKBQKFj/1kl4fFh8Jh264R945gD++vu/Uq8fvXwRfoc1u6MBVdOwhKQMTK0Cb7imJrTG5qic1qQSU6kUNi4bxGO7x31SQvXt/PM9W3HUskG85zUbtXw3x4HJIm68bzt2NOjdwXyWiRK9qQtAV5zvPDCNWx7fg99/1XoVwAHNMyy1moMb79uOl61fjFPXjarXeaBI28xm0vjp0/vx7NgM3vHyYJbOdH9V3g+Vqt4xuOqWOPIJ2ONJ04To1vRq4JSv6a78/OFZ/OfDz+LtL1+ruojbjkdpWDSdjbuipe3zY+CwDWAHp9xrF7X5ocmwaBoWn9QkBUO5TAqLClnMlktGwOJfOeU4TtNlzWa59X1b9+O2J/bhoe0H68fSeBbTKbfUmiNuWjCfTWtuyl4NS2NyZs8y3Xsuw1IPAIcKWRwuVjQPFsDeSwjgKSGqEnIXSPT95vW596n9uP3J+ni+ZCCP975uIwbyWTVmUXfyw7MVjE2XUaoaRpg+GpZwRrumGlKaCwxeKQToDUMXD+TwQqO3EuDVKhJoHDUZFsANxlwfFnuQH2RW2G6GhTOwNn8tGmMXR7j/k1Il1NaAZePGjVi1ahVuv/12FaBMTEzgwQcfxAc/+EHrZ/L5PE477TTcfvvtuOCCCwAAtVoNt99+Oy6//PJ27l7LiMqwLBusTxBPPT+JpxpdkQkvWrFI/X9Rn4VhsZQochCFT9Q3TVCFbNql7YwqIVt26ZgVQ3hs97iVmlw8kMeugzP4wWN76tvOZXDZmS+y7s9X79uO/3PH0+r3ZYvyvn4hHmv+moMv3fEU/uPh3Rjuy+H3Nh2pXh/XrPmjG8c9sO0ArvrBEzjpiBF8/49fq163dbodyAMf/tZmPH+4iNe+aBnWjPb7btfPOK5oEd1aGZZq6ykh/pkqZ1gyKfTndd3UV+/bjmvu3IpipYoPnX2stp0aW8GRcVzVcg/S/R7US4hXFJUU1ewyLLPleorMb3KOpGHxCVgpGBrIZ9V79eZ2/gzLVMmt5mq2Soj266PfeUyt3IH6JF1/X31SNzU4cd2OzXHHTHXZGZaGhmWmrP2+erQPh/dNqqDB9h18gTNi9BPiGhbHsd8XH/72Zi0AWD3aj985ba0aq0b6c1g5XMC+iSJ2HZqOUCWk348meKBbrNTQl8t4ghwzQBhkwlrz+vsxLLQNWrzx1BFN/mYvIfPeDTIr5OJ2WxrTnBPoPjjsx7CwwDjVMI8rM33MRGOfzQo9G+YswzI5OYmnn3YnqG3btmHz5s1YsmQJjjzySHzoQx/CZz7zGRxzzDHYuHEjPv7xj2PNmjUqGAGAs846CxdeeKEKSK644gpceumlePnLX45XvvKV+Id/+AdMTU3hPe95T+tH2EZELWv+f05ZjYnZslbpcvPm57D70Aweb9hi81WxrYrEz+OFBpCJ2frNRgNSXThVfw9FwW7zQ+8D+JFzjsUp60Zw/qlrPH+7+q0n4dbH9+LBZw7iZ9sP4vkJ/5J0CsjOOG45TjpiBOeduFrloOm46KGlCdxNCQETDaHbPvYdh2crHm+PqHi6sT/PH9b3eaZkX8XRNZoMqWbh4mbA0LAYolsKTnjAQufCdf2NekQuOCtTq3E2Ls0q0+rHeaDhjklCQg6uvSCGRWsYqDQD6cb2/bUkVaZ3cVAfEPl9D9QDC9NnhUD7WzAClnwm3Jqf94WhxcOM0dwOsN8/FFTVA6V4F8P0paFtvetV67F+6QD+n1Pq7HI2nUIJunEgEJ9h4fcRD+zo3JlsAsBSQiS6bXzmf7/9FGzZexgnHjGifYfNhwWwVQm5Cyq6HbxmZPX3rlvSj10HZ3Cg4X3CfU6G+3LYN1HEZLES6sMS5HJL2yPMlqtawELHZQqrKZgF9IqdVMou7AWA97xmI5YPFfCWU9aobVPgRd2n6ZrSwtJkP1zdVHCVUBSGhVijCba446ga439/LoNytaLYILPqLAj01XOOYXnooYdw5plnqt+vuOIKAMCll16KG2+8EX/+53+OqakpfOADH8DY2Bhe+9rX4tZbb0Vfn+sBsHXrVuzfv1/9/s53vhMvvPACPvGJT2Dv3r049dRTceutt3qEuL1G1LLmgXwW73vdUdpre8eL2H1oN57cexhAPaVgywHTpOA3mJkdVN3SzLzWAtxxnMD00uqRflxy+gbrd5ywZgQnrBnB//3JM/jZ9oOal4MJamJ26ekbcObxKwAAv9xdD8pooC4ZrBGNh7Waox4avirnGgggXpUQeTscmi4rehiwNIxsKPttHX5tMI+hT6sSYhoW5sOSzdRt3LnxVZioOggZP4Yl7e3WTPtkC8R4AKDckS33oJmPD6oSyqRTyCONcrWKQ1P6/TJdrPoGLDylqaWEsm7e3U9vRMzWQCGrqhdoguD9lewBi1shlIqZnlNVQo1jp/vzj848GqtHXJbOdcQ1NCwxg1YeTBQyaU3sCdhTJkp0qzQs9c+cvHYUJ68d9XyHqR8iqG7GpGFhepKKwRoC9WeaAqiTjhjBroMz6l4kQXhfLqPKiqeKVc8k6Od86zfeUiPGas1R97/Z3dnDsBQ4w+L+rS+b8b0flgzmPWPm+qWD2DdRxNYX6gsluuZ+6ZpADQtLvUbRsIwapn4mXIal/vtgIYuJ2YpKpZquv0Ew24L0CrEDljPOOCOwtCmVSuGqq67CVVdd5fue7du3e167/PLLE5cCMuEpa46g8ieQyO3JvRMA6g+tTVRIk13OZ0IbMVY8fODlFDOfJJspoQX0xmA2OI6jlP7cNdPUPJgrJF6eS+wE/44xI0CKw7BsZ94Os+Uas+32CiS5SC9MYOyWSRoMi+HsykscM2l3IFV6njYYxwH1YNDeS6gxGDX2ySZ65WLRPsWwWO7BGFVC9WoWB1OlqpVh8YOWEsqaKSH/7wXc9M9gPqOCBhLi5jJpZmvvvX/GA1a6YeA+LDV2bb3jg13HEMea39xuPssClqo+OWsMi9Ffx69Ul2/X3G+AMyyGhiWTRilNGhb3+HiwQeMH3Yu8JYlyaS1VPOfBo2GpeAMyE33ZNKZKbt8kM8gZMVLfnGHh90Bctm3j0kH8bNtB7Juos0j0rHBTN75wCqpMC9ew6PvmthUoo1ZzPGlmPg7xfaJFjNlXKQhRGtZ2A3OySqhX8DYKjH761jdEbk/tq0fifbmMD8PSuMl8Hk7lzNiYFLgRka/GodmARblc2iP4Fw4XMV2qIp0C1i52AxZT82CarqVZtE4TKg9SzAkvjuh2O+sCy5kaT4drM2AJyc16RbcuMzFuCIR5JZB5jeM0vjOh2Xcb19fsWEtBgi1YoGNJp9yKB34Plo2UUJQqobpxoZ6GIARVCpUYdW+mhPwM2gi0ch/IZ9V3zzSON5tJeZgIjmZdbmnb9f2qafemycD6VYq0khIqZNOqh41Hw2Jpfuj+HnzDaSkhm3GcqWFhDFjVJ2AhLY9iWFhKyO00XPWtCiLYWg+YMHtpcUdewJsS0hgWFjyEBXYm1i/Tq60Uw1KgRrTQBNNBvXs0Hxar061+v5D2pOZA9SfiMMd/HiTWfzYYlnx0hqXXGhYJWGIgqg+LDRsbvgeq9DFn75VSDSlrXjyoDyB84OUDINc4NCPw1L7Lh2GhdNDaxQPaufFjWIhK5wZ3UxaGhQIAmp+jMizVmoNdB6fV73zi9AQs1ZrmWRJW5mwKG3kZKNeJ1J1u3TSJeS4qxqonDrSAlJVm815CtKKmwchWQcBXn7ZJNciHxWRXVY8XnoIxzqUfw8LFv/lMWjunUXoJ0cp9sJBRkxmlibLptLpWtsH/UJMlzbRvQP08cfbGayxpH+Tjim55uiafdc8Tfbddw2IGLMETcYF9VmdY3Oqa2XJVY0ttDshcf0LnliZIxfZkM6zTcEVz665/l92HxU90y49PpYRCRLeahoWnhGIGLBsMPxt6ruuppfprXJQf1B2ZBwVWa35jvunLZZQGzUyjA2z8b+yI2yyxsaghhqUQhWGp/+x1SkgClhjwNj+MfvqONHwP+n0YlnLIhGaq9knDsngwp4syHcdtftVkwDKi2ByfgGW/Nx3Ev4+Oy6thYSmhxsPMWRz6vqWNaquoGpbnxma01bgesJjCvqoWxIStHMxjKGTTakAigSvtq51haV10S9uk/eX9SygFQKu5KYP25eBBgo09MVN4/P4xT5MKwBijQaDzM+0TsJjshF4lxDvM+lUJuQwLTUx0/PlMyjOxc7SWEnK1KXxyNRcwfj4ypvNzGPh5zWfTyGfsVUK6hkW/Fn5maAQ/HxbeMuHQdEnzRLGNX7xMfRHTqQAu+9GXS2sMC6WK6P1+VUNBDEvBSImaztQmkzbokxKy+VIFwTP20aIsncJATmc0ePWjNSXEtFGU5uMxrY3RX2wwYBxm01kVJBZ1hiWa6DYZGhYJWGKgFYZlpD+HJYM69Wgb0NyupD4pIUNXotsru++rhohuo4Ae5InZsnVCp/SLd5Whr7xMepZXCdkYFjqmFUP1gCUqw8LTQYAbzAFe0W2pqqeEwho9mpN4KuVWofCywpKmYUl53EDj6hdMcNM9HiyYxnFBDIvWwM6iEzGN43h60vTcqCrPlrSHYVjauN+nfFJCJjuhaViy4VVCNoZlWqWE3P0xV+wAN42LnxLiDAvX4JhiTT+GxQ1a4wcshWzGIrr1amjM9FRoSoj7sLCBhPfhGZsua99lc7rlIuoB1euGGBY3JcTTExSQLPIx+gvzYQH8/amUD8ugwbAwVmFxCykhv7Gv/h16wDYxW1bVj3bRrbdKaAnbN9vCcyRAZxjKsDBbgDBISmgOwhOwxKT1ubtkX85OqZYNetSEqStxjYjy2iTIRaTNCDwB96FyHHvpHJnFeRkWfdXuFd3W3zdTqqgV+/iMGxQRvblyOB7DQikqgtaPyKph8abi/GD2JgHsgxtvhGZr4Gd2dY0LZeBUs1cJ0bmaUqsoL7tRYiJGa0rISEuahnUctvYABDKs82VY2HXNZVLapJqPYBynaVhUwNJICUXUsERx+TTBPTb4BG3Cr8qpbaLbRnDsLnK46NYIWEKElZqGJavvF2d1w5xueQBHQclUqQrHcSt4Cjk3mJkquWXNQ0YXanObwRoWXWRsjjlDhaw2pg76poTiPZeDhSyWD7nGjFntO3SGhe65wXzGmt5y73dXw6Jt2xKwuVWj3pSQR8NiMixF0rCEB2lJqRKSgCUGWqkSAvRovC+bsXb0rBirWxOmL4JrRKSnhPhDH6VniQ05RuvaInhiNDYu82NYgjUsXCjmOMBh8pZpPNgrh/saxxLNOG7Hfp1h4ftspoRKlZq1Hb0frOZcFpq9Lrr1ali8JnrBx+IHPqj5VQk5jqMmbhu7oU863pSQeQ/ygd4UJ/NB0Xw+aLD1Z1jcPli8EzntG2cybOBVQjQBKPfbtLf8lyPIDyMMnBmlicUWsPj12mnG6Vb936h+0joZa6LbeCkhP+M4wGWhxmdKmnFcxgjG6/vkXlNauU8XK9qio58zLEx0q1oO+Djd+vmjAMzI0RDdUgf7VCqlApN0Sj8/epVQPIYF0BeiGsNiMBphvatsVUI8YLEFbKrbtGV8NqtEfRmWGCkhqRKaQ4jqw+IH3nCsL5dhHT356jZYd0K52OlSFcVKVRt4uSiTb7NZDQvAV1d6BO84DtOw6AELfZ/jNHwZjLJLW8BS/45GmmvGSAlFfEoogFJCtADRbbFS09JEcTUsgH01Vq25QsxsOuVJubRS1gy4KSHz+vKUEK9UmilXPcemaVgUW8B1VI39Vz4s7nGaJmi2KiECDbZhDAtNwHQ+0ym9/4mv0y2tEAuu0+0UqxIK8mEZb6FKiDdlJJGpbTLNMU0CR9x7wDSO42XN/NngKZP+vJkSCtGwZHX9EMfiAQvD4uMjpTEsSlhb1cS4fbmMVvareqv5MSwRqoT6jZSorbKI2IjBfFZL3/EAor+JgIWPfxrDYjAaYb17+FhB+88DFluAa1ZxcZgBi3+VkIhu5yX8qgCiYgMrgSvk0opyDzLtMjHUl1U3D5UVA+7ASzcnH8ia1UsAXkaHsH+yhKlSFalU3dGSQ9c8OJaUUP3v5NZLcHU59Qd7eYNhKVZqkdqaU0ropIaLp24RH5wSCjOOs7lt+k0CdE1sDEvc1bUJdX05g5bWewmZjMaMcex2Wt9bJZTPuAGE+lsAw8In1lwmpe7JKYuOBoCHnaDJgs5xLqysueiuEOkz5HSbYwZrtpTi2EzzVUKq3JpR90EUv1d0G49l0zUsae13XjLOU9SelFCMsmaT3VXi+5myZshmS2lrGpa86/tBi4NMui6m1oIZoxmsrw9LjCohm1CXPKzMqhguLG6GYeEMMy+WMBmNMKE3fZbr4DSGxXLDBBVGuE63DYbF0NRMFqMzLColJBqWuQP+UKdS8SedDQbDEiS69QuG0mmX2iQNSSrl5n9p1cYf+lYYFkU5Gg8EGcatGenXVmfm91VqNXhEt419NF1YlbcMpYQaD6vjhPukVGv1RooAcOqRo9p2AGglzEC9022cKqEgN1HAaITGdBSmDqNVIbRb+smvr+sSO1upeiqDpo3fdS8Nb9qlbATNqZTXT4bAj4ffBwP5rGeFacJsd0AMJv2e9WEoCFNaSqj+3mkVsHROw8K1Ke4E7Z3o/PxrWhHd1quE3N/pGcqmUxrDGresWRfd6vs1amNYGDvHj6/IAjheukzPBFWzuVVCTHTb17zotmCkRG0LDM6wcHBhcVwNC6Br+KwMi6Fh8QtY6LN8gbGcNS61pfYXG8Z+BN7N3cawcP1VNIbFFfv3EhKwxIC2gkx7qwLCYGpYgsqag0SZRGFSCqReIUSTS2M7VX0F3izMbq2Ebfvt+hXz+zjDQhoW+rt579MKhJgW0rAA4ZVCe8ZnUKrWkMuk8JLVw43tRGdYQp1ureZc7v+H+3KKiaABqu50q09aLTMsKQpY3OOpC15doypztWUGhtzIj2ti1N8tXb5tq2nAqBJi52Ywn/GsME0UK/o5pUmVAlteJWRj2Ka1suYGw1J2fViUwZoxAfJOzX5dyINAk3ulplcJmfBLaamJpInmh/lsWhuH6Nqa6RKPhiWOcZyxLddR1dSweDU6PEVG179cdVT6l64xt643RbfcY6j++egaFmq2SbcL/wyNZTbfEQpcbYFnGPi4btWwGOaYIz5pSPrsLHte/AS9BL+UEJ9TTA3LZLGiVQ/GqRIShmUOgd/8cQW3QJ2S5JF8kHFc0PZNhoWbEJkpg3QKsQMrDqVCnzEZFnuFEODVPJg5aL+5emy6bjFNwdGKYfdhDQtYaH/WLRlQ5eOBPiwV3YcljMExdTiAvmodLGTUYKcYlnTKExDENQ0zYUsJZdMpLfd+YKqofcYsbeb5fRuLUbGsaKMwLPz5GChkPStMEyY70acClZTn+20M2FRgWbNbtWTeOzMNnQ9gN/AKA39uucjUhK0U1HEcVRkX1dCRT6KFhkCZzvWUClj0bXkYljAflqz/2EZj1qGpCFVCLLDnlu90T9J+UdAwyQS5vN8UDzKjaFhUSrRS1XU9rOKJxk3bBE3BTDMpIY1hMTxsAPca0QJqcZMMi7Wsud++oORMiNsuwE3D0XPCmcggzNluzQsZ6bTborvZNMuGpYPYPD3WEN1aGBbL6tYEDSAkeuWiMZUSMuzVm4VfBO/nwQJ4NQ9+1vwmDk2XMMlKnRcP5JFNp1CpOR4dwg8f24NMOoVzT1zl2R+bct7GsHDY0g7/8fBurBwu4HXHLLdrWIwUSD5bxgxrhqhpWMyy5iYrt+hy0v6nUo37MlU/7zXH26HZTBHxFWvWskpWLB87Vr9+Qvx4/BiWyWJd+Pt/f/IM9ja6cr98/RI1oXkYFpUScrdXqTkw51wbwzLNNSw+Pix0L+cyqUh9VExkmVi+WPFf/duqnPjpa0Z0S8FLPptGqVpTDIs56ZhVS+GiW3+Ghbw+Hts9prFitnuCB6GkIypVauqepCBSZ1i8BmalSg00rIV1a64fn6thIp2N+RkaF2wpEApcm0kJDfXlsGxRHvsnS3rpNBMWA0zo7ath0QOWbDqlMYCBotsZf4aF7le1P8WK2zg0ArsCcOO4SG/vGIRhiQkamOJWCBGOXbkIQL3zZy7jnSyi9P8ZNRkW9gC4VSStlc+632WP4HcdmgFQZzRMmJoHj+jWZ6Aemy4r19iBfN351KZDGJsu4U+++Sj+5BuPqslo18H6/hy5ZIDtM/NhMY3jKjWNejVTQs9PzOIj3/kFPvytzQDC3UR5aa2dYamp8xF0DsJAgw+vRAKglQWbAYvJsPBVMK/ocjtKN46V3YN+jfzoPssYotuBfBaLmIbl7t88j6t/9CRu+Ol23PDT7fiTbz6KFyaLaj8AYOmi+nWj+5k/A7ZKMQpIFxWyKt3IuzX7aVg4Nd8M++hWCbkpIdODBrAHefz8RWVYTB8W/pOeSzOVwY0N/faPY1FfVgVw5ti2ZqSemn1ufBaOUz+3g4Us8xjyim5p/yg4oHuSgvwBxj7QZ/rzGbXY4ddM+bBk/c8XL2vm9wq/h9Y0OmkvY6wFYfVo/RiXNpEiBIBjVgwB0DVRFCCQMFq1g/BJCSmGhQXdK4f7kE7Vt2u7V/00hhXtPqv/HGBBIrcEiAIa9npdJSQMS0zkG11Bm10hX/Hbx+HEI0Zw4UuPwJZ9hwHYjeOCtm9qWIJSQq0yLGZ3aAINlMsW+edj614hNab/0DUsJsZnykrMu67RTDGfTddXYVV30n1m/1TdMAt1q+sVQxm1P0sH82qfZxr2+325jEoJEWNTqtRQMcTBHFTBdGCqpIn48j4poYGCa17Ge6OYk5ZbIdIkw2IM6Pxc9uUymC5VccBkWEp2hiWXSWn3Wf0cpNUqKmdjWDwVL+551RiWgq5hoaafx68awnNjM5iYrWDL3vr9T+ftJauH8fnfORkvbmiQ+Peb3zs+XVYBy9rF/eq9ykQt618l1EqFEGD3YYla1lyzUPVhMH1Y+E86r0cs7vd8ri/ndrEOY1gG8llc9/unacwJ4bT1i/G3F56EZ8fqC6SXrluMRcyITdOwGCmywUIWh6bL6p6kIH+Q2fBTkEkVULPlmnbNlENuQFprIO+mO/izyif5N5+yBsVKFb/14pWez//xbx2DY1cO4cKXrQ04S/749AUn4mfbDuL0o5Z69sl08x4JqRKi481lUlgymMc/XXwahvvtU/Uoq+DiXaFrVobFTdEqhiVChRAgKaE5i/pKptw0w7JqpA+XnL4BgFumVrFUCQUNZhTF00PNU0L0sTDH3KgY7benhKIo3osghsXuw0Loy9UHqbHpkmKNqATcpfXdAWwH78g8XcaKoT5tf4YKWZUemZgpoy+XUauW4f4cDk6VUKzUtD4dZqqDNCvUbdXuw8I0LPmMZxWbTXsrKehrmk0pmmXrWa2Utf7/g5MGw2KUOeuiWz0ocBy2Oo2rYTEYFj5AUsn5G1+yEg88cxA/234Qv2kE7HTeUqkU3v7yddqx0nU03WIpWF8+VKj7sHhcqP2bMboeLE0GLIw1UyLTIOM4y/MNNO/DArjn7DfP1wOWDRYtWV8ujfGZxv8jiEnPskzkQP26/N6mIz2v26qgFOOU0VM/dE8qDQtb2dOzW2hUQHkDlvCgi6c7/KqK+vMZvKsx9ppYOeyOy83gRSsW4UUrFun7xBgNIPy+MzUsdK0p7W0Djb/VmoPJYgVDDR2QxrCk9P2ZKjKGJWLAkpEqobkJuomaDVg4bCuUSgSBmSna4jRk2ihrbjlgUS6XbsBSrTmKgQhTvHP9iZ/o9ojR+upwbKbs0cbYGtht3+/tyEyr5pGBvFb6Tasa8oGg10sVvazZXMFzIfRUsaom+bwPzc7t4fk5MCctWm03L7rV0xwmwwIgAsPiemnoDIuj3YtWhsVTJeRqrnhaQmNYilUVZK5fOqhEisQOBFV/KDbDCJSUy3LjPjGflyz3YSmbDEvzLreAew9UqsE+LDnLOeMDfrM+LABnWOpB3wZLtR6f4JvRZoQhUMPS+D4S17oMS/33AmNyKFVSN8Xzmv3xpol+cFNMrKN0zEaG7QYduyu6DXa6pbJlnhIKQ18uo84LX1TyakRiXegczZSrqmorckpIqoTmJmjwaMXbhMAdMwkVRrH7wbzh+cBrpoRaD1i8TreHQ5p4Abrmwc84jrCmEbCMT5dZ9VF9AFZpFh6waAyL7t1Cqxc6R4caAyUFJ8PM60Era/ZoM9y/8QZtfqLbepWQOWmmPOaANHc178NS/0nUO79PCkrDElwlxI9F88yp1rR7kf/Nl2GpBjAsaoVZUQLxDcsG1ORKAtygKgU16RssiVmlljdW07lMypOiI4SVl4aBmIVSiA+LbUKvNcGwmGXN/Oee8fo5tInf+f3ZTPVLGGw+LGaKTDEsqkrIZdNoAqXrkc+4zxC/ZkXWNNEPi1ijRVtFXy/AGRZe/RjVhyXq/lNaiC8qbX5PnE3Z39CPRRXdpkR0Ozfhmlp1iGGJUEVi5kA10a1RJdSsuNPc9vhMWQ221HBxUSHrO9lwzYOp/zD1G3aGhTQs3hUXb3Jodq2mzqumep6Ck2FfhkWf1Eomw2LocABDw5L3ngurhiWmaZgJ0xhQZ1gaKaGIVUK5bH31xfeRmxjybYdWCZkalnxGrTCnS1XsmXAnVnNyDQpYbOaKAKsKW+bDsAT0EqKJw6+8NAx24zjvMdhM+Wz+GGEIEt0SbPYCnJHoRMCSsQSTprfOgI/oFvB2Zy7kWJ8k9my6KaEghsXVS0XxbekGuIaFVz/6LfKUD4uREgqDKjtni0qbuL+QTbsu6Y2AZdDiSWPfN327vYIELDFBVGeQ62JU2MoeK1HKmo0bnqvO6WPt0rDQw1Vz3N4/YT0xAHsjL1L5m0EUMSxj0yXsOkgalgbDYpl0uIZl3EgJ0cPrdrWmgIUYFtL/VDX3Wy/D4v4+Xap4SrMBb5WQzfHXXYXWrO6TceEVVbOApfH9VGlFp9nrw2JnvEgkDXgFi1mLHoM+Q9sosHMzWMhqjqKOU++Yu2Qw75lcg8y6eGdkDreP1YB2LGp/M26VjF+VULMpIVdM6wT6sNhM+ShgTaWi+yPxHmbKFdgTsHgZlkKHU0JhvYQAd1VP92RBC/L1657P6H2SCFFEt9xVOYozbjfAq4RoHOrLpX2Dx2YZlhGLztBWbZpKpdQz+cJEPIZFdYkXDcvcgmJY2pASsvmwNJMS4owL3VhRqo2ioJDNuNRtIyiIogGgYyvXaqGi29WNssmaUw8U8tk0VjVcbnlnWqAe1PAHc2ymhNlyVa3C6Fwoh97GPitzKiZYDtSwsEluqhQuuh2wsE2ahqXmNOXBYcK05s9YyqwPNxgVKtH0MiyuhgXQ0y5up2Z9/0KdbplRG1A/H325tCZsXr9sAKlUyqO3sLETBL9ASYmzScNibIN3NfakhJjeqRlwHxazvYD2PkvKV6UEY1x/vm3VvoBN3suHCpqHCUHTsDTh4BoGe5WQniKjsYPuSS3IN/ZZa+xo1bAEVQm5DEuQrqib4AyLyQDbQGMFaVjMNKcfbF4saiFhbINYz+cPNxiWiBqWpFQJScASE+0U3SrHTEvjuaCUk8mw8IcgbazAW00J8e+jhy7MAAlwAy4eFLjGcfp7ly7KawPZ+iUD6jjcSae+HZ4Oon2i3G0mncJQYxA0Vx2KYel3G6wVNadbfVLTNCzaqs2fYfE2x9TdQJvx4DBBwZ7rw+JP+5PfhEfDUvFnWNzqI33/bHoF+gxtgx//YD6jregAN7hYVMhqXhiBGpas9xmZmHXLZP00LNzIzrR6N/VOcaH5sBgNHLV9sAzyyuk4xvUPKmsG7BVCgFs1ls+km77fghBUJWQyLGqfghgW1nZAC1jK/l43BF6RZuvU3AsohqVUVemaKKw0HW9sDUtISghwdTUvNAKWqGXNUiU0R1FoY8BCZc2aaVeElMFwf05buWo+LErD0lrqgWNkwK31B9yUkJ8BEv9eHrDQuTP3aSCf1YIuTm+bolueDqJ94o3siGb3alj0lFCY6FbTsPjkxXXRbbiGhdOp7SprtlUJEagPidlLyBQQ89SkX5VauIZF7yVEK14+KXHtCp9kg7QGttJ/anK5bFFelXEGaVj4MQPhXXPDoHocsQo4ey8hr/6m5jORBEF3uvWmhGzpIIBV5HQgHQTo9wT1elIpsoyuYSH0a1YA+mTJO1HbfFj6IzAs5aqjmm32OmChY6/WHCUwj8JKxxbdWtzI/VLPxLAoDUtMhqXH8YoELHFBVGerqRZAp+tUN98I+ddMOqX13Ri2GMe1S8MCcIZFTwn5GSAB7uprpuQOPH5Ot4P5rLby2LiMTWbGiotKmmnwqqeIKIByt+HVsBgpoXJNUc2AV3Tr0bAYOhwA6MvzgMVSJZTWHX/5ZN9yt+aylwkxdQoUsJi9fJQexzDy4yZ/5v0d14eFVrw8VcG1K3ySDUwJWdIq25R+xd2GObjzKiHAdEomhqXJlBAFIpVaYMBiLWtuQsMUFrD4MSz0jARN9K2A33t0W3idbk2GRU8bcvBO1DaGJTglxHxdZqjqqNcBi3t8z43VDXGC7jmP021k0a2+oAQCAhZVtdVwFI9qHJeyP//dhgQsMeGWNbePYQG4T0e0AY2i6uG+rPbeVEAVSbMwe/NEodTN1UI65b5m0tMDhYy28rBNZkWDYTnpiBG1L1S1xAMormFxHMfrw1KtBTY/5CmhyaKdZvb2EgpgWKpGSqjV5oeWgNQUr1LAMmUaxxlskcawMMbE9r1BVUIF43wAemdcrl3RGJYIGhbOkOyw9LEyt5HNpJHNuF4fWsDSotMtD0SCujXbuhm7zS+jf19QWTNg92AB3OCgExVCgH3BZabIzM7IptkiRyHjtrcoxixrpr5FAOsVFWDl3w1k0il1DVTAEsSwZPQxM7aGhTMsPtWI5jmP7sPS2K4ELHML7iDfPtEt4A5q9DOMDjT9Rtxt1n+WfbQIzcB8IChwCRKQZY2Hjx+POVkP5rPaysM2EVHAQuWspx45qvZpXHVBdbdBwcuhqTJK1ZrHN6Ze1uzVDhF4wML7dPhrWLwBSzbDGZaaYZfdZMBCGhbWIM3dHyNgWeTDsBjBl1Yl5CNYdPUKOhPl58NCDMuARcMC6JNsoIaF6UUI25XgdoC9z2RYdK0H3T82gXZc8HLlIB8Wu+g2PsMSGrCEpIQ6USEE6PceTWShDIslqCXUNSzNGcfVv8tlXYHep4QAl2F8bqyeEgpmpfV7IrqGhRaUXMNiH/9NTZFUCc1ztFV0a5h28Z9hA9qI4TdCMH062iG2UyZsjYFACcgi5GNnS3pOm+8jwcuwBKSEGpPVqetGAdSDJxvjs5g59PLARBnHGVVC5srBlkIwj0OvEsr4MCzuKltvSNZ+hsWk/hXDEmAcB+gTq9st3C66DewllNEDuPrPjPrJ+04FsSMcboNQL8Oyngc9lpQQ37ZbZeYVaMcFF8sHMSxBZc2xAhabDwt77UiflFBBBSwdYlgsCy63Ssguui1oVUJe0a17ver3LG/tEVbpRJOv242799Mb7VOUlFAmbd7D0fZ/xMKw0HNqjjNmABnVh4W2IwHLHAM9iO3QsKTTKUUNm6LbXEjKiSZnU3WeNia0tjAshh4kSkrI4ynABnTz0AbzWfXQ5TNp5ctS/93tBzM+U1a515PX1lNCk8WKcm3UUkJMd1NkaSkaQGcrVU3YZ/p8cA3LGFu56N2adQGh14dF7yVUa9E0jn9WaVh8GB+AaVj8jOMa+2bzzDGr1MI1LGmjVUGDYWmc7/VLBzXfkfVMpxTkw6KCA3Y9tu23MCwG/U+MkFl1otJBPt1vo4ALgU2Rqb7vXsGwan4ZR3TL7jM6V3Sulw7mNT0bh0oJdaCkGdDThtWqH8PinxLiq/tsI31qLlD4oiIs8KLJl65xrzUsgPscPBshJdQ8w0ILSm9KyNymmaKL2kvI1bBEenvHIM0PY0IxLG3QsAD1Qa1UqaleKX718yZGB3xSQil9gG+nhoVEXeMhPTEAJrplnUfVPhpC0Uw6pR66dUv6dV0G9RIq11h1SAGrR/qRStVV6+TJwVcvtM9TpSrzgHCFsWSCRzAnYh7AUICWSnn3nTBgEd2aVUJ+pYZxEBSQmgP6CgpYynVrcPps2Uj7KF+RmqMYEzPlyY/jwWcO4OkXJnHxpvWuhsUQudJASBPWRkNnMdyXw9LBPA5MlSIxLN95eDce2XkIjuPaigeJbrMGw0Lna8yid4oLVWpdrcUua26mNYOdYamfVz/9CuAGKp2qEuKHUDFSQsqHJaCseRGbPFVTx4CAJUicDdgYlt5qWAC9KzUQ7K5s3hP5iBoc7nT719//FVYM9eH41UONbernzMOwRE0JEcMi3ZrnFpYM2lMxzSKbTqEEd4WiqoRCBrTVI3UWYk3DdI3gNj+sP+jtCVjqx3ygMVGE9cQAmIbF0siLT9j0wKwZrR/HsSuHtO24/WCq2HWoHpgc2QhqhvtyGJ9x+w/x/RnqyyGTTqFac/Dsofrqpi/npm08AUpASogCtJzh/jrcl0Muk0I2ncZAzubDolcJtepyC0Sz5icsX1Q/p45TZ5RoQDd9WLgbr29KiHlufOQ/foFdB2ewaeNSTSQ+3F8/5wMsMCS/lWNW6p1s6bUDzxwMHMTp3rvnNy/gnt+8oF5fNdynsYt+KSFKk002AlRyXA3SX4XBNY5zglNCFpfeZppf5jIpLCpkMVOuYqiR0lwyWD/2Yy3nlbC0kYIjA8F2I5VKIZdJocwE5aZpm4dhsZS+8/d7GBZ2fsPSqKQX4c9rr2GWdQf1r2qWYVkymEc+W1/43vDT7QCA33/VkQBcTaPaH4NhMffPD+mE+LBIwBIT73jFOuSzaZx34uq2bI9u0nJDlEnzZtik9nubjsRAPoM3nazvBwXU7oTW+kO7bnGdet9xcBq1muMyLBGqhFRfDPbk8EmfHqBzTliFT59/As44boW2HT6AkXZmaWMSHB2oBywkxDWbQB4x2o+dB6fxm0ZH2z5WNmnCFJPaGBbzs4OFLK69+DQUcmmtOzDfB14y3I6Ahe4XW/NDvnrNZ9IY6ssqFmqq6AYsZCRHg5W6ByP4sJSrNeybcANXXiU00p/DP138ssb31t//3tduxIqhAi586VrPsXzmgpPws20HcfpRS32P98/POQ5HLx/0pOx+6/iV2u82HxYAOGJxP556flIFuzsO1u+VI5fYdR9RwJuWBvYSsjEsTaQFU6kU/uVdp2GyWFHpnwtfthY1Bzj3xFW+nzvnhFX49AUn4oxjl0f+rrjIpOsBCwViReN5D2JYuH5CtRywiKQBPdDxg9lMsdfdmgEvgxHFh4UQNWDpy2XwL+86DT/ffhB3PPkCfr1nAlv2Hm5sM4RhiWoc19iMMCxzDMN9OVxy+oa2bY93NebivLDmiiP9OVz6au9+ZNjkA7RHw7KhoTcYmy5j96EZt4lXhHysrUpI6yDaeID6chm8y3JeOUXs6cjcn8MOuIObqedZv3QAOw9O49d7DqvvKPjkwc3meryMlnLiNor57Je4E2eYD0szJa0mPE7GbEDSyooLGaQbbMdUqdqoFNKdb2mw0u9Bu8smHcdUscro+pqnDP+cE/QJdOmiAt79mo3WY3nRikV40Qp/hgAA1i0ZwIfOPjbwPfX9tQ/2dXHvCyqo3bFf7/LcDJQPS5hxHEu1EapNpIQA4NUvWqb9vqiQtT7/HH25DN71qvWxvicu6sdYi86w+GhYKG3lp2GJIhym+zlRGhaD0YjCShPiMERnHLcCZxy3Atl0Gr/eM4GtL9Tvd4+GJd8awyKi2wWOLFu58pVYs4GG2a25Wb8PjoF8VukhfrF7rPGat9kfh/JhUSZITMPCGZaQB4b3gzFTUWYvGJPmp0qULfsm6tuypG0IQRqWqFbZgVVCVUetTlrp9G2mhPyM4waVD0qjxwrzYiHnW3oPvwdVoOujYTkwVVSvzZarvuWT3Ya5mqYAhoS5FKhst3i4xP4u5a0TUiXEUm0EV3Tb9NcnCqY/j1klZJbN9vlUCblNHV2RPRAvYKGxxH1ee3+SPQxLjCqhqD4sHLS4pOIEj0knY1Qy6VSoLojgpoRi71JbIQFLj5Fjq1veL6XZKiTT6bZdEwkN8L/YNQYgvA+LV3RrrxIKoyRVmWOZMSxU0m12rR7wMiwA8NS+SQD1wdJvEPM43Va8T2acgCWbTiGVsjvdthJEkhhblTX7VC0NsHJiQPdioaohmjB4NYt739hFrCR4Beq6GNeHpbdDiUc/1PidSp8pUKGf7WBYao495anex7QuhHZUiiUJZtrLDODyWf2Z82NYqJmjl2Ehl9vw+8scSxKhYTGExUHH0ayGhcNs0+B1utXHiKiVckkR3fb+ii5w8BQOL39stgopHSDKbAU0wBPDEtbp1tSw+BnHhTEsvMrD7BJtBijm6oUqU2jV15etP6C21XCQ0625L777akl7WauEWnjqXOO44CohYlZoUiBWpVZzMF2uan/Tgiqf1hB0HPsn3RLv2XJN07D0Eh7juDQxLG7AMlWsKP2NWbUU77vcYyWPG1uq0daNvZmy5iSDOzk7jj1FxgMTrf9WgOiWNFrNMCyEJAQs/BjDSuk9GpYmNDgbQwIWHtRFrRAC5nG35g0bNiCVSnn+XXbZZdb333jjjZ739vX1Wd87H8F9Okg/kEq13s233QELlU/+8tlxAFEYFl3DYpvMgfCHhso3i5Wa2yW638uwpFJQFRQEc7VBqxsbDWoaopUsAUsYxcwnLTp+mw9LK20dlA+Ltfmhu10qGXW72DYmgEpVuf4qhoUJv92UkF3EemBSTwlFbSXRaWSYpxHg7v/axfWKstlyDQ/tOASgrnUKKskPg20itDEsXJxLaMY4LsnQPXzcZ6iQsVvwFwwrAPW6YYhXNBmWCF4y5lgStsDoBngQFVZZ2g6GZXQgp8wxgRCGJaJpHIDEdGtuu+j25z//OapVN1/++OOP47d/+7fx9re/3fczw8PD2LJli/q9WUOnuQjlhlmtuRUaLU1o9Z+dSgnRABL28Hk0LGyy1xiWkIeGi24prWHzoBnpz3mCvHVL+pFOuY3ZVPfabBqHje+pBFQJEUJTQoEMiytQbSV7YvbG0RgWWy+fPGlYKo2f9euRSrnvtwXNfgzLgSnOsFQ1H5ZeI5dJq4mO9j+XSWPt4n7sODCNu7fUy6L9mgVGhe2ZsvcS0vUdQHPW/EkGpSQrtZoW5BcsTQ5TKX2xwAMM1dQxZxfdRvGSMceSRGhYCpxhicZKE5rRsKRSKWxYNojHdtcXlh5r/nyTDEtjM858C1iWL9dL6D772c/i6KOPxhve8Abfz6RSKaxa5V+eN59BK1c9ZdCCxsGoEmqHNT/gzfmHrhYylBLyClZjMSzMWl2ZfvV7U0I2xqeQzWDNaD92Mx8WwLTXT2vVLgSzasg8hqB9BdwVPl+BqsmqFQ1L2gwk+LF4V7Umw0JB30Auo+4NrrUo+wTNdBzc/rtYqakAJwkTcF4LWNz9X790EDsOTOOu3zwPINhsLQpsx2pj7XhTScJ8Swlxfx7uXaS3aXAXCnwx2pdLq7J7er/ru0Q+LDGqhPIJ1LDEYlhM4Xhz+79hqRuw2BrN2vYtDPM2JcRRKpXwta99DX/wB38QyJpMTk5i/fr1WLduHc4//3z86le/CtxusVjExMSE9m+uIstWKK4tevODmerW3G6GxRjkgwyQAG+3Zs2an+1SVNFtqVJloltvwOKnqeHVIH1G6SQALCrUtxHU/FDtS8gAwictl2HxBqStBJHmROdXJWRqWKZKOsPC/TF4g8ZKSJUQh8awJCBgyWkBo7s/xKg88wIJblsLWMgwjcMuunVTbYSaj2X6XAVnkbg3EL/H6Rk3g45UKqWCDI+GpWyKbuemhmURZ1gistKE5gMWd3Fp3md8fxbF6KXlpoSa2qW2oaNX9KabbsLY2Bje/e53+77nuOOOw/XXX4+bb74ZX/va11Cr1fDqV78au3fv9v3M1VdfjZGREfVv3bp1Hdj77sBNCTltGfyDnFBbwaJCVrmWAsEW0wCrErI0P6xrler/jyq6HZ8pqyCMUkE8aPLbH84MqT4sLHVCWg8zJcRXi+a++IEHLErDYvFhaen6ps3f7aLbQbNKqKgzLFxXwPv1uH2G7AwLh65h6f3kwIMIvlo1A5RWU0L170qz/6esQShPtREoDm4X89lr8Pvbr8SbgmazOSfgMoAFI2Axy5r7m6gSSoQPCxfdhuimPD4sTWpw+P1ujv/1woPGvsUJWBZCldBXvvIVnHfeeVizZo3ve04//XRccsklOPXUU/GGN7wB3/3ud7F8+XL88z//s+9nrrzySoyPj6t/u3bt6sTudwU8JeQneIwDU+PQTqqeD/SRNSyWXkKAG1iFMSw0kJF2IptOqck2LCVU32f34e3P66WTALCoIVCLwrCE5cTzVobFG5C2VNbsk6oB9ICJBko6v4phKekVQnybvLTeDFBsAUmSqoQAbxBB2LhMD1BaZVgA/Xj9JsYs8+AhKNHtPEkJcYbFz/WXghIbS2IyLMqHpaI75zbFsETsxdNJcK8Z09jSRDs0LIDrxWLbJplJAl5TvyAkJSXUMafbHTt24Mc//jG++93vxvpcLpfDS1/6Ujz99NO+7ykUCigUCr5/n0vg/UbaMfjTZFi2VJG0ivVLB1mlRchqIYTeTDfUsFGN40jrNTqQV2kvHqT4rV54Kqsv6w1YaMBsu4bFxrC0sZeQ+p0NaqlUSmlyBlWVUMOOnxgWw4MF0KtZKn5VQpbBc7bMfVh6PznwwCGb8WdYWilpJvB7wY9544JrwnwT3fJ0op/rLwXHNp0PaSp8mx9WoqeEzBRHPhN9Qu4UdIal81VCgL5Is91nA4UspkpVmKZ+QaDNzFun2xtuuAErVqzAm970plifq1ar+OUvf4nVq9vTqyfp4F4NanXbgoaF7vFKGwSeJpphWAie3jTEsEQsa7Z9L1+x+K1e+D4rDQvblyHFsESoEmrJh6XWFv2COYaZ26KB3a0Sqv8ezLC4q2Q6D+bqzqphqcwNhmXt4n414A71ZUPTmVHAn1E/x+dA0W0Czlc7wBlEv4CFVvK2oIPuQ3rOfX1YovQS8hjH9f4c84VBWJVQu0S3SwbzGGqcC9v4bwryo4C2My8DllqthhtuuAGXXnopsln9Jrrkkktw5ZVXqt+vuuoq/M///A+eeeYZPPLII/j93/997NixA+973/s6sWuJAx/U3MG/+ctiphsybXxo17OVadzVgs22HggvazY/x1mVbCatHky//Vm3ZEDlbFVZs+ZXYmdYKIfOhayholvNh6VRJcRLhttQuWWmZszfiUVSDIvR8HDKyrCwtKRP+wB/DUuCqoTYvcKrnKhaDKivPtthm8Cf0XCGxZYSankXEgFblZD5nAwo0a33PKkKImMx4S1rjlIlZKaEkqZhiVZZSWg2YEmlUljfSAvZFr+m5UEUJCUl1JEr+uMf/xg7d+7EH/zBH3j+tnPnTuzZs0f9fujQIbz//e/Hi1/8Yvyv//W/MDExgfvuuw8veclLOrFriQMf1NrhnWJOhu1c+XIXxXBPAXO1oO8HzRlhDItJI5sP/YiP6y2hL5fBmpH+xv+9DIvSsPg43fL+RKEaFivD4gYDtTboF8IZlvob1KDUCEyUDwuVNdsYlqqDcsXO8oVWCSVgBtZEt8b+UBqo1ZJm23f5BSw247j5lhLSNCxV0rDogUMgw1IghqWREiIfFiW6jVMllETRbQsalhY0OJQWst1ng4XmGZZeVwl1RMPyxje+0ddg5q677tJ+/+IXv4gvfvGLndiNOQE1qNVqndE4tDMltGwAuUzdjbjV1cJIfw6HZytYuig48DEnA1M7s2ak7rOyarjfdxvHrFyEZ8dmsGSw4NkmlTVXa3VrcVp9Uy+hkf4c9ozPWo/BhG3C1DUs9b+1cn09DJqxraWLCth+YFpVdFFASNb8pGXh+f4cS1tR4Obnw8KRvCqhtPX/AHDMiiH85Kn9ODakO3Qz3+U3MXIPoWrNQSadYh2750fAwhlEvyqh5Y3GqUsGvc/68kX63yjYqbcqqTFr/vD7i/oWKS+hBAQsuUwaiwdyGJspY+VwsIN7uzQsAHDsyiEAezDc5x2n6Xrwqs8w0Dgz74zjBPHAKwkqbXjQgozFWsVQXw7/8q6XA6nwFY93taDvxz/+7kvx7NgM1i4OLjH1pISMQOkzF56Ih3ccwqaNS3y38ck3n4CzX7wfbzh2uWebi9gqo1JzVNBRViXU7veFXRfqU1Sq1Oy9hNpgy24Oaubvf3PhifjFrjG87MhRAC4DNd7ow+QyLO5xZzTjOD+GJflVQjbRM+GPzjwaRy7px4UvW9uW7+IpMz8X1uWLCmoC3TNev9fnM8NCuhPzmf1fJ63GVLGCM49f4fn8H51xNI5aPogLX3oEAGi28hOzFVd0G8GaH6izLHSvJ0HDAgDX/v5pGJsuqUDBD+3yYQGAS1+9ASP9ObzpZK8W9C/OfTFOP3oZznqx93r4geLrXqeEJGDpMbKW1W07V+Dtpuptg44NHg2L8fCdtn4xTlu/ONJ2yA0T8JYvH7tyqLGa8MfGZYNaZYjuw+I+AtWaA4rDlOcLY3Si9CYpNAIWs0qoUq2h2ga9hzcg1X8/ftUwjl81rH6n80V9mIhh4eXk7iq55hs0hzMsvZ8caJ9TKe/+LFtUwLtfs7GN38VSQn5lzZk01i0ewDP7p7DjwDTWLh6Yd6Jbfn+XGodkpnH7chm86/QN1s+vGO7DJexvpEs7XKxgbLoUq/khUE8/uQFL7xkWAHjVUUsjva9dolugzgxf+uoN1r8duXQA71q6Ptb2bI08e4FkXNEFDNfp1r9TbhyY42CvqOd2rRZSqZQ2AI5aaOW40PqZsImbVwbZGZbwc0nbtndrrr+nlWsSV6NE5d6HixWUqzUrw8LNC8N6CXHMVqptuWfbBdU/KJ3ueD8yzYclIJAlzcz2A3WXXdIALCQflrggVnBspsx8WKJtk1cKJaH5YRyYz1ir57GdmNdVQoLoyLCUULkdGpYOim7joJ35WL6CDesSHWl7bCDgHZ756oHy4CMxUkKAu6+qSohVUdTakD7x+rAE75NGsc+UVbUQFztTekMzLzQ1LCwgocmD92BKkoalGwJgLSUUMLGQ0/KOA9MA5p/oVqsSqto1LHFBi4Tx6bIynozDsBCSwrBERTvHzHZjXlcJCaIjl+ErcLstehyYK/BeUc9hVUJxkGcpnDCxb6TtsfPLKwtosuYmbzwlFClgCWBYKm1IB8QNSLOZtArKxmbKqlqIl5PztKS/hsX9fVVDPJi0XkJusNj5feH3s58PC+BWa2zbTwzL/BLdahqWsr2sOS7omTs0XWJVQhEZFvY8J4H1iwPTgiJJ+++Kbnu7HxKw9BhuSWmNrW7btwJPCsPSyqpLSwmFlFPH3V5fLqNV8gB6aogHSFEGYpq8lIaFVVG0w5Y9TMNiA5Vmj02XfBgWlhKKoGFZNVIPWIrl9uiu2gXa526sTKM43QKcYWkELOp8dXDnugjudNtuhmVsuuz6sEQU3fJS3SSUNceBh2FJUEqIdq0qKaGFDRr4dOv29jEsvZpI2ql41wKWdjAsWsCS1tojAK7gFtBTUFFWPL4MS7XmpgNacjKOH5DyCcCmYcnxflYRegkRw1Kq1triHdQuUO+YrqSEuHFcwL1NYu8dB6ZRY2nBJAR47YBeJWT3YYmLUaZhiSu61RmWuTW9eXsJJWf/iRGUlNACB92k5DsAtFd026uBsV2ujYAeYIy0PWDJaHl4AMo8DdDNnqKseGjbNh+WdrRLaIZhoWMYmy5bq4R0a/4Gw5L1Z1hWjrh+ErTgSsIE3F2GJZro9ojRfmTTKRQrNew7PDvvUkKKQaz6+7DEBbGo49Ml1kso2jY1B+cEMRRR0M4qoXZjQXRrFoQjxyjVdtDrHlFmYhiWVjQsLmsxFKMletj2gLq/g1upVR8ceWpuUV+8FRutioiR4MFAO1bX3pRf+D5RpZCmYeFVQsyRlRgT0zjOpmGJux+dRr6LAUtU0W02k8baxXVTw237p+Y5w2L3YYkLYlgOTpdVEBRddDt3NSz8lkinknWPKIZFUkILG8q0q9Ye47hOWvPHQZgPSxzQhDDan2tLuSqnrPtyaSY61TUsuUxaYyIiaVhyuvCTszftMI5rJuU3qhiWkkoJaT4sLCVE58BkyPj1XDKY95Y9J2ByyHVTdBuxrBlwu0XvODA9/xiWCL2E4oIYwX0Ts+q1/qgpIc3BeW5Nb6lUSt27SWJXAPd+7THBIgFLr8Ep1bYwLInRsBj0ZgurLpoQ2pEO4tsDgL68mxKigLHEUnODMXPiLsPirRKqtiMl1ISomlas+yZm1YATyrAEVAmNDuQ9zqOJ0LCosuZuMCzRA5aNzIulHe0ZkgSrD0vE9I0fiBHkAUvcsuZsOjUnzfnofCZJvwJISkjQAA305VptfmlYOuDD0g4PFr49oJ4ScnVENe1nPpvWyn/jiG5Np1vA7UDbUllzE8wGTQDPjbkTABcnajqbCD4so/05T/fcJEzAJLrtRiogapUQwCqF9k+7DTATcL7aAWuVUKtlzY0Ae6/q4ZWKfL6IYUkaQxEVimFJmP6GTqekhBY4lGlXmxgWT3O8xDjdtq5hGR1ovaQZcFNM6VR9v3Ks9BhwGx/mM2kM5OKJ+DxVQuy4aUBvZSxtimFpBHrPjc0AqNPr/PrQPch7CZkDPmfMRgdyHhFkEpxbu6lhidL8kEBeLHWGZX6lhGw+LK06tNL9WozZRwhwGZa5pl8h0PlM2v5LlZAAALTJsqJKSpu/LElJCbVXw1IfhNrFsNCA2pfLIJVKMYbFSAll08hm0ur9TfmwWBiWbl9fWrE+2whYzLbytn5W5oDJj2O0P69R9OlUMnrjdFPDwr/DZJtMcLfb+evD0j6nWzP1G3Z+OYg5nGu2/IRsF4PuOJCUkAAAtHSEEjy20wm1R5F6O31YOqVhoUmXe+EA8LAMgzFoZreXkM60AFBVFK2srr0+LFGqhPQVK08H1bdR3+be8VlMztZFuaYOhL43naq3M+AMSxIqhIDuljVrVUIh37d28QAy6RRmylXc89QLAJLBSLUDGSbYLrXLh8Uwh4xa0gy4wXjSJvyoSKqGRUS3AgCukl3TD7RSJWQMhL2ins1jaCUnu6TR8HDNSH9L+0RY3NgebVcFjTVdw0KD3vJF9bbwUUzryFWWKh3qjfjqf5tqeKC0lBJqyodFnwC44BZwU20TsxWUqjWkUnqPpfo26sezargP6XRKo+mTosdY3Lg+7QpsgxDVh4X+TsLbZ16oO94Ot4kt7DVIYDtbqrbNhyWfTWs9gaIKbgFg+VD9WR2Zo+c3sVVCxKT1WMPSuqmFoCW4k6VrHNcKw2IGKL1a/XpFt80f0/tfdxTWLu7HBS89otXdAgAcvXwRvvjOU3DUskUA3OCqWtUZlnxjn//320/Bb/YdxrErh0K3fcnp67F4MIc3n7wGQP1BXzPSj2fHZlQ/mZacjFuoEiIMGl42x65chM/9zsnKPv6ENSNY1gjSCGtG+/Gli16KI0brHix8EklChRAA/NaLV+AzF5yI1x+zvOPfpTndRpigv/iOU/Hfv9oLBw6G+nJ4xyvWdXL3uoYjRuuLiJ0Hp9lz0/qYMzqQx1SpnsKMw7Acv2oYf//2UyI9q0mE0rBkk/FMEYb6svijM47ueSAlAUuP4faaqfl6YMSBeT8lxTiulUFs+VABl5y+ocU90nHhS9eq/3MNBwCUKrofzklrR3DS2pFI2108mPfs64ZlA3h2bAbPvDAJoDWGxWuZH4Vh0QMWk2FJpVJ4x8vDJ9C3nLJG/Z8HLEnwYAHqqYjff9X6rnwXn1CiiEzj3ENzCa6geBrLFtWZulbLmoH6PUuaqziiWwB422lrw9+UUCSVYRnuy+HPzz2+17shKaFeg1Zq5SovKW1jldA8sObvNIKM49oBGtQnGvqQdlrzRwluc5m05hA8mG99naJrWJIRsHQTuZgMy3zF+mV1QfH+ySIOTZcAtIthcYPsOCmhuY5MQgOWpEDOSo+R1aqEWtewJLVKKMkPIO1bxUgJtcsLgQIWQrdTQoCu6xgotD4BaAzLAgxYNOO4BN/bncZwXw5LB8norQigPQGcHrAsnPNLC9iFfE8FQc5Kj6FW99UaK2tu3wo8MU63CUkb2JDxYVjybdpnKmt1v6/5bXmvb7SN8Qmg/QzLwhtG+KJiITMsgPf+bsf54ELxOGXNcx1J9WFJChb2k5YAKOM4zrC0EGSYvXaS0Esol0m1pQdQp0CDA4meS23o6cSxYZnOsLTkdNtkryheKtoWhiWBVULdBO8l1GoZ71yHySC243xoDMsCOr/E3CWZke4l5Kz0GC7D4lYJZVpJCSVEw5LRApZk32YehqXSXg3LkUsGwC9LtzUsgJ4Sag/DkrwqoW4ijjX/fIcZkLfqdAvoJpELKSXkVgktnGOOAzkrPQavUCHjslxLK3Dz9yQwLMm+zdz2CHYfllbRl8tg9XCf+r2l5pZNBqR8AjCrhJoBn0QWIsPCA8V2TNBzGZ1ICS1mbTgWkuiWxk3RsNghZ6XHUJ1ya46yhm+ncVwSGJakr0D9qoTybfRCWM9o85YCFo9lfnwNy6JCexmWhRiwCMPiwkwJtWOyHVmgolvRsARj4dwJCQVNOJWqoxiWtlrz94xhid4crtfIMntxoP0aFqDuxULoBcPCV6wDbQhYuBCyV+0fegmtl5AELNrv7fBh4Yxg/4JiWJLZSygpkLPSY7gMS02t7FuZAJJizc+ZgKSvFngDN6D9KSFAH9Rb6sZt7FLksuZ+rmFph+iWp4QW3jAiDIuLkYGcaosAtM/plrCQUkLiwxIMOSs9Rpb1EmoHw2JWoPRq9Tu3NCyN9ghUJdRm0S1gpIRaCCLNFFBkDQtnWER02zLEh0UH3d/pVGspbQJPYS6ksmalYVngQbAf5Kz0GO5k6aCsApY2Vgn1imGZSwGLD8PSLh8WQE8JtVTW3GTZuubDIsZxLYPu6XZN0HMdGxrC23ZNtJwR7FtAk7doWIKxcO6EhEIzjlNlze1LGfRMdMsm1qSX6NGEUzadbtvJsCxxGZbWGDT99+aqhMSav1XQhLLQPVgIxLC063z05TLqHltIKSHxYQmGnJUegybL2UoNzzWafeXaat3em0ucTqdA81g7mYpOgAeNAGt+2MZAqz+fwapGaXNLolv22Uw6uiHfSJsZlv4FzrAoC/WEB+PdwsaGF0s7zweZHS6kgCUjottAyFnpMRbls0in6umIQ9NlAN7uunFgTh691EPOFcU7Ly0HOsOwAMAxKxcBqPdfaRZmwBIVo/159OXSyGVSLX0/YaFrWCjFtmQwH/LOhQG6t7n4tlWsHq0H+AvpHBMTyqv6BC5a54YFLWFkIIdrf/80PLZ7DACwbvEATjxiuOntJYVhARoTajX5AUtGlTXrxnHtZob++i0n4P5nDuC1xyxrehs81RYnUMhn0/jXS16OUqWGwbb4sCzsKqH1Swfxj797Ko5cMhD+5gWAE9aM4AvvOAVHL1/Utm1e/daTsHnnGF525Gjbtpl0XHbmi3DsykU4/9Q1vd6VREIClgTgnBNW4ZwTVrVlW0lpfgi4E2rSA5acj+i23ft91PJFOKrFAb1ZhgUAXnfM8pa+m4NrFRYiwwIA5596RK93IVF468vWtnV7x68axvGrml+8zUWsGunDu07f0OvdSCzaPpN86lOfQiqV0v4df/zxgZ/5zne+g+OPPx59fX046aSTcMstt7R7txYMktJLCHDFw+10jO0EMqxSC+iMcVy7kEq52qBeBgpalVDCNUoCgWB+oCMj8gknnIA9e/aof/fee6/ve++77z5cdNFFeO9734tHH30UF1xwAS644AI8/vjjndi1eQ9Tg9nLxe/cYVhcLxyANT9MqKCSgtBepmIWepWQQCDoPjoy4mWzWaxatUr9W7bMP2f/j//4jzj33HPx0Y9+FC9+8Yvx6U9/Gi972cvw5S9/uRO7Nu/RbBVJJ/cl6QGLaRzXKQ1Lu0A6pcQwLBKwCASCLqAjM8lTTz2FNWvW4KijjsLFF1+MnTt3+r73/vvvx9lnn629ds455+D+++/3/UyxWMTExIT2T1BHKxqHdmPOVAl1ScPSLrgMS++uby6TVt8vDItAIOgG2j4ib9q0CTfeeCNuvfVWXHvttdi2bRte97rX4fDhw9b37927FytXrtReW7lyJfbu3ev7HVdffTVGRkbUv3Xr1rX1GOYy0k1WkXQCNKEllakgmMZxpGFJqseGChR6fF7JgXQhVgkJBILuo+0jzXnnnYe3v/3tOPnkk3HOOefglltuwdjYGL797W+37TuuvPJKjI+Pq3+7du1q27bnOjSGpYfpIGDuaFgyimHRU0JJ3e8kMCyAmxbqdWAsEAgWBjpe1jw6Oopjjz0WTz/9tPXvq1atwr59+7TX9u3bh1Wr/Mt8C4UCCoVCW/dzvoDPHb2u3lAaloQyFYRcl4zj2oVMAjQsgBuw9DpwEggECwMdH5EnJyexdetWrF692vr3008/Hbfffrv22m233YbTTz+907s2L5HElFBSJ36CMo6r6lVCSe3Cm4QqIQAoNCqFen2fCQSChYG2j3gf+chHcPfdd2P79u247777cOGFFyKTyeCiiy4CAFxyySW48sor1fv/9E//FLfeeiv+/u//Hk8++SQ+9alP4aGHHsLll1/e7l1bEOCrXdP1ttsgjUXSNSxkHEdOt8qHJaH+MUkRu1I/oV4zeQKBYGGg7Smh3bt346KLLsKBAwewfPlyvPa1r8UDDzyA5cvrLps7d+5Emq0MX/3qV+PrX/86/uqv/gp/+Zd/iWOOOQY33XQTTjzxxHbv2oIAD1h6PaHNlUZemfTcSglRINrrVIxoWAQCQTfR9oDlm9/8ZuDf77rrLs9rb3/72/H2t7+93buyIMFZlXTPy5rnRkqI9k+lhKrJTgkRc9XrQIHM43qdmhIIBAsDMtLMM/A5rNcT2lwR3c41hiWTFIYlKwyLQCDoHpI5IguaRrKM4+aGhoUYi0q1BsdxlB9LLqH7TcxZz31YpEpIIBB0ERKwzDOkExSwjA7kGj/zPd2PMGRZLyEKVoDkMkMuw9Lb/Vu6qH5dR/pzPd0PgUCwMNBxHxZBd8HN4no9oX3s3OPx6qOX4czjVvR0P8KgegnVaiodBCRXw5KUKqHLznwRjlmxCBe+9Iie7odAIFgYkIBlniFJPizrlw5i/dLBnu5DFNB5qlQdlCpuwJJYDUtCnG5XDvfhXadv6Ok+CASChYNkjsiCpsFJlV5XCc0VUEqoUnMUw5JO9T4g8EM6IQyLQCAQdBMSsMwzZBLEsMwVcNFtKeEVQoB7XZMaUAkEAkEnkNxRWdAUktT8cK4gy8qaSXSbVP0KkJxeQgKBQNBNJHdUFjSFVCoFilNkBR4N3DhOebAktEIIcNN+vRZVCwQCQTchI948BAlve+3TMVdAgV215opuk+rBAriaG2FYBALBQoIELPMQlDLodfPDuQJbWXOSNSwkupWmgwKBYCEhuaOyoGlQpkBW4NFAjIXjAMVKsvsIAQDFKXJ9BQLBQkJyR2VB00hKr5m5Ap46mylVASSbYUmKD4tAIBB0E8kdlQVNIy0TWixwpmKm3AhYssk9d0lxuhUIBIJuQgKWeYi0MCyxkGXVNtNzimFJ7j4KBAJBuyEj3jyEpAziwcqwJDhgSYsPi0AgWIBI7qgsaBrCsMRDOp0CnaqZUgVAskW34nQrEAgWIpI7KguaRkaqhGKD0kIzpeT7sEgvIYFAsBAhAcs8hFQJxQdVCo3PlAEAfblML3cnECP9ufrPgVyP90QgEAi6h2yvd0DQfqQkYIkNOlfb9k8CANYu7u/l7gTig284GkctG8SFL1vb610RCASCrkEClnkIt+xVCLSoIJHt0y/UA5b1Swd7uTuBWDHch3edvqHXuyEQCARdhcxo8xAUsIg1f3TQOdt9aAYAsHFZcgMWgUAgWIiQgGUegjJB0vwwOnKNk+Y49d/XLx3o4d4IBAKBwIQELPMQaWl+GBu8kWA+k8bqkeRqWAQCgWAhQgKWeQixbo+PHNP7rFvSL4JlgUAgSBgkYJmHEOO4+ODnSvQrAoFAkDxIwDIPIdb88ZFlzrZJrhASCASChQoJWOYhpFtzfHBn2w0iuBUIBILEQQKWeQhVJSQBS2Tw4E4YFoFAIEgeJGCZhxBr/vjgolvRsAgEAkHyIAHLPISkhOKDzlUuk8Lqkb4e741AIBAITEjAMg8hDEt8kMneusUDmgBXIBAIBMmAjMzzEFIlFB+k9xGHW4FAIEgmJGCZh0iJ6DY2iFXZIPoVgUAgSCTaHrBcffXVeMUrXoGhoSGsWLECF1xwAbZs2RL4mRtvvBGpVEr719cnOoJmMdKfAwAM9+V6vCdzB3TOjl051OM9EQgEAoEN2XZv8O6778Zll12GV7ziFahUKvjLv/xLvPGNb8QTTzyBwUH/1evw8LAW2KSkD07T+PNzjserjlqK33rxil7vypzBh3/7WJy8dgQXvvSIXu+KQCAQCCxoe8By6623ar/feOONWLFiBR5++GG8/vWv9/1cKpXCqlWr2r07CxJHLh3A7y9d3+vdmFM4YrQfl5y+ode7IRAIBAIfdFzDMj4+DgBYsmRJ4PsmJyexfv16rFu3Dueffz5+9atf+b63WCxiYmJC+ycQCAQCgWD+oqMBS61Ww4c+9CG85jWvwYknnuj7vuOOOw7XX389br75Znzta19DrVbDq1/9auzevdv6/quvvhojIyPq37p16zp1CAKBQCAQCBKAlOM4Tqc2/sEPfhA/+tGPcO+992Lt2rWRP1cul/HiF78YF110ET796U97/l4sFlEsFtXvExMTWLduHcbHxzE8PNyWfRcIBAKBQNBZTExMYGRkJNL83XYNC+Hyyy/HD37wA9xzzz2xghUAyOVyeOlLX4qnn37a+vdCoYBCodCO3RQIBAKBQDAH0PaUkOM4uPzyy/G9730Pd9xxBzZu3Bh7G9VqFb/85S+xevXqdu+eQCAQCASCOYi2MyyXXXYZvv71r+Pmm2/G0NAQ9u7dCwAYGRlBf38/AOCSSy7BEUccgauvvhoAcNVVV+FVr3oVXvSiF2FsbAyf//znsWPHDrzvfe9r9+4JBAKBQCCYg2h7wHLttdcCAM444wzt9RtuuAHvfve7AQA7d+5EmnXHPXToEN7//vdj7969WLx4MU477TTcd999eMlLXtLu3RMIBAKBQDAH0VHRbbcQR7QjEAgEAoEgGYgzf0svIYFAIBAIBImHBCwCgUAgEAgSDwlYBAKBQCAQJB4SsAgEAoFAIEg8JGARCAQCgUCQeHTM6baboEInaYIoEAgEAsHcAc3bUQqW50XAcvjwYQCQJogCgUAgEMxBHD58GCMjI4HvmRc+LLVaDc899xyGhoaQSqXaum1qrLhr16556/Ey349xvh8fIMc4HzDfjw+QY5wPaPfxOY6Dw4cPY82aNZqhrA3zgmFJp9OxGyzGxfDw8Ly8+Tjm+zHO9+MD5BjnA+b78QFyjPMB7Ty+MGaFIKJbgUAgEAgEiYcELAKBQCAQCBIPCVhCUCgU8MlPfhKFQqHXu9IxzPdjnO/HB8gxzgfM9+MD5BjnA3p5fPNCdCsQCAQCgWB+QxgWgUAgEAgEiYcELAKBQCAQCBIPCVgEAoFAIBAkHhKwCAQCgUAgSDwkYAnBNddcgw0bNqCvrw+bNm3Cz372s17vUlO4+uqr8YpXvAJDQ0NYsWIFLrjgAmzZskV7zxlnnIFUKqX9+8M//MMe7XF8fOpTn/Ls//HHH6/+Pjs7i8suuwxLly7FokWL8La3vQ379u3r4R7Hw4YNGzzHl0qlcNlllwGYm9fvnnvuwZvf/GasWbMGqVQKN910k/Z3x3HwiU98AqtXr0Z/fz/OPvtsPPXUU9p7Dh48iIsvvhjDw8MYHR3Fe9/7XkxOTnbxKIIRdIzlchkf+9jHcNJJJ2FwcBBr1qzBJZdcgueee07bhu3af/azn+3ykdgRdg3f/e53e/b93HPP1d4zl68hAOtzmUql8PnPf169J8nXMMr8EGX83LlzJ970pjdhYGAAK1aswEc/+lFUKpW27acELAH41re+hSuuuAKf/OQn8cgjj+CUU07BOeecg+eff77XuxYbd999Ny677DI88MADuO2221Aul/HGN74RU1NT2vve//73Y8+ePerf5z73uR7tcXM44YQTtP2/99571d8+/OEP4/vf/z6+853v4O6778Zzzz2Ht771rT3c23j4+c9/rh3bbbfdBgB4+9vfrt4z167f1NQUTjnlFFxzzTXWv3/uc5/Dl770JVx33XV48MEHMTg4iHPOOQezs7PqPRdffDF+9atf4bbbbsMPfvAD3HPPPfjABz7QrUMIRdAxTk9P45FHHsHHP/5xPPLII/jud7+LLVu24C1veYvnvVdddZV2bf/4j/+4G7sfirBrCADnnnuutu/f+MY3tL/P5WsIQDu2PXv24Prrr0cqlcLb3vY27X1JvYZR5oew8bNareJNb3oTSqUS7rvvPnz1q1/FjTfeiE984hPt21FH4ItXvvKVzmWXXaZ+r1arzpo1a5yrr766h3vVHjz//PMOAOfuu+9Wr73hDW9w/vRP/7R3O9UiPvnJTzqnnHKK9W9jY2NOLpdzvvOd76jXfv3rXzsAnPvvv79Le9he/Omf/qlz9NFHO7VazXGcuX/9ADjf+9731O+1Ws1ZtWqV8/nPf169NjY25hQKBecb3/iG4ziO88QTTzgAnJ///OfqPT/60Y+cVCrlPPvss13b96gwj9GGn/3sZw4AZ8eOHeq19evXO1/84hc7u3NtgO34Lr30Uuf888/3/cx8vIbnn3++81u/9Vvaa3PlGjqOd36IMn7ecsstTjqddvbu3avec+211zrDw8NOsVhsy34Jw+KDUqmEhx9+GGeffbZ6LZ1O4+yzz8b999/fwz1rD8bHxwEAS5Ys0V7/93//dyxbtgwnnngirrzySkxPT/di95rGU089hTVr1uCoo47CxRdfjJ07dwIAHn74YZTLZe16Hn/88TjyyCPn5PUslUr42te+hj/4gz/QGn7O9evHsW3bNuzdu1e7ZiMjI9i0aZO6Zvfffz9GR0fx8pe/XL3n7LPPRjqdxoMPPtj1fW4HxsfHkUqlMDo6qr3+2c9+FkuXLsVLX/pSfP7zn28r1d5p3HXXXVixYgWOO+44fPCDH8SBAwfU3+bbNdy3bx9++MMf4r3vfa/nb3PlGprzQ5Tx8/7778dJJ52ElStXqvecc845mJiYwK9+9au27Ne8aH7YCezfvx/ValU7+QCwcuVKPPnkkz3aq/agVqvhQx/6EF7zmtfgxBNPVK//3u/9HtavX481a9bgsccew8c+9jFs2bIF3/3ud3u4t9GxadMm3HjjjTjuuOOwZ88e/PVf/zVe97rX4fHHH8fevXuRz+c9k8DKlSuxd+/e3uxwC7jpppswNjaGd7/73eq1uX79TNB1sT2D9Le9e/dixYoV2t+z2SyWLFkyJ6/r7OwsPvaxj+Giiy7SGsv9yZ/8CV72spdhyZIluO+++3DllVdiz549+MIXvtDDvY2Gc889F29961uxceNGbN26FX/5l3+J8847D/fffz8ymcy8u4Zf/epXMTQ05Ek3z5VraJsfooyfe/futT6r9Ld2QAKWBYjLLrsMjz/+uKbvAKDljE866SSsXr0aZ511FrZu3Yqjjz6627sZG+edd576/8knn4xNmzZh/fr1+Pa3v43+/v4e7ln78ZWvfAXnnXce1qxZo16b69dvoaNcLuMd73gHHMfBtddeq/3tiiuuUP8/+eSTkc/n8f/+v/8vrr766sRbwP/u7/6u+v9JJ52Ek08+GUcffTTuuusunHXWWT3cs87g+uuvx8UXX4y+vj7t9blyDf3mhyRAUkI+WLZsGTKZjEcFvW/fPqxatapHe9U6Lr/8cvzgBz/AnXfeibVr1wa+d9OmTQCAp59+uhu71naMjo7i2GOPxdNPP41Vq1ahVCphbGxMe89cvJ47duzAj3/8Y7zvfe8LfN9cv350XYKewVWrVnlE8JVKBQcPHpxT15WClR07duC2227T2BUbNm3ahEqlgu3bt3dnB9uIo446CsuWLVP35Xy5hgDwk5/8BFu2bAl9NoFkXkO/+SHK+Llq1Srrs0p/awckYPFBPp/Haaedhttvv129VqvVcPvtt+P000/v4Z41B8dxcPnll+N73/se7rjjDmzcuDH0M5s3bwYArF69usN71xlMTk5i69atWL16NU477TTkcjntem7ZsgU7d+6cc9fzhhtuwIoVK/CmN70p8H1z/fpt3LgRq1at0q7ZxMQEHnzwQXXNTj/9dIyNjeHhhx9W77njjjtQq9VUwJZ0ULDy1FNP4cc//jGWLl0a+pnNmzcjnU57UilzAbt378aBAwfUfTkfriHhK1/5Ck477TSccsopoe9N0jUMmx+ijJ+nn346fvnLX2rBJwXfL3nJS9q2owIffPOb33QKhYJz4403Ok888YTzgQ98wBkdHdVU0HMFH/zgB52RkRHnrrvucvbs2aP+TU9PO47jOE8//bRz1VVXOQ899JCzbds25+abb3aOOuoo5/Wvf32P9zw6/uzP/sy56667nG3btjk//elPnbPPPttZtmyZ8/zzzzuO4zh/+Id/6Bx55JHOHXfc4Tz00EPO6aef7px++uk93ut4qFarzpFHHul87GMf016fq9fv8OHDzqOPPuo8+uijDgDnC1/4gvPoo4+qCpnPfvazzujoqHPzzTc7jz32mHP++ec7GzdudGZmZtQ2zj33XOelL32p8+CDDzr33nuvc8wxxzgXXXRRrw7Jg6BjLJVKzlve8hZn7dq1zubNm7Vnkyor7rvvPueLX/yis3nzZmfr1q3O1772NWf58uXOJZdc0uMjqyPo+A4fPux85CMfce6//35n27Ztzo9//GPnZS97mXPMMcc4s7Ozahtz+RoSxsfHnYGBAefaa6/1fD7p1zBsfnCc8PGzUqk4J554ovPGN77R2bx5s3Prrbc6y5cvd6688sq27acELCH4P//n/zhHHnmkk8/nnVe+8pXOAw880OtdagoArP9uuOEGx3EcZ+fOnc7rX/96Z8mSJU6hUHBe9KIXOR/96Eed8fHx3u54DLzzne90Vq9e7eTzeeeII45w3vnOdzpPP/20+vvMzIzzR3/0R87ixYudgYEB58ILL3T27NnTwz2Oj//+7/92ADhbtmzRXp+r1+/OO++03peXXnqp4zj10uaPf/zjzsqVK51CoeCcddZZnmM/cOCAc9FFFzmLFi1yhoeHnfe85z3O4cOHe3A0dgQd47Zt23yfzTvvvNNxHMd5+OGHnU2bNjkjIyNOX1+f8+IXv9j527/9W23C7yWCjm96etp54xvf6CxfvtzJ5XLO+vXrnfe///2eRd9cvoaEf/7nf3b6+/udsbExz+eTfg3D5gfHiTZ+bt++3TnvvPOc/v5+Z9myZc6f/dmfOeVyuW37mWrsrEAgEAgEAkFiIRoWgUAgEAgEiYcELAKBQCAQCBIPCVgEAoFAIBAkHhKwCAQCgUAgSDwkYBEIBAKBQJB4SMAiEAgEAoEg8ZCARSAQCAQCQeIhAYtAIBAIBILEQwIWgUAgEAgEiYcELAKBQCAQCBIPCVgEAoFAIBAkHhKwCAQCgUAgSDz+/9/yjI89/vv8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3035240173339844, 2.302521228790283, 2.3026676177978516, 2.302656412124634, 2.3028721809387207, 2.3025622367858887, 2.3025240898132324, 2.302683115005493, 2.3025505542755127, 2.302184820175171, 2.3025755882263184, 2.3023738861083984, 2.3026206493377686, 2.3026344776153564, 2.302588701248169, 2.3023152351379395, 2.3027570247650146, 2.302600383758545, 2.3025553226470947, 2.302473783493042, 2.302593469619751, 2.3025810718536377, 2.302614450454712, 2.302398204803467, 2.302471160888672, 2.302567958831787, 2.302489995956421, 2.3025643825531006, 2.3028438091278076, 2.302565336227417, 2.3027212619781494, 2.3025565147399902, 2.3024792671203613, 2.30263352394104, 2.302564859390259, 2.302828550338745, 2.3026444911956787, 2.3024349212646484, 2.3028318881988525, 2.3018572330474854, 2.3025569915771484, 2.302593469619751, 2.302699327468872, 2.302600145339966, 2.302572727203369, 2.3025927543640137, 2.302605152130127, 2.3030588626861572, 2.3026061058044434, 2.302591323852539, 2.3026280403137207, 2.3025600910186768, 2.3031938076019287, 2.3026010990142822, 2.30265474319458, 2.302611827850342, 2.302579879760742, 2.302616834640503, 2.3025624752044678, 2.3025856018066406, 2.3026013374328613, 2.3025710582733154, 2.3025877475738525, 2.30255126953125, 2.302582263946533, 2.302622079849243, 2.3024649620056152, 2.302588701248169, 2.302534341812134, 2.3025052547454834, 2.3025877475738525, 2.302600145339966, 2.302588939666748, 2.3026070594787598, 2.3025929927825928, 2.302593469619751, 2.3025894165039062, 2.3025851249694824, 2.3025944232940674, 2.30257248878479, 2.302640676498413, 2.302574396133423, 2.3026020526885986, 2.302586078643799, 2.302584171295166, 2.302556276321411, 2.3025851249694824, 2.302600145339966, 2.3025872707366943, 2.3025825023651123, 2.302588701248169, 2.302604913711548, 2.3026044368743896, 2.3024847507476807, 2.302586078643799, 2.3025853633880615, 2.3025758266448975, 2.302586793899536, 2.302582263946533, 2.3026671409606934, 2.302522659301758, 2.3025782108306885, 2.302548885345459, 2.3026106357574463, 2.3025829792022705, 2.3024847507476807, 2.302603006362915, 2.302576780319214, 2.3026154041290283, 2.302588939666748, 2.3025779724121094, 2.302537441253662, 2.3025996685028076, 2.302623748779297, 2.3026065826416016, 2.302666425704956, 2.3025929927825928, 2.3025927543640137, 2.302642822265625, 2.3025946617126465, 2.302687883377075, 2.302826166152954, 2.302589178085327, 2.3025453090667725, 2.302074670791626, 2.3025777339935303, 2.3025853633880615, 2.3025684356689453, 2.3025829792022705, 2.3025951385498047, 2.3026015758514404, 2.3025882244110107, 2.3025317192077637, 2.3025779724121094, 2.3025853633880615, 2.302586317062378, 2.3026013374328613, 2.3025782108306885, 2.302583932876587, 2.3025875091552734, 2.3025877475738525, 2.30255389213562, 2.3026340007781982, 2.3026340007781982, 2.3025870323181152, 2.3025870323181152, 2.3025848865509033, 2.30259370803833, 2.302623987197876, 2.3025858402252197, 2.3025715351104736, 2.3025736808776855, 2.3025949001312256, 2.3026061058044434, 2.3025853633880615, 2.3026199340820312, 2.302595376968384, 2.302582263946533, 2.3025803565979004, 2.3025283813476562, 2.3025853633880615, 2.30259108543396, 2.302584409713745, 2.3025853633880615, 2.3026504516601562, 2.3025848865509033, 2.3025448322296143, 2.3025882244110107, 2.3025858402252197, 2.3026318550109863, 2.3025784492492676, 2.3025147914886475, 2.3025832176208496, 2.3025853633880615, 2.302581310272217, 2.3025763034820557, 2.302579402923584, 2.3025858402252197, 2.302583932876587, 2.302583932876587, 2.3025801181793213, 2.3025825023651123, 2.3025927543640137, 2.3025810718536377, 2.3025856018066406, 2.3025832176208496, 2.3025848865509033, 2.302598476409912, 2.3025832176208496, 2.302633762359619, 2.302565097808838, 2.3025803565979004, 2.3025498390197754, 2.3025877475738525, 2.3025882244110107, 2.302584409713745, 2.3025872707366943, 2.3025131225585938, 2.302579879760742, 2.3025856018066406]\n",
      "[14.285714285714286, 12.5, 8.035714285714286, 14.285714285714286, 10.714285714285714, 13.392857142857142, 9.821428571428571, 9.821428571428571, 9.821428571428571, 8.928571428571429, 12.5, 5.357142857142857, 5.357142857142857, 12.5, 12.5, 13.392857142857142, 9.821428571428571, 8.035714285714286, 9.821428571428571, 14.285714285714286, 2.6785714285714284, 11.607142857142858, 14.285714285714286, 10.714285714285714, 9.821428571428571, 14.285714285714286, 16.071428571428573, 9.821428571428571, 9.821428571428571, 8.035714285714286, 7.142857142857143, 8.928571428571429, 9.821428571428571, 9.821428571428571, 12.5, 4.464285714285714, 9.821428571428571, 18.75, 7.142857142857143, 9.821428571428571, 8.035714285714286, 8.928571428571429, 10.714285714285714, 6.25, 8.035714285714286, 8.928571428571429, 7.142857142857143, 8.928571428571429, 9.821428571428571, 8.035714285714286, 7.142857142857143, 10.714285714285714, 6.25, 9.821428571428571, 2.6785714285714284, 3.5714285714285716, 8.928571428571429, 6.25, 11.607142857142858, 11.607142857142858, 8.035714285714286, 10.714285714285714, 6.25, 14.285714285714286, 6.25, 5.357142857142857, 15.178571428571429, 10.714285714285714, 16.071428571428573, 10.714285714285714, 11.607142857142858, 11.607142857142858, 13.392857142857142, 3.5714285714285716, 11.607142857142858, 10.714285714285714, 7.142857142857143, 9.821428571428571, 7.142857142857143, 5.357142857142857, 8.035714285714286, 13.392857142857142, 6.25, 6.25, 12.5, 14.285714285714286, 6.25, 8.035714285714286, 4.464285714285714, 12.5, 8.035714285714286, 10.714285714285714, 8.035714285714286, 8.928571428571429, 8.928571428571429, 8.035714285714286, 12.5, 8.928571428571429, 14.285714285714286, 8.035714285714286, 8.035714285714286, 8.035714285714286, 8.928571428571429, 11.607142857142858, 6.25, 12.5, 8.035714285714286, 7.142857142857143, 8.035714285714286, 9.821428571428571, 11.607142857142858, 21.428571428571427, 14.285714285714286, 10.714285714285714, 12.5, 11.607142857142858, 5.357142857142857, 9.821428571428571, 9.821428571428571, 14.285714285714286, 7.142857142857143, 6.25, 6.25, 16.964285714285715, 13.392857142857142, 16.071428571428573, 13.392857142857142, 12.5, 8.035714285714286, 12.5, 8.035714285714286, 8.928571428571429, 14.285714285714286, 11.607142857142858, 8.035714285714286, 11.607142857142858, 9.821428571428571, 10.714285714285714, 13.392857142857142, 8.928571428571429, 15.178571428571429, 10.714285714285714, 8.928571428571429, 8.928571428571429, 14.285714285714286, 6.25, 5.357142857142857, 9.821428571428571, 9.821428571428571, 7.142857142857143, 10.714285714285714, 9.821428571428571, 7.142857142857143, 11.607142857142858, 7.142857142857143, 5.357142857142857, 8.928571428571429, 14.285714285714286, 10.714285714285714, 12.5, 8.928571428571429, 6.25, 11.607142857142858, 10.714285714285714, 8.928571428571429, 11.607142857142858, 10.714285714285714, 8.928571428571429, 12.5, 12.5, 16.071428571428573, 9.821428571428571, 14.285714285714286, 9.821428571428571, 8.928571428571429, 16.964285714285715, 9.821428571428571, 7.142857142857143, 8.928571428571429, 10.714285714285714, 16.964285714285715, 13.392857142857142, 5.357142857142857, 10.714285714285714, 8.928571428571429, 16.071428571428573, 12.5, 9.821428571428571, 8.035714285714286, 8.035714285714286, 7.142857142857143, 16.071428571428573, 9.821428571428571, 7.142857142857143, 9.821428571428571, 11.607142857142858, 13.392857142857142, 14.285714285714286, 17.857142857142858, 6.25]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.03%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 11.00%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: 9.775162e-06\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
