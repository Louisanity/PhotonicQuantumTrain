{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 76.17%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "def generate_random_qubit_state_torch(n_qubit):\n",
    "    # Generate a single random state of size (n_qubit,)\n",
    "    random_state = torch.randint(0, 2, (n_qubit,)) * 2 - 1  # Converts {0,1} â†’ {-1,1}\n",
    "    \n",
    "    # Repeat this state 2^N times\n",
    "    repeated_states = random_state.repeat((2**n_qubit, 1))\n",
    "    \n",
    "    return repeated_states\n",
    "#############################################\n",
    "def generate_random_tensor():\n",
    "    return torch.randn(126 * 70, 1).cuda()  # Generates a tensor with standard normal distribution\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=9)\n",
    "\n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        probs_ = generate_random_tensor()\n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_random_qubit_state_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  2511\n",
      "# of trainable parameter in full model:  2511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "# print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.3014, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3009, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3051, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.3041, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.3038, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 2.3006, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 2.3060, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 2.3034, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 2.3044, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.3017, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 2.3039, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 2.3053, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 2.3035, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 2.3034, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 2.3047, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 2.3018, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 2.3014, batch time: 0.01, accuracy:  18.75%\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 2.2994, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 2.3011, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 2.3043, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 2.3015, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 2.3016, batch time: 0.01, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 2.3036, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 2.3032, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 2.3035, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  18.75%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 2.3019, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 2.3036, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 2.3042, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  14.06%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 2.3003, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 2.3043, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 2.3037, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.02, accuracy:  7.81%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  19.53%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 2.3037, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  20.31%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 2.3038, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 2.3015, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 2.3019, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 2.3036, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 2.3019, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 2.3036, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 2.3033, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 2.3034, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 2.3016, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 2.3032, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 2.3036, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.02, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  2.34%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.97%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 2.3021, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 2.3030, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 2.3022, batch time: 0.01, accuracy:  20.31%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 2.3033, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  18.75%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 2.3031, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 2.3018, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 2.3020, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.02, accuracy:  9.38%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 2.3016, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  18.75%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  20.31%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  3.91%\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.12%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  3.91%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  15.62%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 2.3029, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 2.3029, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 2.3021, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 2.3024, batch time: 0.01, accuracy:  17.19%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  4.69%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 2.3028, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 2.3030, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 2.3010, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 2.3031, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  11.72%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 2.3024, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 2.3023, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  5.47%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 2.3027, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.84%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 2.3023, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  6.25%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  9.38%\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 2.3028, batch time: 0.01, accuracy:  10.16%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 2.3027, batch time: 0.01, accuracy:  7.81%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 2.3020, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  16.41%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  9.38%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  7.03%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  13.28%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  8.59%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 2.3025, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  14.06%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 2.3022, batch time: 0.01, accuracy:  10.94%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 2.3026, batch time: 0.01, accuracy:  12.50%\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.302668333053589, 2.302680492401123, 2.3029608726501465, 2.303234577178955, 2.3034310340881348, 2.3013126850128174, 2.302443027496338, 2.302581548690796, 2.3022522926330566, 2.302402973175049, 2.3025896549224854, 2.302574396133423, 2.3028273582458496, 2.302677631378174, 2.3025758266448975, 2.302520275115967, 2.302837610244751, 2.3023111820220947, 2.3052444458007812, 2.302584409713745, 2.302579402923584, 2.3025591373443604, 2.3025927543640137, 2.3026185035705566, 2.3028969764709473, 2.3026106357574463, 2.3025875091552734, 2.3025765419006348, 2.3025705814361572, 2.30259108543396, 2.302595376968384, 2.3026211261749268, 2.3027844429016113, 2.3025875091552734, 2.302704095840454, 2.3025569915771484, 2.3025851249694824, 2.3024919033050537, 2.302584171295166, 2.302626132965088, 2.3025729656219482, 2.30237078666687, 2.302755117416382, 2.302583694458008, 2.302515745162964, 2.3026185035705566, 2.302574634552002, 2.302600145339966, 2.3025710582733154, 2.3025896549224854, 2.3025453090667725, 2.3025882244110107, 2.3025872707366943, 2.3025832176208496, 2.302579402923584, 2.303135633468628, 2.3025879859924316, 2.3026421070098877, 2.302603006362915, 2.3026504516601562, 2.3025166988372803, 2.302905797958374, 2.302534580230713, 2.302812337875366, 2.3025829792022705, 2.302602767944336, 2.3026483058929443, 2.302381992340088, 2.3026256561279297, 2.3021280765533447, 2.3026063442230225, 2.3023698329925537, 2.3025543689727783, 2.302546739578247, 2.3024775981903076, 2.3025336265563965, 2.302471160888672, 2.3025710582733154, 2.302591323852539, 2.3025569915771484, 2.302751064300537, 2.3027522563934326, 2.302344560623169, 2.3023483753204346, 2.3026039600372314, 2.3025155067443848, 2.302692174911499, 2.302593231201172, 2.3025877475738525, 2.3026034832000732, 2.3023014068603516, 2.302534580230713, 2.302611827850342, 2.30253529548645, 2.3026039600372314, 2.302406072616577, 2.302600383758545, 2.3026492595672607, 2.302649974822998, 2.3024744987487793, 2.302603006362915, 2.3025195598602295, 2.3024818897247314, 2.3023054599761963, 2.302586078643799, 2.3027541637420654, 2.302600622177124, 2.302586317062378, 2.302543878555298, 2.302631378173828, 2.3025729656219482, 2.302597761154175, 2.302501678466797, 2.302574396133423, 2.3025829792022705, 2.302588939666748, 2.302590847015381, 2.3025708198547363, 2.302553415298462, 2.30257248878479, 2.3025784492492676, 2.302584409713745, 2.3025851249694824, 2.302584171295166, 2.3025963306427, 2.302562713623047, 2.302567958831787, 2.3026020526885986, 2.3025832176208496, 2.302581787109375, 2.3025577068328857, 2.3026137351989746, 2.302565813064575, 2.302586793899536, 2.302917003631592, 2.302586078643799, 2.3025901317596436, 2.302537202835083, 2.302582025527954, 2.302584409713745, 2.3025410175323486, 2.3025925159454346, 2.302579641342163, 2.3025996685028076, 2.302564859390259, 2.302586793899536, 2.302581548690796, 2.3026816844940186, 2.302582263946533, 2.302591323852539, 2.302616834640503, 2.302525043487549, 2.302630662918091, 2.302497386932373, 2.3025670051574707, 2.3031961917877197, 2.3026163578033447, 2.302617311477661, 2.3025543689727783, 2.3026249408721924, 2.3025553226470947, 2.3025851249694824, 2.302623987197876, 2.3025779724121094, 2.302645444869995, 2.302583932876587, 2.3025848865509033, 2.3024847507476807, 2.3025906085968018, 2.3025717735290527, 2.30259108543396, 2.3025810718536377, 2.302574872970581, 2.3026185035705566, 2.3025872707366943, 2.3025965690612793, 2.302572250366211, 2.3024489879608154, 2.3025968074798584, 2.302598476409912, 2.3026082515716553, 2.3025898933410645, 2.302510976791382, 2.3025760650634766, 2.3027901649475098, 2.30261492729187, 2.3025739192962646, 2.3025717735290527, 2.3024067878723145, 2.302375078201294, 2.3025553226470947, 2.3026950359344482, 2.302583932876587, 2.302579164505005, 2.3025832176208496, 2.302595615386963, 2.302438735961914, 2.3023643493652344, 2.3026349544525146, 2.3025567531585693]\n",
      "[8.035714285714286, 9.821428571428571, 8.928571428571429, 8.928571428571429, 8.035714285714286, 8.928571428571429, 13.392857142857142, 8.928571428571429, 11.607142857142858, 10.714285714285714, 8.035714285714286, 9.821428571428571, 7.142857142857143, 9.821428571428571, 14.285714285714286, 10.714285714285714, 11.607142857142858, 14.285714285714286, 3.5714285714285716, 15.178571428571429, 8.035714285714286, 11.607142857142858, 12.5, 8.035714285714286, 4.464285714285714, 8.035714285714286, 5.357142857142857, 7.142857142857143, 11.607142857142858, 11.607142857142858, 11.607142857142858, 5.357142857142857, 6.25, 10.714285714285714, 6.25, 11.607142857142858, 12.5, 12.5, 8.035714285714286, 9.821428571428571, 13.392857142857142, 12.5, 7.142857142857143, 16.071428571428573, 11.607142857142858, 11.607142857142858, 9.821428571428571, 7.142857142857143, 9.821428571428571, 9.821428571428571, 13.392857142857142, 11.607142857142858, 8.928571428571429, 10.714285714285714, 7.142857142857143, 10.714285714285714, 11.607142857142858, 8.035714285714286, 11.607142857142858, 7.142857142857143, 13.392857142857142, 5.357142857142857, 11.607142857142858, 7.142857142857143, 10.714285714285714, 8.035714285714286, 11.607142857142858, 11.607142857142858, 11.607142857142858, 11.607142857142858, 7.142857142857143, 8.928571428571429, 7.142857142857143, 8.035714285714286, 16.964285714285715, 18.75, 9.821428571428571, 11.607142857142858, 5.357142857142857, 15.178571428571429, 8.928571428571429, 6.25, 9.821428571428571, 8.035714285714286, 10.714285714285714, 14.285714285714286, 5.357142857142857, 8.928571428571429, 9.821428571428571, 8.035714285714286, 10.714285714285714, 14.285714285714286, 8.035714285714286, 11.607142857142858, 8.035714285714286, 15.178571428571429, 8.928571428571429, 6.25, 9.821428571428571, 5.357142857142857, 9.821428571428571, 10.714285714285714, 13.392857142857142, 16.071428571428573, 12.5, 10.714285714285714, 7.142857142857143, 8.928571428571429, 11.607142857142858, 9.821428571428571, 11.607142857142858, 8.928571428571429, 8.035714285714286, 8.928571428571429, 7.142857142857143, 7.142857142857143, 9.821428571428571, 10.714285714285714, 18.75, 12.5, 12.5, 10.714285714285714, 11.607142857142858, 10.714285714285714, 12.5, 13.392857142857142, 7.142857142857143, 7.142857142857143, 10.714285714285714, 15.178571428571429, 16.964285714285715, 8.928571428571429, 10.714285714285714, 10.714285714285714, 8.928571428571429, 12.5, 6.25, 8.928571428571429, 15.178571428571429, 14.285714285714286, 14.285714285714286, 8.928571428571429, 11.607142857142858, 5.357142857142857, 6.25, 8.928571428571429, 9.821428571428571, 5.357142857142857, 15.178571428571429, 12.5, 8.928571428571429, 10.714285714285714, 12.5, 10.714285714285714, 12.5, 3.5714285714285716, 6.25, 5.357142857142857, 8.035714285714286, 11.607142857142858, 12.5, 8.928571428571429, 9.821428571428571, 8.035714285714286, 10.714285714285714, 11.607142857142858, 12.5, 10.714285714285714, 7.142857142857143, 14.285714285714286, 9.821428571428571, 8.035714285714286, 11.607142857142858, 11.607142857142858, 13.392857142857142, 8.928571428571429, 14.285714285714286, 9.821428571428571, 5.357142857142857, 9.821428571428571, 5.357142857142857, 8.928571428571429, 10.714285714285714, 13.392857142857142, 1.7857142857142858, 8.035714285714286, 8.928571428571429, 13.392857142857142, 9.821428571428571, 16.964285714285715, 9.821428571428571, 12.5, 15.178571428571429, 12.5, 8.928571428571429, 4.464285714285714, 10.714285714285714, 14.285714285714286, 3.5714285714285716, 13.392857142857142]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.841748058795929, 0.5383376479148865, 0.37141960859298706, 0.2189747840166092, 0.2170722633600235, 0.2683789134025574, 0.1937561184167862, 0.2995546758174896, 0.13230514526367188, 0.12556131184101105, 0.08791607618331909, 0.13517722487449646, 0.1180429607629776, 0.2700677216053009, 0.23012836277484894, 0.11778731644153595, 0.08971132338047028, 0.0745047926902771, 0.044976893812417984, 0.030214795842766762, 0.14274518191814423, 0.16257527470588684, 0.13489486277103424, 0.22497442364692688, 0.04410076141357422, 0.0439407117664814, 0.0999048724770546, 0.09295899420976639, 0.05333646386861801, 0.042801376432180405, 0.0852958932518959, 0.035196453332901, 0.09896297752857208, 0.09667126089334488, 0.11132311820983887, 0.07094293087720871, 0.11317868530750275, 0.17386971414089203, 0.04825839400291443, 0.1526862233877182, 0.12213451415300369, 0.0335562527179718, 0.14572270214557648, 0.14732243120670319, 0.08901072293519974, 0.10628568381071091, 0.1219853013753891, 0.04227989539504051, 0.1546023041009903, 0.07231778651475906, 0.08872615545988083, 0.06031284108757973, 0.11893129348754883, 0.07610543072223663, 0.05435555428266525, 0.03299633413553238, 0.06796611100435257, 0.09908641129732132, 0.1245361715555191, 0.13339823484420776, 0.044910043478012085, 0.039106521755456924, 0.08405368030071259, 0.03416334092617035, 0.18436889350414276, 0.06167331337928772, 0.05363277718424797, 0.03776988759636879, 0.010305949486792088, 0.08863425254821777, 0.11051689833402634, 0.03690870478749275, 0.021718373522162437, 0.08610344678163528, 0.08286675065755844, 0.05776119977235794, 0.09465332329273224, 0.032651614397764206, 0.07205092906951904, 0.0745658427476883, 0.08170061558485031, 0.10555801540613174, 0.016445361077785492, 0.12694816291332245, 0.11931197345256805, 0.08286337554454803, 0.07604096084833145, 0.04736681655049324, 0.07517056912183762, 0.13407494127750397, 0.02461135759949684, 0.026882896199822426, 0.050736844539642334, 0.03605273738503456, 0.056351643055677414, 0.09767205268144608, 0.07290007919073105, 0.08676333725452423, 0.0794496163725853, 0.04368472844362259, 0.050167299807071686, 0.04737326130270958, 0.05501176789402962, 0.08879045397043228, 0.01769072189927101, 0.11385718733072281, 0.045953329652547836, 0.057710688561201096, 0.03719104081392288, 0.07977698743343353, 0.02595260553061962, 0.1046842560172081, 0.06301649659872055, 0.02800893224775791, 0.024529291316866875, 0.020508909597992897, 0.14025148749351501, 0.05224132165312767, 0.02634393982589245, 0.03067580796778202, 0.010352589190006256, 0.030206164345145226, 0.09297139197587967, 0.1973668485879898, 0.11294060945510864, 0.10930002480745316, 0.0792819932103157, 0.11282505095005035, 0.06902279704809189, 0.034222979098558426, 0.01758032664656639, 0.20883719623088837, 0.0871180072426796, 0.021445829421281815, 0.058817390352487564, 0.11408091336488724, 0.04319537431001663, 0.028295835480093956, 0.009734376333653927, 0.0865861177444458, 0.013264675624668598, 0.03975219279527664, 0.03132316842675209, 0.07329122722148895, 0.031415101140737534, 0.057007454335689545, 0.07466187328100204, 0.03515228256583214, 0.01828647591173649, 0.034930113703012466, 0.04921986907720566, 0.05617351084947586, 0.025701504200696945, 0.07073844969272614, 0.0677885115146637, 0.0442965142428875, 0.08668070286512375, 0.01085565984249115, 0.10640285909175873, 0.042185988277196884, 0.045891039073467255, 0.010602300986647606, 0.07824820280075073, 0.029184645041823387, 0.1528889238834381, 0.0852082297205925, 0.01046351995319128, 0.26733046770095825, 0.008088228292763233, 0.1218838021159172, 0.06059052422642708, 0.17010393738746643, 0.09900021553039551, 0.027551589533686638, 0.009467942640185356, 0.0559978224337101, 0.015254249796271324, 0.06907999515533447, 0.026691734790802002, 0.09885875135660172, 0.01129892561584711, 0.03152812644839287, 0.08123517781496048, 0.04274165257811546, 0.03844240680336952, 0.06572488695383072, 0.10163140296936035, 0.020722707733511925, 0.016591958701610565, 0.10138952732086182, 0.10918857157230377, 0.028943251818418503, 0.04512939602136612, 0.040990330278873444, 0.04000023752450943, 0.045494887977838516, 0.011356256902217865, 0.05481533333659172, 0.013076278381049633, 0.04331720620393753]\n",
    "# acc_list_epoch_ = [71.42857142857143, 83.03571428571429, 84.82142857142857, 95.53571428571429, 91.07142857142857, 91.96428571428571, 93.75, 91.96428571428571, 96.42857142857143, 94.64285714285714, 98.21428571428571, 93.75, 96.42857142857143, 92.85714285714286, 94.64285714285714, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 91.96428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 97.32142857142857, 98.21428571428571, 95.53571428571429, 98.21428571428571, 96.42857142857143, 96.42857142857143, 95.53571428571429, 98.21428571428571, 95.53571428571429, 97.32142857142857, 99.10714285714286, 93.75, 95.53571428571429, 98.21428571428571, 94.64285714285714, 95.53571428571429, 97.32142857142857, 95.53571428571429, 94.64285714285714, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 96.42857142857143, 98.21428571428571, 98.21428571428571, 95.53571428571429, 99.10714285714286, 94.64285714285714, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 97.32142857142857, 95.53571428571429, 98.21428571428571, 100.0, 97.32142857142857, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 98.21428571428571, 95.53571428571429, 93.75, 100.0, 99.10714285714286, 98.21428571428571, 99.10714285714286, 98.21428571428571, 96.42857142857143, 97.32142857142857, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 98.21428571428571, 96.42857142857143, 98.21428571428571, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 93.75, 97.32142857142857, 99.10714285714286, 98.21428571428571, 100.0, 99.10714285714286, 95.53571428571429, 91.07142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 96.42857142857143, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 98.21428571428571, 98.21428571428571, 100.0, 96.42857142857143, 100.0, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 99.10714285714286, 99.10714285714286, 98.21428571428571, 99.10714285714286, 99.10714285714286, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 100.0, 96.42857142857143, 99.10714285714286, 96.42857142857143, 97.32142857142857, 100.0, 91.96428571428571, 100.0, 96.42857142857143, 97.32142857142857, 91.96428571428571, 97.32142857142857, 99.10714285714286, 100.0, 96.42857142857143, 99.10714285714286, 98.21428571428571, 99.10714285714286, 96.42857142857143, 100.0, 99.10714285714286, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 97.32142857142857, 100.0, 100.0, 95.53571428571429, 94.64285714285714, 99.10714285714286, 97.32142857142857, 98.21428571428571, 98.21428571428571, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 99.10714285714286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 10.12%\n",
      "Loss on the train set: 2.30\n",
      "Accuracy on the test set: 11.67%\n",
      "Loss on the test set: 2.30\n",
      "Generalization error: -0.00028038025\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
