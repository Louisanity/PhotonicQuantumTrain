{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.946661</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.216041</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.762549</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.888702</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.192976</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.335925</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.845656</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.134949</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.838202</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.126907</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.690768</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.811824</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.238254</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.513921</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.352668</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.092257</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.434965</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.653527</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.385846</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.225845</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.89941</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.554059</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.919791</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.538773</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.027805</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.918787</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.731068</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.876332</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.794934</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.92046</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.35376</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.543733</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.656779</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.215757</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.523106</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.337292</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.796565</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.830876</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.411504</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.389775</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.133372</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.200884</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.499339</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.828497</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.250784</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.69365</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.667396</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.584369</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.381709</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.110182</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.062886</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.395899</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.831522</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.213898</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.728832</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.488309</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.091043</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.576065</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.232001</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.115928</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.533105</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.160643</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.335263</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.752452</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.911063</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.652514</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.570264</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.211161</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.421698</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.610554</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.53839</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.32951</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.768559</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.273047</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.47139</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.847573</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.612053</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.034718</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.833837</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.460957</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.028607</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.203101</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.23932</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.920982</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.121097</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.624143</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.118805</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.384874</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.727565</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.406765</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.601137</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.107376</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.34625</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.168128</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.915129</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.074698</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7f87be3ff430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.131684</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.518604</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.781613</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.140093</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.855349</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.602657</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.304604</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.198253</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.833779</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.624772</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.846447</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.354826</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.883202</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.994166</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.330789</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.293471</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.319707</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.171733</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.697228</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.315732</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.834712</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.633117</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.287102</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.369134</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.163068</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.656017</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.342891</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.12691</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.125561</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.490535</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.714249</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.95246</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.14062</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.081208</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.015356</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.908203</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.086164</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.634552</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.891236</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.670446</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.204015</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.029986</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.996958</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.170811</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.411182</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.548982</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.435597</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.007022</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.343462</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.608703</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.658138</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.734484</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.139084</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.414147</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.630066</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.105927</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.283443</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.677742</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.533287</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.80424</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.697046</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.046384</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.74231</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.679847</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.222774</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.104762</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.135427</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.938906</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.27439</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.426031</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.515964</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.953077</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.179609</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.50812</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.212873</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7f87be314970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 72.17%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=1)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  31\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.2912, batch time: 0.09, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.2441, batch time: 0.12, accuracy:  22.66%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.1608, batch time: 0.04, accuracy:  27.34%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.0588, batch time: 0.05, accuracy:  24.22%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.1506, batch time: 0.05, accuracy:  24.22%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.1365, batch time: 0.21, accuracy:  25.00%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.1293, batch time: 0.20, accuracy:  22.66%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.2758, batch time: 0.31, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.1505, batch time: 0.10, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.0824, batch time: 0.17, accuracy:  27.34%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 2.1131787300109863, accuracy: 21.6 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 2.128694534301758, accuracy: 18.3 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 2.100529670715332, accuracy: 19.0 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 2.0806479454040527, accuracy: 19.7 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 2.0775163173675537, accuracy: 20.7 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 2.07586932182312, accuracy: 21.0 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 2.0759084224700928, accuracy: 21.1 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 2.074425458908081, accuracy: 20.7 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 2.0691306591033936, accuracy: 20.1 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 2.0663609504699707, accuracy: 20.1 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.9693, batch time: 0.04, accuracy:  21.88%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.0533, batch time: 0.11, accuracy:  17.97%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.0558, batch time: 0.04, accuracy:  20.31%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 1.9922, batch time: 0.04, accuracy:  30.47%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.0881, batch time: 0.05, accuracy:  13.28%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.0689, batch time: 0.05, accuracy:  24.22%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.2123, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.0772, batch time: 0.04, accuracy:  26.56%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.0346, batch time: 0.05, accuracy:  21.09%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.0682, batch time: 0.05, accuracy:  16.41%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 2.0578529834747314, accuracy: 28.4 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 2.0492303371429443, accuracy: 27.0 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 2.0305235385894775, accuracy: 26.8 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 2.018629312515259, accuracy: 29.6 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 2.0106916427612305, accuracy: 31.3 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 2.0299794673919678, accuracy: 23.5 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 1.9958066940307617, accuracy: 29.1 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 1.9998157024383545, accuracy: 29.6 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 1.9809390306472778, accuracy: 30.4 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 2.043936252593994, accuracy: 23.5 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.1076, batch time: 0.05, accuracy:  27.34%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 1.8358, batch time: 0.08, accuracy:  31.25%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 1.8930, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 1.7853, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 2.0702, batch time: 0.05, accuracy:  28.12%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 1.9546, batch time: 0.10, accuracy:  30.47%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 1.9322, batch time: 0.06, accuracy:  31.25%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 1.8876, batch time: 0.05, accuracy:  32.81%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 2.0865, batch time: 0.05, accuracy:  30.47%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 1.9586, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 1.928043246269226, accuracy: 29.1 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 1.994937539100647, accuracy: 28.4 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 1.8936131000518799, accuracy: 32.9 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 1.8918570280075073, accuracy: 32.4 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 1.952881932258606, accuracy: 29.6 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 1.8927092552185059, accuracy: 31.9 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 1.8743983507156372, accuracy: 34.0 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 2.005817413330078, accuracy: 28.0 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 1.8338373899459839, accuracy: 35.4 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 1.8195661306381226, accuracy: 35.6 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 1.8001, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 1.7539, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 1.7462, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 1.8133, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 1.8840, batch time: 0.08, accuracy:  30.47%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 1.7391, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 1.7099, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 1.7403, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 1.9177, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 1.7549, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 1.8863190412521362, accuracy: 30.0 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 2.196422576904297, accuracy: 23.1 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 1.8256099224090576, accuracy: 31.9 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 1.8217273950576782, accuracy: 33.4 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 2.2047009468078613, accuracy: 28.7 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 1.810401201248169, accuracy: 33.5 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 1.8080672025680542, accuracy: 33.3 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 1.8027825355529785, accuracy: 34.7 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 1.803521752357483, accuracy: 34.6 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 1.8012173175811768, accuracy: 34.7 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 1.8107, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 1.7878, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 1.7309, batch time: 0.11, accuracy:  42.19%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 1.7646, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 1.7797, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 1.8793, batch time: 0.04, accuracy:  25.00%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 1.7624, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 1.8806, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 1.7120, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 1.6908, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 1.801515817642212, accuracy: 35.9 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 1.8058357238769531, accuracy: 35.6 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 3.593446969985962, accuracy: 14.5 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 1.8364603519439697, accuracy: 36.7 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 1.9249141216278076, accuracy: 29.7 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 1.7779265642166138, accuracy: 39.5 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 1.7826852798461914, accuracy: 32.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 1.7445886135101318, accuracy: 36.1 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 1.9579424858093262, accuracy: 32.7 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 1.732588529586792, accuracy: 36.6 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 1.6430, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 1.7413, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 1.7280, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 1.8807, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 1.6482, batch time: 0.05, accuracy:  39.06%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 1.7015, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 1.6488, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 1.7566, batch time: 0.10, accuracy:  32.03%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 1.6686, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 1.6094, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 1.6943635940551758, accuracy: 40.8 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 2.133852005004883, accuracy: 26.6 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 1.7856934070587158, accuracy: 37.6 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 2.0756285190582275, accuracy: 28.1 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 1.6824679374694824, accuracy: 38.6 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 1.6693148612976074, accuracy: 39.4 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 1.6720749139785767, accuracy: 39.3 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 1.6716208457946777, accuracy: 40.2 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 1.7092047929763794, accuracy: 38.9 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 1.6733542680740356, accuracy: 40.2 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 1.7306, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 1.6987, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 1.8072, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 1.7981, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 1.8062, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 1.8653, batch time: 0.05, accuracy:  32.03%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 2.0303, batch time: 0.05, accuracy:  24.22%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 1.7847, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 1.6047, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 1.6660, batch time: 0.05, accuracy:  30.47%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 1.7297838926315308, accuracy: 38.6 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 2.0041043758392334, accuracy: 34.1 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 1.6945884227752686, accuracy: 37.7 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 1.6875653266906738, accuracy: 36.5 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 1.7878351211547852, accuracy: 35.1 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 3.121021032333374, accuracy: 16.0 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 1.6707266569137573, accuracy: 38.8 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 1.6645383834838867, accuracy: 40.0 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 1.666298747062683, accuracy: 39.5 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 1.685288906097412, accuracy: 38.2 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.9112, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 1.6353, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 1.7446, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 1.6898, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 1.7330, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 1.6165, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 1.9227, batch time: 0.06, accuracy:  32.81%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 1.7136, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 1.6341, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 1.6097, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 1.717315673828125, accuracy: 37.3 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.1349680423736572, accuracy: 25.3 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 1.787621021270752, accuracy: 33.2 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 1.8614901304244995, accuracy: 33.6 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 1.714372992515564, accuracy: 37.7 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 1.9153789281845093, accuracy: 33.4 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 1.7135210037231445, accuracy: 37.9 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 1.7501232624053955, accuracy: 36.6 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 1.7091588973999023, accuracy: 38.3 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 1.7641727924346924, accuracy: 37.1 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 1.7178, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 1.7025, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 1.6229, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 1.7825, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 1.6833, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 1.8040, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 1.7142, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 1.9045, batch time: 0.05, accuracy:  29.69%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 1.7018, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 1.6905, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 1.6888010501861572, accuracy: 38.1 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 1.7582110166549683, accuracy: 36.0 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 1.68118417263031, accuracy: 38.5 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 2.0331029891967773, accuracy: 27.9 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 1.6807990074157715, accuracy: 37.7 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 1.6848886013031006, accuracy: 37.9 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 1.6757193803787231, accuracy: 38.3 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 1.6753818988800049, accuracy: 39.0 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 2.342893123626709, accuracy: 29.7 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 1.6722476482391357, accuracy: 38.1 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 1.7113, batch time: 0.11, accuracy:  39.84%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 1.9486, batch time: 0.10, accuracy:  25.00%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 1.7939, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 1.6130, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 1.5876, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 1.7270, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 1.6307, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 1.7391, batch time: 0.05, accuracy:  35.16%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 1.7509, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 1.7246, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 1.6470099687576294, accuracy: 39.5 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 1.703476905822754, accuracy: 36.9 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 1.681570291519165, accuracy: 38.7 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 1.632596492767334, accuracy: 41.2 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 1.9496210813522339, accuracy: 32.4 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 1.6307722330093384, accuracy: 41.4 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 1.6434484720230103, accuracy: 40.6 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 1.628775715827942, accuracy: 41.6 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 1.6228481531143188, accuracy: 40.7 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 1.6181586980819702, accuracy: 41.9 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 1.7790, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 1.6752, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 1.7059, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 1.7160, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 1.7504, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 1.5531, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 1.7261, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 1.6729, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 1.5650, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 1.6969, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 1.6728612184524536, accuracy: 39.6 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 1.8463152647018433, accuracy: 33.5 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 1.7282671928405762, accuracy: 39.6 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 2.0119566917419434, accuracy: 27.4 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 1.7057768106460571, accuracy: 39.1 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 1.6668168306350708, accuracy: 39.8 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 1.662846565246582, accuracy: 40.4 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 1.6576298475265503, accuracy: 41.1 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 1.656988263130188, accuracy: 41.3 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 1.6550506353378296, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 1.5631, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 1.5829, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 1.6934, batch time: 0.05, accuracy:  34.38%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 1.5740, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 1.5840, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 1.5938, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 1.6548, batch time: 0.11, accuracy:  42.97%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 1.6840, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 1.5784, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 1.6834, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 1.6103672981262207, accuracy: 44.4 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 1.617740511894226, accuracy: 43.5 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 1.6091686487197876, accuracy: 44.8 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 1.6091686487197876, accuracy: 44.8 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 1.6066246032714844, accuracy: 43.6 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 1.6015573740005493, accuracy: 43.5 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 1.6298630237579346, accuracy: 42.9 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 1.5969505310058594, accuracy: 43.7 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 1.6013720035552979, accuracy: 44.2 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 1.5946968793869019, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 1.6453, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 1.7751, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 1.6262, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 1.5298, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 1.5468, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 1.8093, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 1.5414, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 1.6920, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 1.6809, batch time: 0.11, accuracy:  38.28%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 1.6880, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 1.6669381856918335, accuracy: 41.5 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 1.911486029624939, accuracy: 32.9 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 1.9226950407028198, accuracy: 34.5 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 1.8330974578857422, accuracy: 33.9 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 1.6710513830184937, accuracy: 41.3 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 1.6568266153335571, accuracy: 41.4 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 1.6563584804534912, accuracy: 41.1 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 1.6538830995559692, accuracy: 40.9 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 1.6525124311447144, accuracy: 41.4 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 1.6516308784484863, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 1.6393, batch time: 0.11, accuracy:  38.28%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 1.7085, batch time: 0.11, accuracy:  35.16%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 1.5519, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 1.6163, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 1.7823, batch time: 0.11, accuracy:  29.69%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 1.7157, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 1.6356, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 1.7480, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 1.7497, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 1.5591, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 1.6566132307052612, accuracy: 41.6 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 1.9122282266616821, accuracy: 34.4 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 1.7607935667037964, accuracy: 38.1 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 3.284060478210449, accuracy: 18.1 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 1.6607558727264404, accuracy: 41.3 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 1.6470924615859985, accuracy: 40.8 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 1.6470322608947754, accuracy: 41.2 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 1.6553809642791748, accuracy: 41.3 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 1.6451780796051025, accuracy: 41.3 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 1.6421371698379517, accuracy: 40.5 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 1.8285, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 1.7143, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 1.8526, batch time: 0.10, accuracy:  28.91%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 1.7072, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 1.7378, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 1.5108, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 1.8434, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 1.7351, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 1.5530, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 1.8364, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 1.6467883586883545, accuracy: 43.1 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 1.6915236711502075, accuracy: 38.5 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 1.6288970708847046, accuracy: 42.9 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 1.628725528717041, accuracy: 43.1 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 2.6278350353240967, accuracy: 30.7 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 1.6297355890274048, accuracy: 43.2 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 1.7605960369110107, accuracy: 35.9 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 1.6227858066558838, accuracy: 42.8 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 1.6198638677597046, accuracy: 44.0 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 1.6121143102645874, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 1.5540, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 1.7310, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 1.5754, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 1.6613, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 1.6127, batch time: 0.05, accuracy:  36.72%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 1.5869, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 1.8233, batch time: 0.05, accuracy:  31.25%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 1.9163, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 1.5017, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 1.5549, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 1.7436929941177368, accuracy: 36.9 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 2.966387987136841, accuracy: 23.4 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 1.964029312133789, accuracy: 34.1 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 2.0576889514923096, accuracy: 33.5 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 1.669082522392273, accuracy: 38.8 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 1.6651854515075684, accuracy: 38.9 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 1.6923614740371704, accuracy: 39.3 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 1.660090446472168, accuracy: 39.3 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 1.6693235635757446, accuracy: 39.1 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 1.657470941543579, accuracy: 40.0 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 1.7134, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 1.7628, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 1.4742, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 1.5939, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 1.7092, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 1.7215, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 1.6463, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 1.6666, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 1.5594, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 1.6210, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 1.6074692010879517, accuracy: 41.9 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 1.868137001991272, accuracy: 34.5 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 1.789951205253601, accuracy: 35.0 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 3.3887851238250732, accuracy: 18.8 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 1.602729320526123, accuracy: 44.1 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 1.5985039472579956, accuracy: 43.1 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 1.6011433601379395, accuracy: 43.4 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 1.6211910247802734, accuracy: 42.7 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 1.5937681198120117, accuracy: 43.6 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 1.6124907732009888, accuracy: 42.7 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 1.8997, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 1.5711, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 1.5392, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 1.5170, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 1.6082, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 1.5837, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 1.6538, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 1.5950, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 1.4908, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 1.6383, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 1.6222947835922241, accuracy: 43.6 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 3.06891131401062, accuracy: 21.3 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 1.7430834770202637, accuracy: 36.9 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 1.6260912418365479, accuracy: 43.0 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 1.6136995553970337, accuracy: 44.8 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 1.609632968902588, accuracy: 45.1 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 1.6162222623825073, accuracy: 44.7 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 1.6072944402694702, accuracy: 44.7 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 1.6058073043823242, accuracy: 45.0 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 1.60605788230896, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 1.6843, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 1.8006, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 1.3664, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 1.8221, batch time: 0.10, accuracy:  34.38%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 1.8142, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 1.5857, batch time: 0.11, accuracy:  37.50%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 1.6099, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 1.6117, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 1.5679, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 1.6951, batch time: 0.08, accuracy:  42.97%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 1.6280173063278198, accuracy: 42.8 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 1.6656203269958496, accuracy: 41.4 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 1.6685090065002441, accuracy: 42.6 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 1.6670030355453491, accuracy: 43.1 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 1.5748203992843628, accuracy: 45.1 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 1.5734405517578125, accuracy: 44.9 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 1.5735059976577759, accuracy: 44.6 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 1.568992257118225, accuracy: 44.8 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 1.60621178150177, accuracy: 42.8 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 1.567128300666809, accuracy: 44.8 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 1.5293, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 1.6785, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 1.7101, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 1.5651, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 1.6290, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.5185, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 1.6428, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 1.5528, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 1.5529, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 1.6681, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 1.6440882682800293, accuracy: 44.1 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 1.876928448677063, accuracy: 36.1 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 2.169466257095337, accuracy: 28.2 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 1.669012188911438, accuracy: 41.8 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 1.6356866359710693, accuracy: 44.0 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 1.6296017169952393, accuracy: 43.6 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 1.6395258903503418, accuracy: 44.1 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 1.6731617450714111, accuracy: 42.1 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 1.6415199041366577, accuracy: 45.1 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 1.6178224086761475, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 1.5832, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 1.4712, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 1.5310, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 1.5515, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 1.8035, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 1.5497, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 1.6139, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 1.5884, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 1.8163, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 1.6150, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 1.721430778503418, accuracy: 39.9 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 1.8635817766189575, accuracy: 34.6 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 2.0887715816497803, accuracy: 32.8 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 1.656145453453064, accuracy: 40.6 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 1.6645455360412598, accuracy: 40.6 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 1.6737265586853027, accuracy: 40.8 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 1.6638437509536743, accuracy: 40.3 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 1.6435294151306152, accuracy: 41.2 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 1.6591825485229492, accuracy: 40.8 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 1.639286994934082, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 1.7262, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 1.6444, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 1.7887, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 1.5288, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 1.6946, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 1.6310, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 1.5782, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 1.6093, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 1.5847, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 1.6252, batch time: 0.11, accuracy:  43.75%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 1.5857666730880737, accuracy: 44.9 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 2.0993692874908447, accuracy: 34.4 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 1.5985822677612305, accuracy: 45.3 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 1.9184805154800415, accuracy: 34.5 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 1.5803014039993286, accuracy: 44.7 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 1.5735011100769043, accuracy: 44.1 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 1.5943784713745117, accuracy: 43.2 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 1.5956560373306274, accuracy: 44.1 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 1.6149710416793823, accuracy: 44.3 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 1.5736383199691772, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 1.4332, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 1.6427, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 1.5268, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 1.5949, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 1.8156, batch time: 0.10, accuracy:  33.59%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 1.6726, batch time: 0.11, accuracy:  36.72%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 1.6853, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 1.5956, batch time: 0.08, accuracy:  44.53%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 1.4575, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 1.4297, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 1.5878351926803589, accuracy: 43.3 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 2.4974234104156494, accuracy: 28.0 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 1.6708669662475586, accuracy: 41.3 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 1.8992952108383179, accuracy: 37.0 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 1.6149566173553467, accuracy: 40.7 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 1.580213189125061, accuracy: 43.2 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 1.5793020725250244, accuracy: 43.3 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 1.6121482849121094, accuracy: 41.6 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 1.5928422212600708, accuracy: 42.6 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 1.57671058177948, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 1.6753, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 1.5538, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 1.6320, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 1.7490, batch time: 0.10, accuracy:  35.94%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 1.5621, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 1.5511, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 1.5757, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 1.5665, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 1.4959, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 1.6587, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 1.5563416481018066, accuracy: 45.1 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 1.5503467321395874, accuracy: 45.2 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 1.5349642038345337, accuracy: 45.0 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 1.5349642038345337, accuracy: 45.0 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 1.690697193145752, accuracy: 39.6 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 1.5289748907089233, accuracy: 46.3 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 1.5417059659957886, accuracy: 45.3 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 1.5426733493804932, accuracy: 45.9 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 1.524953842163086, accuracy: 46.4 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 1.5206685066223145, accuracy: 46.4 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 1.8432, batch time: 0.10, accuracy:  32.03%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 1.6056, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 1.6259, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 1.6337, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 1.5304, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 1.6096, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 1.4801, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 1.5393, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 1.5452, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 1.3957, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 1.6194114685058594, accuracy: 43.8 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 2.8225207328796387, accuracy: 25.3 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 2.3577721118927, accuracy: 28.9 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 2.826667308807373, accuracy: 21.3 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 1.6111541986465454, accuracy: 45.1 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 1.6042065620422363, accuracy: 43.1 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 1.770732045173645, accuracy: 39.3 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 1.7387751340866089, accuracy: 40.5 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 1.5937919616699219, accuracy: 45.0 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 1.589654803276062, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 1.5581, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 1.4605, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 1.5808, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 1.6522, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 1.6934, batch time: 0.06, accuracy:  39.06%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 1.6349, batch time: 0.05, accuracy:  38.28%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 1.4451, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 1.7000, batch time: 0.06, accuracy:  43.75%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 1.6981, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 1.5202, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 1.5713437795639038, accuracy: 44.4 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 2.8555941581726074, accuracy: 28.3 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 1.6577997207641602, accuracy: 43.2 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 1.7404096126556396, accuracy: 40.0 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 1.6008704900741577, accuracy: 45.2 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 1.5467183589935303, accuracy: 44.4 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 1.5449081659317017, accuracy: 45.0 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 1.5424189567565918, accuracy: 44.7 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 1.539766550064087, accuracy: 44.8 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 1.5384882688522339, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 1.5897, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 1.4272, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 1.5860, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 1.4688, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 1.5060, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 1.5802, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 1.6348, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 1.5360, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 1.5792, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 1.5352, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 1.6110947132110596, accuracy: 43.8 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 2.746325969696045, accuracy: 27.7 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 1.6603326797485352, accuracy: 43.2 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 6.358171463012695, accuracy: 11.0 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 1.5917848348617554, accuracy: 44.5 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 1.63906991481781, accuracy: 43.4 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 1.5959275960922241, accuracy: 45.4 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 1.5837204456329346, accuracy: 44.9 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 1.5824049711227417, accuracy: 44.7 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 1.5813437700271606, accuracy: 45.4 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 1.4351, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.4987, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 1.5976, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 1.4058, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 1.6609, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 1.6566, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 1.6827, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 1.6031, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 1.6371, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 1.5263, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 1.514585256576538, accuracy: 46.4 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 1.6742162704467773, accuracy: 41.4 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 1.5062743425369263, accuracy: 46.4 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 1.5062743425369263, accuracy: 46.4 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 1.6240904331207275, accuracy: 42.5 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 1.5021638870239258, accuracy: 46.9 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 1.4938372373580933, accuracy: 47.9 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 1.4900022745132446, accuracy: 47.7 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 1.49477219581604, accuracy: 47.2 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 1.506974697113037, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 1.4924, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 1.5009, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 1.5462, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 1.5239, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 1.4270, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 1.4435, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 1.6986, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 1.7456, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 1.6756, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 1.5299, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 1.5591126680374146, accuracy: 46.7 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 1.6821004152297974, accuracy: 43.0 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 1.5163846015930176, accuracy: 45.8 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 1.5163846015930176, accuracy: 45.8 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 1.5524386167526245, accuracy: 45.7 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 1.503722906112671, accuracy: 47.0 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 1.5209623575210571, accuracy: 47.6 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 1.5313646793365479, accuracy: 47.7 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 1.500090479850769, accuracy: 48.3 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 1.4980945587158203, accuracy: 48.3 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 1.7588, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 1.5725, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 1.5290, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 1.6362, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 1.4891, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 1.5244, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 1.5474, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 1.6129, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 1.4555, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 1.5936, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 1.5249627828598022, accuracy: 47.6 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 1.5212270021438599, accuracy: 46.5 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 1.5209861993789673, accuracy: 47.7 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 1.5209861993789673, accuracy: 47.7 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 2.797520637512207, accuracy: 23.2 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 1.5076026916503906, accuracy: 47.8 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 1.5198163986206055, accuracy: 47.5 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 1.5059030055999756, accuracy: 47.5 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 1.5524635314941406, accuracy: 44.8 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 1.5048246383666992, accuracy: 48.0 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 1.5855, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 1.6190, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 1.6037, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 1.5239, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 1.5892, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 1.4752, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 1.7134, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 1.5312, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 1.5458, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 1.5617, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 1.5861220359802246, accuracy: 45.2 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 3.870025873184204, accuracy: 18.8 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 1.7855546474456787, accuracy: 37.8 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 1.6638617515563965, accuracy: 43.8 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 1.555724024772644, accuracy: 46.8 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 1.5600918531417847, accuracy: 45.4 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 1.5816771984100342, accuracy: 43.4 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 1.5497299432754517, accuracy: 47.1 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 1.5483723878860474, accuracy: 46.3 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 1.545045018196106, accuracy: 47.1 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 1.5129, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 1.5593, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 1.7450, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 1.5861, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 1.5184, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 1.4780, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 1.4234, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 1.6203, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 1.3787, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 1.4930, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 1.501200556755066, accuracy: 47.6 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 1.6344588994979858, accuracy: 44.4 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 1.6277544498443604, accuracy: 43.6 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 2.2254765033721924, accuracy: 27.7 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 1.5063849687576294, accuracy: 48.4 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 1.48224675655365, accuracy: 48.6 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 1.485953450202942, accuracy: 48.9 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 1.4833767414093018, accuracy: 49.3 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 1.5442789793014526, accuracy: 46.1 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 1.4791853427886963, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 1.6655, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 1.5990, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 1.4937, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 1.5660, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 1.3932, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 1.5480, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 1.4243, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 1.6101, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 1.4866, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 1.4128, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 1.5243793725967407, accuracy: 47.8 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 1.5851035118103027, accuracy: 46.8 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 1.7659127712249756, accuracy: 40.2 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 9.527222633361816, accuracy: 10.4 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 1.6519343852996826, accuracy: 44.8 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 1.5392333269119263, accuracy: 48.2 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 1.5116711854934692, accuracy: 48.8 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 1.5058270692825317, accuracy: 49.4 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 1.5062615871429443, accuracy: 48.4 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 1.5019205808639526, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 1.8423, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 1.5307, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 1.5147, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 1.4343, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 1.5910, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 1.6394, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 1.3422, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 1.6091, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 1.7248, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 1.5178, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 1.5040713548660278, accuracy: 46.9 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 1.9417188167572021, accuracy: 35.0 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 1.668898344039917, accuracy: 42.4 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 1.5196772813796997, accuracy: 47.5 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 1.521032452583313, accuracy: 46.7 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 1.499351978302002, accuracy: 46.8 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 1.4969574213027954, accuracy: 46.7 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 1.494654655456543, accuracy: 46.9 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 1.4946401119232178, accuracy: 47.1 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 1.4947561025619507, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.4578, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 1.4387, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 1.5807, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 1.4313, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.4119, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 1.4365, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.6020, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 1.3318, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 1.5823, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 1.4702, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 1.512759804725647, accuracy: 48.8 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 1.9024100303649902, accuracy: 36.3 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 1.6565101146697998, accuracy: 44.1 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 7.882681369781494, accuracy: 20.0 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 1.51131010055542, accuracy: 49.8 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 1.5188642740249634, accuracy: 47.6 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 1.4844645261764526, accuracy: 49.1 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 1.4840236902236938, accuracy: 48.7 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 1.4821524620056152, accuracy: 49.1 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 1.4829223155975342, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.6886, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 1.6538, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 1.4692, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 1.5867, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 1.6108, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 1.5619, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 1.5782, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 1.6175, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 1.6357, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 1.5908, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 1.4917421340942383, accuracy: 50.1 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 2.269577980041504, accuracy: 36.6 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 1.7048630714416504, accuracy: 42.3 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 3.4337759017944336, accuracy: 22.3 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 1.5216405391693115, accuracy: 48.2 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 1.46066415309906, accuracy: 49.9 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 1.6133017539978027, accuracy: 44.3 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 1.450176477432251, accuracy: 49.0 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 1.446818470954895, accuracy: 49.5 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 1.4464420080184937, accuracy: 51.0 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 1.5252, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 1.6365, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 1.4636, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 1.7114, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 1.4498, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 1.6017, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 1.4391, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 1.5657, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 1.3724, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 1.6006, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 1.4464752674102783, accuracy: 52.0 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 2.3622004985809326, accuracy: 32.1 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 1.7067310810089111, accuracy: 44.1 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 1.5890257358551025, accuracy: 49.1 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 1.4397329092025757, accuracy: 52.4 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 1.4368128776550293, accuracy: 51.8 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 1.4561021327972412, accuracy: 51.9 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 1.483182668685913, accuracy: 51.2 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 1.4386591911315918, accuracy: 51.6 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 1.4328469038009644, accuracy: 51.9 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 1.4905, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 1.5579, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 1.4956, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 1.2645, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 1.6719, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 1.2811, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 1.5534, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 1.4915, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 1.4434, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.2829, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 1.4748468399047852, accuracy: 49.9 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 2.2391231060028076, accuracy: 34.4 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 1.7571178674697876, accuracy: 40.4 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 2.3070614337921143, accuracy: 33.9 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 1.4813932180404663, accuracy: 51.0 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 1.5269830226898193, accuracy: 48.2 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 1.5033622980117798, accuracy: 47.9 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 1.4582972526550293, accuracy: 50.7 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 1.456087589263916, accuracy: 49.9 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 1.455453872680664, accuracy: 50.5 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 1.3502, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 1.5378, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 1.4250, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 1.5152, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 1.4408, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 1.5439, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 1.4971, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 1.5226, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 1.4083, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.3777, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 1.5263370275497437, accuracy: 50.4 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 2.144214391708374, accuracy: 37.1 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 1.7717676162719727, accuracy: 39.6 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 4.486443996429443, accuracy: 18.7 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 1.557485818862915, accuracy: 48.8 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 1.5315444469451904, accuracy: 49.9 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 1.462878942489624, accuracy: 49.2 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 1.4624652862548828, accuracy: 50.0 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 1.4573675394058228, accuracy: 50.6 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 1.4520072937011719, accuracy: 51.0 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 1.4890, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 1.5473, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 1.4626, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 1.3497, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 1.2940, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 1.4636, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 1.4241, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 1.5621, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 1.5444, batch time: 0.24, accuracy:  56.25%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 1.3791, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 1.4105947017669678, accuracy: 52.7 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 1.5567905902862549, accuracy: 47.1 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 2.936788320541382, accuracy: 26.0 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 3.6713778972625732, accuracy: 23.9 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 1.4101778268814087, accuracy: 52.3 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 1.402752161026001, accuracy: 53.7 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 1.4280545711517334, accuracy: 52.5 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 1.4572731256484985, accuracy: 52.5 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 1.3992701768875122, accuracy: 53.6 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 1.3980581760406494, accuracy: 53.6 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 1.5981, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 1.5104, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 1.4976, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 1.5054, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 1.4093, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 1.6035, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 1.4833, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 1.5951, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 1.3672, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 1.5118, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 1.4130730628967285, accuracy: 52.4 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 1.5185267925262451, accuracy: 47.4 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 1.7365763187408447, accuracy: 44.7 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 1.8821419477462769, accuracy: 34.1 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 1.409665584564209, accuracy: 52.8 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 1.4089000225067139, accuracy: 52.7 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 1.4828356504440308, accuracy: 50.4 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 1.4278473854064941, accuracy: 51.6 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 1.403248906135559, accuracy: 52.6 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 1.39983332157135, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 1.3628, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 1.4888, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 1.3248, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 1.5594, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 1.4547, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 1.5591, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 1.5893, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 1.4361, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 1.3782, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 1.5066, batch time: 0.08, accuracy:  55.47%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 1.536289930343628, accuracy: 50.2 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 2.2453737258911133, accuracy: 29.6 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 3.0672144889831543, accuracy: 17.3 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 2.2820546627044678, accuracy: 29.1 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 1.4950190782546997, accuracy: 49.6 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 1.5966894626617432, accuracy: 45.6 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 1.7301558256149292, accuracy: 42.6 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 1.5321898460388184, accuracy: 49.8 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 1.4747241735458374, accuracy: 51.4 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 1.4733480215072632, accuracy: 50.7 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 1.5201, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 1.5335, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 1.2946, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 1.2828, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.4624, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 1.4582, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 1.5231, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 1.3511, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 1.5640, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 1.3801, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 1.4553784132003784, accuracy: 50.7 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.4868215322494507, accuracy: 49.5 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 1.741512656211853, accuracy: 43.9 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 4.403184413909912, accuracy: 21.2 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 1.4752604961395264, accuracy: 50.1 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 1.4367676973342896, accuracy: 50.7 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 1.5619693994522095, accuracy: 48.9 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 1.4346702098846436, accuracy: 50.9 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 1.4328709840774536, accuracy: 50.7 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 1.430084228515625, accuracy: 50.9 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 1.5265, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 1.5903, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.2774, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 1.2964, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 1.3234, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 1.3717, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 1.6067, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 1.3735, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.4948, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 1.4429, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 1.422040581703186, accuracy: 51.7 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 1.4414750337600708, accuracy: 51.4 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 1.616784930229187, accuracy: 45.0 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 2.1589181423187256, accuracy: 34.5 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 1.4283616542816162, accuracy: 51.6 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 1.4160900115966797, accuracy: 52.9 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 1.4393519163131714, accuracy: 50.9 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 1.4102007150650024, accuracy: 52.9 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 1.4098457098007202, accuracy: 52.4 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 1.4087176322937012, accuracy: 52.3 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.3622, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 1.5540, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.3601, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 1.4019, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.3330, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 1.2711, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.4185, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.3593, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 1.5158, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 1.4566, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 1.4892925024032593, accuracy: 49.5 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.5343947410583496, accuracy: 48.5 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 1.4886325597763062, accuracy: 49.3 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 1.4880375862121582, accuracy: 48.3 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 1.4881391525268555, accuracy: 49.0 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 1.4812233448028564, accuracy: 49.0 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 1.476550817489624, accuracy: 47.9 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 1.474310278892517, accuracy: 48.9 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 1.4784793853759766, accuracy: 48.9 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 1.5021460056304932, accuracy: 47.7 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 1.5288, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 1.4851, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.3265, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 1.6643, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 1.4845, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 1.4837, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.4016, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 1.6328, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 1.4337, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 1.5890, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 1.4212312698364258, accuracy: 51.5 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 1.4781675338745117, accuracy: 50.5 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 1.5738493204116821, accuracy: 47.3 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 1.4453394412994385, accuracy: 52.6 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 1.402817964553833, accuracy: 53.5 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 1.4017294645309448, accuracy: 52.8 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 1.4028127193450928, accuracy: 53.3 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 1.3991038799285889, accuracy: 53.3 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 1.399725079536438, accuracy: 53.3 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 1.3972188234329224, accuracy: 53.3 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 1.2490, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 1.5335, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.2410, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 1.4049, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 1.4466, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.4606, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.3309, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.5959, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.3891, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 1.4054, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 1.4581466913223267, accuracy: 51.9 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 1.8968144655227661, accuracy: 41.7 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 1.6896122694015503, accuracy: 45.5 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 7.362644195556641, accuracy: 18.6 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 1.4557613134384155, accuracy: 49.7 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 1.446985125541687, accuracy: 51.7 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 1.7365703582763672, accuracy: 42.5 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 1.5461620092391968, accuracy: 51.2 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 1.5856354236602783, accuracy: 48.6 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 1.4422396421432495, accuracy: 52.3 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.5770, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.4538, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.3496, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 1.4100, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.3163, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.3390, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.4108, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.3949, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.5209, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.3506, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 1.4809514284133911, accuracy: 51.5 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 2.2159311771392822, accuracy: 33.8 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 1.4789854288101196, accuracy: 51.7 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 2.9805967807769775, accuracy: 26.4 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 1.8592406511306763, accuracy: 40.1 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 1.4634615182876587, accuracy: 51.8 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 1.4797793626785278, accuracy: 51.9 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 1.488617181777954, accuracy: 51.0 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 1.470259189605713, accuracy: 51.8 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 1.4649946689605713, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.4373, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.4991, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 1.4174, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.4826, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.3354, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.2228, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.5684, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 1.4470, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 1.5253, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.2680, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 1.3398005962371826, accuracy: 55.4 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 2.217618942260742, accuracy: 35.9 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 1.5449200868606567, accuracy: 50.4 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 4.398412704467773, accuracy: 19.9 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 1.3580073118209839, accuracy: 55.1 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 1.3346707820892334, accuracy: 55.2 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 1.3329761028289795, accuracy: 55.0 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 1.3295484781265259, accuracy: 54.8 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 1.3294050693511963, accuracy: 55.1 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 1.33174729347229, accuracy: 55.1 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 1.3910, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 1.5775, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.2605, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.3078, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 1.5369, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 1.4650, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.3315, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 1.5587, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.4928, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.5044, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 1.3987964391708374, accuracy: 52.7 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 2.4603395462036133, accuracy: 29.0 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 1.4544717073440552, accuracy: 49.0 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 2.375870704650879, accuracy: 31.9 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 1.4016374349594116, accuracy: 53.1 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 1.3950470685958862, accuracy: 53.4 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 1.4273314476013184, accuracy: 52.3 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 1.4294319152832031, accuracy: 51.1 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.4370509386062622, accuracy: 52.7 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 1.3840315341949463, accuracy: 54.4 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.4056, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.3264, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.5440, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 1.2427, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.6631, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.3511, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.4495, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.4010, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.6530, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 1.3776, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 1.3808002471923828, accuracy: 56.2 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 2.088489294052124, accuracy: 37.1 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 1.4434205293655396, accuracy: 53.0 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 5.18117094039917, accuracy: 12.5 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 1.5663390159606934, accuracy: 49.3 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 1.4091861248016357, accuracy: 53.3 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 1.3867065906524658, accuracy: 54.7 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 1.3743340969085693, accuracy: 55.5 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 1.373813271522522, accuracy: 55.1 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 1.3729525804519653, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.5557, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.3508, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.3865, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.5201, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.2376, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.3781, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.5211, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.3832, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.3341, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.2139, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 1.4102100133895874, accuracy: 53.3 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 2.237138032913208, accuracy: 34.4 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 1.6504757404327393, accuracy: 47.4 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 4.792057991027832, accuracy: 17.9 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 1.449440360069275, accuracy: 51.4 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 1.4130362272262573, accuracy: 52.8 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 1.4076768159866333, accuracy: 53.3 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 1.405381202697754, accuracy: 53.6 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 1.4057058095932007, accuracy: 53.4 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 1.4055176973342896, accuracy: 53.2 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.3592, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.3522, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.1799, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.4504, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.3772, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.4709, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.4882, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.3181, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 1.4242, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.4438, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 1.3804770708084106, accuracy: 53.8 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 2.4208786487579346, accuracy: 36.5 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 1.6365207433700562, accuracy: 46.9 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 1.972263216972351, accuracy: 42.1 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 1.398953914642334, accuracy: 54.1 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 1.4087493419647217, accuracy: 52.7 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 1.4446767568588257, accuracy: 52.3 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 1.372489094734192, accuracy: 54.9 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 1.3719373941421509, accuracy: 54.6 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 1.3708568811416626, accuracy: 55.1 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.4496, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 1.5457, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 1.4990, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.4934, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 1.2524, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.4655, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.4793, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.3622, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.3906, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.4947, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 1.433263897895813, accuracy: 54.1 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 2.4849278926849365, accuracy: 33.6 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 1.6634516716003418, accuracy: 44.5 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 1.9753750562667847, accuracy: 38.1 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 1.4228754043579102, accuracy: 53.4 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 1.3999075889587402, accuracy: 54.0 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 1.4926873445510864, accuracy: 50.1 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 1.3971667289733887, accuracy: 53.7 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 1.397573709487915, accuracy: 54.4 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 1.395963191986084, accuracy: 54.4 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.4151, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.3957, batch time: 0.06, accuracy:  55.47%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.3813, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.4541, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.5131, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.3779, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.4402, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.4666, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.4031, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.4159, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 1.368235468864441, accuracy: 54.7 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 2.446795701980591, accuracy: 35.0 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 1.5932339429855347, accuracy: 46.5 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 2.1729156970977783, accuracy: 35.1 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.3685598373413086, accuracy: 53.7 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.3703463077545166, accuracy: 54.1 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 1.364051103591919, accuracy: 53.5 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 1.360076904296875, accuracy: 54.6 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 1.3737938404083252, accuracy: 53.3 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 1.3636094331741333, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.3685, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.4500, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 1.6016, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.4391, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.5053, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.4871, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.4614, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.3740, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.4667, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.2734, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 1.3970575332641602, accuracy: 51.9 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 1.4510868787765503, accuracy: 53.2 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 1.5859813690185547, accuracy: 46.7 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 5.186961650848389, accuracy: 23.2 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 1.437015414237976, accuracy: 51.6 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 1.4271745681762695, accuracy: 51.9 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 1.4426075220108032, accuracy: 52.5 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 1.8681246042251587, accuracy: 36.7 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 1.3782880306243896, accuracy: 54.5 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 1.3763142824172974, accuracy: 54.4 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.3606, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.5495, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.5786, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.3492, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.5062, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.4273, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.4163, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.3433, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.1817, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.4146, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 1.3868581056594849, accuracy: 54.6 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 1.4359909296035767, accuracy: 52.0 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 1.5824235677719116, accuracy: 48.2 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 1.928554892539978, accuracy: 40.8 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 1.4161250591278076, accuracy: 53.9 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.4406052827835083, accuracy: 53.0 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 1.3797316551208496, accuracy: 55.0 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 1.4267542362213135, accuracy: 52.0 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 1.3768538236618042, accuracy: 54.5 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 1.3764655590057373, accuracy: 54.9 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.3892, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.4093, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.2860, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.3335, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.4338, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.2256, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.2946, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.5268, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.5370, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.3539, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 1.4367520809173584, accuracy: 51.7 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 14.908442497253418, accuracy: 12.4 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 1.8689666986465454, accuracy: 42.4 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 1.739966869354248, accuracy: 42.8 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 1.4446073770523071, accuracy: 52.3 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 1.4305237531661987, accuracy: 51.8 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 1.5116519927978516, accuracy: 48.0 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 1.426205039024353, accuracy: 51.5 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 1.4262182712554932, accuracy: 51.4 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 1.4245022535324097, accuracy: 51.6 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.3275, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.3240, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.5866, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.3828, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.3245, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.3392, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.3253, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.4001, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.4091, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.1872, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 1.3677390813827515, accuracy: 53.8 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 2.277418613433838, accuracy: 34.5 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 1.6290998458862305, accuracy: 45.2 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 1.7020838260650635, accuracy: 45.3 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 1.50984525680542, accuracy: 50.2 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 1.5898174047470093, accuracy: 47.8 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 1.4287073612213135, accuracy: 51.6 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 2.3915040493011475, accuracy: 31.1 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 1.3598928451538086, accuracy: 53.4 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 1.358512282371521, accuracy: 53.6 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.3972, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.3514, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.2414, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.3394, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.2725, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.3188, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.4945, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.4384, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.4890, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.2567, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 1.38172447681427, accuracy: 54.6 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 2.544173002243042, accuracy: 29.8 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 1.6857085227966309, accuracy: 41.9 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 2.65667986869812, accuracy: 29.5 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 1.4052327871322632, accuracy: 53.5 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 1.3670778274536133, accuracy: 55.0 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 1.3621859550476074, accuracy: 55.5 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 1.3624039888381958, accuracy: 55.4 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 1.3604376316070557, accuracy: 55.3 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 1.3595554828643799, accuracy: 56.0 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.4841, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.6170, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.4519, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.2440, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.3419, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.4837, batch time: 0.11, accuracy:  46.09%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.4034, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.2844, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.3759, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.3749, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 1.3876453638076782, accuracy: 54.8 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 2.209085464477539, accuracy: 33.9 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 1.652305245399475, accuracy: 45.2 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 5.465116500854492, accuracy: 11.0 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 1.3891509771347046, accuracy: 55.2 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 1.3826282024383545, accuracy: 54.9 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 1.3796687126159668, accuracy: 54.1 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 1.3785443305969238, accuracy: 54.6 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 1.3800082206726074, accuracy: 53.9 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 1.3808330297470093, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.4053, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.5924, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.2732, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.1644, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.3896, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.3240, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.3342, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.3990, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.2776, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.3707, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 1.353190541267395, accuracy: 54.5 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 2.4222328662872314, accuracy: 30.9 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 1.640061855316162, accuracy: 45.9 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 6.095733165740967, accuracy: 9.1 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 1.4380898475646973, accuracy: 52.4 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 1.3422783613204956, accuracy: 53.8 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 1.3379626274108887, accuracy: 54.5 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 1.333896279335022, accuracy: 54.6 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 1.3349378108978271, accuracy: 55.0 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 1.332879662513733, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.3826, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.2807, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.2797, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.2298, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.5489, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.3338, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.6827, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.2270, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.3857, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.4940, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 1.3757548332214355, accuracy: 57.0 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 2.2738211154937744, accuracy: 35.1 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 1.5681383609771729, accuracy: 50.5 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 4.313586711883545, accuracy: 14.4 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 1.4385457038879395, accuracy: 53.2 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 1.4174431562423706, accuracy: 55.5 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 1.3754879236221313, accuracy: 56.5 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 1.371910572052002, accuracy: 56.8 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 1.3716449737548828, accuracy: 57.2 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 1.3708323240280151, accuracy: 56.8 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.4826, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.5371, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.3227, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.4146, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.4208, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.3808, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.2994, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.4812, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.4546, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.3059, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 1.317618489265442, accuracy: 56.6 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 2.278763771057129, accuracy: 35.5 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 1.5061793327331543, accuracy: 51.6 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 3.9938530921936035, accuracy: 27.9 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 1.3765218257904053, accuracy: 54.2 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 1.334012746810913, accuracy: 55.9 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 1.295409917831421, accuracy: 57.8 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 1.2943702936172485, accuracy: 57.4 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 1.294780969619751, accuracy: 57.3 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 1.2945326566696167, accuracy: 57.2 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.5414, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.3280, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.2667, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.4286, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.3805, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.4786, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.1994, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.3843, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.4491, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.2791, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 1.3747903108596802, accuracy: 53.3 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 2.523442268371582, accuracy: 32.4 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 1.593071699142456, accuracy: 47.3 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 6.331491470336914, accuracy: 18.5 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 1.391598105430603, accuracy: 53.4 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 1.3944013118743896, accuracy: 53.2 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 1.3631690740585327, accuracy: 54.4 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 1.3622268438339233, accuracy: 54.0 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 1.365823745727539, accuracy: 54.2 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 1.3505055904388428, accuracy: 54.2 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.3567, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.5228, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.4484, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.4165, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.3251, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.2692, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.5463, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.3724, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.3104, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.3875, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 1.3337596654891968, accuracy: 57.2 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 2.3554062843322754, accuracy: 35.0 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 1.5595020055770874, accuracy: 49.6 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 5.1026930809021, accuracy: 21.4 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 1.3216252326965332, accuracy: 56.6 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 1.3681944608688354, accuracy: 55.0 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 1.3199135065078735, accuracy: 57.0 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 1.3875312805175781, accuracy: 53.9 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 1.316334843635559, accuracy: 56.7 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 1.314538598060608, accuracy: 56.7 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.3403, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.3860, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.4328, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.5306, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.1312, batch time: 0.05, accuracy:  69.53%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.4126, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.2774, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.4481, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.3892, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.4294, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 1.426184892654419, accuracy: 51.7 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 1.453416109085083, accuracy: 49.7 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 1.80756676197052, accuracy: 43.6 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 2.4195845127105713, accuracy: 29.8 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 1.4187697172164917, accuracy: 52.5 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 1.4183164834976196, accuracy: 50.8 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 1.44058096408844, accuracy: 52.4 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 1.43621027469635, accuracy: 50.7 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 1.4769164323806763, accuracy: 50.0 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 1.417420506477356, accuracy: 51.0 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.2498, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.2924, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.3277, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.4394, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.3913, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.4686, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.2173, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.3402, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.2190, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.4119, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 1.3471503257751465, accuracy: 55.0 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 2.373474597930908, accuracy: 31.2 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 1.5507768392562866, accuracy: 46.8 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 1.434536337852478, accuracy: 53.7 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 1.3668380975723267, accuracy: 54.9 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 1.3854299783706665, accuracy: 52.8 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 1.4157065153121948, accuracy: 53.4 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 1.3379955291748047, accuracy: 54.6 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 1.3375946283340454, accuracy: 54.5 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 1.3418728113174438, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.3468, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.3943, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.4051, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.1564, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.4400, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.4398, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.4307, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.4607, batch time: 0.06, accuracy:  56.25%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.4076, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.3704, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 1.4314419031143188, accuracy: 52.2 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 2.595973253250122, accuracy: 30.3 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 1.6613757610321045, accuracy: 43.0 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 2.2497568130493164, accuracy: 29.8 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 1.4232614040374756, accuracy: 52.0 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 1.409178376197815, accuracy: 52.4 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 1.4135596752166748, accuracy: 52.2 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 1.405168056488037, accuracy: 53.1 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 1.407260537147522, accuracy: 52.7 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 1.4032480716705322, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.4740, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.3868, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.5109, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.3665, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.2348, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.4774, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.2632, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.4402, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.2629, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.4415, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 1.4085081815719604, accuracy: 53.4 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 1.4982645511627197, accuracy: 50.4 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 1.4035106897354126, accuracy: 52.6 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 1.4035106897354126, accuracy: 52.6 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.3921012878417969, accuracy: 53.2 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 1.3902825117111206, accuracy: 52.7 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 1.3907204866409302, accuracy: 52.9 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 1.4022748470306396, accuracy: 52.7 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 1.3930354118347168, accuracy: 52.2 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 1.3870830535888672, accuracy: 51.9 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.4458, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.4314, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.5215, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.3345, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.3061, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.4197, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.3355, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.2359, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.4449, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.4112, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 1.4091390371322632, accuracy: 52.5 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 2.5447587966918945, accuracy: 26.0 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 1.6721208095550537, accuracy: 42.9 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 3.1197972297668457, accuracy: 22.8 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 1.3982956409454346, accuracy: 52.4 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 1.449791431427002, accuracy: 50.6 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 1.627343773841858, accuracy: 46.1 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 1.3929859399795532, accuracy: 52.8 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 1.3924531936645508, accuracy: 53.2 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 1.3917491436004639, accuracy: 53.1 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.3906, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.4390, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.3151, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.2135, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.4912, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.3268, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.3045, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.3440, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.4741, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.4770, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 1.3485203981399536, accuracy: 56.8 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 1.3731242418289185, accuracy: 54.3 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 2.8084709644317627, accuracy: 29.0 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 1.3235687017440796, accuracy: 55.9 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 1.3308534622192383, accuracy: 55.9 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 1.3131513595581055, accuracy: 55.7 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 1.4425503015518188, accuracy: 51.0 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 1.3117620944976807, accuracy: 55.7 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 1.3100645542144775, accuracy: 55.9 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 1.3108335733413696, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.3530, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.2906, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.4746, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.4548, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.4244, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.4363, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.3309, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.3335, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.3370, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.4107, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 1.362541675567627, accuracy: 54.5 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 2.5171291828155518, accuracy: 28.7 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 1.595770239830017, accuracy: 45.5 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 5.812771797180176, accuracy: 14.2 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 1.428755283355713, accuracy: 52.5 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 1.353163480758667, accuracy: 54.7 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 1.3527535200119019, accuracy: 54.9 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 1.349365472793579, accuracy: 55.5 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 1.3486090898513794, accuracy: 55.1 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 1.3474763631820679, accuracy: 55.7 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.3585, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.5229, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.4290, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.5086, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.5710, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.3869, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.4190, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.5025, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.5103, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.3358, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 1.3749067783355713, accuracy: 54.0 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 2.6556968688964844, accuracy: 31.1 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 1.6249428987503052, accuracy: 44.1 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 2.758134126663208, accuracy: 23.4 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 1.5363997220993042, accuracy: 47.6 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 1.4163028001785278, accuracy: 53.8 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 1.3638522624969482, accuracy: 55.2 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 1.3557606935501099, accuracy: 56.4 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 1.3563041687011719, accuracy: 55.5 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 1.3549578189849854, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.2570, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.5420, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.3249, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.5087, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.3171, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.3510, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.3866, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.2933, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.5569, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.2653, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 1.3712282180786133, accuracy: 54.9 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 1.5038363933563232, accuracy: 50.5 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 3.0897932052612305, accuracy: 31.2 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 1.3638968467712402, accuracy: 55.6 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 1.4136543273925781, accuracy: 53.4 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 1.359677791595459, accuracy: 54.5 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 1.6712726354599, accuracy: 48.1 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 1.3658314943313599, accuracy: 55.5 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 1.3550866842269897, accuracy: 55.3 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 1.3532676696777344, accuracy: 55.3 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.3495, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.2934, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.3550, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.3758, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.1758, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.3979, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.4091, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.4671, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.2131, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.5536, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 1.3637758493423462, accuracy: 54.1 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 2.865196943283081, accuracy: 27.9 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 1.5524965524673462, accuracy: 46.7 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 14.805229187011719, accuracy: 20.4 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 1.4217239618301392, accuracy: 52.6 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 1.3490198850631714, accuracy: 54.2 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 1.3463677167892456, accuracy: 54.9 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 1.3461087942123413, accuracy: 54.8 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 1.3454136848449707, accuracy: 54.7 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 1.357096552848816, accuracy: 54.8 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.3043, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.5462, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.4912, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.3128, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.3053, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.2530, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.3383, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.3048, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.4217, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.4115, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 1.3574987649917603, accuracy: 54.8 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 3.0016696453094482, accuracy: 29.3 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 1.5852805376052856, accuracy: 49.2 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 11.081791877746582, accuracy: 11.7 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 1.3562290668487549, accuracy: 55.2 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 1.3720388412475586, accuracy: 54.3 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 1.3752938508987427, accuracy: 53.9 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 1.3571099042892456, accuracy: 55.2 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 1.3509756326675415, accuracy: 55.5 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 1.3497101068496704, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.5449, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.3302, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.3316, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.3716, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.1920, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.3142, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.4233, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.4962, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.4936, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.3819, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 1.4200122356414795, accuracy: 52.3 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.6388014554977417, accuracy: 43.9 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 1.4860597848892212, accuracy: 51.5 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 1.5526344776153564, accuracy: 49.5 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 1.398786187171936, accuracy: 53.4 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 1.4035820960998535, accuracy: 53.8 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 1.3940740823745728, accuracy: 53.2 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 1.667256236076355, accuracy: 46.1 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 1.4773510694503784, accuracy: 52.1 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 1.3832991123199463, accuracy: 53.9 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.3220, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.4698, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.5059, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.5022, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.5340, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.3955, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.4326, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.4837, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.3879, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.4436, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 1.3718637228012085, accuracy: 54.9 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 1.5268902778625488, accuracy: 49.6 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 1.6857848167419434, accuracy: 45.8 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 1.9122172594070435, accuracy: 40.4 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 1.3943554162979126, accuracy: 53.4 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 1.582220196723938, accuracy: 50.3 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 2.0076751708984375, accuracy: 37.2 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 1.3632124662399292, accuracy: 55.3 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 1.3614674806594849, accuracy: 55.8 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 1.3611658811569214, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.3164, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.5141, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.4069, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.4305, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.3638, batch time: 0.06, accuracy:  51.56%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.3873, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.2477, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.6529, batch time: 0.05, accuracy:  41.41%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.5065, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.4918, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 1.4048728942871094, accuracy: 52.6 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.4453601837158203, accuracy: 49.6 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 1.381767749786377, accuracy: 53.6 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.3797402381896973, accuracy: 53.9 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.5803171396255493, accuracy: 45.7 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 1.378150463104248, accuracy: 53.9 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 1.3776646852493286, accuracy: 53.5 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 1.3735437393188477, accuracy: 54.3 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 1.378821611404419, accuracy: 54.5 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 1.4292329549789429, accuracy: 52.8 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.3703, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.4097, batch time: 0.35, accuracy:  56.25%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.2236, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.3982, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.6202, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.3682, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.3023, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.3808, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.4264, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.4397, batch time: 0.25, accuracy:  50.00%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 1.39213228225708, accuracy: 54.4 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 2.4879403114318848, accuracy: 31.6 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 1.5471562147140503, accuracy: 47.2 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 1.8151812553405762, accuracy: 42.3 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 1.3792725801467896, accuracy: 55.3 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 1.307321310043335, accuracy: 56.9 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 1.3000500202178955, accuracy: 57.1 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 1.2957640886306763, accuracy: 56.9 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 1.294441819190979, accuracy: 57.0 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 1.2925751209259033, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.4001, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.2997, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.5280, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.3435, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.3995, batch time: 0.08, accuracy:  51.56%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.4629, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.3400, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.3495, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.4101, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.3253, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 1.3005801439285278, accuracy: 56.9 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 2.566103935241699, accuracy: 32.5 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 1.600291132926941, accuracy: 43.2 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 20.631364822387695, accuracy: 20.8 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 1.352278470993042, accuracy: 56.1 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 1.3163007497787476, accuracy: 56.0 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 1.288973331451416, accuracy: 57.1 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 1.2905611991882324, accuracy: 57.1 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 1.2847437858581543, accuracy: 57.6 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 1.283965826034546, accuracy: 57.3 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.4787, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.3484, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.3486, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.3842, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.4727, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.2375, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.3981, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.5659, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.1947, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.4325, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 1.3679922819137573, accuracy: 55.9 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 2.619666337966919, accuracy: 30.4 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 1.3688865900039673, accuracy: 55.9 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 3.5337584018707275, accuracy: 27.9 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 1.4237680435180664, accuracy: 53.3 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 1.3700940608978271, accuracy: 54.5 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 1.4010151624679565, accuracy: 54.5 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 1.3649563789367676, accuracy: 56.5 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 1.3673125505447388, accuracy: 56.0 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 1.3636407852172852, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.1670, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.4675, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.4693, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.3725, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.3469, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.3859, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.2323, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.2696, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.2556, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.1924, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 1.4102751016616821, accuracy: 52.9 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 2.5761313438415527, accuracy: 30.5 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 1.6636289358139038, accuracy: 43.0 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 2.8358395099639893, accuracy: 26.6 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 1.4556618928909302, accuracy: 50.5 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 1.3728852272033691, accuracy: 54.3 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 1.3751181364059448, accuracy: 54.4 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 1.3709713220596313, accuracy: 54.2 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 1.3715276718139648, accuracy: 54.1 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 1.3697354793548584, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.3523, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.3836, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.2017, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.3476, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.2423, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.2249, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.3105, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.3760, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.2421, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.4269, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 1.3830461502075195, accuracy: 53.4 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 2.71488094329834, accuracy: 30.7 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 1.3678114414215088, accuracy: 55.3 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 2.6790242195129395, accuracy: 22.9 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 1.3668357133865356, accuracy: 54.9 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 1.3640397787094116, accuracy: 55.6 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 1.3680764436721802, accuracy: 55.0 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 1.4759588241577148, accuracy: 52.8 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 1.3567862510681152, accuracy: 55.4 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 1.3507553339004517, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.4493, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.3602, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.3605, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.3909, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.4158, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.4168, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.3961, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.2608, batch time: 0.25, accuracy:  57.81%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.4077, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.3368, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 1.3898959159851074, accuracy: 52.2 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 2.6617226600646973, accuracy: 28.9 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 1.6546143293380737, accuracy: 41.8 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 8.057518005371094, accuracy: 14.9 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 1.5780216455459595, accuracy: 50.5 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 1.372467279434204, accuracy: 53.1 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 1.3647066354751587, accuracy: 53.9 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 1.3572802543640137, accuracy: 54.8 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 1.357970118522644, accuracy: 54.2 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 1.3547078371047974, accuracy: 54.4 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.4339, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.3557, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.4833, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 1.3740, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.3407, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.2520, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.4312, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.4803, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.4276, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.3382, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 1.3498433828353882, accuracy: 54.1 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 2.0360915660858154, accuracy: 39.8 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 1.5489193201065063, accuracy: 49.0 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 1.3086735010147095, accuracy: 56.5 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 1.3501880168914795, accuracy: 54.7 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 1.302695870399475, accuracy: 56.8 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 1.3016862869262695, accuracy: 57.1 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 1.295750617980957, accuracy: 57.7 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 1.2967209815979004, accuracy: 56.1 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 1.2921006679534912, accuracy: 57.3 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.4512, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.2942, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.3649, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.3142, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.3449, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.3425, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.5445, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.4272, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.4350, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.4579, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 1.3210687637329102, accuracy: 55.6 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 2.54079270362854, accuracy: 31.2 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 1.585036277770996, accuracy: 47.5 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 1.6697931289672852, accuracy: 47.4 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 1.3353341817855835, accuracy: 55.1 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 1.3958306312561035, accuracy: 52.7 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 1.3111059665679932, accuracy: 56.6 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 1.3111790418624878, accuracy: 56.4 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 1.3110222816467285, accuracy: 56.6 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 1.31776762008667, accuracy: 55.6 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.4125, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.2345, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.2317, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.2182, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.2973, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.3679, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.3925, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.3984, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.3621, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.3139, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 1.3553166389465332, accuracy: 54.6 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 1.4054313898086548, accuracy: 51.9 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 1.346487283706665, accuracy: 54.5 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 1.345328688621521, accuracy: 54.5 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 1.3582552671432495, accuracy: 52.8 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 1.3411436080932617, accuracy: 53.7 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 1.343459129333496, accuracy: 54.0 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 1.3471157550811768, accuracy: 52.9 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 1.6461442708969116, accuracy: 44.1 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 1.336593508720398, accuracy: 53.7 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.4645, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.4650, batch time: 0.08, accuracy:  53.91%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.4786, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.5104, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.3166, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.3698, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.3290, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.3767, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.4569, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.5299, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 1.3628225326538086, accuracy: 54.4 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 1.8715264797210693, accuracy: 40.5 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 1.5824941396713257, accuracy: 48.6 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 1.9782668352127075, accuracy: 39.4 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 1.3568655252456665, accuracy: 56.0 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 1.3492279052734375, accuracy: 54.5 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 1.3493461608886719, accuracy: 55.8 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 1.3470176458358765, accuracy: 55.2 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 1.3474669456481934, accuracy: 55.0 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 1.343971848487854, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.3821, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.3204, batch time: 0.06, accuracy:  59.38%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.4510, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.2988, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.2346, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.3560, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.2448, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.4372, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.3480, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.2928, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 1.341177225112915, accuracy: 55.4 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 2.3134396076202393, accuracy: 33.4 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 1.612000584602356, accuracy: 45.2 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 11.739884376525879, accuracy: 22.1 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 1.3484622240066528, accuracy: 55.6 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 1.412744164466858, accuracy: 53.7 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.3425604104995728, accuracy: 56.1 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 1.3410067558288574, accuracy: 56.0 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 1.3389211893081665, accuracy: 55.7 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.3395473957061768, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.3511, batch time: 0.08, accuracy:  50.78%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.4233, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.2839, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.3160, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.4886, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.2873, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.2993, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.4193, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.4569, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.5080, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 1.3651573657989502, accuracy: 53.7 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.8663479089736938, accuracy: 40.2 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 1.3588156700134277, accuracy: 54.7 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 1.3584296703338623, accuracy: 54.6 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 1.5046664476394653, accuracy: 49.7 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 1.414223313331604, accuracy: 53.1 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 1.3427776098251343, accuracy: 55.9 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 1.3398090600967407, accuracy: 56.4 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 1.3505702018737793, accuracy: 55.2 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 1.3393958806991577, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.2525, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.3182, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.3590, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.5101, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.3403, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.4035, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.2797, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.4623, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.4160, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.4792, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 1.2793529033660889, accuracy: 56.5 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 2.0919041633605957, accuracy: 35.3 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 1.548208475112915, accuracy: 47.1 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 2.3547775745391846, accuracy: 29.1 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 1.3714321851730347, accuracy: 52.8 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 1.341243028640747, accuracy: 53.8 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 1.3289480209350586, accuracy: 54.4 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 1.2745214700698853, accuracy: 56.9 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 1.2733125686645508, accuracy: 56.7 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 1.2720849514007568, accuracy: 57.0 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.3905, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.1727, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.4012, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.2302, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.4943, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.2208, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.4080, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.1872, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.3151, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.4224, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 1.3836109638214111, accuracy: 55.0 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 2.0106687545776367, accuracy: 36.1 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 1.6000142097473145, accuracy: 47.4 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 9.200821876525879, accuracy: 16.6 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 1.3842730522155762, accuracy: 54.8 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 1.41680908203125, accuracy: 54.2 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 1.4657100439071655, accuracy: 53.4 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 1.3720757961273193, accuracy: 55.1 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 1.39239501953125, accuracy: 55.1 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 1.3719608783721924, accuracy: 55.3 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.3589, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.4785, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.2828, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.4174, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.4285, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.3879, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.3317, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.2508, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.3632, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.3954, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 1.282241702079773, accuracy: 56.8 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.9331823587417603, accuracy: 38.7 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 1.5024645328521729, accuracy: 49.0 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 4.746514320373535, accuracy: 23.3 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 1.3135111331939697, accuracy: 55.1 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 1.3579055070877075, accuracy: 54.4 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 1.2748771905899048, accuracy: 56.5 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 1.2719711065292358, accuracy: 56.2 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 1.272048830986023, accuracy: 56.5 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 1.2765555381774902, accuracy: 56.9 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.9987, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.2624, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.4198, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.3410, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.2989, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.4022, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.4819, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.3538, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.3157, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.4038, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 1.3338744640350342, accuracy: 52.4 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 2.1049420833587646, accuracy: 36.4 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 1.5997079610824585, accuracy: 45.9 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 2.0401222705841064, accuracy: 36.8 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 1.312374234199524, accuracy: 53.7 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 1.3104971647262573, accuracy: 53.4 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 1.4553515911102295, accuracy: 50.4 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 1.3079460859298706, accuracy: 53.2 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 1.308010458946228, accuracy: 53.5 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 1.30777108669281, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.5972, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.3497, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.0692, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.6289, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.2595, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.3632, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.4080, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.2356, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.4610, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.3653, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 1.3558889627456665, accuracy: 53.8 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 1.9145594835281372, accuracy: 38.3 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 1.5946805477142334, accuracy: 46.4 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 14.770119667053223, accuracy: 19.0 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 1.3757001161575317, accuracy: 53.6 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 1.3941518068313599, accuracy: 52.4 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 1.3519396781921387, accuracy: 53.4 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 1.350478172302246, accuracy: 53.8 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 1.3501585721969604, accuracy: 52.7 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 1.3486725091934204, accuracy: 53.0 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.2157, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.7086, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.6111, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.4605, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.2647, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.5357, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.3748, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.3027, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.3390, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.3182, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 1.347777009010315, accuracy: 56.0 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 2.4376847743988037, accuracy: 33.4 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 1.5940886735916138, accuracy: 45.5 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 3.5576894283294678, accuracy: 24.3 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 1.6194968223571777, accuracy: 43.7 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 1.4072890281677246, accuracy: 54.3 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 1.3416892290115356, accuracy: 56.1 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 1.3408684730529785, accuracy: 56.1 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 1.340610384941101, accuracy: 56.4 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 1.340735912322998, accuracy: 56.9 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.4821, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.2858, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.3790, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.3333, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.3865, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.2453, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.1858, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.2839, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.1777, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.4066, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 1.3572282791137695, accuracy: 52.0 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.4065625667572021, accuracy: 51.4 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 1.3501644134521484, accuracy: 53.8 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 1.3497108221054077, accuracy: 52.9 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 1.4639778137207031, accuracy: 50.2 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 1.3432323932647705, accuracy: 52.9 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 1.3443166017532349, accuracy: 53.0 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 1.4678831100463867, accuracy: 51.6 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 1.3407752513885498, accuracy: 53.5 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 1.3426998853683472, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.5010, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.4439, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.2031, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.1689, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.4011, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.3280, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.2565, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.3685, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.4616, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.3960, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 1.3743069171905518, accuracy: 51.1 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 1.8940088748931885, accuracy: 40.3 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 1.553189992904663, accuracy: 45.8 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 1.6710853576660156, accuracy: 44.8 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 1.371742844581604, accuracy: 53.0 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 1.370174527168274, accuracy: 52.6 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 1.4119091033935547, accuracy: 50.1 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 1.3675634860992432, accuracy: 52.9 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 1.366237759590149, accuracy: 53.0 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 1.3647828102111816, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.3437, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.1607, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.3459, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.1887, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.5296, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.3628, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.4759, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.2310, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.2891, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.1316, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 1.3410154581069946, accuracy: 53.7 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 1.7703733444213867, accuracy: 42.4 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 1.4694881439208984, accuracy: 48.9 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 1.6004352569580078, accuracy: 43.5 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 1.3480232954025269, accuracy: 53.3 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 1.336574912071228, accuracy: 54.4 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 1.3416579961776733, accuracy: 53.7 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 2.9249930381774902, accuracy: 28.1 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 1.3263983726501465, accuracy: 55.1 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 1.325582504272461, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.1520, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.4181, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.3137, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.4205, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.4016, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.2431, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.3171, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.3145, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.2446, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.2637, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 1.3444815874099731, accuracy: 52.0 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 2.3468799591064453, accuracy: 33.6 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 1.5620850324630737, accuracy: 48.0 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 1.9523334503173828, accuracy: 42.2 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 1.3410032987594604, accuracy: 52.1 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 1.348756194114685, accuracy: 52.7 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 1.3438318967819214, accuracy: 53.3 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 1.3376905918121338, accuracy: 52.4 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 1.336548924446106, accuracy: 52.4 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 1.3421422243118286, accuracy: 52.7 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.3104, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.2254, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.4280, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.2696, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.2578, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.3198, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.2572, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.2577, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.4163, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.3076, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 1.265175461769104, accuracy: 55.7 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 1.9174374341964722, accuracy: 39.0 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 1.476143717765808, accuracy: 51.1 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 1.692254662513733, accuracy: 47.6 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 1.3609516620635986, accuracy: 55.0 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 1.2566403150558472, accuracy: 55.3 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 1.2571953535079956, accuracy: 56.2 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 1.2542426586151123, accuracy: 56.0 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 1.2535672187805176, accuracy: 56.2 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 1.2531282901763916, accuracy: 56.7 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.4006, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.3110, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.3599, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.3003, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.2638, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.2235, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.4901, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.1063, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.3551, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.2086, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 1.2920427322387695, accuracy: 53.1 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 1.9461767673492432, accuracy: 42.3 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 1.4453704357147217, accuracy: 49.8 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 1.489343523979187, accuracy: 47.8 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 1.297103762626648, accuracy: 52.0 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 1.2806313037872314, accuracy: 53.6 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 1.3003044128417969, accuracy: 53.7 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 1.275930404663086, accuracy: 53.4 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 1.2757879495620728, accuracy: 53.3 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 1.3250118494033813, accuracy: 51.3 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.3070, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.3451, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.2609, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.2093, batch time: 0.06, accuracy:  62.50%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.2888, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.3864, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.2356, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.4556, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.3825, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.2749, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 1.34966242313385, accuracy: 53.7 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 2.0442419052124023, accuracy: 38.1 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 1.6054414510726929, accuracy: 44.3 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 13.916831970214844, accuracy: 14.7 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 1.341342568397522, accuracy: 53.5 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 1.3340188264846802, accuracy: 53.4 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 1.8448803424835205, accuracy: 37.4 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 1.3266648054122925, accuracy: 53.5 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 1.3250013589859009, accuracy: 53.9 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 1.3234220743179321, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.2007, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.1201, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.3732, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.1593, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.3357, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.3933, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.3270, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.3626, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.4618, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.1467, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 1.3058069944381714, accuracy: 54.5 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 2.245237112045288, accuracy: 36.6 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 1.8145989179611206, accuracy: 44.6 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 17.368112564086914, accuracy: 17.3 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 1.303059697151184, accuracy: 55.0 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 1.3018672466278076, accuracy: 54.7 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 1.3141438961029053, accuracy: 54.9 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 1.353596568107605, accuracy: 54.0 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 1.30764901638031, accuracy: 54.6 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 1.294858455657959, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.2850, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.2025, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.3805, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.3812, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.2744, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.3052, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.2517, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.3928, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.2529, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.5263, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 1.3199585676193237, accuracy: 54.1 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 2.2492289543151855, accuracy: 37.1 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 1.3109369277954102, accuracy: 53.8 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 1.3109369277954102, accuracy: 53.8 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 1.3249657154083252, accuracy: 53.7 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 1.30025053024292, accuracy: 55.6 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 3.0859873294830322, accuracy: 27.1 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 1.2981681823730469, accuracy: 55.6 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 1.2953437566757202, accuracy: 55.3 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 1.2937884330749512, accuracy: 55.7 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.3467, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.2576, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.3740, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.3319, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.4271, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.3388, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.1335, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.3009, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.2696, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.3791, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 1.3002934455871582, accuracy: 54.9 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 2.066148519515991, accuracy: 40.0 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 2.0707783699035645, accuracy: 40.3 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 1.6354502439498901, accuracy: 47.5 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 1.2896294593811035, accuracy: 54.9 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 1.286916971206665, accuracy: 55.0 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 1.300252914428711, accuracy: 54.2 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 1.3091273307800293, accuracy: 54.4 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 1.2799323797225952, accuracy: 55.2 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 1.2767622470855713, accuracy: 54.9 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.1849, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.3506, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.4305, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.3288, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.2477, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.3188, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.2822, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.2861, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.2813, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.2046, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 1.2577335834503174, accuracy: 56.0 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 1.9345808029174805, accuracy: 42.8 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 2.117152214050293, accuracy: 43.5 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 2.7417569160461426, accuracy: 34.0 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 1.271573543548584, accuracy: 54.5 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 1.282133936882019, accuracy: 56.2 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 1.2483125925064087, accuracy: 56.9 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 1.2645988464355469, accuracy: 57.2 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 1.2496998310089111, accuracy: 56.1 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 1.2435358762741089, accuracy: 57.3 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.3714, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.5784, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.0914, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.2546, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.3248, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.3238, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.2174, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.3952, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.3179, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.4061, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 1.3421508073806763, accuracy: 52.9 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 3.0580434799194336, accuracy: 27.7 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 1.8075934648513794, accuracy: 42.8 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 2.866792678833008, accuracy: 26.2 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 1.340347409248352, accuracy: 52.8 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 1.338561773300171, accuracy: 53.3 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 1.3914798498153687, accuracy: 51.9 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 1.3366115093231201, accuracy: 53.4 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 1.3351563215255737, accuracy: 54.1 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 1.3331085443496704, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.2656, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.4891, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.3648, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.3904, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.2504, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.2236, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.2841, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.3918, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.3126, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.3674, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 1.3460537195205688, accuracy: 53.0 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.569811224937439, accuracy: 48.4 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 1.3667362928390503, accuracy: 52.7 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 4.155499458312988, accuracy: 20.2 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 1.4167314767837524, accuracy: 52.5 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 1.329482078552246, accuracy: 54.5 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 1.3191554546356201, accuracy: 55.0 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 1.3171766996383667, accuracy: 54.7 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 1.3183057308197021, accuracy: 54.6 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 1.316169023513794, accuracy: 54.8 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.2260, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.2437, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.5318, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.3176, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.3570, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.3811, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.4217, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.3179, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.3038, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.2099, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 1.3429062366485596, accuracy: 54.7 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 3.8291053771972656, accuracy: 26.2 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 1.7655237913131714, accuracy: 42.9 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 1.7014182806015015, accuracy: 45.7 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 1.3482908010482788, accuracy: 54.9 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 1.3366729021072388, accuracy: 54.2 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 1.3407381772994995, accuracy: 55.1 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 1.336023211479187, accuracy: 55.0 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 1.4523420333862305, accuracy: 52.0 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 1.3324792385101318, accuracy: 54.3 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.2664, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.4628, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.4615, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.5033, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.4606, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.2430, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.2202, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.3573, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.3385, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.4558, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 1.3608033657073975, accuracy: 54.2 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1.4814642667770386, accuracy: 48.9 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 1.3574802875518799, accuracy: 53.2 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 1.3774052858352661, accuracy: 52.5 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 1.3596819639205933, accuracy: 53.8 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 1.3748984336853027, accuracy: 52.0 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 1.3424712419509888, accuracy: 54.7 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 1.338779330253601, accuracy: 54.2 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 1.6052944660186768, accuracy: 47.1 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 1.3350682258605957, accuracy: 53.7 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.2360, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.3081, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.4061, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.3918, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.3366, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.3262, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.2256, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.4757, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.3928, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.2182, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 1.3121607303619385, accuracy: 55.2 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 3.877826690673828, accuracy: 26.9 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 1.635525107383728, accuracy: 47.3 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 4.008077621459961, accuracy: 13.5 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 1.289900302886963, accuracy: 55.5 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 1.2732250690460205, accuracy: 56.6 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 1.2738040685653687, accuracy: 57.4 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 1.2712459564208984, accuracy: 56.6 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 1.270939826965332, accuracy: 57.4 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.270909309387207, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.3865, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.4621, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.3693, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.3507, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.2471, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.3710, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.3057, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.2607, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.5588, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.3250, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 1.330507755279541, accuracy: 53.1 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 2.0052852630615234, accuracy: 38.7 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 1.8972798585891724, accuracy: 41.2 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 1.7197825908660889, accuracy: 44.2 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 1.3404828310012817, accuracy: 53.4 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 1.3439860343933105, accuracy: 52.0 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 1.3228518962860107, accuracy: 53.6 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 1.3157085180282593, accuracy: 53.2 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 1.314577579498291, accuracy: 53.9 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 1.3133528232574463, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.2905, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.1755, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.6234, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.2811, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.2907, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.2329, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.3671, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.2654, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.5017, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.1280, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 1.2963076829910278, accuracy: 54.0 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 1.5408046245574951, accuracy: 48.4 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 1.75728178024292, accuracy: 40.3 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 5.373544692993164, accuracy: 20.6 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 1.3004366159439087, accuracy: 53.7 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 1.295693039894104, accuracy: 54.0 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 1.3057528734207153, accuracy: 52.0 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 1.3645201921463013, accuracy: 52.8 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 1.3307297229766846, accuracy: 50.6 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 1.2831823825836182, accuracy: 54.7 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.2763, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.2053, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.2379, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.3473, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.4693, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.3210, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.4478, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.3129, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.2480, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.2963, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 1.276214599609375, accuracy: 55.4 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 2.723222017288208, accuracy: 30.4 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 1.7503544092178345, accuracy: 38.3 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 2.0835115909576416, accuracy: 34.1 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 1.3078277111053467, accuracy: 53.3 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 1.266419529914856, accuracy: 55.4 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 1.2663090229034424, accuracy: 54.9 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 1.2661902904510498, accuracy: 55.4 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 1.2659425735473633, accuracy: 54.3 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 1.2633497714996338, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.4081, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.2970, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.2066, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.2784, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.3188, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.3609, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.4132, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 1.4431, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 1.3255, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 1.2763, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 1.2694281339645386, accuracy: 54.2 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 3.2229535579681396, accuracy: 28.7 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 1.8415319919586182, accuracy: 37.0 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 1.450680136680603, accuracy: 50.0 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 1.3959251642227173, accuracy: 50.4 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 1.7314618825912476, accuracy: 42.2 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 1.2647650241851807, accuracy: 55.6 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 1.2627979516983032, accuracy: 55.4 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 1.2621690034866333, accuracy: 55.4 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 1.2639360427856445, accuracy: 55.3 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 1.2028, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 1.2134, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 1.4311, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 1.0712, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 1.2335, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 1.4405, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 1.3365, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 1.1808, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 1.3933, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 1.3820, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 1.2945460081100464, accuracy: 53.1 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 2.0345025062561035, accuracy: 37.3 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 1.2772315740585327, accuracy: 53.2 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 1.2771975994110107, accuracy: 54.1 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 1.273427963256836, accuracy: 54.4 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 1.2733103036880493, accuracy: 53.7 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 1.3515474796295166, accuracy: 53.9 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 1.2723662853240967, accuracy: 54.0 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 1.272249460220337, accuracy: 54.0 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 1.2710201740264893, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 1.1904, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 1.2424, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.9992, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 1.2179, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 1.4317, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 1.2428, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 1.2737, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 1.4830, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 1.3582, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 1.4784, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 1.2641515731811523, accuracy: 56.2 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.4494662284851074, accuracy: 51.9 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 1.3297172784805298, accuracy: 53.0 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 7.197405815124512, accuracy: 16.6 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 1.2810825109481812, accuracy: 55.6 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 1.2685214281082153, accuracy: 56.3 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 1.2807873487472534, accuracy: 54.8 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 1.2564233541488647, accuracy: 56.9 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 1.2551757097244263, accuracy: 56.4 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 1.2543715238571167, accuracy: 56.4 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 1.2362, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 1.2465, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 1.2507, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 1.4542, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 1.2668, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 1.4101, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 1.3153, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 1.3067, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 1.4585, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 1.2665, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 1.3919224739074707, accuracy: 50.9 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 1.9421271085739136, accuracy: 40.0 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 1.442591667175293, accuracy: 50.2 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 1.3347747325897217, accuracy: 53.4 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 1.7963135242462158, accuracy: 42.6 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 1.3121323585510254, accuracy: 54.6 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 1.3107682466506958, accuracy: 55.3 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 1.357076644897461, accuracy: 54.1 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 1.3092983961105347, accuracy: 54.5 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 1.3220572471618652, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 1.3867, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 1.2548, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 1.3131, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 1.2455, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 1.3246, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 1.1910, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 1.1994, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 1.6036, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 1.3647, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 1.2036, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 1.3347548246383667, accuracy: 53.3 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 2.0469539165496826, accuracy: 39.7 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 1.3282344341278076, accuracy: 52.4 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 1.3597489595413208, accuracy: 51.9 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 1.3194552659988403, accuracy: 52.7 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 1.3035718202590942, accuracy: 53.1 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 1.3441088199615479, accuracy: 52.7 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 1.3094594478607178, accuracy: 52.9 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 1.301162600517273, accuracy: 53.2 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 1.2997679710388184, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 1.5101, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 1.4253, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 1.3064, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 1.4446, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 1.3223, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 1.2172, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 1.3102, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 1.2861, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 1.3357, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 1.3372, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 1.2922039031982422, accuracy: 52.8 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.6302427053451538, accuracy: 45.5 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 1.8007972240447998, accuracy: 37.5 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 3.869905710220337, accuracy: 16.8 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 1.293457269668579, accuracy: 52.7 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 1.3104079961776733, accuracy: 53.4 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 1.286312222480774, accuracy: 53.8 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 1.2834177017211914, accuracy: 54.5 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 1.2829113006591797, accuracy: 54.3 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 1.3415563106536865, accuracy: 51.4 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 1.2631, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 1.3343, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 1.2293, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 1.5101, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 1.3924, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 1.3449, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 1.5204, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 1.2273, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 1.2769, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 1.3716, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 1.2291024923324585, accuracy: 56.9 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 2.391691207885742, accuracy: 33.4 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 1.3095687627792358, accuracy: 53.2 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 7.584760665893555, accuracy: 8.9 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 1.27659010887146, accuracy: 54.4 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 1.244578242301941, accuracy: 56.6 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 1.4530524015426636, accuracy: 50.0 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 1.2179019451141357, accuracy: 57.5 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 1.218545913696289, accuracy: 55.7 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 1.2170318365097046, accuracy: 56.8 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 1.2387, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 1.2562, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 1.3254, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 1.2085, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 1.3449, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 1.2083, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 1.3318, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 1.1871, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 1.4031, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 1.2542, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 1.3465337753295898, accuracy: 52.2 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1.6863569021224976, accuracy: 44.5 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 1.8102110624313354, accuracy: 42.0 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 2.729884624481201, accuracy: 23.7 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 1.340155839920044, accuracy: 52.4 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 1.3306440114974976, accuracy: 52.3 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 1.351055383682251, accuracy: 52.8 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 1.3246768712997437, accuracy: 52.8 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 1.3233219385147095, accuracy: 52.8 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 1.32231605052948, accuracy: 52.7 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 1.2083, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 1.1791, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 1.1830, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 1.1822, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 1.3473, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 1.2915, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 1.2493, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 1.3445, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 1.5296, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 1.3374, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 1.3005356788635254, accuracy: 54.6 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 2.0225250720977783, accuracy: 42.1 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 2.9254508018493652, accuracy: 28.4 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 1.4191514253616333, accuracy: 52.9 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 1.2551348209381104, accuracy: 55.6 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 1.260315179824829, accuracy: 57.0 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 1.2402178049087524, accuracy: 56.5 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 1.2392162084579468, accuracy: 56.5 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 1.2395823001861572, accuracy: 56.0 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 1.237826943397522, accuracy: 56.5 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 1.3189, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 1.2711, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 1.2623, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 1.3393, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 1.3133, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 1.3142, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 1.1714, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 1.4057, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 1.2495, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 1.3225, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 1.2604633569717407, accuracy: 54.9 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 1.8413221836090088, accuracy: 43.9 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 1.4092501401901245, accuracy: 51.9 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 8.68343734741211, accuracy: 7.3 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 1.2968393564224243, accuracy: 52.2 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 1.281976342201233, accuracy: 55.4 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 1.2912225723266602, accuracy: 55.0 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 1.2467387914657593, accuracy: 55.0 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 1.2460805177688599, accuracy: 55.0 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 1.2456117868423462, accuracy: 55.1 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 1.4486, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 1.1104, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 1.3558, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 1.5596, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 1.2531, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 1.2677, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 1.3546, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 1.2513, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 1.2977, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 1.1135, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 1.2772860527038574, accuracy: 54.3 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 1.4181907176971436, accuracy: 51.4 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 1.2737829685211182, accuracy: 53.9 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 1.2730640172958374, accuracy: 54.0 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 1.3020286560058594, accuracy: 54.3 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 1.2815805673599243, accuracy: 54.0 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 1.3282978534698486, accuracy: 54.0 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 1.2949202060699463, accuracy: 53.0 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 1.2684224843978882, accuracy: 53.9 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 1.269644856452942, accuracy: 53.8 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 1.3108, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 1.2915, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 1.2928, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 1.4584, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 1.3025, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 1.2998, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 1.4343, batch time: 0.05, accuracy:  42.97%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 1.3282, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 1.2710, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 1.1517, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 1.3544992208480835, accuracy: 49.8 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 1.7632477283477783, accuracy: 43.9 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 1.8612534999847412, accuracy: 41.4 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 1.5001428127288818, accuracy: 48.2 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 1.3815679550170898, accuracy: 50.9 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 1.3591467142105103, accuracy: 51.5 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 1.3448984622955322, accuracy: 51.6 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 1.3534581661224365, accuracy: 51.0 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 1.3399827480316162, accuracy: 51.3 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 1.3389872312545776, accuracy: 51.2 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 1.0986, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 1.3287, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 1.2314, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 1.2871, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 1.3032, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 1.4806, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 1.1709, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 1.4049, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 1.2061, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 1.2187, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 1.2687009572982788, accuracy: 56.2 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 1.6290801763534546, accuracy: 49.5 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 1.2687009572982788, accuracy: 56.2 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 1.2687009572982788, accuracy: 56.2 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 1.2691296339035034, accuracy: 55.0 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 1.2628732919692993, accuracy: 56.2 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 1.2830990552902222, accuracy: 55.0 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 1.2664778232574463, accuracy: 56.1 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 1.3138313293457031, accuracy: 55.3 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 1.2586655616760254, accuracy: 55.6 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 1.3191, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 1.4124, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 1.2910, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 1.2418, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 1.1642, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 1.3583, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 1.2443, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 1.2703, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 1.2946, batch time: 0.08, accuracy:  51.56%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 1.4271, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 1.2592099905014038, accuracy: 54.2 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 1.5793174505233765, accuracy: 48.5 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 2.565983295440674, accuracy: 32.0 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 1.4007872343063354, accuracy: 52.9 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 1.283897042274475, accuracy: 55.3 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 1.2473548650741577, accuracy: 56.5 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 1.2574957609176636, accuracy: 56.1 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 1.2565886974334717, accuracy: 55.2 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 1.2425085306167603, accuracy: 56.2 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 1.2373641729354858, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 1.3806, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 1.2769, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 1.0998, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 1.3894, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 1.3145, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 1.1389, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 1.3058, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 1.3801, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 1.3508, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 1.1512, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 1.349723219871521, accuracy: 53.7 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 1.7946271896362305, accuracy: 42.6 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 1.425804615020752, accuracy: 49.0 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 5.30592155456543, accuracy: 14.9 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 1.3317584991455078, accuracy: 53.2 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 1.3254141807556152, accuracy: 53.6 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 1.3202953338623047, accuracy: 53.4 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 1.3497172594070435, accuracy: 54.4 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 1.3123506307601929, accuracy: 51.9 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 1.3006783723831177, accuracy: 53.9 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 1.2477, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 1.1905, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 1.3017, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 1.1683, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 1.2716, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 1.2327, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 1.3484, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 1.3486, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 1.2529, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 1.3190, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 1.2142399549484253, accuracy: 54.5 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 1.6791874170303345, accuracy: 44.1 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 2.485658884048462, accuracy: 30.5 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 4.772229194641113, accuracy: 14.0 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 1.29257071018219, accuracy: 52.0 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 1.2032850980758667, accuracy: 55.2 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 1.2362464666366577, accuracy: 53.4 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 1.204338550567627, accuracy: 54.0 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 1.2032339572906494, accuracy: 55.3 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 1.1931233406066895, accuracy: 55.3 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 1.3605, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 1.3048, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 1.2742, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 1.4683, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 1.4741, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 1.2930, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 1.2758, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 1.2938, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 1.2277, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 1.2264, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 1.3088362216949463, accuracy: 54.5 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.931354284286499, accuracy: 40.5 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 1.4830853939056396, accuracy: 47.8 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 4.928264617919922, accuracy: 23.4 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 1.3475062847137451, accuracy: 54.0 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 1.2935158014297485, accuracy: 53.7 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 1.2881239652633667, accuracy: 54.3 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 1.2999138832092285, accuracy: 53.0 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 1.2958041429519653, accuracy: 53.3 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 1.2819862365722656, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 1.2208, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 1.2805, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 1.2664, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 1.4729, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 1.2783, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 1.5084, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 1.3983, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 1.1509, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 1.4117, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 1.3075, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 1.2769439220428467, accuracy: 53.6 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.27499258518219, accuracy: 54.0 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 1.2699090242385864, accuracy: 54.4 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 1.2689920663833618, accuracy: 54.2 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 3.4599926471710205, accuracy: 26.2 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 1.266188383102417, accuracy: 56.1 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 1.284006953239441, accuracy: 53.6 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 1.2624728679656982, accuracy: 55.2 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 1.2685389518737793, accuracy: 55.4 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 1.2573875188827515, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 1.3936, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 1.4029, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 1.1688, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 1.2969, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 1.5183, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 1.2166, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 1.5052, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 1.2742, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 1.4105, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 1.2574, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 1.335537314414978, accuracy: 53.3 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 1.793250322341919, accuracy: 42.0 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 1.5373480319976807, accuracy: 49.0 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 3.9210550785064697, accuracy: 21.6 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 1.3410245180130005, accuracy: 53.9 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 1.359075665473938, accuracy: 54.4 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 1.3539260625839233, accuracy: 51.7 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 1.952564001083374, accuracy: 39.0 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 1.3416032791137695, accuracy: 51.9 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 1.3226144313812256, accuracy: 54.0 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 1.2581, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 1.2553, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 1.1213, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 1.3735, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 1.1900, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 1.2226, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 1.1891, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 1.2601, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 1.2017, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 1.2284, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 1.2728219032287598, accuracy: 56.0 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 1.7141214609146118, accuracy: 44.8 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 1.2686055898666382, accuracy: 55.8 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 1.8647911548614502, accuracy: 36.7 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 1.303332805633545, accuracy: 55.1 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 1.2636022567749023, accuracy: 55.7 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 1.2614915370941162, accuracy: 56.0 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 1.3011832237243652, accuracy: 54.5 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 1.8610708713531494, accuracy: 41.5 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 1.2613399028778076, accuracy: 57.0 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 1.0769, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 1.2413, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 1.3185, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 1.4438, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 1.2737, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 1.3635, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 1.1486, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 1.2113, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 1.4248, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 1.4858, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 1.2724382877349854, accuracy: 54.5 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 1.7486563920974731, accuracy: 45.6 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 2.0526204109191895, accuracy: 39.4 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 4.463051795959473, accuracy: 24.0 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 1.2878668308258057, accuracy: 55.1 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 1.2673791646957397, accuracy: 54.5 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 1.2782882452011108, accuracy: 55.3 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 1.2821778059005737, accuracy: 54.0 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 1.2636638879776, accuracy: 54.5 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 1.2694852352142334, accuracy: 54.3 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 1.2431, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 1.2821, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 1.0362, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 1.2397, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 1.2829, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 1.2799, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 1.1786, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 1.3787, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 1.2730, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 1.4784, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 1.307366132736206, accuracy: 56.2 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 1.7765227556228638, accuracy: 43.6 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 1.3023154735565186, accuracy: 55.2 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 1.3010286092758179, accuracy: 54.9 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 1.2972675561904907, accuracy: 55.8 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 1.2940800189971924, accuracy: 55.0 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 1.4427211284637451, accuracy: 51.9 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 1.292761206626892, accuracy: 55.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 1.311002254486084, accuracy: 55.9 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 1.2897802591323853, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 1.3447, batch time: 0.08, accuracy:  49.22%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 1.2249, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.9966, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 1.2984, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 1.2351, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 1.3254, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 1.2605, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 1.1699, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 1.2283, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 1.1720, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 1.299736738204956, accuracy: 54.3 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 1.393570899963379, accuracy: 52.3 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 1.2977170944213867, accuracy: 54.5 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 1.2968038320541382, accuracy: 55.0 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 1.4466520547866821, accuracy: 50.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 1.2860208749771118, accuracy: 55.7 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 1.2884979248046875, accuracy: 54.8 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 1.2804808616638184, accuracy: 55.2 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 1.2802008390426636, accuracy: 55.3 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 1.280173897743225, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 1.2878, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 1.0859, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 1.3505, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 1.1799, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 1.2512, batch time: 0.32, accuracy:  59.38%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 1.2743, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 1.1703, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 1.4598, batch time: 0.05, accuracy:  46.88%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 1.2682, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 1.3446, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 1.3267353773117065, accuracy: 51.8 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 1.3333498239517212, accuracy: 51.4 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 1.5360236167907715, accuracy: 46.1 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 4.419872760772705, accuracy: 17.4 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 1.3216111660003662, accuracy: 53.1 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 1.362784504890442, accuracy: 53.2 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 1.3138492107391357, accuracy: 54.1 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 1.307778000831604, accuracy: 54.0 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 1.3100216388702393, accuracy: 53.0 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 1.3025093078613281, accuracy: 53.7 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 1.3056, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 1.3094, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 1.2647, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 1.3311, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 1.3470, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 1.3551, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 1.3515, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 1.1681, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 1.2048, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 1.2800, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 1.3432687520980835, accuracy: 52.1 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 1.9029546976089478, accuracy: 42.3 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 1.5078825950622559, accuracy: 48.0 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 1.3677970170974731, accuracy: 50.5 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 1.3417346477508545, accuracy: 51.6 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 1.4970073699951172, accuracy: 47.5 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 1.3416792154312134, accuracy: 52.1 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 1.3368042707443237, accuracy: 52.5 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 1.3858730792999268, accuracy: 50.4 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 1.407383918762207, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 1.4821, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 1.2274, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 1.2221, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 1.2818, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 1.3986, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 1.3119, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 1.0709, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 1.2005, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 1.2564, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 1.1060, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 1.2465121746063232, accuracy: 55.6 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 2.0199429988861084, accuracy: 43.2 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 1.658584713935852, accuracy: 45.3 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 4.089139938354492, accuracy: 21.1 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 1.2490313053131104, accuracy: 55.9 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 1.2379789352416992, accuracy: 56.5 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 1.2453560829162598, accuracy: 55.9 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 1.284841775894165, accuracy: 55.9 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 1.2324999570846558, accuracy: 56.1 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 1.231245517730713, accuracy: 56.1 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 1.3186, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 1.0952, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 1.2440, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 1.2131, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 1.2934, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 1.1716, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 1.0433, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 1.3751, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 1.2532, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 1.1522, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 1.2904506921768188, accuracy: 55.6 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 1.2714314460754395, accuracy: 55.2 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 1.2697445154190063, accuracy: 55.8 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 1.2847920656204224, accuracy: 55.3 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 1.2881183624267578, accuracy: 54.5 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 1.2675340175628662, accuracy: 56.1 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 1.478269338607788, accuracy: 49.2 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 1.2602629661560059, accuracy: 56.0 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 1.2588313817977905, accuracy: 56.0 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 1.2567116022109985, accuracy: 56.4 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 1.1762, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 1.3776, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 1.0634, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 1.4450, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 1.3383, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 1.4407, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 1.3352, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 1.2726, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 1.2172, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 1.3077, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 1.2611308097839355, accuracy: 56.2 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 1.341662883758545, accuracy: 53.4 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 2.4503777027130127, accuracy: 33.7 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 4.970879554748535, accuracy: 11.7 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 1.2979527711868286, accuracy: 54.2 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 1.2510840892791748, accuracy: 57.1 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 1.2520208358764648, accuracy: 57.1 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 1.2484663724899292, accuracy: 57.4 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 1.2435158491134644, accuracy: 57.8 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 1.2436351776123047, accuracy: 57.0 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 1.3049, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 1.2156, batch time: 0.06, accuracy:  58.59%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 1.3532, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 1.1352, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 1.2039, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 1.3346, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 1.1790, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 1.2957, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 1.2741, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 1.3245, batch time: 0.08, accuracy:  50.78%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 1.2824801206588745, accuracy: 55.3 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 2.1732029914855957, accuracy: 35.2 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 1.5482118129730225, accuracy: 47.6 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 1.4072450399398804, accuracy: 48.0 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 1.2820532321929932, accuracy: 55.0 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 1.5194525718688965, accuracy: 46.4 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 1.2757869958877563, accuracy: 54.5 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 1.2731263637542725, accuracy: 54.6 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 1.2750139236450195, accuracy: 54.6 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 1.2745722532272339, accuracy: 55.0 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 1.2777, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 1.2538, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 1.1142, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 1.2546, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 1.3010, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 1.4905, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 1.3522, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 1.2959, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 1.3123, batch time: 0.11, accuracy:  47.66%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 1.2715, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 1.189539909362793, accuracy: 57.2 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 2.651388645172119, accuracy: 33.5 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 1.5017297267913818, accuracy: 47.4 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 1.2967414855957031, accuracy: 51.8 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 1.2950029373168945, accuracy: 54.9 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 1.368349313735962, accuracy: 53.2 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 1.185625433921814, accuracy: 57.4 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 1.1824328899383545, accuracy: 57.5 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 1.1822290420532227, accuracy: 57.7 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 1.1817851066589355, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 1.3207, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 1.3751, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 1.1376, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 1.4449, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 1.4103, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 1.2052, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 1.4959, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 1.4183, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 1.1154, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 1.1430, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 1.2076303958892822, accuracy: 55.5 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 2.3802669048309326, accuracy: 33.9 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 1.5589144229888916, accuracy: 45.1 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 5.768655776977539, accuracy: 9.1 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.2706156969070435, accuracy: 55.0 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 1.2174721956253052, accuracy: 56.0 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 1.2001575231552124, accuracy: 56.0 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 1.198702335357666, accuracy: 55.6 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 1.1984919309616089, accuracy: 55.5 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 1.197916865348816, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 1.1379, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 1.3531, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 1.2241, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 1.3026, batch time: 0.08, accuracy:  56.25%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 1.4038, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 1.2357, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 1.3892, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 1.1491, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 1.2731, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 1.2657, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 1.23111891746521, accuracy: 56.3 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 1.3172354698181152, accuracy: 53.9 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 1.2266212701797485, accuracy: 57.3 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 1.2266212701797485, accuracy: 57.3 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 1.227809190750122, accuracy: 56.8 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 1.221799612045288, accuracy: 57.1 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 1.2273058891296387, accuracy: 56.5 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 1.2480156421661377, accuracy: 54.8 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 1.2194875478744507, accuracy: 56.9 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 1.2187391519546509, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 1.1602, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 1.1704, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 1.2393, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 1.3880, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 1.3039, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 1.2486, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 1.3121, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 1.1734, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 1.3371, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 1.2749, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 1.2235053777694702, accuracy: 56.6 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.9129875898361206, accuracy: 44.4 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 1.46356201171875, accuracy: 49.3 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 1.2111432552337646, accuracy: 56.5 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 2.456645965576172, accuracy: 34.4 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 1.2008987665176392, accuracy: 56.3 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 1.2165158987045288, accuracy: 56.9 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 1.2625789642333984, accuracy: 54.4 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 1.1973202228546143, accuracy: 58.1 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 2.2842676639556885, accuracy: 33.7 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 1.2604, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 1.3473, batch time: 0.06, accuracy:  53.91%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 1.4534, batch time: 0.11, accuracy:  44.53%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 1.3658, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 1.1472, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 1.1256, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 1.2785, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 1.5285, batch time: 0.11, accuracy:  46.88%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 1.1107, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 1.2427, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 1.294336199760437, accuracy: 54.0 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 1.374299168586731, accuracy: 51.1 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 1.2896889448165894, accuracy: 53.8 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 1.2896889448165894, accuracy: 53.8 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 1.3938658237457275, accuracy: 51.4 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 1.4136903285980225, accuracy: 50.7 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 1.285347580909729, accuracy: 55.5 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 1.2826111316680908, accuracy: 55.5 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 1.2857273817062378, accuracy: 55.0 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 1.3186112642288208, accuracy: 53.3 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 1.2219, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 1.3332, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 1.2707, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 1.2694, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 1.1708, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 1.2827, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 1.4201, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 1.5120, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 1.1714, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 1.2739, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 1.1921969652175903, accuracy: 57.9 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 1.5608347654342651, accuracy: 47.8 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 1.4395108222961426, accuracy: 48.9 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 1.567098617553711, accuracy: 47.9 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 1.1961907148361206, accuracy: 57.7 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 1.17891526222229, accuracy: 58.4 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 1.1911118030548096, accuracy: 58.6 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 1.2142384052276611, accuracy: 57.2 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 1.2005802392959595, accuracy: 58.4 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 1.1709409952163696, accuracy: 59.4 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 1.3388, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 1.2627, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 1.4462, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 1.3879, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 1.2750, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 1.3053, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 1.2214, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 1.1693, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 1.3699, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 1.3226, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 1.2373712062835693, accuracy: 58.7 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 1.3773926496505737, accuracy: 53.4 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 1.237043857574463, accuracy: 58.1 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 1.2337377071380615, accuracy: 58.0 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 1.2412160634994507, accuracy: 57.7 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 1.226852297782898, accuracy: 59.3 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 1.226454496383667, accuracy: 58.7 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 1.2246930599212646, accuracy: 59.1 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 1.2244988679885864, accuracy: 59.2 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 1.2236168384552002, accuracy: 59.9 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 1.0957, batch time: 0.05, accuracy:  65.62%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 1.1418, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 1.3046, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 1.2871, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 1.2552, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 1.1548, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 1.0703, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 1.4603, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 1.4589, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 1.2808, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 1.2849918603897095, accuracy: 55.0 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 1.2822352647781372, accuracy: 55.6 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 1.4099482297897339, accuracy: 51.5 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 1.2789392471313477, accuracy: 55.1 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 1.971993327140808, accuracy: 33.6 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 1.250989556312561, accuracy: 56.2 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 1.236720323562622, accuracy: 57.1 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 1.235953450202942, accuracy: 56.7 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 1.4662420749664307, accuracy: 50.8 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 1.304848313331604, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 1.3082, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 1.2384, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 1.2885, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 1.2150, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 1.2531, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 1.2323, batch time: 0.07, accuracy:  58.59%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 1.2326, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 1.4552, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 1.1034, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 1.2697, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 1.2576795816421509, accuracy: 54.1 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 1.3040770292282104, accuracy: 52.1 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 1.2558019161224365, accuracy: 53.8 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 1.255185842514038, accuracy: 54.1 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 1.680213212966919, accuracy: 45.9 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 1.2476054430007935, accuracy: 54.3 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 1.259097695350647, accuracy: 53.9 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 1.2483758926391602, accuracy: 53.3 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 1.252833366394043, accuracy: 53.3 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 1.2479326725006104, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 1.2104, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 1.1421, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 1.2907, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 1.3238, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 1.2604, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 1.2027, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 1.3595, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 1.2045, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 1.3278, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 1.1948, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 1.2563408613204956, accuracy: 54.7 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 1.3660478591918945, accuracy: 51.8 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 1.2553802728652954, accuracy: 55.5 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 1.254647970199585, accuracy: 55.6 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 2.165649175643921, accuracy: 37.2 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 1.2497957944869995, accuracy: 55.6 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 1.5799790620803833, accuracy: 46.5 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 1.2519193887710571, accuracy: 55.6 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 1.2626129388809204, accuracy: 54.9 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 1.3138751983642578, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 1.1773, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 1.2206, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 1.6207, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 1.2896, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 1.3779, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 1.3127, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 1.1509, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 1.3132, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 1.4118, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 1.1577, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 1.1994174718856812, accuracy: 55.2 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 1.3038785457611084, accuracy: 54.5 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 1.198079228401184, accuracy: 55.3 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 1.198079228401184, accuracy: 55.3 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 1.2035068273544312, accuracy: 56.4 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 1.1936604976654053, accuracy: 55.4 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 1.194369912147522, accuracy: 57.1 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 2.0034940242767334, accuracy: 42.6 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 1.1904717683792114, accuracy: 56.6 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 1.1895157098770142, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 1.2519, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 1.2199, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 1.1662, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 1.1943, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 1.2383, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 1.3119, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 1.3747, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 1.1893, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 1.1952, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 1.2616, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 1.226194977760315, accuracy: 58.5 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 1.3289586305618286, accuracy: 55.9 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 1.2236735820770264, accuracy: 57.8 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 1.2236735820770264, accuracy: 57.8 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 2.009748935699463, accuracy: 36.6 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 1.2170499563217163, accuracy: 58.3 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 1.214752197265625, accuracy: 58.3 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 1.2213529348373413, accuracy: 58.6 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 1.229183316230774, accuracy: 58.1 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 1.2402609586715698, accuracy: 58.5 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 1.5161, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 1.2703, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 1.3687, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 1.2802, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 1.3037, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 1.1690, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 1.3238, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 1.2969, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 1.0881, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 1.3337, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 1.222085952758789, accuracy: 58.1 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 1.7218234539031982, accuracy: 44.0 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 1.2239031791687012, accuracy: 58.1 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 3.411102533340454, accuracy: 24.3 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 1.225844144821167, accuracy: 57.6 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 1.2139732837677002, accuracy: 57.9 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 1.2995463609695435, accuracy: 54.9 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 1.2347888946533203, accuracy: 58.0 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 1.2092186212539673, accuracy: 57.8 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 1.2058660984039307, accuracy: 58.2 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 1.4473, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 1.3625, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 1.1949, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 1.2638, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 1.3438, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 1.1187, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 1.1870, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 1.2002, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 1.1730, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 1.3091, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 1.250495195388794, accuracy: 56.0 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 1.8374955654144287, accuracy: 42.9 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 2.634989023208618, accuracy: 32.5 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 2.6682486534118652, accuracy: 30.7 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 1.248874545097351, accuracy: 55.6 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 1.301681637763977, accuracy: 54.1 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 2.171959400177002, accuracy: 40.5 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 1.240026593208313, accuracy: 55.6 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.2401756048202515, accuracy: 55.5 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 1.2396275997161865, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 1.2333, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 1.1621, batch time: 0.06, accuracy:  57.81%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 1.3718, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 1.5380, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 1.4281, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 1.2858, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 1.0961, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 1.3513, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 1.2684, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 1.1780, batch time: 0.07, accuracy:  60.16%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 1.2430552244186401, accuracy: 57.6 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.2425295114517212, accuracy: 57.4 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 1.7345290184020996, accuracy: 44.9 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 10.80691909790039, accuracy: 7.4 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 1.2499208450317383, accuracy: 56.6 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 1.2360831499099731, accuracy: 58.3 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 1.251632571220398, accuracy: 56.5 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 1.236810564994812, accuracy: 57.7 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 2.1519925594329834, accuracy: 37.0 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 1.2284692525863647, accuracy: 58.8 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 1.2415, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 1.2625, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 1.1590, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 1.3159, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 1.2590, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 1.3132, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 1.3364, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 1.1987, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 1.1555, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 1.1405, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 1.2621891498565674, accuracy: 57.0 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 1.262410283088684, accuracy: 56.8 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 2.3647446632385254, accuracy: 32.4 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 5.490588188171387, accuracy: 21.9 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 1.4250659942626953, accuracy: 48.9 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 1.2618496417999268, accuracy: 56.5 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 1.2540010213851929, accuracy: 56.8 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 1.3813444375991821, accuracy: 52.5 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 1.249191403388977, accuracy: 56.7 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 1.2533928155899048, accuracy: 57.9 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 1.2105, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 1.2120, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 1.2630, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 1.1969, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 1.3133, batch time: 0.04, accuracy:  53.12%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 1.2754, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 1.2528, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 1.2242, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 1.2850, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 1.1488, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 1.2725772857666016, accuracy: 55.9 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 1.5106834173202515, accuracy: 47.8 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 1.5047765970230103, accuracy: 45.1 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 1.2863473892211914, accuracy: 54.6 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 1.2926791906356812, accuracy: 55.0 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 1.259416103363037, accuracy: 56.9 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 1.2705892324447632, accuracy: 55.8 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 1.313582420349121, accuracy: 54.0 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 1.2576794624328613, accuracy: 55.6 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 1.2541755437850952, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 1.2690, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 1.1842, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 1.4098, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 1.2899, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 1.2336, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 1.1704, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 1.2591, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 1.2207, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 1.2169, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 1.3561, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 1.2055848836898804, accuracy: 57.9 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 1.697092890739441, accuracy: 45.1 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 1.5472323894500732, accuracy: 49.2 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 3.2726147174835205, accuracy: 23.6 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 1.3809312582015991, accuracy: 51.2 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 1.22472083568573, accuracy: 57.0 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 1.2116038799285889, accuracy: 58.5 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 1.225944995880127, accuracy: 57.3 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 2.9196033477783203, accuracy: 33.0 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 1.1972651481628418, accuracy: 58.0 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 1.2618, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 1.0150, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 1.3544, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 1.3098, batch time: 0.05, accuracy:  47.66%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 1.2880, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 1.2741, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 1.3049, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 1.3109, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 1.2927, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 1.2887, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 1.2439262866973877, accuracy: 56.3 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 1.5915924310684204, accuracy: 49.4 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 1.2418975830078125, accuracy: 56.2 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 3.64634108543396, accuracy: 14.7 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 1.2306078672409058, accuracy: 56.2 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 1.265355110168457, accuracy: 55.8 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 1.3459727764129639, accuracy: 54.9 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 1.2216531038284302, accuracy: 56.1 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 1.2122722864151, accuracy: 57.2 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 1.2088426351547241, accuracy: 57.4 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 1.1151, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 1.1600, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 1.2449, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 1.2859, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 1.3385, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 1.1446, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 1.2085, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 1.0863, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 1.1335, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 1.1430, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 1.154677391052246, accuracy: 59.3 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 1.7659409046173096, accuracy: 42.1 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 1.1533982753753662, accuracy: 59.1 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 1.152124047279358, accuracy: 59.3 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 1.1899360418319702, accuracy: 57.4 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 1.1516469717025757, accuracy: 59.5 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 1.1656478643417358, accuracy: 58.0 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 1.2280665636062622, accuracy: 55.8 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 1.1488815546035767, accuracy: 60.1 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 1.1475757360458374, accuracy: 60.0 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 1.3023, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 1.0743, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 1.1503, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 1.0365, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 1.2430, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 1.4891, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 1.1195, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 1.3198, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 1.2178, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 1.2036, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 1.2487437725067139, accuracy: 56.7 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 1.6178604364395142, accuracy: 46.8 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 1.4911108016967773, accuracy: 48.3 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 1.3463062047958374, accuracy: 53.2 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 1.2487242221832275, accuracy: 56.6 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 1.2365844249725342, accuracy: 56.8 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 1.2399929761886597, accuracy: 56.5 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 1.23251211643219, accuracy: 56.2 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 1.23081374168396, accuracy: 56.6 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 1.2279918193817139, accuracy: 56.3 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 1.2030, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 1.2722, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 1.3698, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 1.3489, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 1.2780, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 1.3199, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 1.3098, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 1.1232, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 1.1920, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 1.2350, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 1.209067702293396, accuracy: 57.4 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 4.4029645919799805, accuracy: 25.8 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 2.0353169441223145, accuracy: 40.3 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 1.2114349603652954, accuracy: 58.2 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 1.2078427076339722, accuracy: 57.9 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 1.2808607816696167, accuracy: 56.1 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 1.2042280435562134, accuracy: 57.9 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 1.2032874822616577, accuracy: 57.8 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 1.2011343240737915, accuracy: 58.5 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 1.2010608911514282, accuracy: 58.8 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 1.2344, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 1.2400, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 1.2686, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 1.2079, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 1.0893, batch time: 0.05, accuracy:  67.19%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 1.2771, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 1.1978, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 1.3167, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 1.2871, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 1.0595, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 1.2152655124664307, accuracy: 59.4 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 1.3071649074554443, accuracy: 58.2 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 1.2152119874954224, accuracy: 59.5 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 1.2147860527038574, accuracy: 59.8 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 1.4068759679794312, accuracy: 53.8 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 1.2064098119735718, accuracy: 59.6 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 1.2100683450698853, accuracy: 58.8 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 1.2127763032913208, accuracy: 58.6 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 1.205087661743164, accuracy: 59.7 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 1.2027677297592163, accuracy: 59.5 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 1.2512, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 1.1538, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 1.1558, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 1.0615, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 1.2755, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 1.1941, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 1.3372, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 1.3300, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 1.0077, batch time: 0.05, accuracy:  66.41%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 1.2837, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 1.1947816610336304, accuracy: 57.2 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 1.4642915725708008, accuracy: 50.0 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 1.6177433729171753, accuracy: 45.5 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 4.4996232986450195, accuracy: 18.0 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 1.2165511846542358, accuracy: 56.9 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 1.1823190450668335, accuracy: 57.3 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 1.1951030492782593, accuracy: 57.4 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 1.1796948909759521, accuracy: 57.5 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 1.1759319305419922, accuracy: 57.9 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 1.1746394634246826, accuracy: 57.7 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 1.0873, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 1.1186, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 1.0582, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 1.2545, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 1.2249, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 1.2524, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 1.1191, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 1.2327, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 1.4105, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 1.2089, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 1.2950389385223389, accuracy: 55.9 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 1.4893523454666138, accuracy: 48.7 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 2.6025853157043457, accuracy: 29.0 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 1.9472695589065552, accuracy: 31.5 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 1.2869948148727417, accuracy: 57.2 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 1.3070296049118042, accuracy: 55.0 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 1.2921104431152344, accuracy: 55.3 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 1.2732962369918823, accuracy: 56.3 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 1.2697020769119263, accuracy: 56.8 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 1.2711374759674072, accuracy: 56.8 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 1.3253, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 1.1930, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 1.1103, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 1.4196, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 1.2589, batch time: 0.08, accuracy:  57.81%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 1.0752, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 1.0746, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 1.1136, batch time: 0.08, accuracy:  63.28%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 1.4086, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 1.2056, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 1.2710886001586914, accuracy: 55.2 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 1.77998948097229, accuracy: 45.4 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 1.470829963684082, accuracy: 49.6 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 4.153115749359131, accuracy: 22.2 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 1.2828514575958252, accuracy: 55.7 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 1.2659653425216675, accuracy: 55.9 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 1.3172762393951416, accuracy: 53.8 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 1.2669979333877563, accuracy: 55.3 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 1.2626758813858032, accuracy: 55.6 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 1.2631937265396118, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 1.3381, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 1.1663, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 1.4187, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 1.3813, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 1.2400, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 1.2715, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 1.2645, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 1.2891, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 1.0793, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 1.2147, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 1.2598731517791748, accuracy: 56.0 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 2.0474982261657715, accuracy: 40.5 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 1.5717014074325562, accuracy: 46.0 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 2.296609401702881, accuracy: 37.2 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 1.2831504344940186, accuracy: 54.8 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 1.2909717559814453, accuracy: 55.1 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 1.2722618579864502, accuracy: 54.7 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 1.2542144060134888, accuracy: 56.3 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 1.231752872467041, accuracy: 56.0 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 1.2282934188842773, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 1.1711, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 1.2117, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 1.1380, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 1.1868, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 1.2572, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 1.3326, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 1.2249, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 1.1512, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 1.0414, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 1.3124, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 1.2772636413574219, accuracy: 55.7 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 1.2773054838180542, accuracy: 55.6 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 1.5154485702514648, accuracy: 48.1 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 1.3796753883361816, accuracy: 53.8 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 1.3510959148406982, accuracy: 53.3 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 1.431668758392334, accuracy: 50.1 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 1.2705495357513428, accuracy: 55.7 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 1.2675613164901733, accuracy: 55.9 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 1.2661900520324707, accuracy: 56.3 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 1.2669861316680908, accuracy: 56.3 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 1.1871, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 1.2755, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 1.2105, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 1.1451, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 1.1383, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 1.2175, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 1.1575, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 1.2609, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 1.3422, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 1.2629, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 1.2087327241897583, accuracy: 57.0 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 3.2332396507263184, accuracy: 25.3 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 1.3562941551208496, accuracy: 53.0 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 2.9394359588623047, accuracy: 30.1 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 1.2042490243911743, accuracy: 57.1 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 1.3437234163284302, accuracy: 54.2 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 1.2080366611480713, accuracy: 55.4 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 1.2126926183700562, accuracy: 57.1 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 1.1971145868301392, accuracy: 57.1 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 1.1964865922927856, accuracy: 56.9 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 1.2556, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 1.1331, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 1.0696, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 1.2677, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 1.3156, batch time: 0.05, accuracy:  50.00%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 1.1865, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 1.0793, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 1.1356, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 1.3786, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 1.2555, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 1.1760551929473877, accuracy: 57.8 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 1.2704545259475708, accuracy: 52.0 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 1.352787733078003, accuracy: 51.7 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 4.037282943725586, accuracy: 26.2 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 1.1698812246322632, accuracy: 58.1 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 1.328339695930481, accuracy: 51.4 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 1.1655070781707764, accuracy: 58.8 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 1.1633033752441406, accuracy: 58.3 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 1.162634253501892, accuracy: 58.9 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 1.1614711284637451, accuracy: 57.8 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 1.2812, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 1.4333, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 1.1157, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 1.2590, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 1.2392, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 1.3157, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.9785, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 1.3537, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 1.1493, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 1.0836, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 1.2317670583724976, accuracy: 56.5 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 1.3708785772323608, accuracy: 53.5 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 1.2270629405975342, accuracy: 57.1 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 1.2270629405975342, accuracy: 57.1 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 1.2281326055526733, accuracy: 57.7 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 1.22018563747406, accuracy: 56.9 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 1.2331007719039917, accuracy: 56.1 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 1.4085144996643066, accuracy: 51.2 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 1.2231451272964478, accuracy: 56.6 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 1.2146469354629517, accuracy: 56.2 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 1.1332, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 1.2685, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 1.0427, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 1.1458, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 1.2162, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 1.2920, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 1.1366, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 1.1776, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 1.2464, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 1.1594, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 1.2317700386047363, accuracy: 55.6 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 1.3263614177703857, accuracy: 54.6 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 1.3636723756790161, accuracy: 53.4 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 1.4287012815475464, accuracy: 51.8 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 1.2376177310943604, accuracy: 56.3 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 1.2233132123947144, accuracy: 55.4 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 1.2293610572814941, accuracy: 56.6 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 1.224615454673767, accuracy: 56.9 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 1.218530297279358, accuracy: 56.3 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 1.2168446779251099, accuracy: 56.3 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 1.3670, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 1.0617, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 1.2179, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 1.3369, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 1.1958, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 1.2433, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 1.1217, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 1.5142, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 1.0564, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 1.2155, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 1.2035882472991943, accuracy: 56.4 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 1.2122243642807007, accuracy: 55.5 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 1.1946961879730225, accuracy: 56.8 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 1.1871296167373657, accuracy: 57.5 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 1.5271711349487305, accuracy: 48.5 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 1.1841108798980713, accuracy: 58.8 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 1.2015565633773804, accuracy: 56.3 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 1.1812657117843628, accuracy: 58.0 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 1.1783931255340576, accuracy: 58.0 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 1.2215137481689453, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 1.2576, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 1.2407, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 1.2485, batch time: 0.08, accuracy:  55.47%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 1.1990, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 1.1404, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 1.2474, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 1.2538, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 1.1062, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 1.1400, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 1.2601, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 1.2105896472930908, accuracy: 57.9 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 1.3739794492721558, accuracy: 52.1 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 3.043260097503662, accuracy: 30.8 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 1.8122289180755615, accuracy: 41.8 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 1.214273452758789, accuracy: 58.7 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 1.2094906568527222, accuracy: 58.2 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 1.213362455368042, accuracy: 57.0 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 1.2108941078186035, accuracy: 58.3 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 1.2175278663635254, accuracy: 58.5 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 1.2048020362854004, accuracy: 58.9 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 1.3249, batch time: 0.05, accuracy:  49.22%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 1.1260, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 1.0850, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 1.2018, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 1.3334, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 1.3557, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 1.2890, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 1.2113, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 1.2542, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 1.2463, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 1.1724450588226318, accuracy: 59.4 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 1.518367052078247, accuracy: 49.0 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 1.266140341758728, accuracy: 54.2 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 2.6492772102355957, accuracy: 21.6 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 1.230931043624878, accuracy: 56.8 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 1.1783654689788818, accuracy: 57.7 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 1.1711413860321045, accuracy: 59.9 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 1.1899120807647705, accuracy: 57.1 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 1.1650599241256714, accuracy: 59.4 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 1.1719915866851807, accuracy: 59.0 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 1.2865, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 1.1608, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 1.2269, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 1.2740, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 1.3625, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 1.2916, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 1.3514, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 1.2602, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 1.3177, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 1.2633, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 1.2467687129974365, accuracy: 58.4 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 1.2488689422607422, accuracy: 58.2 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 1.3795241117477417, accuracy: 53.1 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 1.3541678190231323, accuracy: 52.4 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 1.4005937576293945, accuracy: 53.5 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 1.3874930143356323, accuracy: 50.7 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 1.244947075843811, accuracy: 58.0 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 1.239513635635376, accuracy: 58.7 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 1.2383620738983154, accuracy: 58.6 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 1.2375590801239014, accuracy: 57.5 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 1.1921, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 1.3457, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 1.3554, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 1.1414, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 1.0163, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 1.1870, batch time: 0.06, accuracy:  60.16%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 1.1912, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 1.2333, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 1.2210, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.9847, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 1.2108124494552612, accuracy: 58.5 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 1.2340186834335327, accuracy: 56.9 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 1.3084235191345215, accuracy: 55.8 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 5.339086055755615, accuracy: 18.2 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 1.2095887660980225, accuracy: 58.8 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 1.2057133913040161, accuracy: 59.3 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 1.2593398094177246, accuracy: 57.6 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 1.9228743314743042, accuracy: 37.6 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 1.195196509361267, accuracy: 58.1 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 1.1923508644104004, accuracy: 58.5 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 1.3186, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 1.1551, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 1.0702, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 1.1654, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 1.3059, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 1.0714, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 1.1886, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 1.2514, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 1.3224, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 1.1221, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 1.1584577560424805, accuracy: 58.3 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 4.754941940307617, accuracy: 24.9 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 1.5700706243515015, accuracy: 49.2 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 1.3013845682144165, accuracy: 53.2 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 1.2151119709014893, accuracy: 58.4 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 1.1658011674880981, accuracy: 58.4 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 1.1521742343902588, accuracy: 58.5 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 1.152055025100708, accuracy: 58.7 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 1.1544127464294434, accuracy: 57.7 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 1.1643506288528442, accuracy: 58.7 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 1.1859, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 1.1974, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 1.3230, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 1.2370, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 1.1004, batch time: 0.08, accuracy:  64.06%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 1.2832, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 1.1699, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 1.2706, batch time: 0.05, accuracy:  53.12%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 1.0639, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 1.1978, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 1.1852221488952637, accuracy: 58.7 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 1.2088779211044312, accuracy: 59.0 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 1.581327199935913, accuracy: 46.9 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 1.5320438146591187, accuracy: 48.2 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 1.2174218893051147, accuracy: 58.2 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 1.2119715213775635, accuracy: 56.9 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 1.2156683206558228, accuracy: 58.7 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 1.1765661239624023, accuracy: 59.1 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 1.1758917570114136, accuracy: 59.7 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 1.1752690076828003, accuracy: 59.4 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 1.2721, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 1.2588, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 1.1422, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 1.1507, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 1.4656, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 1.2304, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 1.3471, batch time: 0.05, accuracy:  54.69%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 1.2805, batch time: 0.05, accuracy:  55.47%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 1.0576, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 1.4820, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 1.1518189907073975, accuracy: 59.7 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 1.1755492687225342, accuracy: 58.8 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 1.1495862007141113, accuracy: 59.5 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 1.1488101482391357, accuracy: 59.4 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 1.1476713418960571, accuracy: 60.7 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 1.164856195449829, accuracy: 59.9 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 1.1466000080108643, accuracy: 60.6 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 1.1468383073806763, accuracy: 59.9 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 1.1435686349868774, accuracy: 60.0 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 1.1428126096725464, accuracy: 59.9 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 1.2894, batch time: 0.05, accuracy:  51.56%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 1.1510, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 1.3822, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 1.3401, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 1.2278, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 1.4497, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 1.1824, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 1.1492, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 1.2399, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 1.0074, batch time: 0.05, accuracy:  70.31%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 1.23823082447052, accuracy: 56.9 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 1.8517671823501587, accuracy: 44.6 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 1.3881193399429321, accuracy: 53.9 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 1.7108122110366821, accuracy: 47.2 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 1.280076503753662, accuracy: 56.4 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 1.229012131690979, accuracy: 56.7 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 1.394349217414856, accuracy: 52.8 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 1.2321603298187256, accuracy: 55.9 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 1.2249804735183716, accuracy: 56.6 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 1.2299213409423828, accuracy: 56.7 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 1.0681, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 1.1051, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 1.1011, batch time: 0.05, accuracy:  61.72%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 1.1403, batch time: 0.05, accuracy:  63.28%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 1.2671, batch time: 0.05, accuracy:  53.91%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 1.2497, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 1.2537, batch time: 0.05, accuracy:  56.25%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 1.1145, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 1.2061, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 1.4231, batch time: 0.05, accuracy:  45.31%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 1.2340625524520874, accuracy: 57.8 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 1.3881340026855469, accuracy: 50.6 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 1.2359952926635742, accuracy: 56.0 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 1.2276802062988281, accuracy: 57.6 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 1.2217015027999878, accuracy: 57.3 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 1.3128647804260254, accuracy: 55.5 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 1.215638518333435, accuracy: 57.9 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 1.2168073654174805, accuracy: 58.1 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 1.220192790031433, accuracy: 57.5 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 1.2143014669418335, accuracy: 57.7 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 1.1237, batch time: 0.05, accuracy:  59.38%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 1.2071, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 1.2147, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 1.3251, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 1.2676, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 1.1520, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 1.3143, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 1.1698, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 1.2471, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 1.1259, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 1.1580522060394287, accuracy: 59.5 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 1.1675339937210083, accuracy: 59.1 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 1.2905774116516113, accuracy: 54.1 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 1.181220293045044, accuracy: 59.7 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 1.1961838006973267, accuracy: 59.1 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 1.1528542041778564, accuracy: 59.3 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 1.1518009901046753, accuracy: 59.1 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 1.1694302558898926, accuracy: 59.8 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 1.1496235132217407, accuracy: 59.8 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 1.2189910411834717, accuracy: 56.9 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 1.3455, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 1.2278, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 1.0656, batch time: 0.05, accuracy:  64.84%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 1.1745, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 1.1719, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 1.1413, batch time: 0.05, accuracy:  62.50%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 1.4062, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 1.3239, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 1.0929, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 1.1688, batch time: 0.05, accuracy:  60.16%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 1.2243307828903198, accuracy: 58.0 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 1.2413302659988403, accuracy: 57.6 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 1.2231675386428833, accuracy: 57.7 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 1.2220686674118042, accuracy: 58.5 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 1.3290055990219116, accuracy: 52.4 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 1.217932105064392, accuracy: 58.3 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 1.2236354351043701, accuracy: 58.4 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 1.21282160282135, accuracy: 58.8 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 1.2280999422073364, accuracy: 56.5 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 1.2361643314361572, accuracy: 57.7 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 1.2037, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 1.1703, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 1.3364, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 1.2180, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 1.1723, batch time: 0.05, accuracy:  60.94%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.9059, batch time: 0.10, accuracy:  69.53%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 1.3308, batch time: 0.05, accuracy:  50.78%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 1.2731, batch time: 0.05, accuracy:  57.03%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 1.1445, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 1.3229, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 1.2176635265350342, accuracy: 58.0 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 2.2829525470733643, accuracy: 38.1 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 1.3499382734298706, accuracy: 54.3 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 1.242365837097168, accuracy: 55.8 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 1.465205430984497, accuracy: 47.9 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 1.2240383625030518, accuracy: 58.0 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 1.213363528251648, accuracy: 58.2 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 1.2109652757644653, accuracy: 58.9 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 1.210864543914795, accuracy: 59.1 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 1.2091882228851318, accuracy: 58.2 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 1.1776, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 1.2271, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 1.2951, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 1.2953, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 1.3332, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 1.1645, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 1.2497, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 1.1199, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 1.2983, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 1.5087, batch time: 0.05, accuracy:  44.53%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 1.207366943359375, accuracy: 57.2 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 2.4992473125457764, accuracy: 32.3 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 2.784558057785034, accuracy: 28.3 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 1.5126430988311768, accuracy: 48.0 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 1.207647442817688, accuracy: 56.0 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 1.2651522159576416, accuracy: 51.4 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 1.2485171556472778, accuracy: 55.4 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 1.1883641481399536, accuracy: 58.4 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 1.1888536214828491, accuracy: 58.3 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 1.1901570558547974, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 1.0987, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 1.1701, batch time: 0.05, accuracy:  58.59%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 1.4963, batch time: 0.05, accuracy:  52.34%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 1.3029, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 1.2102, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 1.1975, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 1.2502, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 1.1253, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 1.1828, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 1.2283, batch time: 0.05, accuracy:  57.81%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 1.2188791036605835, accuracy: 57.5 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 1.3677527904510498, accuracy: 52.1 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 2.845216989517212, accuracy: 31.5 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 1.5693769454956055, accuracy: 44.2 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 1.2317172288894653, accuracy: 56.5 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 1.2148131132125854, accuracy: 58.1 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 1.2191115617752075, accuracy: 57.9 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 1.213416576385498, accuracy: 58.1 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 1.2146477699279785, accuracy: 58.5 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 1.2263139486312866, accuracy: 57.8 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 1.1212, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 1.2789, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 1.3961, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 1.3315, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 1.1332, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 1.3354, batch time: 0.09, accuracy:  53.91%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 1.3667, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 1.2675, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 1.3551, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 1.1638, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 1.190653920173645, accuracy: 56.3 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 7.4507036209106445, accuracy: 15.3 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 1.1841458082199097, accuracy: 57.6 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 1.1841458082199097, accuracy: 57.6 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 1.2992552518844604, accuracy: 56.2 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 1.1757186651229858, accuracy: 58.2 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 1.1808900833129883, accuracy: 58.5 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 1.188812494277954, accuracy: 57.6 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 1.1755133867263794, accuracy: 60.1 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 1.1700465679168701, accuracy: 58.0 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 1.2133, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 1.2631, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 1.0881, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 1.1910, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 1.2611, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 1.2036, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 1.3189, batch time: 0.07, accuracy:  59.38%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 1.1359, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 1.3824, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 1.2236, batch time: 0.05, accuracy:  48.44%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 1.2283945083618164, accuracy: 55.2 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 1.9093655347824097, accuracy: 41.3 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 1.374869465827942, accuracy: 48.8 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 4.170475959777832, accuracy: 23.1 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 1.2896757125854492, accuracy: 53.4 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 1.261286735534668, accuracy: 53.8 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 1.2225909233093262, accuracy: 55.8 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 1.2210493087768555, accuracy: 56.3 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 1.2197555303573608, accuracy: 55.9 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 1.2196928262710571, accuracy: 55.3 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 1.0605, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 1.3187, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 1.1796, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 1.1024, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 1.2085, batch time: 0.04, accuracy:  57.81%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 1.1649, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 1.0140, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 1.4170, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 1.1281, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 1.1145, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 1.2230380773544312, accuracy: 57.8 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 1.7440482378005981, accuracy: 44.8 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 1.256373405456543, accuracy: 56.4 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 1.2200162410736084, accuracy: 57.9 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 1.2220213413238525, accuracy: 58.2 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 1.30088210105896, accuracy: 54.8 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 1.221409797668457, accuracy: 56.8 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 1.208741545677185, accuracy: 58.3 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 1.207409143447876, accuracy: 57.9 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 1.2089276313781738, accuracy: 57.2 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 1.1005, batch time: 0.04, accuracy:  66.41%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 1.0561, batch time: 0.04, accuracy:  60.94%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 1.5220, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 1.3320, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 1.2854, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 1.1739, batch time: 0.04, accuracy:  56.25%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 1.1012, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 1.1997, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 1.1733, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 1.0573, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 1.158454418182373, accuracy: 58.2 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 1.7906414270401, accuracy: 45.4 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 1.1580334901809692, accuracy: 58.1 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 1.157996654510498, accuracy: 58.8 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 1.2965247631072998, accuracy: 55.1 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 1.2968649864196777, accuracy: 54.3 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 1.1822893619537354, accuracy: 58.7 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 1.225319504737854, accuracy: 58.0 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 1.1493324041366577, accuracy: 60.4 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 1.1485968828201294, accuracy: 60.3 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 1.1700, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 1.1811, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 1.2629, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 1.2551, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 1.1260, batch time: 0.06, accuracy:  63.28%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 1.2946, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 1.1352, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 1.2545, batch time: 0.04, accuracy:  65.62%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 1.2330, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 1.2523, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 1.168042778968811, accuracy: 59.1 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 1.4862710237503052, accuracy: 49.6 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 1.372554063796997, accuracy: 51.7 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 1.1657224893569946, accuracy: 60.3 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 1.165981411933899, accuracy: 60.5 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 1.1646876335144043, accuracy: 60.1 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 1.1961003541946411, accuracy: 58.4 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 1.1851707696914673, accuracy: 59.5 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 1.2014387845993042, accuracy: 58.0 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 1.158100962638855, accuracy: 60.0 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 1.1508, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 1.2715, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 1.0526, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 1.1828, batch time: 0.04, accuracy:  60.16%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 1.1481, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 1.2713, batch time: 0.04, accuracy:  54.69%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 1.0686, batch time: 0.04, accuracy:  62.50%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 1.0566, batch time: 0.04, accuracy:  61.72%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 1.2606, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 1.0872, batch time: 0.36, accuracy:  53.91%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 1.1699631214141846, accuracy: 58.4 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 1.9216018915176392, accuracy: 42.4 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 1.3363018035888672, accuracy: 52.5 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 1.568656086921692, accuracy: 47.8 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 1.6055471897125244, accuracy: 45.7 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 1.16425621509552, accuracy: 58.2 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 1.1685160398483276, accuracy: 59.1 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 1.1609748601913452, accuracy: 59.5 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 1.1647422313690186, accuracy: 58.7 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 1.1597416400909424, accuracy: 59.3 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 1.1273, batch time: 0.04, accuracy:  57.03%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 1.1342, batch time: 0.04, accuracy:  63.28%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 1.2734, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 1.1624, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.9469, batch time: 0.04, accuracy:  67.19%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 1.3549, batch time: 0.04, accuracy:  55.47%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 1.2192, batch time: 0.04, accuracy:  59.38%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 1.2525, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 1.1011, batch time: 0.04, accuracy:  58.59%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 1.2361, batch time: 0.04, accuracy:  64.06%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 1.1952770948410034, accuracy: 56.8 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 1.5175966024398804, accuracy: 50.3 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 1.51597261428833, accuracy: 52.8 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 4.862055778503418, accuracy: 8.8 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 1.313778042793274, accuracy: 54.7 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 1.3223633766174316, accuracy: 53.6 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 1.2169203758239746, accuracy: 56.8 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 1.18545663356781, accuracy: 57.6 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 1.1848089694976807, accuracy: 57.3 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 1.1912004947662354, accuracy: 57.2 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.149613618850708, 2.1110739707946777, 1.7564061880111694, 1.7092539072036743, 1.929527997970581, 1.7095725536346436, 1.9216549396514893, 1.690267562866211, 1.6028610467910767, 1.6295711994171143, 1.573036789894104, 1.694886565208435, 1.6495144367218018, 1.6637262105941772, 1.6380361318588257, 1.5907968282699585, 1.7822449207305908, 1.7411184310913086, 1.5795848369598389, 1.5599356889724731, 1.4623576402664185, 1.522243618965149, 1.7387726306915283, 1.5159761905670166, 1.536880612373352, 1.6139177083969116, 1.7068501710891724, 1.8695920705795288, 1.5959938764572144, 1.5842989683151245, 1.5631402730941772, 1.622499704360962, 1.4152424335479736, 1.5524331331253052, 1.3067001104354858, 1.3930407762527466, 1.5747548341751099, 1.3302451372146606, 1.2404205799102783, 1.3741261959075928, 1.3469451665878296, 1.4082132577896118, 1.5284547805786133, 1.481879472732544, 1.385299563407898, 1.3949590921401978, 1.6969114542007446, 1.4658633470535278, 1.3639488220214844, 1.4080469608306885, 1.435824990272522, 1.3576868772506714, 1.355737328529358, 1.211047887802124, 1.1806385517120361, 1.4945590496063232, 1.431732177734375, 1.3978853225708008, 1.4888893365859985, 1.3326560258865356, 1.38235342502594, 1.3996059894561768, 1.2699981927871704, 1.470725417137146, 1.4648042917251587, 1.2996766567230225, 1.3426514863967896, 1.4608738422393799, 1.1927253007888794, 1.3271424770355225, 1.751233458518982, 1.3147945404052734, 1.336505651473999, 1.3774125576019287, 1.3135823011398315, 1.1714907884597778, 1.3122090101242065, 1.5196077823638916, 1.727774977684021, 1.3817237615585327, 1.3439079523086548, 1.3584860563278198, 1.3585423231124878, 1.4466406106948853, 1.4295817613601685, 1.3208450078964233, 1.4261585474014282, 1.1730800867080688, 1.3262673616409302, 1.3936707973480225, 1.5109682083129883, 1.5080000162124634, 1.3715484142303467, 1.4883873462677002, 1.3748618364334106, 1.3147374391555786, 1.6534959077835083, 1.3781582117080688, 1.4487841129302979, 1.2834621667861938, 1.1992844343185425, 1.2246416807174683, 1.2174936532974243, 1.2801870107650757, 1.4153635501861572, 1.3611068725585938, 1.4315690994262695, 1.350080132484436, 1.331992268562317, 1.269446611404419, 1.3916263580322266, 1.48589026927948, 1.4198893308639526, 1.324070692062378, 1.3119210004806519, 1.455413818359375, 1.1780136823654175, 1.285886526107788, 1.3063730001449585, 1.239674687385559, 1.3392198085784912, 1.4237533807754517, 1.2929048538208008, 1.3164924383163452, 1.4023815393447876, 1.2375916242599487, 1.1567413806915283, 1.1739073991775513, 1.283149003982544, 1.3841407299041748, 1.39276921749115, 1.4181172847747803, 1.3424808979034424, 1.5153028964996338, 1.3186712265014648, 1.384055256843567, 1.253011703491211, 1.1889837980270386, 1.2348588705062866, 1.411724328994751, 1.2138105630874634, 1.2356294393539429, 1.2724412679672241, 1.3405967950820923, 1.2408621311187744, 1.1243817806243896, 1.3533754348754883, 1.4067147970199585, 1.3322839736938477, 1.3355588912963867, 1.2011082172393799, 1.0627847909927368, 1.252074122428894, 1.457547903060913, 1.2895163297653198, 1.4694997072219849, 1.4164355993270874, 1.3908908367156982, 1.110138177871704, 1.135118842124939, 1.1140762567520142, 1.1711288690567017, 1.2373313903808594, 1.178210973739624, 1.2174538373947144, 1.2703298330307007, 1.2727376222610474, 1.2522649765014648, 1.2939974069595337, 1.2928458452224731, 1.2743291854858398, 1.1612656116485596, 1.266381859779358, 1.3835004568099976, 1.0639413595199585, 1.2748544216156006, 1.1178382635116577, 1.142370343208313, 1.3197470903396606, 1.1593315601348877, 1.2184524536132812, 1.1456832885742188, 1.0033552646636963, 1.1036912202835083, 1.0706684589385986, 1.2189605236053467, 1.0865697860717773, 1.1265884637832642, 1.2211415767669678, 1.221909523010254, 1.1851226091384888, 1.3360201120376587, 1.172418475151062, 1.1661938428878784, 1.1422548294067383, 1.3562980890274048, 1.1255662441253662, 1.219422459602356, 1.1674516201019287, 1.1031314134597778]\n",
      "[22.321428571428573, 16.964285714285715, 40.17857142857143, 38.392857142857146, 26.785714285714285, 44.642857142857146, 28.571428571428573, 39.285714285714285, 44.642857142857146, 39.285714285714285, 41.07142857142857, 37.5, 41.07142857142857, 38.392857142857146, 40.17857142857143, 42.857142857142854, 34.82142857142857, 42.857142857142854, 47.32142857142857, 42.857142857142854, 48.214285714285715, 50.0, 46.42857142857143, 41.964285714285715, 49.107142857142854, 40.17857142857143, 41.964285714285715, 33.92857142857143, 42.857142857142854, 47.32142857142857, 41.964285714285715, 38.392857142857146, 49.107142857142854, 50.892857142857146, 56.25, 50.892857142857146, 49.107142857142854, 56.25, 64.28571428571429, 56.25, 50.0, 52.67857142857143, 48.214285714285715, 54.464285714285715, 62.5, 53.57142857142857, 45.535714285714285, 48.214285714285715, 52.67857142857143, 53.57142857142857, 42.857142857142854, 58.92857142857143, 53.57142857142857, 58.035714285714285, 64.28571428571429, 51.785714285714285, 52.67857142857143, 54.464285714285715, 47.32142857142857, 54.464285714285715, 51.785714285714285, 54.464285714285715, 53.57142857142857, 50.892857142857146, 47.32142857142857, 60.714285714285715, 57.142857142857146, 47.32142857142857, 63.392857142857146, 55.357142857142854, 45.535714285714285, 58.92857142857143, 53.57142857142857, 52.67857142857143, 54.464285714285715, 63.392857142857146, 57.142857142857146, 50.892857142857146, 46.42857142857143, 54.464285714285715, 52.67857142857143, 58.035714285714285, 51.785714285714285, 52.67857142857143, 49.107142857142854, 56.25, 50.0, 58.035714285714285, 57.142857142857146, 51.785714285714285, 50.0, 51.785714285714285, 51.785714285714285, 48.214285714285715, 56.25, 52.67857142857143, 49.107142857142854, 55.357142857142854, 52.67857142857143, 53.57142857142857, 60.714285714285715, 57.142857142857146, 55.357142857142854, 64.28571428571429, 50.0, 54.464285714285715, 45.535714285714285, 56.25, 57.142857142857146, 53.57142857142857, 51.785714285714285, 44.642857142857146, 51.785714285714285, 51.785714285714285, 53.57142857142857, 51.785714285714285, 61.607142857142854, 51.785714285714285, 58.035714285714285, 54.464285714285715, 52.67857142857143, 41.964285714285715, 57.142857142857146, 55.357142857142854, 48.214285714285715, 50.892857142857146, 55.357142857142854, 53.57142857142857, 50.892857142857146, 57.142857142857146, 46.42857142857143, 53.57142857142857, 47.32142857142857, 48.214285714285715, 52.67857142857143, 51.785714285714285, 55.357142857142854, 60.714285714285715, 53.57142857142857, 57.142857142857146, 58.92857142857143, 59.82142857142857, 53.57142857142857, 54.464285714285715, 58.035714285714285, 59.82142857142857, 52.67857142857143, 54.464285714285715, 52.67857142857143, 50.0, 58.92857142857143, 63.392857142857146, 53.57142857142857, 47.32142857142857, 58.035714285714285, 49.107142857142854, 50.0, 56.25, 61.607142857142854, 54.464285714285715, 62.5, 57.142857142857146, 54.464285714285715, 58.92857142857143, 55.357142857142854, 56.25, 58.92857142857143, 56.25, 53.57142857142857, 49.107142857142854, 43.75, 58.92857142857143, 55.357142857142854, 50.0, 58.92857142857143, 59.82142857142857, 62.5, 57.142857142857146, 53.57142857142857, 57.142857142857146, 58.035714285714285, 60.714285714285715, 66.96428571428571, 66.96428571428571, 64.28571428571429, 61.607142857142854, 66.07142857142857, 61.607142857142854, 58.035714285714285, 59.82142857142857, 55.357142857142854, 48.214285714285715, 60.714285714285715, 58.92857142857143, 55.357142857142854, 54.464285714285715, 58.035714285714285, 59.82142857142857, 57.142857142857146, 60.714285714285715]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [2.181758403778076, 2.0800328254699707, 1.9113519191741943, 1.7873510122299194, 2.010037899017334, 1.6513739824295044, 1.7825473546981812, 1.707285761833191, 1.6182714700698853, 1.6775875091552734, 1.7792770862579346, 1.5184249877929688, 1.613982081413269, 1.582148790359497, 1.5099925994873047, 1.5111676454544067, 1.5821151733398438, 1.3782964944839478, 1.5507811307907104, 1.4803277254104614, 1.5449422597885132, 1.3644582033157349, 1.5389660596847534, 1.388230562210083, 1.4657150506973267, 1.3372951745986938, 1.3690675497055054, 1.4174163341522217, 1.332667589187622, 1.2755534648895264, 1.4989807605743408, 1.3738235235214233, 1.3766955137252808, 1.3186330795288086, 1.2987433671951294, 1.3430877923965454, 1.1920098066329956, 1.2732549905776978, 1.313113808631897, 1.3439140319824219, 1.273341178894043, 1.2552624940872192, 1.4518897533416748, 1.2770353555679321, 1.2692269086837769, 1.32889723777771, 1.4667245149612427, 1.183014154434204, 1.2832908630371094, 1.526262640953064, 1.3969553709030151, 1.4551345109939575, 1.2529014348983765, 1.269129991531372, 1.2660857439041138, 1.3396437168121338, 1.3297064304351807, 1.3368031978607178, 1.323429822921753, 1.2604036331176758, 1.286124348640442, 1.2277231216430664, 1.3039203882217407, 1.4600270986557007, 1.2554348707199097, 1.356606364250183, 1.386740803718567, 1.1783103942871094, 1.1205838918685913, 1.3522627353668213, 1.2018154859542847, 1.1229127645492554, 1.2872291803359985, 1.1772546768188477, 1.214295744895935, 1.333033800125122, 1.3178682327270508, 1.109094262123108, 1.392215609550476, 1.418505311012268, 1.517653226852417, 1.2559953927993774, 1.3089559078216553, 1.269590139389038, 1.272265076637268, 1.188071608543396, 1.2733105421066284, 1.3886979818344116, 1.3456918001174927, 1.1471779346466064, 1.3745677471160889, 1.2683442831039429, 1.235698938369751, 1.232881784439087, 1.1579028367996216, 1.2386480569839478, 1.3132861852645874, 1.4662226438522339, 1.335034728050232, 1.1445297002792358, 1.1835731267929077, 1.1042321920394897, 1.1467297077178955, 1.318407416343689, 1.2307922840118408, 1.3246859312057495, 1.2954763174057007, 1.1391161680221558, 1.2673819065093994, 1.4617633819580078, 1.2026783227920532, 1.242130160331726, 1.0252546072006226, 1.2436681985855103, 1.3377313613891602, 1.2418862581253052, 1.1981217861175537, 1.0359219312667847, 1.4083162546157837, 1.2499717473983765, 1.4352489709854126, 1.3252525329589844, 1.2754875421524048, 1.3823469877243042, 1.4201316833496094, 1.3396159410476685, 1.0669749975204468, 1.066733479499817, 1.3329380750656128, 1.1660356521606445, 1.257463812828064, 1.3749560117721558, 1.3424235582351685, 1.2410694360733032, 1.3309400081634521, 1.3215464353561401, 1.5480822324752808, 1.164183497428894, 1.3782432079315186, 1.1613460779190063, 1.2386778593063354, 1.2876695394515991, 1.0774728059768677, 1.3293523788452148, 1.2220085859298706, 1.225321888923645, 1.207922339439392, 1.0817488431930542, 1.1480398178100586, 1.2403888702392578, 1.2670297622680664, 1.3535255193710327, 1.23381769657135, 1.1537551879882812, 1.198246955871582, 1.0624487400054932, 1.3231946229934692, 1.04517662525177, 1.2314239740371704, 1.2562955617904663, 0.9647848010063171, 1.148559331893921, 1.0539649724960327, 1.2239235639572144, 1.4946081638336182, 1.1764888763427734, 1.3440656661987305, 1.2643102407455444, 1.148903250694275, 1.0862091779708862, 1.1565221548080444, 1.2101253271102905, 1.06053626537323, 1.2440563440322876, 1.132211446762085, 1.2512319087982178, 1.2562793493270874, 1.2431327104568481, 1.2919228076934814, 1.201576590538025, 1.0369642972946167, 1.3534268140792847, 1.1693713665008545, 1.0815515518188477, 1.0685991048812866, 1.260898232460022, 1.0983182191848755, 1.013895869255066, 1.298538088798523, 1.3364924192428589, 1.1518117189407349, 1.2480412721633911, 1.0587397813796997, 1.110772967338562, 1.3706262111663818, 0.9972884058952332, 1.2655360698699951, 1.4233003854751587, 1.217613935470581, 1.3071744441986084]\n",
    "# acc_list_epoch_ = [18.75, 21.428571428571427, 25.892857142857142, 32.142857142857146, 22.321428571428573, 35.714285714285715, 35.714285714285715, 31.25, 31.25, 40.17857142857143, 33.92857142857143, 47.32142857142857, 41.07142857142857, 42.857142857142854, 34.82142857142857, 41.07142857142857, 47.32142857142857, 49.107142857142854, 45.535714285714285, 43.75, 43.75, 47.32142857142857, 37.5, 41.07142857142857, 40.17857142857143, 54.464285714285715, 50.892857142857146, 43.75, 50.0, 56.25, 37.5, 49.107142857142854, 53.57142857142857, 56.25, 59.82142857142857, 50.0, 55.357142857142854, 57.142857142857146, 52.67857142857143, 52.67857142857143, 56.25, 44.642857142857146, 39.285714285714285, 58.92857142857143, 52.67857142857143, 51.785714285714285, 53.57142857142857, 62.5, 48.214285714285715, 50.0, 55.357142857142854, 37.5, 52.67857142857143, 57.142857142857146, 52.67857142857143, 54.464285714285715, 51.785714285714285, 49.107142857142854, 54.464285714285715, 57.142857142857146, 50.892857142857146, 57.142857142857146, 56.25, 48.214285714285715, 53.57142857142857, 52.67857142857143, 50.0, 58.035714285714285, 60.714285714285715, 56.25, 55.357142857142854, 66.07142857142857, 48.214285714285715, 61.607142857142854, 55.357142857142854, 52.67857142857143, 58.92857142857143, 61.607142857142854, 52.67857142857143, 46.42857142857143, 54.464285714285715, 50.892857142857146, 50.0, 54.464285714285715, 53.57142857142857, 60.714285714285715, 49.107142857142854, 49.107142857142854, 60.714285714285715, 58.035714285714285, 57.142857142857146, 54.464285714285715, 55.357142857142854, 59.82142857142857, 58.035714285714285, 48.214285714285715, 55.357142857142854, 55.357142857142854, 54.464285714285715, 58.92857142857143, 59.82142857142857, 58.035714285714285, 64.28571428571429, 54.464285714285715, 59.82142857142857, 49.107142857142854, 54.464285714285715, 60.714285714285715, 55.357142857142854, 58.035714285714285, 52.67857142857143, 61.607142857142854, 66.07142857142857, 57.142857142857146, 54.464285714285715, 58.92857142857143, 57.142857142857146, 66.07142857142857, 51.785714285714285, 51.785714285714285, 50.0, 57.142857142857146, 55.357142857142854, 51.785714285714285, 55.357142857142854, 50.892857142857146, 59.82142857142857, 63.392857142857146, 50.0, 64.28571428571429, 53.57142857142857, 54.464285714285715, 56.25, 58.92857142857143, 49.107142857142854, 50.892857142857146, 45.535714285714285, 59.82142857142857, 46.42857142857143, 54.464285714285715, 62.5, 57.142857142857146, 61.607142857142854, 45.535714285714285, 50.892857142857146, 51.785714285714285, 52.67857142857143, 62.5, 57.142857142857146, 60.714285714285715, 58.92857142857143, 55.357142857142854, 50.0, 55.357142857142854, 60.714285714285715, 56.25, 55.357142857142854, 66.07142857142857, 58.92857142857143, 55.357142857142854, 64.28571428571429, 58.035714285714285, 62.5, 60.714285714285715, 50.0, 53.57142857142857, 50.892857142857146, 51.785714285714285, 55.357142857142854, 58.92857142857143, 55.357142857142854, 54.464285714285715, 60.714285714285715, 57.142857142857146, 61.607142857142854, 56.25, 56.25, 57.142857142857146, 59.82142857142857, 56.25, 65.17857142857143, 56.25, 61.607142857142854, 66.07142857142857, 58.035714285714285, 53.57142857142857, 57.142857142857146, 66.07142857142857, 51.785714285714285, 47.32142857142857, 54.464285714285715, 58.92857142857143, 53.57142857142857, 60.714285714285715, 60.714285714285715, 61.607142857142854, 56.25, 44.642857142857146, 53.57142857142857, 53.57142857142857]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 59.15%\n",
      "Loss on the train set: 1.19\n",
      "Accuracy on the test set: 58.33%\n",
      "Loss on the test set: 1.21\n",
      "Generalization error: 0.022678375\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
