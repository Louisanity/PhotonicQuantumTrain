{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.022221</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.729488</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.279416</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.745685</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.171221</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.933095</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.043621</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.905426</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.06141</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.341671</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.308488</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.136929</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.022875</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.387354</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.461961</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.14215</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.325338</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.967445</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.30966</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.214037</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.720249</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.385515</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.104261</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.414145</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.068408</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.606459</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.588886</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.558412</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.585566</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.611718</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.277701</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.00273</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.209514</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.875718</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.288666</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.728713</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.792118</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.160506</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.395265</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.738762</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.022986</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.408515</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.690771</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.947356</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.200273</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.914285</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.536136</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.32038</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.237381</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.441686</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.046395</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.998404</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.878137</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.922923</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.76375</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.725235</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.212197</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.798251</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.558747</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.613859</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.041493</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.781257</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.783509</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.78083</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.858278</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.655385</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.182511</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.956432</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.475763</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.292683</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.197677</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.326522</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.61027</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.757543</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.851312</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7229c79a32b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 63, and embedding size = 35\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1260.0\" height=\"468.75\" viewBox=\"-29.0 0 1008.0 375.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.896189</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.006793</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.822223</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.543285</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.079178</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.552835</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.377458</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.860564</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.662759</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.199216</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.998396</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.948046</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.268883</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.974966</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.899181</text>\n",
       "<path d=\"M25,325.0 L175,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.778971</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.45307</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.471954</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.410307</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.631167</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.476273</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.533524</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.948612</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.991307</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.866309</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.756201</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.454178</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.61407</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.995067</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.5212</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.078397</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.880267</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.120904</text>\n",
       "<path d=\"M325,325.0 L475,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.392563</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.969591</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.972423</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.490733</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.499683</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.081782</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.398752</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.357664</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.590512</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.505172</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.971692</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.614117</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.730471</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.477393</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.553855</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.986564</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.578357</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.41181</text>\n",
       "<path d=\"M625,325.0 L775,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.339327</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.552143</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.715988</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25.0 L940,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,75.0 L940,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,125.0 L940,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,175.0 L940,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,225.0 L940,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,275.0 L940,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,325.0 L940,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"950\" y=\"28.0\" font-size=\"8\" text-anchor=\"end\">0</text>\n",
       "<text x=\"950\" y=\"78.0\" font-size=\"8\" text-anchor=\"end\">1</text>\n",
       "<text x=\"950\" y=\"128.0\" font-size=\"8\" text-anchor=\"end\">2</text>\n",
       "<text x=\"950\" y=\"178.0\" font-size=\"8\" text-anchor=\"end\">3</text>\n",
       "<text x=\"950\" y=\"228.0\" font-size=\"8\" text-anchor=\"end\">4</text>\n",
       "<text x=\"950\" y=\"278.0\" font-size=\"8\" text-anchor=\"end\">5</text>\n",
       "<text x=\"950\" y=\"328.0\" font-size=\"8\" text-anchor=\"end\">6</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"8\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"8\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"8\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"8\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"8\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"8\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"8\" text-anchor=\"start\">6</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7229c79172b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 7, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35 * 70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(165)\n",
    "# res = bs.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(4*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "    #     self.fc1 = nn.Linear(12*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  1838\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 37.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  1838\n",
      "Required qubit number:  11\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:84] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[84:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(70 * 35,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  113\n",
      "# of trainable parameter in QNN model:  147\n",
      "# of trainable parameter in full model:  260\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(147)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 15.2196, batch time: 0.04, accuracy:  17.19%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 8.6400, batch time: 0.07, accuracy:  14.06%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 3.4153, batch time: 0.07, accuracy:  9.38%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.6714, batch time: 0.07, accuracy:  13.28%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 2.5481, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 2.4579, batch time: 0.07, accuracy:  10.94%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 2.4009, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 2.3218, batch time: 0.03, accuracy:  10.16%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 2.3437, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 2.3829, batch time: 0.03, accuracy:  14.84%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 2.255789041519165, accuracy: 16.4 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 2.2824440002441406, accuracy: 11.3 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 2.226039409637451, accuracy: 18.4 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 2.213857889175415, accuracy: 17.4 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 2.2174389362335205, accuracy: 18.4 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 2.2241928577423096, accuracy: 18.6 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 2.162311315536499, accuracy: 23.4 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 2.195775032043457, accuracy: 16.7 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 2.151535749435425, accuracy: 22.5 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 2.3268380165100098, accuracy: 12.5 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 2.0908, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 2.0107, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 2.1085, batch time: 0.05, accuracy:  25.00%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 2.0857, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 2.0504, batch time: 0.03, accuracy:  25.00%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 2.0073, batch time: 0.03, accuracy:  28.12%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 2.0352, batch time: 0.03, accuracy:  25.78%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 2.0393, batch time: 0.04, accuracy:  24.22%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 2.0288, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 2.1020, batch time: 0.03, accuracy:  21.09%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 2.014307975769043, accuracy: 26.8 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 2.2164299488067627, accuracy: 14.3 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 2.0670855045318604, accuracy: 24.5 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 2.0059616565704346, accuracy: 26.2 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 2.014165163040161, accuracy: 24.9 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 2.0258102416992188, accuracy: 24.4 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 2.4587574005126953, accuracy: 16.5 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 1.9995951652526855, accuracy: 26.8 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 1.998293399810791, accuracy: 27.0 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 1.9969562292099, accuracy: 27.9 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 2.0595, batch time: 0.07, accuracy:  25.78%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 2.0860, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 2.0126, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 1.9482, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 1.8914, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 1.9797, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 1.9634, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 1.9900, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 1.9435, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 2.0545, batch time: 0.07, accuracy:  28.12%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 1.9924782514572144, accuracy: 30.2 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.028977394104004, accuracy: 29.3 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 1.9873801469802856, accuracy: 30.8 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 1.9997750520706177, accuracy: 29.9 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 2.0098493099212646, accuracy: 30.1 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 2.1172196865081787, accuracy: 26.7 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 1.9751719236373901, accuracy: 29.8 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 1.9773592948913574, accuracy: 29.8 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 1.9845271110534668, accuracy: 29.5 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 1.990606665611267, accuracy: 28.9 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 1.9374, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 1.9698, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 1.9638, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 1.9257, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 2.1345, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 1.9254, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 1.9114, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 1.9948, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 1.9628, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 2.0390, batch time: 0.07, accuracy:  26.56%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 1.9911975860595703, accuracy: 34.9 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 2.093994140625, accuracy: 27.5 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 2.134612560272217, accuracy: 29.0 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 1.9840924739837646, accuracy: 34.3 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 1.9797035455703735, accuracy: 34.5 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 2.152656078338623, accuracy: 24.7 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 1.980534553527832, accuracy: 34.8 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 1.9975379705429077, accuracy: 32.2 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 2.0482616424560547, accuracy: 30.7 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 1.9684576988220215, accuracy: 35.2 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 1.8588, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 1.9668, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 1.9696, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 1.9700, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 1.8992, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 1.9391, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 1.9148, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 1.9929, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 2.0360, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 1.9839, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 2.005829095840454, accuracy: 29.6 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 2.4537460803985596, accuracy: 19.9 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 1.9562785625457764, accuracy: 34.0 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 1.9416760206222534, accuracy: 34.1 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 1.9357712268829346, accuracy: 34.4 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 1.9517983198165894, accuracy: 32.1 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 1.9365555047988892, accuracy: 32.2 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 1.9234778881072998, accuracy: 32.8 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 1.9544768333435059, accuracy: 32.4 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 1.9290552139282227, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 1.7889, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 1.8658, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 1.9136, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 1.9267, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 1.9929, batch time: 0.03, accuracy:  26.56%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 1.7615, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 1.9504, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 1.8810, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 1.8335, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 1.7953, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 1.9258307218551636, accuracy: 34.2 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 2.164958953857422, accuracy: 21.4 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 2.527463912963867, accuracy: 20.0 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 1.9039987325668335, accuracy: 36.3 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 1.9028236865997314, accuracy: 36.3 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 1.9730305671691895, accuracy: 31.7 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 1.8873194456100464, accuracy: 37.6 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 1.8839584589004517, accuracy: 37.5 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 1.882067084312439, accuracy: 37.4 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 1.882098913192749, accuracy: 37.3 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 1.7731, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 1.9686, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 1.9701, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 1.8931, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 1.8009, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 1.9146, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 1.7258, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 1.7280, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 1.9528, batch time: 0.07, accuracy:  28.91%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 1.8483, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 1.8912197351455688, accuracy: 34.2 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 2.0594911575317383, accuracy: 25.8 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 1.8420240879058838, accuracy: 37.8 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 2.3324472904205322, accuracy: 18.9 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 1.8313087224960327, accuracy: 38.9 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 1.8273464441299438, accuracy: 39.3 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 1.8276094198226929, accuracy: 39.4 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 1.8219010829925537, accuracy: 38.5 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 1.8208411931991577, accuracy: 39.7 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 1.819423794746399, accuracy: 38.3 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 1.7493, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 1.7647, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 1.8197, batch time: 0.07, accuracy:  29.69%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 1.9417, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 1.7789, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 1.8843, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 1.7686, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 1.8915, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 1.8143, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 1.8098, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 1.8977433443069458, accuracy: 32.7 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 2.9103903770446777, accuracy: 17.1 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 3.866330862045288, accuracy: 12.2 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 1.8388608694076538, accuracy: 35.9 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 1.8323801755905151, accuracy: 34.9 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 1.83036470413208, accuracy: 34.9 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 1.8274959325790405, accuracy: 35.3 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 1.8268964290618896, accuracy: 34.5 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 1.8480883836746216, accuracy: 36.1 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 1.8221732378005981, accuracy: 35.4 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 1.7042, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 1.9293, batch time: 0.03, accuracy:  28.12%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 1.8319, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 1.8664, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 1.7996, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 1.7483, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 1.7491, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 1.8558, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 1.9238, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 1.8428, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 1.9123936891555786, accuracy: 30.0 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 3.781392812728882, accuracy: 13.3 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 1.8366494178771973, accuracy: 35.1 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 2.059093475341797, accuracy: 22.0 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 1.8349381685256958, accuracy: 35.3 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 1.8385299444198608, accuracy: 34.1 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 1.8311374187469482, accuracy: 35.5 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 1.8511565923690796, accuracy: 33.9 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 1.8279911279678345, accuracy: 36.3 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 1.8270483016967773, accuracy: 36.0 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 1.7532, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 1.7313, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 1.8596, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 1.8263, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 1.8856, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 1.8208, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 1.8774, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 1.8023, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 1.8392, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 1.7474, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 1.9034444093704224, accuracy: 30.2 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 1.7978829145431519, accuracy: 34.6 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 1.7940011024475098, accuracy: 34.3 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 1.811567783355713, accuracy: 34.5 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 1.7910044193267822, accuracy: 34.1 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 1.7851368188858032, accuracy: 34.8 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 1.7839515209197998, accuracy: 34.1 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 1.7808576822280884, accuracy: 34.8 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 1.7814167737960815, accuracy: 34.8 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 1.7784634828567505, accuracy: 34.8 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 1.9380, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 1.9963, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 1.7501, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 1.8573, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 1.7322, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 1.8428, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 1.7800, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 1.7005, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 1.9245, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 1.7884, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 1.836322546005249, accuracy: 35.2 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 3.595580577850342, accuracy: 15.2 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 2.9029784202575684, accuracy: 24.0 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 1.7680647373199463, accuracy: 38.9 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 1.751226544380188, accuracy: 39.9 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 1.7485196590423584, accuracy: 40.2 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 1.7436635494232178, accuracy: 40.1 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 1.742056965827942, accuracy: 41.1 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 1.772414207458496, accuracy: 38.1 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 1.7676116228103638, accuracy: 37.9 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 1.6943, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 1.8174, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 1.8227, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 1.6637, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 1.8964, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 2.0961, batch time: 0.03, accuracy:  24.22%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 1.6112, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 1.5336, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 1.7035, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 1.8164, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 1.880028486251831, accuracy: 31.9 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 1.7616100311279297, accuracy: 37.8 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 1.7547187805175781, accuracy: 37.0 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 1.817108392715454, accuracy: 35.6 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 1.756935954093933, accuracy: 37.3 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 1.7495415210723877, accuracy: 37.6 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 1.7478227615356445, accuracy: 37.5 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 1.752263069152832, accuracy: 38.2 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 1.749200463294983, accuracy: 37.4 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 1.7494406700134277, accuracy: 37.5 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 1.7755, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 1.5917, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 1.8497, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 1.8396, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 1.7652, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 1.8246, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 1.6981, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 1.6563, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 1.8179, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 1.7732, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 1.931842565536499, accuracy: 30.8 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 2.740050792694092, accuracy: 19.8 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 1.7866437435150146, accuracy: 35.3 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 1.8134018182754517, accuracy: 36.5 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 1.8169149160385132, accuracy: 35.7 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 1.7829862833023071, accuracy: 36.3 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 1.7730385065078735, accuracy: 35.6 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 1.7716631889343262, accuracy: 35.1 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 1.7678626775741577, accuracy: 36.3 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 1.7663514614105225, accuracy: 36.7 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 1.7729, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 1.7228, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 1.5329, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 1.7904, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 1.6482, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 1.7429, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 1.7617, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 1.7940, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 1.8129, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 1.7729, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 1.9209433794021606, accuracy: 35.9 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 1.7815024852752686, accuracy: 38.3 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 1.748634934425354, accuracy: 39.8 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 1.7400145530700684, accuracy: 40.0 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 1.7370039224624634, accuracy: 40.6 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 1.765187382698059, accuracy: 38.9 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 1.7994786500930786, accuracy: 37.4 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 1.7394036054611206, accuracy: 39.6 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 1.73149836063385, accuracy: 39.8 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 1.7301846742630005, accuracy: 40.7 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 1.5706, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 1.7762, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 1.8290, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 1.9541, batch time: 0.07, accuracy:  30.47%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 1.8732, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 1.7669, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 1.9011, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 1.6929, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 1.7035, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 1.7002, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 1.946529507637024, accuracy: 34.8 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 1.9787448644638062, accuracy: 33.1 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 1.7997320890426636, accuracy: 39.3 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 1.8141288757324219, accuracy: 37.3 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 1.7975654602050781, accuracy: 38.8 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 1.7948063611984253, accuracy: 38.7 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 1.794689416885376, accuracy: 38.0 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 1.7897039651870728, accuracy: 39.0 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 1.7903544902801514, accuracy: 38.9 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 1.7896174192428589, accuracy: 39.4 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 1.7559, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 1.8273, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 1.7195, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 1.7335, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 1.6961, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 1.6320, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 1.6293, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 1.7491, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 1.6817, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 1.6812, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 1.9078621864318848, accuracy: 34.1 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 2.939884662628174, accuracy: 14.0 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 3.553046464920044, accuracy: 13.5 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 1.7850008010864258, accuracy: 36.8 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 1.748958945274353, accuracy: 37.1 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 1.7063030004501343, accuracy: 39.2 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 1.7137104272842407, accuracy: 39.3 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 1.7060277462005615, accuracy: 39.1 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 1.7073601484298706, accuracy: 38.9 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 1.7022011280059814, accuracy: 39.4 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 1.6917, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 1.7806, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 1.7092, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 1.6963, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 1.6797, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 1.6895, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 1.6288, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 1.7195, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 1.6219, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 1.7234, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 2.022216320037842, accuracy: 31.6 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 3.9097049236297607, accuracy: 11.0 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 4.869917392730713, accuracy: 10.9 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 1.761757254600525, accuracy: 39.0 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 1.7321761846542358, accuracy: 41.1 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 1.731046438217163, accuracy: 41.0 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 1.729161024093628, accuracy: 41.6 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 1.7323741912841797, accuracy: 41.5 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 1.7243717908859253, accuracy: 41.2 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 1.7484618425369263, accuracy: 40.1 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 1.8230, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 1.7925, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 1.8767, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 1.9072, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 1.8263, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 1.6844, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 1.8688, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 1.8873, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 1.8615, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 1.6611, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 1.9274876117706299, accuracy: 33.2 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 1.7851749658584595, accuracy: 36.0 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 1.7380765676498413, accuracy: 39.2 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 1.7653888463974, accuracy: 37.3 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 1.7342627048492432, accuracy: 40.5 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 1.7330121994018555, accuracy: 39.7 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 1.732029914855957, accuracy: 39.8 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 1.733715534210205, accuracy: 39.1 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 1.7331041097640991, accuracy: 39.8 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 1.7419925928115845, accuracy: 38.2 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 1.9001, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 1.6686, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 1.6602, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 1.6138, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 1.7651, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 1.6848, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 1.7095, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 1.6585, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 1.6288, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 1.7062, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 2.041182279586792, accuracy: 29.3 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 2.7800521850585938, accuracy: 16.2 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 1.7927125692367554, accuracy: 35.7 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 1.7793233394622803, accuracy: 37.0 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 1.8269070386886597, accuracy: 36.0 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 3.0098750591278076, accuracy: 17.0 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 1.766731858253479, accuracy: 37.5 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 1.7641699314117432, accuracy: 37.0 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 1.7683004140853882, accuracy: 37.7 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 1.7600698471069336, accuracy: 37.6 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 1.6889, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 1.6905, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 1.7425, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 1.6680, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 1.7661, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 1.7413, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 1.6763, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 1.9112, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 1.7016, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 1.7065, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 2.080779552459717, accuracy: 30.3 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 2.670405864715576, accuracy: 19.0 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 2.6534409523010254, accuracy: 19.3 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 1.7385116815567017, accuracy: 40.7 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 1.7204378843307495, accuracy: 41.7 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 1.7242213487625122, accuracy: 39.8 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 1.728513240814209, accuracy: 41.5 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 1.7140997648239136, accuracy: 40.4 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 1.7111189365386963, accuracy: 40.3 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 1.7393691539764404, accuracy: 39.4 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 1.5460, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 1.8638, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 1.7562, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 1.6443, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 1.7153, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 1.7716, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 1.8932, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 1.7815, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 1.8050, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 1.8695, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 2.203657388687134, accuracy: 28.5 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 4.573700904846191, accuracy: 21.2 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 2.1367712020874023, accuracy: 30.5 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 1.7912797927856445, accuracy: 37.8 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 1.743741512298584, accuracy: 36.7 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 1.7435539960861206, accuracy: 37.1 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 1.752025842666626, accuracy: 37.2 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 1.7440954446792603, accuracy: 37.3 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 1.7423166036605835, accuracy: 36.8 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 1.7365249395370483, accuracy: 37.5 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 1.8557, batch time: 0.03, accuracy:  30.47%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 1.7210, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 1.8778, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 1.5151, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 1.6872, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 1.6636, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 1.7562, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 1.8235, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 1.7465, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 1.6729, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 2.051547050476074, accuracy: 31.6 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 2.7579219341278076, accuracy: 17.9 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 4.170483112335205, accuracy: 16.6 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 1.6936720609664917, accuracy: 40.2 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 2.0849645137786865, accuracy: 28.7 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 1.6900359392166138, accuracy: 40.6 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 1.6894360780715942, accuracy: 40.6 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 1.720224142074585, accuracy: 39.1 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 1.686099648475647, accuracy: 40.6 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 1.6858447790145874, accuracy: 40.8 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 1.7846, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 1.7578, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 1.6815, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 1.8242, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 1.6018, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 1.7320, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 1.8458, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 1.6801, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 1.5726, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 1.7843, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 2.0277748107910156, accuracy: 32.0 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 2.5795998573303223, accuracy: 14.2 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 2.0507185459136963, accuracy: 35.1 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 1.6737123727798462, accuracy: 42.3 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 1.66141676902771, accuracy: 42.0 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 2.130652904510498, accuracy: 27.3 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 1.6684534549713135, accuracy: 43.1 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 1.6502476930618286, accuracy: 43.1 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 1.6569617986679077, accuracy: 44.2 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 1.6504992246627808, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 1.8204, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 1.7045, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 1.7573, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 1.6230, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 1.5893, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 1.8617, batch time: 0.03, accuracy:  28.91%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 1.6667, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 1.8436, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 1.7089, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 1.7058, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 2.055410861968994, accuracy: 33.5 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 2.3910155296325684, accuracy: 23.5 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 2.558973550796509, accuracy: 22.9 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 1.8071705102920532, accuracy: 37.4 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 1.6838425397872925, accuracy: 43.2 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 1.6858633756637573, accuracy: 43.6 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 1.710404634475708, accuracy: 42.2 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 1.7021876573562622, accuracy: 42.1 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 1.6741533279418945, accuracy: 43.2 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 1.6752279996871948, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 1.6420, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 1.6354, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 1.7560, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 1.6856, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 1.6378, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 1.7240, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 1.6615, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 1.7714, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 1.6133, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 1.6164, batch time: 0.05, accuracy:  40.62%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 1.8176612854003906, accuracy: 38.0 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 2.451514720916748, accuracy: 27.7 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 3.923342227935791, accuracy: 17.9 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 1.651727318763733, accuracy: 41.8 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 1.717315912246704, accuracy: 42.2 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 1.668104648590088, accuracy: 43.1 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 1.641713261604309, accuracy: 42.5 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 1.6387982368469238, accuracy: 42.5 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 1.6373980045318604, accuracy: 42.5 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 1.6379331350326538, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 1.6418, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 1.7107, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 1.6801, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 1.7170, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 1.8740, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 1.5417, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 1.7833, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 1.6690, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 1.6770, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 1.8194, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 2.0237412452697754, accuracy: 33.2 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 3.4674441814422607, accuracy: 20.1 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 1.788778305053711, accuracy: 37.0 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 1.722062349319458, accuracy: 39.4 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 1.7134490013122559, accuracy: 40.6 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 1.779017448425293, accuracy: 37.9 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 1.7112501859664917, accuracy: 40.6 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 1.7091853618621826, accuracy: 40.2 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 1.7082778215408325, accuracy: 40.4 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 1.7074812650680542, accuracy: 41.3 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 1.7958, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 1.6212, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 1.6253, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 1.7109, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 1.6566, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 1.7579, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 1.6076, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 1.6418, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 1.7667, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 1.8018, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 1.9776073694229126, accuracy: 32.2 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 1.759450912475586, accuracy: 37.8 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 1.6616220474243164, accuracy: 41.3 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 1.664207100868225, accuracy: 42.8 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 1.6612205505371094, accuracy: 42.0 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 1.6607176065444946, accuracy: 42.5 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 1.658636212348938, accuracy: 41.9 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 1.6575913429260254, accuracy: 42.4 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 1.6567994356155396, accuracy: 41.4 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 1.6555999517440796, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 1.6200, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 1.7521, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 1.7077, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 1.6831, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 1.7748, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 1.6650, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 1.7071, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 1.6613, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 1.8387, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 1.7243, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 2.0554206371307373, accuracy: 33.6 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 3.2493953704833984, accuracy: 18.5 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 3.659245014190674, accuracy: 17.2 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 1.6760203838348389, accuracy: 44.7 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 1.6918812990188599, accuracy: 42.4 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 1.6729322671890259, accuracy: 42.8 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 1.6896003484725952, accuracy: 41.7 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 1.6747030019760132, accuracy: 43.4 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 1.7032592296600342, accuracy: 43.1 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 1.667514443397522, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 1.6362, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 1.7120, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 1.6286, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 1.5659, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 1.6136, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 1.6809, batch time: 0.06, accuracy:  39.06%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 1.6805, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 1.7304, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 1.7414, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 1.6497, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 2.036330461502075, accuracy: 35.4 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 1.6729815006256104, accuracy: 43.7 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 1.6439416408538818, accuracy: 43.9 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 1.677931308746338, accuracy: 44.3 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 1.6407121419906616, accuracy: 42.6 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 1.639041543006897, accuracy: 42.0 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 1.6381196975708008, accuracy: 42.9 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 1.6365081071853638, accuracy: 43.0 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 1.6450237035751343, accuracy: 44.7 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 1.6390787363052368, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 1.6515, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 1.6649, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 1.8215, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 1.7508, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 1.5884, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 1.5285, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 1.6679, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 1.6676, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 1.7337, batch time: 0.05, accuracy:  35.94%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 1.9295, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 2.0506632328033447, accuracy: 34.3 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 1.689292550086975, accuracy: 43.2 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 1.6694568395614624, accuracy: 42.0 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 2.0644969940185547, accuracy: 30.4 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 1.6613837480545044, accuracy: 41.1 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 1.6590536832809448, accuracy: 42.6 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 1.6534504890441895, accuracy: 43.4 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 1.6494210958480835, accuracy: 43.3 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 1.6586549282073975, accuracy: 41.7 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 1.6497381925582886, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 1.7483, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 1.9139, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 1.6944, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 1.6395, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 1.7595, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 1.6197, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 1.8814, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 1.7155, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 1.5917, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 1.6385, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 1.9315587282180786, accuracy: 36.1 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 1.686569094657898, accuracy: 40.3 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 1.644205927848816, accuracy: 40.6 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 2.0003724098205566, accuracy: 33.5 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 1.6443501710891724, accuracy: 40.4 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 1.6377071142196655, accuracy: 40.9 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 1.638655662536621, accuracy: 41.9 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 1.6369258165359497, accuracy: 42.1 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 1.6392308473587036, accuracy: 41.7 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 1.6395375728607178, accuracy: 41.8 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 1.8456, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 1.9451, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 1.6364, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 1.6493, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 1.5629, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 1.6845, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 1.6423, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 1.6725, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 1.6313, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 1.6508, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 2.1639902591705322, accuracy: 32.3 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 1.7401423454284668, accuracy: 36.9 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 1.6791577339172363, accuracy: 39.6 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 1.7075449228286743, accuracy: 38.2 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 1.6782816648483276, accuracy: 39.4 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 1.6668415069580078, accuracy: 39.8 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 1.6555641889572144, accuracy: 40.2 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 1.6486032009124756, accuracy: 42.3 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 1.6467543840408325, accuracy: 42.9 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 1.645188570022583, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 1.8296, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 1.6854, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 1.6293, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 1.7154, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 1.7230, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 1.7086, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 1.7045, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 1.7725, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 1.8691, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 1.6288, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 1.8407771587371826, accuracy: 36.4 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 2.154954433441162, accuracy: 28.6 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 4.3863091468811035, accuracy: 15.5 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 1.6817342042922974, accuracy: 42.9 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 1.738311767578125, accuracy: 39.4 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 2.528559684753418, accuracy: 20.5 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 1.675520420074463, accuracy: 43.6 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 1.673087477684021, accuracy: 43.6 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 1.6822515726089478, accuracy: 42.8 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 1.6714142560958862, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 1.8586, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 1.6345, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 1.7369, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 1.4367, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 1.6699, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 1.5317, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 1.7327, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 1.4898, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 1.5632, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 1.6291, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 1.7662856578826904, accuracy: 36.9 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 1.6185812950134277, accuracy: 44.0 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 1.605891227722168, accuracy: 43.9 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 1.6042523384094238, accuracy: 44.3 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 1.602060079574585, accuracy: 43.7 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 1.595911979675293, accuracy: 43.1 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 1.595444679260254, accuracy: 44.3 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 1.5940173864364624, accuracy: 44.6 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 1.5906645059585571, accuracy: 43.6 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 1.6427404880523682, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 1.7533, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 1.7473, batch time: 0.06, accuracy:  39.06%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 1.6058, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 1.7200, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 1.7835, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 1.6756, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 1.6748, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 1.7068, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 1.7881, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 1.6836, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 1.937949299812317, accuracy: 34.3 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 1.6742660999298096, accuracy: 40.3 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 1.6435697078704834, accuracy: 41.4 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 1.64528489112854, accuracy: 41.6 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 1.6399894952774048, accuracy: 42.0 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 1.6457785367965698, accuracy: 42.5 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 1.64873468875885, accuracy: 42.3 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 1.6379952430725098, accuracy: 42.1 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 1.662688970565796, accuracy: 41.3 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 1.6373817920684814, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 1.6886, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 1.5235, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 1.6399, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 1.5840, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 1.7426, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 1.5339, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 1.5977, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 1.6643, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 1.8353, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 1.4432, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 1.9560039043426514, accuracy: 33.9 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 3.2532296180725098, accuracy: 14.2 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 1.6533747911453247, accuracy: 43.4 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 1.7123032808303833, accuracy: 42.9 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 1.685346245765686, accuracy: 41.9 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 1.6450556516647339, accuracy: 42.5 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 1.656701922416687, accuracy: 41.8 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 1.6433645486831665, accuracy: 41.7 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 1.643407940864563, accuracy: 41.2 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 1.6579540967941284, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 1.6457, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 1.6333, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 1.6489, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 1.5738, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 1.6682, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 1.7054, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 1.6396, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 1.6164, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 1.6255, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 1.5943, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 1.8515191078186035, accuracy: 35.7 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 4.1420063972473145, accuracy: 13.7 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 1.6859763860702515, accuracy: 41.6 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 1.817414402961731, accuracy: 34.8 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 1.674674391746521, accuracy: 41.6 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 1.6720815896987915, accuracy: 41.5 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 1.693421721458435, accuracy: 43.3 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 1.668254017829895, accuracy: 40.8 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 1.6693984270095825, accuracy: 42.2 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 1.6662729978561401, accuracy: 42.0 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 1.4170, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 1.5596, batch time: 0.06, accuracy:  43.75%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 1.5882, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 1.5816, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 1.7713, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 1.5186, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 1.7221, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 1.7319, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 1.7139, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 1.6327, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 1.763056755065918, accuracy: 36.9 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 1.6936606168746948, accuracy: 41.4 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 1.6699446439743042, accuracy: 43.1 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 1.7417197227478027, accuracy: 42.6 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 1.6652746200561523, accuracy: 42.6 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 1.662448763847351, accuracy: 43.7 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 1.6925444602966309, accuracy: 39.6 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 1.663203239440918, accuracy: 44.3 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 1.658215045928955, accuracy: 43.2 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 1.6789518594741821, accuracy: 40.1 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 1.7081, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 1.6857, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 1.6516, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 1.6491, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 1.7018, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 1.7065, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 1.8252, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 1.5644, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 1.6453, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 1.6353, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 1.7458884716033936, accuracy: 39.0 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 2.684298276901245, accuracy: 26.8 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 2.6807358264923096, accuracy: 21.5 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 1.6546651124954224, accuracy: 43.3 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 1.6527109146118164, accuracy: 43.8 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 1.6780885457992554, accuracy: 41.1 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 1.6853077411651611, accuracy: 43.7 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 1.6495766639709473, accuracy: 43.4 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 1.644588589668274, accuracy: 44.7 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 1.6422311067581177, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 1.6074, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 1.6804, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 1.5331, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 1.6453, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 1.6930, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 1.6111, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 1.5351, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 1.6947, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 1.5311, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 1.7689, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 2.0675456523895264, accuracy: 23.8 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 3.199158191680908, accuracy: 18.2 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 3.0206499099731445, accuracy: 19.5 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 1.6076709032058716, accuracy: 43.9 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 1.597319483757019, accuracy: 44.0 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 1.6250814199447632, accuracy: 41.5 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 3.698401689529419, accuracy: 20.2 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 1.5885387659072876, accuracy: 45.6 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 1.5873703956604004, accuracy: 45.8 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 1.586842656135559, accuracy: 45.8 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 1.6688, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 1.6850, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 1.6585, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 1.5708, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 1.6292, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 1.6499, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 1.7027, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 1.6765, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 1.8557, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 1.4905, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 1.8778244256973267, accuracy: 29.7 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 2.906890869140625, accuracy: 23.3 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 1.5979210138320923, accuracy: 44.6 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 1.6480433940887451, accuracy: 44.6 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 1.5954562425613403, accuracy: 44.7 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 1.5976492166519165, accuracy: 44.0 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 1.5917381048202515, accuracy: 44.5 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 1.598605751991272, accuracy: 44.5 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 1.589465856552124, accuracy: 44.5 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 1.5890247821807861, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 1.4975, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 1.7204, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 1.5563, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 1.8500, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 1.6796, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 1.6833, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 1.4635, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 1.7086, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 1.6431, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 1.4877, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 1.7986723184585571, accuracy: 36.3 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 3.9294042587280273, accuracy: 20.6 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 9.087862014770508, accuracy: 17.9 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 1.6622508764266968, accuracy: 37.8 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 1.760116457939148, accuracy: 37.9 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 1.6377575397491455, accuracy: 43.6 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 1.640732765197754, accuracy: 43.5 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 1.6413735151290894, accuracy: 43.2 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 1.632880449295044, accuracy: 43.6 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 1.6325844526290894, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 1.7231, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 1.5702, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 1.7463, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 1.7034, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 1.6547, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 1.5775, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 1.6798, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 1.7404, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 1.4325, batch time: 0.07, accuracy:  56.25%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 1.7062, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 1.7583333253860474, accuracy: 39.6 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 1.6467732191085815, accuracy: 41.7 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 1.6282058954238892, accuracy: 41.8 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 1.6251002550125122, accuracy: 42.2 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 1.6621867418289185, accuracy: 42.1 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 1.6017390489578247, accuracy: 43.9 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 1.5991052389144897, accuracy: 43.4 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 1.6035912036895752, accuracy: 44.9 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 1.5970650911331177, accuracy: 44.1 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 1.5986021757125854, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 1.6722, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 1.6691, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 1.6934, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 1.5931, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 1.7116, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 1.7011, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 1.7270, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 1.6053, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 1.6810, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 1.7379, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 1.7954065799713135, accuracy: 36.7 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 1.831385612487793, accuracy: 35.8 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 1.5837504863739014, accuracy: 44.7 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 1.6636247634887695, accuracy: 37.0 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 1.5846188068389893, accuracy: 41.6 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 1.5768924951553345, accuracy: 42.8 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 1.5774034261703491, accuracy: 44.0 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 1.5769251585006714, accuracy: 43.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 1.5739414691925049, accuracy: 43.3 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 1.5763282775878906, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 1.8224, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 1.6716, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 1.6879, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 1.4650, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 1.7341, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 1.6834, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 1.6395, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 1.6207, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 1.6742, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 1.5061, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 1.9020029306411743, accuracy: 31.6 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 1.6300534009933472, accuracy: 40.6 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 1.6208609342575073, accuracy: 39.4 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 1.6163476705551147, accuracy: 40.7 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 1.620703101158142, accuracy: 41.9 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 1.609457015991211, accuracy: 41.8 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 1.6102688312530518, accuracy: 41.5 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 1.607724666595459, accuracy: 42.0 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 1.6055855751037598, accuracy: 42.1 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 1.605405569076538, accuracy: 42.1 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 1.5409, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 1.5969, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 1.5748, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 1.6947, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 1.4515, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 1.7473, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 1.7088, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 1.6473, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 1.5348, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 1.6401, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 1.8697620630264282, accuracy: 33.2 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 1.6279289722442627, accuracy: 41.6 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 1.6114225387573242, accuracy: 42.2 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 1.70999276638031, accuracy: 38.8 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 1.6095882654190063, accuracy: 41.6 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 1.6081352233886719, accuracy: 41.7 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 1.6173263788223267, accuracy: 41.8 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 1.6072607040405273, accuracy: 41.9 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 1.6065895557403564, accuracy: 41.9 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 1.6060900688171387, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 1.5866, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 1.5382, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 1.7213, batch time: 0.05, accuracy:  33.59%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 1.6459, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 1.6991, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 1.7637, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 1.8774, batch time: 0.04, accuracy:  29.69%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 1.7065, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 1.7335, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 1.7307, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 1.7520759105682373, accuracy: 39.8 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 3.8940882682800293, accuracy: 18.1 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 1.6254185438156128, accuracy: 42.0 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 1.6230915784835815, accuracy: 42.2 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 1.9842257499694824, accuracy: 32.9 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 1.6207422018051147, accuracy: 42.5 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 1.6173821687698364, accuracy: 42.2 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 1.6164953708648682, accuracy: 42.7 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 1.616763710975647, accuracy: 42.2 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 1.6160107851028442, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 1.6885, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 1.5515, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 1.6283, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 1.7080, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 1.6954, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 1.5327, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 1.7288, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 1.6819, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 1.6986, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 1.5988, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 1.675525188446045, accuracy: 41.1 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 3.038299560546875, accuracy: 20.5 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 3.8399627208709717, accuracy: 15.3 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 2.0782670974731445, accuracy: 26.6 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 1.6426645517349243, accuracy: 41.7 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 1.61617112159729, accuracy: 41.4 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 1.6746337413787842, accuracy: 39.5 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 1.6092240810394287, accuracy: 44.9 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 1.6066702604293823, accuracy: 43.9 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 1.6053791046142578, accuracy: 44.4 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 1.7008, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 1.6784, batch time: 0.06, accuracy:  41.41%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 1.6971, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 1.3248, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 1.4943, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 1.7640, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 1.6752, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 1.7192, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 1.6112, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 1.7723, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 1.8496655225753784, accuracy: 33.2 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 4.3609161376953125, accuracy: 18.2 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 1.6005713939666748, accuracy: 42.8 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 1.6161240339279175, accuracy: 43.4 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 1.6031230688095093, accuracy: 44.3 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 1.5833160877227783, accuracy: 45.8 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 1.5801846981048584, accuracy: 44.0 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 1.5786606073379517, accuracy: 46.0 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 1.5820800065994263, accuracy: 44.1 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 1.5757420063018799, accuracy: 43.7 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 1.7639, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 1.7123, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 1.6892, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 1.7236, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 1.6477, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 1.8292, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 1.9631, batch time: 0.03, accuracy:  29.69%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 1.5057, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 1.6874, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 1.7477, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 2.8422603607177734, accuracy: 16.2 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 3.528393030166626, accuracy: 23.8 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 3.548537254333496, accuracy: 23.2 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 1.6670488119125366, accuracy: 40.4 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 1.74294114112854, accuracy: 38.8 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 1.6603672504425049, accuracy: 41.7 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 1.6591167449951172, accuracy: 42.5 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 1.6541521549224854, accuracy: 41.3 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 1.6536530256271362, accuracy: 42.8 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 1.6574805974960327, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 1.6592, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 1.4825, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 1.6673, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 1.6464, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 1.6955, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 1.6457, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 1.6780, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 1.7365, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 1.6990, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 1.6343, batch time: 0.05, accuracy:  43.75%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 2.3691141605377197, accuracy: 20.3 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 3.670980215072632, accuracy: 15.3 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 1.7828701734542847, accuracy: 38.3 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 1.6510303020477295, accuracy: 42.1 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 1.6282960176467896, accuracy: 43.7 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 1.619350552558899, accuracy: 43.7 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 1.6213680505752563, accuracy: 44.2 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 1.6495966911315918, accuracy: 41.9 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 1.6178412437438965, accuracy: 44.2 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 1.614197015762329, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 1.5550, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 1.6224, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 1.5044, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 1.6192, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 1.4297, batch time: 0.08, accuracy:  51.56%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 1.6952, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 1.5930, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 1.4584, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 1.5966, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 1.5740, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 1.9507192373275757, accuracy: 29.1 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 3.3680169582366943, accuracy: 23.7 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 1.6309624910354614, accuracy: 43.2 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 1.6258189678192139, accuracy: 43.0 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 1.6253037452697754, accuracy: 43.7 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 1.6250935792922974, accuracy: 44.3 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 1.6249362230300903, accuracy: 44.6 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 1.6199915409088135, accuracy: 43.4 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 1.6365913152694702, accuracy: 43.6 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 1.621243953704834, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 1.4953, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 1.6638, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 1.6384, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 1.4972, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 1.6739, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 1.7004, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 1.8006, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 1.5405, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 1.5488, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 1.5500, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 1.9721864461898804, accuracy: 28.2 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 1.5928239822387695, accuracy: 44.5 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 1.5647755861282349, accuracy: 42.9 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 1.6099860668182373, accuracy: 41.8 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 1.5640519857406616, accuracy: 44.1 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 1.5623317956924438, accuracy: 43.6 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 1.5593023300170898, accuracy: 43.6 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 1.569625735282898, accuracy: 43.5 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 1.5548369884490967, accuracy: 44.0 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 1.5583977699279785, accuracy: 43.7 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 1.6256, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 1.6056, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 1.7366, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 1.5342, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 1.7634, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 1.5967, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 1.6586, batch time: 0.26, accuracy:  42.97%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 1.7272, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 1.6633, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 1.5991, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 2.080617666244507, accuracy: 25.4 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 1.6472315788269043, accuracy: 43.9 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 1.6401045322418213, accuracy: 43.0 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 2.3144187927246094, accuracy: 32.1 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 1.6329100131988525, accuracy: 43.8 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 1.629023790359497, accuracy: 43.0 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 1.6262813806533813, accuracy: 44.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 1.626158356666565, accuracy: 45.0 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 1.6443980932235718, accuracy: 45.0 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 1.6465299129486084, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 1.7645, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 1.5154, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 1.7443, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 1.6419, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 1.5894, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 1.7011, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 1.5756, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 1.5569, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 1.5845, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 1.5520, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 2.094693660736084, accuracy: 23.8 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 3.813880443572998, accuracy: 15.3 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 1.688232183456421, accuracy: 38.5 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 1.6895498037338257, accuracy: 39.7 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 1.6875593662261963, accuracy: 41.1 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 1.6705280542373657, accuracy: 39.8 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 1.6672163009643555, accuracy: 39.8 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 1.6659501791000366, accuracy: 40.4 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 1.6643553972244263, accuracy: 40.4 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 1.6635303497314453, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 1.6796, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 1.6567, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 1.6321, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 1.7297, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 1.6238, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 1.5249, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 1.5002, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 1.7489, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 1.4896, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 1.5846, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 2.021759033203125, accuracy: 27.2 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 3.1814002990722656, accuracy: 23.4 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 2.963042736053467, accuracy: 24.3 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 1.6348069906234741, accuracy: 42.5 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 1.6155823469161987, accuracy: 42.8 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 1.613175630569458, accuracy: 42.9 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 1.6130801439285278, accuracy: 43.7 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 1.6146068572998047, accuracy: 43.0 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 1.6093616485595703, accuracy: 43.3 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 1.608824610710144, accuracy: 43.7 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 1.6549, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 1.6625, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 1.3572, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 1.6555, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 1.6882, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 1.7015, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 1.5365, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 1.6262, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 1.7102, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 1.6203, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 2.139249324798584, accuracy: 24.6 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 2.647082567214966, accuracy: 25.3 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 2.1458356380462646, accuracy: 33.6 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 1.6185939311981201, accuracy: 44.1 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 1.5935496091842651, accuracy: 45.8 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 1.9139940738677979, accuracy: 34.6 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 1.5975245237350464, accuracy: 43.1 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 1.5952037572860718, accuracy: 45.4 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 1.5902884006500244, accuracy: 44.3 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 1.5838181972503662, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 1.5580, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 1.6241, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 1.5630, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 1.7325, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 1.6299, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 1.5645, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 1.6209, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 1.7005, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 1.7463, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 1.6061, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 2.0481770038604736, accuracy: 19.7 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 2.5114784240722656, accuracy: 26.2 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 1.8898532390594482, accuracy: 32.8 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 1.6519454717636108, accuracy: 40.8 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 1.6402689218521118, accuracy: 42.2 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 1.64205002784729, accuracy: 40.6 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 1.6525723934173584, accuracy: 41.4 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 1.6344939470291138, accuracy: 41.6 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 1.6319348812103271, accuracy: 42.3 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 1.6360605955123901, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 1.6879, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 1.6324, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 1.5409, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 1.5088, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 1.5686, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 1.6425, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 1.5661, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 1.6246, batch time: 0.04, accuracy:  32.81%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 1.7100, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 1.6970, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 2.2593793869018555, accuracy: 19.0 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 1.603895664215088, accuracy: 43.5 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 1.5821285247802734, accuracy: 43.0 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 1.6070340871810913, accuracy: 43.5 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 1.5772712230682373, accuracy: 43.4 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 1.577804684638977, accuracy: 43.0 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 1.5772109031677246, accuracy: 43.5 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 1.5749790668487549, accuracy: 43.5 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 1.573877215385437, accuracy: 43.1 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 1.5725349187850952, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 1.6207, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 1.6641, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 1.5983, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 1.8103, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 1.6146, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 1.5147, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 1.4363, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 1.5419, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 1.6696, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 1.5106, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 2.1820900440216064, accuracy: 21.3 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 7.468564987182617, accuracy: 17.4 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 2.6317121982574463, accuracy: 16.0 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 1.5440521240234375, accuracy: 43.5 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 1.5744743347167969, accuracy: 45.6 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 1.519194483757019, accuracy: 45.2 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 1.5193098783493042, accuracy: 45.2 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 1.5477755069732666, accuracy: 43.8 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 1.514426350593567, accuracy: 45.7 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 1.5135784149169922, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 1.4662, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 1.4625, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 1.8050, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 1.6805, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 1.6425, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 1.7705, batch time: 0.03, accuracy:  31.25%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 1.5922, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 1.6415, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 1.7541, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 1.4620, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 2.028132915496826, accuracy: 27.4 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 4.552194595336914, accuracy: 15.3 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 5.804648399353027, accuracy: 19.3 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 1.6580848693847656, accuracy: 42.0 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 1.7050747871398926, accuracy: 42.4 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 1.6482850313186646, accuracy: 41.7 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 1.64773690700531, accuracy: 41.4 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 1.6531319618225098, accuracy: 41.6 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 1.7070996761322021, accuracy: 38.1 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 1.6409802436828613, accuracy: 43.0 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 1.6806, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 1.5360, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 1.5605, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 1.8942, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 1.5308, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 1.8655, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 1.7072, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 1.5986, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 1.6657, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 1.6701, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 2.0496771335601807, accuracy: 29.2 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 4.168920993804932, accuracy: 20.0 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 2.141289234161377, accuracy: 31.0 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 1.6243348121643066, accuracy: 42.2 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 1.8613370656967163, accuracy: 36.2 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 2.0584864616394043, accuracy: 31.8 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 1.6051783561706543, accuracy: 41.7 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 1.5972542762756348, accuracy: 44.1 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 1.6025968790054321, accuracy: 43.6 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 1.5969340801239014, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 1.5795, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 1.5195, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 1.5467, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 1.4295, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 1.6129, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 1.5994, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 1.8546, batch time: 0.03, accuracy:  26.56%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 1.5794, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 1.5993, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 1.5945, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 1.924717664718628, accuracy: 29.2 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 3.673248767852783, accuracy: 24.6 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 1.551501989364624, accuracy: 46.8 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 1.561012625694275, accuracy: 43.8 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 1.691573977470398, accuracy: 43.3 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 1.5438389778137207, accuracy: 45.1 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 1.5415936708450317, accuracy: 44.8 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 1.5414831638336182, accuracy: 45.3 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 1.5400140285491943, accuracy: 45.1 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 1.5408029556274414, accuracy: 44.7 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 1.7295, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 1.4105, batch time: 0.04, accuracy:  50.78%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 1.4597, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 1.4930, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 1.5935, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 1.4980, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 1.5245, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 1.5748, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 1.5466, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 1.8928, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 1.9251868724822998, accuracy: 32.8 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 1.5675064325332642, accuracy: 44.0 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 1.5579981803894043, accuracy: 44.1 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 1.7423856258392334, accuracy: 38.5 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 1.5536609888076782, accuracy: 44.7 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 1.553407907485962, accuracy: 44.7 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 1.5580658912658691, accuracy: 44.4 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 1.553038477897644, accuracy: 44.7 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 1.5548646450042725, accuracy: 44.7 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 1.550756812095642, accuracy: 45.1 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 1.5810, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 1.5886, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 1.6894, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 1.5335, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 1.4834, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 1.6116, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 1.6538, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 1.6085, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 1.6524, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 1.5168, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 1.9016512632369995, accuracy: 31.8 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 1.565086007118225, accuracy: 43.7 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 1.5619144439697266, accuracy: 42.9 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 1.698209524154663, accuracy: 38.9 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 1.5602920055389404, accuracy: 43.8 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 1.556613802909851, accuracy: 43.4 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 1.559161901473999, accuracy: 42.8 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 1.5558464527130127, accuracy: 44.0 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 1.555065631866455, accuracy: 43.4 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 1.554537296295166, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 1.5743, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 1.5897, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 1.5552, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 1.6423, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 1.3881, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 1.7650, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 1.5390, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 1.6759, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 1.4279, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 1.4741, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 1.8756723403930664, accuracy: 30.5 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 1.6336357593536377, accuracy: 40.4 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 1.6133068799972534, accuracy: 42.7 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 1.6188446283340454, accuracy: 42.5 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 1.6097538471221924, accuracy: 42.9 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 1.6094447374343872, accuracy: 42.8 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 1.6121702194213867, accuracy: 42.2 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 1.7690620422363281, accuracy: 37.5 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 1.607593059539795, accuracy: 43.3 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 1.6059430837631226, accuracy: 43.3 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 1.6057, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 1.6026, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 1.6246, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 1.5552, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 1.5671, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 1.6669, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 1.7204, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 1.5320, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 1.4584, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 1.4988, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 1.8352375030517578, accuracy: 33.0 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 3.650919198989868, accuracy: 18.0 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 4.6532206535339355, accuracy: 27.8 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 1.5902000665664673, accuracy: 42.6 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 1.590893268585205, accuracy: 44.7 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 1.6277891397476196, accuracy: 42.0 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 1.6651792526245117, accuracy: 38.6 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 1.5768436193466187, accuracy: 43.4 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 1.5761535167694092, accuracy: 43.7 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 1.574357032775879, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 1.6112, batch time: 0.06, accuracy:  45.31%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 1.6978, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 1.6290, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 1.5654, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 1.5058, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 1.6605, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 1.5392, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 1.8164, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 1.6206, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 1.6366, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 1.8285212516784668, accuracy: 34.1 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 1.6491342782974243, accuracy: 44.1 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 1.6289114952087402, accuracy: 44.1 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 1.6355795860290527, accuracy: 42.8 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 1.6267818212509155, accuracy: 43.4 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 1.6253477334976196, accuracy: 43.1 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 1.6329195499420166, accuracy: 42.8 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 1.6289310455322266, accuracy: 44.4 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 1.6282353401184082, accuracy: 42.8 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 1.6352583169937134, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 1.6441, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 1.5872, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 1.6138, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 1.6319, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 1.5511, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 1.7049, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 1.6837, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 1.6509, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 1.5233, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 1.4615, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 2.0951955318450928, accuracy: 24.9 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 3.7018651962280273, accuracy: 18.4 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 30.644668579101562, accuracy: 9.4 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 1.6980626583099365, accuracy: 39.4 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 1.6591575145721436, accuracy: 39.4 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 1.6569958925247192, accuracy: 40.5 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 1.654176950454712, accuracy: 40.9 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 1.6576340198516846, accuracy: 41.6 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 1.6496548652648926, accuracy: 40.2 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 1.657901644706726, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 1.5618, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 1.6088, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 1.5904, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 1.6178, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 1.5598, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 1.4899, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 1.6701, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 1.5591, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 1.5506, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 1.6465, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 1.86183500289917, accuracy: 33.0 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 3.276365041732788, accuracy: 23.5 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 3.539891242980957, accuracy: 19.8 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 1.5728081464767456, accuracy: 43.9 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 1.5692620277404785, accuracy: 42.2 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 1.5614084005355835, accuracy: 43.5 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 1.5590951442718506, accuracy: 43.3 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 1.5572643280029297, accuracy: 44.7 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 1.5559706687927246, accuracy: 43.8 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 1.5544853210449219, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 1.6860, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 1.7268, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 1.4467, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 1.5860, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 1.6308, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 1.6727, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 1.5334, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 1.7839, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 1.7424, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 1.5993, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 2.154726266860962, accuracy: 26.2 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 4.222199440002441, accuracy: 16.7 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 1.8258800506591797, accuracy: 38.3 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 1.654591679573059, accuracy: 41.4 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 1.6348774433135986, accuracy: 42.8 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 1.9039796590805054, accuracy: 32.5 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 1.6185789108276367, accuracy: 44.8 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 1.618404746055603, accuracy: 43.4 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 1.6135858297348022, accuracy: 43.7 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 1.6131237745285034, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 1.6536, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 1.5284, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 1.6228, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 1.6488, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 1.5407, batch time: 0.08, accuracy:  44.53%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 1.6285, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 1.5965, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 1.4590, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 1.5088, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 1.5725, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 2.2004523277282715, accuracy: 26.2 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 1.5880491733551025, accuracy: 41.3 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 1.5779228210449219, accuracy: 41.6 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 1.5770872831344604, accuracy: 42.2 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 1.573084831237793, accuracy: 43.8 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 1.577155590057373, accuracy: 43.0 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 1.5721583366394043, accuracy: 42.1 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 1.5711860656738281, accuracy: 43.5 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 1.5700427293777466, accuracy: 42.6 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 1.5954201221466064, accuracy: 42.0 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 1.6126, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 1.4625, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 1.5411, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 1.6918, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 1.5244, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 1.7891, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 1.6880, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 1.6127, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 1.6328, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 1.4601, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 2.072355031967163, accuracy: 26.9 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 1.5183732509613037, accuracy: 46.2 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 1.5040020942687988, accuracy: 45.9 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 1.4992493391036987, accuracy: 46.9 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 1.497219443321228, accuracy: 46.7 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 1.5000004768371582, accuracy: 46.6 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 1.4958395957946777, accuracy: 47.1 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 1.4940208196640015, accuracy: 47.1 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 1.4930133819580078, accuracy: 47.1 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 1.4923607110977173, accuracy: 47.4 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 1.7346, batch time: 0.08, accuracy:  36.72%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 1.4944, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 1.7439, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 1.6982, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 1.6107, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 1.8265, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 1.6339, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 1.5423, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 1.5872, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 1.5959, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 2.0359013080596924, accuracy: 26.6 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 6.22812032699585, accuracy: 23.6 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 1.5628918409347534, accuracy: 42.2 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 1.6501303911209106, accuracy: 39.4 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 1.5554637908935547, accuracy: 42.5 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 1.549628734588623, accuracy: 41.9 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 1.5509741306304932, accuracy: 42.9 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 1.5466063022613525, accuracy: 42.1 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 1.5413854122161865, accuracy: 42.6 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 1.5405070781707764, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 1.5332, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 1.7491, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 1.5749, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 1.5767, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 1.4783, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 1.4271, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 1.6623, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 1.5204, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 1.5189, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 1.5762, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 2.083303928375244, accuracy: 26.8 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 1.6187564134597778, accuracy: 41.5 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 1.6087470054626465, accuracy: 42.8 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 1.6139286756515503, accuracy: 42.2 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 1.603915810585022, accuracy: 42.0 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 1.6002476215362549, accuracy: 41.8 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 1.6010395288467407, accuracy: 42.0 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 1.598125696182251, accuracy: 42.3 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 1.6068315505981445, accuracy: 41.4 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 1.618216872215271, accuracy: 42.1 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 1.5009, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 1.5227, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 1.5709, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 1.5762, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 1.4488, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 1.6982, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 1.7284, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 1.5602, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 1.6412, batch time: 0.08, accuracy:  38.28%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 1.5273, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 2.0103650093078613, accuracy: 29.5 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 1.5885159969329834, accuracy: 42.8 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 1.5585159063339233, accuracy: 43.3 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 1.5557762384414673, accuracy: 43.8 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 1.547513484954834, accuracy: 44.7 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 1.5457775592803955, accuracy: 45.4 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 1.560304880142212, accuracy: 45.0 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 1.5804979801177979, accuracy: 42.7 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 1.5623201131820679, accuracy: 44.3 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 1.5420691967010498, accuracy: 45.4 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 1.5474, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 1.5138, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 1.8557, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 1.5026, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 1.5802, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 1.6254, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 1.5627, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 1.6168, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 1.6307, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 1.5649, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 2.025071620941162, accuracy: 29.9 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 1.5858345031738281, accuracy: 42.7 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 1.5703651905059814, accuracy: 43.2 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 1.5734503269195557, accuracy: 42.5 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 1.5658859014511108, accuracy: 43.1 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 1.6475948095321655, accuracy: 40.3 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 1.564112663269043, accuracy: 43.0 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 1.5629812479019165, accuracy: 43.2 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 1.5622005462646484, accuracy: 43.2 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 1.5615354776382446, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 1.5434, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 1.6992, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 1.4601, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 1.7288, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 1.4722, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 1.7199, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 1.6160, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 1.5162, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 1.5316, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 1.6491, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 1.8349204063415527, accuracy: 34.6 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 1.6144846677780151, accuracy: 43.4 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 1.5646902322769165, accuracy: 44.1 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 1.597236156463623, accuracy: 42.7 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 1.5607807636260986, accuracy: 44.0 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 1.5705963373184204, accuracy: 43.8 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 1.5570358037948608, accuracy: 44.2 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 1.5594185590744019, accuracy: 43.1 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 1.5754812955856323, accuracy: 43.8 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 1.5545107126235962, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 1.5910, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 1.6395, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 1.6397, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 1.6058, batch time: 0.04, accuracy:  35.16%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 1.5910, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 1.6231, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 1.6508, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 1.4610, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 1.3945, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 1.4693, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 1.8996100425720215, accuracy: 32.1 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 1.5922372341156006, accuracy: 43.3 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 1.567395806312561, accuracy: 44.9 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 1.5726995468139648, accuracy: 42.4 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 1.563194751739502, accuracy: 44.0 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 1.5604511499404907, accuracy: 45.0 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 1.5611205101013184, accuracy: 45.0 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 1.560144066810608, accuracy: 44.9 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 1.5599595308303833, accuracy: 43.7 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 1.5592095851898193, accuracy: 44.9 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 1.6586, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 1.7350, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 1.4795, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 1.4232, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 1.6309, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 1.4653, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 1.7782, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 1.6195, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 1.6783, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 1.5423, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 1.938716173171997, accuracy: 31.1 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 1.558384895324707, accuracy: 44.2 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 1.5221810340881348, accuracy: 47.1 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 1.611352562904358, accuracy: 40.8 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 1.5153149366378784, accuracy: 46.9 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 1.5136220455169678, accuracy: 47.4 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 1.518897533416748, accuracy: 45.9 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 1.5105695724487305, accuracy: 46.3 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 1.5085984468460083, accuracy: 46.6 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 1.5083218812942505, accuracy: 46.7 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 1.4036, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 1.6891, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 1.4254, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 1.5448, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 1.5603, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 1.3826, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 1.6252, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 1.5634, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 1.5440, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 1.5211, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 1.9789930582046509, accuracy: 29.8 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 1.568416714668274, accuracy: 44.6 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 1.538635015487671, accuracy: 45.9 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 1.5396449565887451, accuracy: 45.0 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 1.5459411144256592, accuracy: 44.2 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 1.524133563041687, accuracy: 45.0 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 1.5214712619781494, accuracy: 45.0 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 1.5210098028182983, accuracy: 44.4 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 1.5201878547668457, accuracy: 45.7 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 1.5190613269805908, accuracy: 44.7 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 1.5309, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 1.6349, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 1.5598, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 1.6530, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 1.5085, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 1.4169, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 1.5565, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 1.5814, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 1.5914, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 1.5218, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 1.941222906112671, accuracy: 31.2 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 1.5691735744476318, accuracy: 42.0 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 1.5525743961334229, accuracy: 42.6 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 1.5688185691833496, accuracy: 42.3 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 1.6078115701675415, accuracy: 40.1 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 1.5519933700561523, accuracy: 42.3 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 1.550591230392456, accuracy: 43.2 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 1.5835685729980469, accuracy: 40.9 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 1.5698537826538086, accuracy: 41.5 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 1.5487335920333862, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 1.6471, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 1.6394, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 1.5677, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 1.5803, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 1.4626, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 1.5316, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 1.5307, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 1.7087, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 1.5559, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 1.4838, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 1.9370180368423462, accuracy: 31.2 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 2.0457165241241455, accuracy: 32.8 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 1.5713773965835571, accuracy: 44.4 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 1.572329044342041, accuracy: 44.5 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 1.567753791809082, accuracy: 45.3 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 1.5660377740859985, accuracy: 45.4 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 1.56525456905365, accuracy: 45.4 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 1.5678707361221313, accuracy: 45.1 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 1.5723369121551514, accuracy: 44.8 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 1.5625261068344116, accuracy: 45.7 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 1.6647, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 1.5810, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 1.6134, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 1.4941, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 1.5072, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 1.6238, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 1.5759, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 1.6141, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 1.4891, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 1.6447, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 1.9613157510757446, accuracy: 30.5 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 1.930736780166626, accuracy: 33.6 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 1.5501933097839355, accuracy: 44.7 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 1.5464333295822144, accuracy: 43.7 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 1.565403699874878, accuracy: 41.4 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 1.5454306602478027, accuracy: 44.4 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 1.5430034399032593, accuracy: 44.3 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 1.5422459840774536, accuracy: 44.5 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 1.5421875715255737, accuracy: 43.9 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 1.5423024892807007, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 1.5687, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 1.5182, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 1.4324, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 1.7126, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 1.7231, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 1.5270, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 1.3973, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 1.5084, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 1.6465, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 1.5286, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 1.9127589464187622, accuracy: 31.0 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 1.5879335403442383, accuracy: 44.3 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 1.5532307624816895, accuracy: 44.7 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 1.5506460666656494, accuracy: 43.3 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 1.5810290575027466, accuracy: 42.7 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 1.5540783405303955, accuracy: 43.5 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 1.5475414991378784, accuracy: 44.3 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 1.5477133989334106, accuracy: 43.6 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 1.5439780950546265, accuracy: 44.7 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 1.5431255102157593, accuracy: 44.7 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 1.5980, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 1.6733, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 1.6401, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 1.5445, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 1.8321, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 1.5587, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 1.6533, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 1.5646, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 1.4555, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 1.5977, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 1.813071608543396, accuracy: 33.1 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 2.1074957847595215, accuracy: 28.1 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 1.6087065935134888, accuracy: 40.4 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 1.610679268836975, accuracy: 40.1 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 1.6112602949142456, accuracy: 41.3 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 1.6032716035842896, accuracy: 41.0 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 1.6095385551452637, accuracy: 40.7 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 1.600724697113037, accuracy: 41.1 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 1.6001543998718262, accuracy: 41.1 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 1.5994566679000854, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 1.5483, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 1.6673, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 1.4634, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 1.4126, batch time: 0.03, accuracy:  54.69%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 1.5242, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 1.5436, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 1.5239, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 1.5499, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 1.6846, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 1.5434, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 1.9059842824935913, accuracy: 31.0 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 2.1465249061584473, accuracy: 28.5 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 1.5657157897949219, accuracy: 41.0 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 2.0843825340270996, accuracy: 23.9 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 1.6012629270553589, accuracy: 39.6 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 1.5435429811477661, accuracy: 41.8 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 1.5435899496078491, accuracy: 42.8 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 1.5394155979156494, accuracy: 41.9 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 1.5427589416503906, accuracy: 42.9 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 1.5567231178283691, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 1.5076, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 1.6697, batch time: 0.06, accuracy:  32.81%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 1.6155, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 1.7094, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 1.3894, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 1.6803, batch time: 0.08, accuracy:  37.50%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 1.6216, batch time: 0.08, accuracy:  39.84%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 1.6231, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 1.6201, batch time: 0.08, accuracy:  39.84%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 1.7306, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 2.0050718784332275, accuracy: 29.5 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 1.6090662479400635, accuracy: 42.7 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 1.5703473091125488, accuracy: 44.6 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 1.6223335266113281, accuracy: 40.9 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 1.5630651712417603, accuracy: 43.3 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 1.5554490089416504, accuracy: 44.0 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 1.5566918849945068, accuracy: 43.7 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 1.5716716051101685, accuracy: 44.7 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 1.5540432929992676, accuracy: 44.2 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 1.560931921005249, accuracy: 43.8 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 1.5600, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 1.5943, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 1.4478, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 1.5618, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 1.6026, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 1.8948, batch time: 0.07, accuracy:  31.25%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 1.5464, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 1.5942, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 1.5825, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 1.5408, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 1.9100795984268188, accuracy: 34.1 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 1.5558737516403198, accuracy: 45.6 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 1.5281920433044434, accuracy: 44.7 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 1.5238701105117798, accuracy: 45.9 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 1.5215977430343628, accuracy: 45.7 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 1.519733190536499, accuracy: 46.6 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 1.5258980989456177, accuracy: 46.3 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 1.5186247825622559, accuracy: 46.7 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 1.518239974975586, accuracy: 46.2 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 1.5203708410263062, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 1.7165, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 1.5944, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 1.5221, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 1.6011, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 1.5310, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 1.6304, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 1.7234, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 1.4519, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 1.4165, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 1.5134, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 2.1288251876831055, accuracy: 28.4 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 1.581329107284546, accuracy: 44.2 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 1.5513184070587158, accuracy: 43.8 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 1.5804325342178345, accuracy: 41.1 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 1.5511889457702637, accuracy: 43.4 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 1.5420210361480713, accuracy: 43.7 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 1.5405572652816772, accuracy: 43.3 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 1.5388448238372803, accuracy: 42.6 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 1.537627935409546, accuracy: 42.7 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 1.5439459085464478, accuracy: 44.1 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 1.5945, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 1.5306, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 1.5681, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 1.5209, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 1.6858, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 1.5880, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 1.8806, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 1.5732, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 1.5990, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 1.3912, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 1.9489390850067139, accuracy: 31.8 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 1.5667535066604614, accuracy: 43.0 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 1.5424952507019043, accuracy: 44.7 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 1.553154706954956, accuracy: 44.2 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 1.540295124053955, accuracy: 44.6 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 1.5443094968795776, accuracy: 45.1 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 1.5355093479156494, accuracy: 45.6 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 1.54522705078125, accuracy: 44.5 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 1.5368176698684692, accuracy: 44.8 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 1.5326703786849976, accuracy: 45.7 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 1.5290, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 1.8101, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 1.6587, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 1.4792, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 1.4695, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 1.5613, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 1.8412, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 1.6679, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 1.5528, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 1.5300, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 2.2543139457702637, accuracy: 25.4 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 1.5832773447036743, accuracy: 44.4 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 1.5832773447036743, accuracy: 44.4 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 1.5817341804504395, accuracy: 43.9 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 1.6323237419128418, accuracy: 43.9 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 1.5992192029953003, accuracy: 44.8 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 1.5680427551269531, accuracy: 45.0 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 1.5671740770339966, accuracy: 45.3 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 1.5659383535385132, accuracy: 44.9 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 1.5644488334655762, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 1.5670, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 1.6331, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 1.5749, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 1.7298, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 1.5692, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 1.5801, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 1.4376, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 1.5017, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 1.5546, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 1.6119, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 2.1819357872009277, accuracy: 27.7 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 7.228370189666748, accuracy: 17.6 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 3.4801158905029297, accuracy: 15.9 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 1.6454403400421143, accuracy: 41.6 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 1.6586593389511108, accuracy: 41.2 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 1.614811658859253, accuracy: 43.2 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 1.6064645051956177, accuracy: 45.0 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 1.5986707210540771, accuracy: 44.5 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 1.5951565504074097, accuracy: 45.5 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 1.6023685932159424, accuracy: 44.9 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 1.7349, batch time: 0.03, accuracy:  32.03%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 1.5268, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 1.5281, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 1.5762, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 1.6463, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 1.4198, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 1.5362, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 1.5008, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 1.4343, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 1.5590, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 2.2306339740753174, accuracy: 19.8 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 1.589274287223816, accuracy: 43.7 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 1.5745737552642822, accuracy: 45.7 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 1.6958675384521484, accuracy: 36.4 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 1.5673750638961792, accuracy: 46.4 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 1.5644981861114502, accuracy: 46.2 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 1.5624728202819824, accuracy: 45.8 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 1.5616061687469482, accuracy: 45.0 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 1.5650240182876587, accuracy: 45.6 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 1.560138463973999, accuracy: 44.0 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 1.6519, batch time: 0.06, accuracy:  44.53%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 1.5546, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 1.5538, batch time: 0.08, accuracy:  44.53%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 1.4975, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 1.6992, batch time: 0.05, accuracy:  37.50%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 1.5098, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 1.5115, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 1.5743, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 1.4644, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 1.7025, batch time: 0.05, accuracy:  42.19%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 2.1349446773529053, accuracy: 26.7 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 1.5618454217910767, accuracy: 45.5 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 1.5342440605163574, accuracy: 45.9 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 1.5260019302368164, accuracy: 46.0 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 1.527115821838379, accuracy: 46.9 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 1.521955966949463, accuracy: 46.6 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 1.5380821228027344, accuracy: 46.6 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 1.5240602493286133, accuracy: 46.6 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 1.5225086212158203, accuracy: 46.9 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 1.5177488327026367, accuracy: 47.2 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 1.6971, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 1.5429, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 1.4886, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 1.5736, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 1.6273, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 1.5650, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 1.5142, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 1.7039, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 1.4999, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 1.5301, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 1.9174396991729736, accuracy: 29.8 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 1.5924925804138184, accuracy: 44.0 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 1.5201008319854736, accuracy: 46.2 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 1.5205644369125366, accuracy: 45.8 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 1.5239330530166626, accuracy: 44.4 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 1.5180134773254395, accuracy: 46.0 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 1.5159727334976196, accuracy: 45.8 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 1.514899730682373, accuracy: 46.0 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 1.522101879119873, accuracy: 46.1 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 1.5136436223983765, accuracy: 45.7 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 1.7121, batch time: 0.07, accuracy:  32.81%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 1.6038, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 1.4615, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 1.5607, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 1.4941, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 1.5641, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 1.3363, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 1.4694, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 1.6190, batch time: 0.06, accuracy:  43.75%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 1.5145, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 2.030761957168579, accuracy: 27.0 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 1.8989320993423462, accuracy: 34.6 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 1.5916069746017456, accuracy: 42.2 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 1.5843415260314941, accuracy: 42.7 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 1.580087661743164, accuracy: 44.4 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 1.5767145156860352, accuracy: 43.7 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 1.5796061754226685, accuracy: 43.2 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 1.57539701461792, accuracy: 43.3 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 1.5751349925994873, accuracy: 43.5 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 1.5744688510894775, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 1.5860, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 1.6239, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 1.5847, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 1.4683, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 1.4302, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 1.6386, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 1.5649, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 1.6312, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 1.6505, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 1.4608, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 1.9352720975875854, accuracy: 31.8 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 1.8388770818710327, accuracy: 35.8 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 1.5430326461791992, accuracy: 45.4 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 1.5521180629730225, accuracy: 42.6 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 1.542267084121704, accuracy: 45.3 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 1.5405464172363281, accuracy: 44.8 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 1.5399309396743774, accuracy: 45.3 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 1.5506339073181152, accuracy: 43.8 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 1.538456916809082, accuracy: 45.2 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 1.5374888181686401, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 1.4034, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 1.6328, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 1.5421, batch time: 0.05, accuracy:  46.09%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 1.7190, batch time: 0.24, accuracy:  36.72%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 1.5096, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 1.6159, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 1.6111, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 1.4214, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 1.5492, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 1.6691, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 2.092880964279175, accuracy: 27.4 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 1.5659180879592896, accuracy: 45.5 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 1.5147942304611206, accuracy: 45.5 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 1.5106784105300903, accuracy: 46.4 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 1.5216248035430908, accuracy: 44.1 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 1.5067356824874878, accuracy: 46.0 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 1.5055172443389893, accuracy: 45.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 1.5037426948547363, accuracy: 45.8 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 1.5046719312667847, accuracy: 46.8 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 1.5033355951309204, accuracy: 46.1 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 1.6190, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 1.5345, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 1.7799, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 1.6408, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 1.5178, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 1.7991, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 1.4559, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 1.4287, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 1.4775, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 1.5570, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 2.1050972938537598, accuracy: 29.6 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 1.5994940996170044, accuracy: 44.6 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 1.5447968244552612, accuracy: 45.0 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 1.545915961265564, accuracy: 44.5 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 1.6287678480148315, accuracy: 41.4 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 1.5415542125701904, accuracy: 45.2 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 1.5413728952407837, accuracy: 44.7 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 1.5605008602142334, accuracy: 43.0 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 1.5421745777130127, accuracy: 44.7 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 1.5403721332550049, accuracy: 45.0 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 1.6181, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 1.5688, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 1.4831, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 1.3940, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 1.4919, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 1.5538, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 1.5490, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 1.4924, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 1.5252, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 1.4523, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 2.252403974533081, accuracy: 28.9 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 1.5389580726623535, accuracy: 46.5 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 1.4908561706542969, accuracy: 48.5 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 1.5502623319625854, accuracy: 43.1 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 1.4797924757003784, accuracy: 50.0 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 1.476417899131775, accuracy: 48.9 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 1.4794321060180664, accuracy: 48.9 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 1.471708059310913, accuracy: 49.2 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 1.4711072444915771, accuracy: 49.2 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 1.4701790809631348, accuracy: 49.1 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 1.5133, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 1.4913, batch time: 0.08, accuracy:  46.09%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 1.5316, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 1.6532, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 1.4331, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 1.6394, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 1.5895, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 1.5591, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 1.4737, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 1.4195, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 2.2173938751220703, accuracy: 28.9 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 1.5514109134674072, accuracy: 46.9 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 1.5061298608779907, accuracy: 48.0 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 1.6217950582504272, accuracy: 40.3 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 1.5008578300476074, accuracy: 47.9 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 1.5104106664657593, accuracy: 47.1 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 1.496450424194336, accuracy: 47.8 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 1.5100311040878296, accuracy: 46.8 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 1.4949074983596802, accuracy: 48.4 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 1.4943450689315796, accuracy: 49.0 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 1.6403, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 1.5959, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 1.4204, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 1.5532, batch time: 0.08, accuracy:  42.19%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 1.4193, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 1.4494, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 1.5572, batch time: 0.07, accuracy:  34.38%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 1.6175, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 1.5981, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 1.5973, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 2.2118821144104004, accuracy: 27.1 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 1.5691460371017456, accuracy: 45.5 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 1.5148745775222778, accuracy: 46.7 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 1.5148519277572632, accuracy: 45.6 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 1.5110883712768555, accuracy: 46.1 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 1.5172150135040283, accuracy: 44.9 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 1.5101984739303589, accuracy: 46.7 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 1.508262038230896, accuracy: 46.6 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 1.5085805654525757, accuracy: 46.9 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 1.5073862075805664, accuracy: 46.7 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 1.4924, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 1.5369, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 1.6321, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 1.5354, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 1.4875, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 1.5632, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 1.4113, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 1.6290, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 1.5263, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 1.4670, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 2.330634593963623, accuracy: 27.3 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 1.6019022464752197, accuracy: 44.1 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 1.5897265672683716, accuracy: 44.7 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 1.699334979057312, accuracy: 39.5 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 1.5764148235321045, accuracy: 44.8 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 1.5684856176376343, accuracy: 45.5 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 1.5669105052947998, accuracy: 45.9 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 1.5652952194213867, accuracy: 45.6 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 1.6031162738800049, accuracy: 44.7 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 1.5617351531982422, accuracy: 45.9 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 1.5849, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 1.4926, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 1.5446, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 1.5743, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 1.5736, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 1.4869, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 1.4908, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 1.7558, batch time: 0.07, accuracy:  32.03%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 1.3848, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 1.6177, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 2.3869292736053467, accuracy: 23.2 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 1.6340183019638062, accuracy: 42.5 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 1.5514705181121826, accuracy: 44.4 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 1.7476189136505127, accuracy: 37.9 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 1.5516993999481201, accuracy: 43.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 1.5491712093353271, accuracy: 43.8 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 1.5562548637390137, accuracy: 43.0 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 1.5715432167053223, accuracy: 43.0 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 1.548327922821045, accuracy: 44.5 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 1.5402179956436157, accuracy: 45.7 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 1.4289, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 1.3612, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 1.7461, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 1.5447, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 1.5477, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 1.4830, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 1.5084, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 1.3763, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 1.7274, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 1.6359, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 2.0459725856781006, accuracy: 31.7 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 1.6624325513839722, accuracy: 42.1 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 1.525663137435913, accuracy: 44.4 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 1.5205696821212769, accuracy: 45.9 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 1.5183569192886353, accuracy: 47.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 1.5170129537582397, accuracy: 46.0 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 1.5244596004486084, accuracy: 44.7 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 1.515334963798523, accuracy: 46.5 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 1.514159083366394, accuracy: 46.9 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 1.513629674911499, accuracy: 46.9 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 1.4612, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 1.5300, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 1.7125, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 1.4785, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 1.4437, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 1.4951, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 1.4995, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 1.4561, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 1.6701, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 1.6669, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 2.3871524333953857, accuracy: 25.0 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 1.58408522605896, accuracy: 45.3 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 1.5543938875198364, accuracy: 46.8 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 1.883638620376587, accuracy: 32.7 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 1.6358747482299805, accuracy: 42.0 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 1.567488431930542, accuracy: 45.5 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 1.6509993076324463, accuracy: 40.7 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 1.5501208305358887, accuracy: 47.0 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 1.549878716468811, accuracy: 46.8 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 1.5492671728134155, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 1.4619, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 1.7530, batch time: 0.08, accuracy:  35.94%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 1.4955, batch time: 0.08, accuracy:  48.44%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 1.5188, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 1.6719, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 1.3444, batch time: 0.04, accuracy:  52.34%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 1.5581, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 1.5192, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 1.6433, batch time: 0.04, accuracy:  37.50%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 1.7585, batch time: 0.08, accuracy:  33.59%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 2.202852487564087, accuracy: 27.9 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 1.6216367483139038, accuracy: 43.9 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 1.539638876914978, accuracy: 43.4 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 1.539219856262207, accuracy: 44.2 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 1.5347046852111816, accuracy: 45.5 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 1.5323597192764282, accuracy: 44.6 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 1.5373945236206055, accuracy: 45.5 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 1.5473930835723877, accuracy: 43.8 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 1.5304447412490845, accuracy: 45.4 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 1.5288299322128296, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 1.6543, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 1.6136, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 1.4785, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 1.5684, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 1.6028, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 1.5750, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 1.4455, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 1.4992, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 1.4317, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 1.4459, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 2.560847759246826, accuracy: 21.9 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 1.5644594430923462, accuracy: 44.6 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 1.5134481191635132, accuracy: 45.4 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 1.5202890634536743, accuracy: 44.4 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 1.5929433107376099, accuracy: 42.6 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 1.508095622062683, accuracy: 46.0 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 1.506205677986145, accuracy: 46.0 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 1.5036739110946655, accuracy: 46.3 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 1.503906488418579, accuracy: 45.9 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 1.5015738010406494, accuracy: 46.8 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 1.4663, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 1.4533, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 1.4625, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 1.5846, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 1.6356, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 1.4375, batch time: 0.07, accuracy:  54.69%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 1.4366, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 1.4232, batch time: 0.08, accuracy:  49.22%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 1.5253, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 1.5167, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 2.1016035079956055, accuracy: 29.6 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 1.5434259176254272, accuracy: 45.8 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 1.5213696956634521, accuracy: 46.6 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 1.5270060300827026, accuracy: 45.6 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 1.6478095054626465, accuracy: 39.4 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 1.5296217203140259, accuracy: 45.7 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 1.5287233591079712, accuracy: 45.9 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 1.5195186138153076, accuracy: 46.0 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 1.5091874599456787, accuracy: 47.7 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 1.5087071657180786, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 1.5168, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 1.5821, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 1.5398, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 1.6730, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 1.4793, batch time: 0.08, accuracy:  46.09%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 1.3403, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 1.4479, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 1.6698, batch time: 0.05, accuracy:  39.84%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 1.8038, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 1.4347, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 2.1675503253936768, accuracy: 28.7 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 1.5133224725723267, accuracy: 46.9 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 1.4791969060897827, accuracy: 48.3 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 1.476367473602295, accuracy: 48.6 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 1.4910614490509033, accuracy: 47.3 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 1.4724253416061401, accuracy: 47.8 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 1.4758844375610352, accuracy: 48.0 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 1.4725050926208496, accuracy: 48.3 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 1.4689372777938843, accuracy: 48.3 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 1.4676436185836792, accuracy: 49.1 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 1.4547, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 1.5684, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 1.5675, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 1.5109, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 1.5084, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 1.5996, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 1.5388, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 1.3681, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 1.5748, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 1.5173, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 2.3281495571136475, accuracy: 24.9 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 1.5587079524993896, accuracy: 43.6 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 1.5207831859588623, accuracy: 46.1 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 1.7828232049942017, accuracy: 34.0 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 1.5112648010253906, accuracy: 46.8 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 1.5104445219039917, accuracy: 47.3 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 1.5091679096221924, accuracy: 47.3 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 1.5094268321990967, accuracy: 46.5 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 1.5534940958023071, accuracy: 44.6 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 1.507582426071167, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 1.5489, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 1.5758, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 1.6503, batch time: 0.04, accuracy:  42.19%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 1.5423, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 1.6228, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 1.6256, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 1.4403, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 1.4093, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 1.5690, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 1.5665, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 2.164757013320923, accuracy: 29.8 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 1.6066699028015137, accuracy: 44.1 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 1.5779155492782593, accuracy: 42.6 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 1.570906400680542, accuracy: 42.9 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 1.5689141750335693, accuracy: 43.3 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 1.5721023082733154, accuracy: 43.6 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 1.565750002861023, accuracy: 43.7 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 1.5632749795913696, accuracy: 43.7 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 1.5630332231521606, accuracy: 43.7 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 1.5624433755874634, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 1.3333, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 1.3421, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 1.6452, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 1.6866, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 1.4408, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 1.5747, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 1.5699, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 1.4962, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 1.6766, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 1.5987, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 2.641921043395996, accuracy: 23.3 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 1.5798075199127197, accuracy: 44.4 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 1.5348213911056519, accuracy: 44.7 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 1.5424127578735352, accuracy: 45.0 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 1.530994176864624, accuracy: 44.1 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 1.5266594886779785, accuracy: 44.4 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 1.5267189741134644, accuracy: 44.7 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 1.5240267515182495, accuracy: 45.2 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 1.5224217176437378, accuracy: 44.7 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 1.5200713872909546, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 1.5958, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 1.4310, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 1.6290, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 1.4742, batch time: 0.04, accuracy:  53.91%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 1.6937, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 1.5646, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 1.5498, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 1.6256, batch time: 0.03, accuracy:  32.81%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 1.5774, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 1.4341, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 2.4111151695251465, accuracy: 24.9 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 1.5878113508224487, accuracy: 43.1 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 1.501115083694458, accuracy: 45.3 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 1.5179309844970703, accuracy: 42.8 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 1.4994816780090332, accuracy: 44.8 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 1.5030587911605835, accuracy: 45.3 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 1.4956295490264893, accuracy: 45.0 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 1.4936069250106812, accuracy: 45.0 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 1.4936615228652954, accuracy: 44.4 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 1.493030309677124, accuracy: 44.6 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 1.4384, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 1.5322, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 1.6780, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 1.4499, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 1.6283, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 1.5268, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 1.6383, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 1.5234, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 1.5728, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 1.6390, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 2.3476288318634033, accuracy: 23.2 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 1.578885555267334, accuracy: 43.1 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 1.5268930196762085, accuracy: 43.5 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 1.524504542350769, accuracy: 43.6 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 1.523919939994812, accuracy: 43.7 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 1.5229040384292603, accuracy: 43.0 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 1.5250295400619507, accuracy: 43.4 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 1.5190768241882324, accuracy: 42.9 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 1.5163902044296265, accuracy: 42.8 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 1.5157110691070557, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 1.5250, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 1.5724, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 1.5964, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 1.4837, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 1.4285, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 1.5818, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 1.4190, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 1.6503, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 1.5114, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 1.6414, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 2.261347770690918, accuracy: 24.6 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 1.5864030122756958, accuracy: 40.8 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 1.5143787860870361, accuracy: 43.1 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 1.5079292058944702, accuracy: 43.6 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 1.5057368278503418, accuracy: 43.8 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 1.5046813488006592, accuracy: 43.9 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 1.5022221803665161, accuracy: 44.1 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 1.5009617805480957, accuracy: 43.6 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 1.500013828277588, accuracy: 44.0 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 1.499225378036499, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 1.5189, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 1.5677, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 1.4525, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 1.5548, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 1.4586, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 1.3695, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 1.3373, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 1.5165, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 1.5573, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 1.4521, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 2.480469226837158, accuracy: 22.9 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 1.859480381011963, accuracy: 33.4 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 1.513461709022522, accuracy: 45.0 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 1.5166239738464355, accuracy: 44.8 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 1.513692021369934, accuracy: 44.8 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 1.5310395956039429, accuracy: 42.5 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 1.5083764791488647, accuracy: 45.2 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 1.5063374042510986, accuracy: 45.2 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 1.5060622692108154, accuracy: 45.1 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 1.5052118301391602, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 1.5032, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 1.4274, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 1.7261, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 1.5093, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 1.4535, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 1.5350, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 1.6217, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 1.5467, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 1.5712, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 1.4663, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 2.5264365673065186, accuracy: 24.3 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 1.8244179487228394, accuracy: 35.9 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 1.5551705360412598, accuracy: 45.5 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 1.966585636138916, accuracy: 33.6 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 1.54514741897583, accuracy: 44.2 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 1.5407418012619019, accuracy: 45.4 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 1.5419971942901611, accuracy: 44.8 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 1.5392913818359375, accuracy: 45.3 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 1.5385280847549438, accuracy: 45.7 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 1.536587119102478, accuracy: 44.6 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 1.5766, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 1.4387, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 1.6273, batch time: 0.06, accuracy:  42.19%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 1.5192, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 1.4525, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 1.6432, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 1.5379, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 1.3188, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 1.3403, batch time: 0.07, accuracy:  53.12%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 1.3753, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 2.8932337760925293, accuracy: 28.1 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 1.7883391380310059, accuracy: 36.9 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 1.5920614004135132, accuracy: 44.0 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 1.5498403310775757, accuracy: 44.7 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 1.570369839668274, accuracy: 44.6 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 1.5469369888305664, accuracy: 43.6 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 1.5341914892196655, accuracy: 44.8 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 1.532370686531067, accuracy: 44.2 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 1.5299230813980103, accuracy: 44.1 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 1.528275489807129, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 1.3197, batch time: 0.07, accuracy:  55.47%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 1.6731, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 1.4482, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 1.5841, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 1.3596, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 1.5036, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 1.6284, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 1.5481, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 1.6085, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 1.4377, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 3.548171043395996, accuracy: 22.0 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 1.5903968811035156, accuracy: 45.6 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 1.5050640106201172, accuracy: 47.5 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 1.500077247619629, accuracy: 46.5 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 1.5020701885223389, accuracy: 47.0 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 1.5070011615753174, accuracy: 47.5 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 1.5040109157562256, accuracy: 45.3 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 1.497201681137085, accuracy: 46.3 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 1.496166467666626, accuracy: 46.0 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 1.4955788850784302, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 1.4818, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 1.6652, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 1.4780, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 1.6043, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 1.5192, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 1.4117, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 1.5590, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 1.4863, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 1.5519, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 1.5060, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 3.1247708797454834, accuracy: 23.5 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 1.737755537033081, accuracy: 36.4 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 1.5435084104537964, accuracy: 45.0 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 1.5408058166503906, accuracy: 44.5 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 1.5368107557296753, accuracy: 44.6 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 1.5356510877609253, accuracy: 44.5 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 1.5315825939178467, accuracy: 44.7 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 1.5591543912887573, accuracy: 44.4 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 1.5275923013687134, accuracy: 44.1 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 1.5266234874725342, accuracy: 44.1 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 1.5651, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 1.6065, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 1.5746, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 1.5336, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 1.4406, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 1.4187, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 1.5661, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 1.5672, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 1.4334, batch time: 0.08, accuracy:  49.22%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 1.5912, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 3.016827344894409, accuracy: 23.1 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 1.702676773071289, accuracy: 35.4 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 1.5619701147079468, accuracy: 43.3 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 1.5576809644699097, accuracy: 40.5 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 1.5742738246917725, accuracy: 41.2 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 1.5479079484939575, accuracy: 41.4 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 1.5441439151763916, accuracy: 42.4 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 1.5553542375564575, accuracy: 43.9 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 1.5499299764633179, accuracy: 43.5 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 1.5428029298782349, accuracy: 44.1 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 1.5718, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 1.5053, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 1.4518, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 1.4760, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 1.6825, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 1.4818, batch time: 0.08, accuracy:  40.62%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 1.5704, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 1.6416, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 1.4006, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 1.6110, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 3.250892162322998, accuracy: 24.2 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 1.8790690898895264, accuracy: 31.5 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 1.486950397491455, accuracy: 47.6 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 2.473933696746826, accuracy: 21.3 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 1.4640353918075562, accuracy: 47.6 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 1.482866644859314, accuracy: 44.1 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 1.4619756937026978, accuracy: 47.7 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 1.5007907152175903, accuracy: 45.0 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 1.4596586227416992, accuracy: 49.3 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 1.458532691001892, accuracy: 47.5 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 1.5800, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 1.6454, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 1.4990, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 1.4995, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 1.4149, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 1.5511, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 1.6875, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 1.5841, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 1.5296, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 1.5012, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 2.519955635070801, accuracy: 23.6 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 1.8036925792694092, accuracy: 32.9 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 1.516167402267456, accuracy: 43.1 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 1.6342474222183228, accuracy: 36.7 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 1.5117475986480713, accuracy: 43.2 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 1.5115249156951904, accuracy: 43.7 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 1.5456130504608154, accuracy: 42.7 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 1.5100523233413696, accuracy: 43.9 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 1.5560401678085327, accuracy: 43.0 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 1.5084669589996338, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 1.3935, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 1.6318, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 1.5604, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 1.6841, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 1.4867, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 1.5443, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 1.6058, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 1.4840, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 1.5738, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 1.4804, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 2.454690933227539, accuracy: 24.7 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 1.633705735206604, accuracy: 40.0 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 1.4849448204040527, accuracy: 47.6 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 1.5213290452957153, accuracy: 46.7 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 1.4840197563171387, accuracy: 45.9 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 1.4755998849868774, accuracy: 47.4 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 1.4744915962219238, accuracy: 47.2 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 1.4731969833374023, accuracy: 47.1 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 1.4732762575149536, accuracy: 47.7 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 1.4839578866958618, accuracy: 46.9 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 1.5887, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 1.4815, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 1.3960, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 1.4211, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 1.4482, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 1.4517, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 1.5219, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 1.5552, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 1.5206, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 1.4184, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 2.0850088596343994, accuracy: 26.7 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 1.7472809553146362, accuracy: 36.6 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 1.503125786781311, accuracy: 44.2 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 1.5098544359207153, accuracy: 43.2 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 1.5012643337249756, accuracy: 43.9 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 1.5058889389038086, accuracy: 43.2 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 1.5084917545318604, accuracy: 42.7 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 1.499875783920288, accuracy: 44.0 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 1.686530351638794, accuracy: 37.2 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 1.5110427141189575, accuracy: 42.8 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 1.4073, batch time: 0.03, accuracy:  55.47%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 1.3946, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 1.6455, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 1.6626, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 1.4214, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 1.4602, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 1.5273, batch time: 0.04, accuracy:  39.06%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 1.4626, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 1.4790, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 1.6017, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 1.9861443042755127, accuracy: 32.6 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 1.6804018020629883, accuracy: 37.7 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 1.502845048904419, accuracy: 44.3 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 1.4929314851760864, accuracy: 45.2 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 1.4926798343658447, accuracy: 45.2 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 1.49711012840271, accuracy: 45.3 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 1.4994521141052246, accuracy: 44.9 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 1.4866851568222046, accuracy: 45.2 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 1.4855515956878662, accuracy: 44.7 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 1.4843974113464355, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 1.5943, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 1.6456, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 1.5244, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 1.4321, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 1.4409, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 1.4894, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 1.5314, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 1.4363, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 1.4710, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 1.4139, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 1.9861866235733032, accuracy: 32.5 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 1.617221474647522, accuracy: 41.1 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 1.4862337112426758, accuracy: 46.5 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 1.5101288557052612, accuracy: 45.3 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 1.4811906814575195, accuracy: 47.2 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 1.479918122291565, accuracy: 47.6 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 1.4787089824676514, accuracy: 46.9 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 1.4774699211120605, accuracy: 47.7 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 1.477700114250183, accuracy: 47.4 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 1.4774373769760132, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 1.4931, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 1.4376, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 1.3634, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 1.4743, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 1.4989, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 1.6699, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 1.6479, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 1.4408, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 1.6208, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 1.5445, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 1.9947400093078613, accuracy: 33.7 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 1.719204306602478, accuracy: 37.7 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 1.5322322845458984, accuracy: 43.7 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 1.8030670881271362, accuracy: 36.9 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 1.5224531888961792, accuracy: 43.7 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 1.517690658569336, accuracy: 44.9 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 1.5162385702133179, accuracy: 44.5 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 1.5176489353179932, accuracy: 44.4 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 1.5304824113845825, accuracy: 42.4 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 1.5131486654281616, accuracy: 44.5 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 1.5353, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 1.6053, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 1.4787, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 1.6259, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 1.4083, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 1.7399, batch time: 0.03, accuracy:  35.16%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 1.3538, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 1.3839, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 1.7483, batch time: 0.03, accuracy:  33.59%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 1.5843, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 1.9324395656585693, accuracy: 37.0 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 1.6415051221847534, accuracy: 39.0 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 1.478013515472412, accuracy: 46.8 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 1.4768309593200684, accuracy: 46.7 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 1.4713568687438965, accuracy: 46.4 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 1.4676640033721924, accuracy: 47.2 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 1.46668541431427, accuracy: 47.1 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 1.4650593996047974, accuracy: 46.2 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 1.4676686525344849, accuracy: 47.0 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 1.4625961780548096, accuracy: 46.9 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 1.4532, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 1.5900, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 1.4890, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 1.4711, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 1.6461, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 1.5235, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 1.6023, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 1.7723, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 1.5341, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 1.5212, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 1.915883183479309, accuracy: 34.8 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 1.7394083738327026, accuracy: 35.8 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 1.532857060432434, accuracy: 43.3 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 1.53730046749115, accuracy: 43.3 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 1.523949146270752, accuracy: 44.3 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 1.5227891206741333, accuracy: 43.3 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 1.523973822593689, accuracy: 43.6 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 1.5411839485168457, accuracy: 42.8 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 1.5198768377304077, accuracy: 43.5 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 1.5191402435302734, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 1.6243, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 1.5921, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 1.5665, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 1.6743, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 1.5269, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 1.6630, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 1.5493, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 1.6682, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 1.5542, batch time: 0.06, accuracy:  46.88%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 1.5795, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 2.0548856258392334, accuracy: 30.5 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 1.7472960948944092, accuracy: 35.6 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 1.529295802116394, accuracy: 45.5 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 1.5436656475067139, accuracy: 43.7 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 1.5270782709121704, accuracy: 44.9 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 1.5262565612792969, accuracy: 44.1 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 1.5467599630355835, accuracy: 42.6 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 1.5495816469192505, accuracy: 44.2 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 1.522506594657898, accuracy: 44.6 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 1.522879719734192, accuracy: 44.6 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 1.5348, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 1.5048, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 1.5731, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 1.6832, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 1.6276, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 1.6132, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 1.4905, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 1.4197, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 1.5730, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 1.3964, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 2.036585807800293, accuracy: 29.0 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 1.7831127643585205, accuracy: 33.0 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 1.5287925004959106, accuracy: 42.5 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 1.5281850099563599, accuracy: 42.4 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 1.5245063304901123, accuracy: 42.1 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 1.5225406885147095, accuracy: 41.7 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 1.521523118019104, accuracy: 42.4 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 1.5202380418777466, accuracy: 41.9 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 1.520280361175537, accuracy: 42.0 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 1.5196608304977417, accuracy: 42.3 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 1.5597, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 1.4366, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 1.4822, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 1.5532, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 1.4641, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 1.5114, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 1.4036, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 1.4738, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 1.5883, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 1.3591, batch time: 0.07, accuracy:  52.34%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 2.0146236419677734, accuracy: 31.5 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 1.60490083694458, accuracy: 42.6 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 1.5656275749206543, accuracy: 44.5 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 1.5632363557815552, accuracy: 44.1 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 1.5674692392349243, accuracy: 44.1 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 1.5600084066390991, accuracy: 44.4 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 1.5592856407165527, accuracy: 43.6 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 1.5583590269088745, accuracy: 43.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 1.557927131652832, accuracy: 43.5 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 1.5573103427886963, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 1.5634, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 1.3661, batch time: 0.04, accuracy:  49.22%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 1.5718, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 1.5195, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 1.5666, batch time: 0.08, accuracy:  44.53%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 1.7029, batch time: 0.04, accuracy:  38.28%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 1.5286, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 1.5558, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 1.5600, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 1.5375, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 1.9653832912445068, accuracy: 29.7 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 1.832834005355835, accuracy: 32.5 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 1.5612093210220337, accuracy: 43.0 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 1.6371787786483765, accuracy: 36.1 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 1.563556432723999, accuracy: 42.8 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 1.5559604167938232, accuracy: 42.1 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 1.5646566152572632, accuracy: 42.2 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 1.5506603717803955, accuracy: 43.3 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 1.5472577810287476, accuracy: 42.9 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 1.5465338230133057, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 1.5339, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 1.5061, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 1.5930, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 1.5953, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 1.4699, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 1.3655, batch time: 0.04, accuracy:  51.56%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 1.4239, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 1.5315, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 1.4425, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 1.5924, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 2.1775600910186768, accuracy: 27.2 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 1.5660431385040283, accuracy: 44.4 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 1.5105466842651367, accuracy: 45.1 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 1.5102663040161133, accuracy: 44.0 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 1.504173755645752, accuracy: 44.3 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 1.503123164176941, accuracy: 45.0 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 1.5083401203155518, accuracy: 45.0 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 1.5014798641204834, accuracy: 44.7 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 1.5032689571380615, accuracy: 45.3 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 1.497908592224121, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 1.5040, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 1.4432, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 1.5712, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 1.4614, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 1.4585, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 1.5880, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 1.4694, batch time: 0.08, accuracy:  46.88%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 1.6881, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 1.5714, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 1.4694, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 2.110990047454834, accuracy: 28.1 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 1.758662223815918, accuracy: 33.1 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 1.5346556901931763, accuracy: 42.3 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 1.539184331893921, accuracy: 41.6 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 1.5378586053848267, accuracy: 42.5 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 1.5408886671066284, accuracy: 41.8 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 1.5381475687026978, accuracy: 43.2 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 1.5433269739151, accuracy: 42.2 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 1.5255074501037598, accuracy: 43.1 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 1.5253492593765259, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 1.4801, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 1.5894, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 1.6178, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 1.5362, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 1.4680, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 1.4149, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 1.4850, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 1.5984, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 1.4865, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 1.4982, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 2.014831066131592, accuracy: 30.3 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 1.8047739267349243, accuracy: 34.3 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 1.451094627380371, accuracy: 45.0 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 1.4496015310287476, accuracy: 45.3 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 1.45102858543396, accuracy: 43.9 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 1.4453949928283691, accuracy: 44.7 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 1.4443572759628296, accuracy: 45.1 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 1.4433214664459229, accuracy: 44.9 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 1.4423211812973022, accuracy: 45.2 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 1.4411996603012085, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 1.4860, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 1.5367, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 1.6940, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 1.4993, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 1.4972, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 1.5607, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 1.7061, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 1.4437, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 1.5630, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 1.5095, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 1.9173320531845093, accuracy: 32.8 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 1.7274224758148193, accuracy: 36.7 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 1.3842744827270508, accuracy: 48.8 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 1.3826584815979004, accuracy: 49.7 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 1.3829641342163086, accuracy: 49.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 1.3967889547348022, accuracy: 47.5 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 1.3747825622558594, accuracy: 49.7 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 1.3737504482269287, accuracy: 49.9 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 1.3732844591140747, accuracy: 49.8 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 1.3728946447372437, accuracy: 49.9 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 1.3996, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 1.6159, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 1.4630, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 1.5002, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 1.5464, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 1.4946, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 1.5126, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 1.3828, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 1.5483, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 1.4247, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 1.9655717611312866, accuracy: 32.0 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 1.8720722198486328, accuracy: 32.0 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 1.4831076860427856, accuracy: 46.4 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 1.4725233316421509, accuracy: 47.1 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 1.490882158279419, accuracy: 45.8 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 1.4724705219268799, accuracy: 47.1 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 1.4708482027053833, accuracy: 47.4 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 1.469794511795044, accuracy: 47.3 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 1.4692937135696411, accuracy: 47.4 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 1.4692068099975586, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 1.5923, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 1.5131, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 1.4550, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 1.6373, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 1.5734, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 1.5827, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 1.6078, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 1.4643, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 1.4917, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 1.6822, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 2.03074312210083, accuracy: 30.0 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 1.869795322418213, accuracy: 31.7 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 1.470554232597351, accuracy: 45.6 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 1.511678695678711, accuracy: 44.3 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 1.4678651094436646, accuracy: 45.0 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 1.4631582498550415, accuracy: 45.4 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 1.4641631841659546, accuracy: 45.9 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 1.4617170095443726, accuracy: 44.8 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 1.460795283317566, accuracy: 45.3 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 1.459796667098999, accuracy: 45.4 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 1.5192, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 1.6795, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 1.4264, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 1.6308, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 1.5086, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 1.5123, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 1.7137, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 1.4126, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 1.4748, batch time: 0.03, accuracy:  53.12%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 1.5146, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 1.9796408414840698, accuracy: 31.1 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 2.045497417449951, accuracy: 28.8 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 1.5571428537368774, accuracy: 42.8 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 1.5507868528366089, accuracy: 41.6 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 1.5527476072311401, accuracy: 42.2 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 1.5490074157714844, accuracy: 42.9 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 1.5458502769470215, accuracy: 42.5 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 1.543824315071106, accuracy: 42.7 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 1.5442912578582764, accuracy: 43.1 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 1.5428582429885864, accuracy: 42.9 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 1.5594, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 1.4453, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 1.4513, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 1.5221, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 1.5964, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 1.5681, batch time: 0.04, accuracy:  46.88%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 1.6281, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 1.4586, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 1.5341, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 1.4462, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 2.3923885822296143, accuracy: 27.0 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 1.7195332050323486, accuracy: 34.7 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 1.4642804861068726, accuracy: 45.3 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 1.460426926612854, accuracy: 45.0 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 3.212216854095459, accuracy: 16.6 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 1.4517207145690918, accuracy: 46.9 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 1.4462549686431885, accuracy: 47.0 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 1.4592411518096924, accuracy: 45.2 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 1.4491709470748901, accuracy: 46.8 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 1.4603078365325928, accuracy: 44.9 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 1.3660, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 1.4123, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 1.4562, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 1.4002, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 1.5574, batch time: 0.04, accuracy:  45.31%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 1.6446, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 1.4615, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 1.4876, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 1.6693, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 1.4871, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 2.1792633533477783, accuracy: 28.5 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 1.8645710945129395, accuracy: 32.0 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 1.5095860958099365, accuracy: 43.9 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 1.503224492073059, accuracy: 45.1 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 1.5055062770843506, accuracy: 45.8 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 1.504184365272522, accuracy: 45.3 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 1.495577335357666, accuracy: 44.8 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 1.4934884309768677, accuracy: 45.1 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 1.4922351837158203, accuracy: 45.3 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 1.4921799898147583, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 1.5474, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 1.5764, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 1.5234, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 1.6780, batch time: 0.03, accuracy:  36.72%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 1.4247, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 1.5320, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 1.4753, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 1.5921, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 1.3379, batch time: 0.07, accuracy:  57.03%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 1.5572, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 2.2466845512390137, accuracy: 30.0 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 1.7778642177581787, accuracy: 33.3 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 1.5038686990737915, accuracy: 46.4 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 1.5037477016448975, accuracy: 46.7 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 1.4930896759033203, accuracy: 46.6 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 1.493864893913269, accuracy: 47.5 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 1.489168643951416, accuracy: 46.7 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 1.520382046699524, accuracy: 45.1 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 1.4887739419937134, accuracy: 45.5 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 1.4875036478042603, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 1.5565, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 1.5635, batch time: 0.07, accuracy:  38.28%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 1.5419, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 1.4626, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 1.5875, batch time: 0.04, accuracy:  41.41%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 1.6092, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 1.6514, batch time: 0.04, accuracy:  36.72%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 1.4586, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 1.5804, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 1.4386, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 2.234971523284912, accuracy: 25.4 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 1.761314868927002, accuracy: 35.6 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 1.5161406993865967, accuracy: 44.4 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 1.5079832077026367, accuracy: 43.1 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 1.5006389617919922, accuracy: 44.4 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 1.4909175634384155, accuracy: 45.0 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 1.4914860725402832, accuracy: 44.3 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 1.4880375862121582, accuracy: 44.6 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 1.487317681312561, accuracy: 44.3 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 1.4868806600570679, accuracy: 44.4 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 1.5092, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 1.4293, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 1.5373, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 1.5621, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 1.4267, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 1.4823, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 1.5562, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 1.3661, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 1.5164, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 1.5544, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 2.0197718143463135, accuracy: 29.7 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 1.663367748260498, accuracy: 35.2 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 1.4837743043899536, accuracy: 45.5 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 1.478628158569336, accuracy: 45.8 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 1.475101351737976, accuracy: 45.3 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 1.4720157384872437, accuracy: 45.2 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 1.4667019844055176, accuracy: 45.7 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 1.4684724807739258, accuracy: 44.7 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 1.465442419052124, accuracy: 45.7 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 1.4634859561920166, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 1.4258, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 1.6899, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 1.7707, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 1.5210, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 1.6027, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 1.6054, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 1.5633, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 1.8054, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 1.3068, batch time: 0.03, accuracy:  52.34%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 1.4681, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 2.2326300144195557, accuracy: 26.1 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 1.8161616325378418, accuracy: 32.0 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 1.4722598791122437, accuracy: 46.2 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 1.469208836555481, accuracy: 45.5 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 1.4975556135177612, accuracy: 45.0 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 1.4701666831970215, accuracy: 45.2 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 1.466310739517212, accuracy: 45.3 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 1.4663912057876587, accuracy: 45.2 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 1.4658982753753662, accuracy: 45.8 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 1.4656941890716553, accuracy: 45.5 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 1.5160, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 1.3987, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 1.3782, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 1.4739, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 1.3602, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 1.3794, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 1.4592, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 1.5498, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 1.4940, batch time: 0.04, accuracy:  48.44%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 1.5074, batch time: 0.04, accuracy:  42.97%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 2.2486512660980225, accuracy: 23.3 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.7494678497314453, accuracy: 32.0 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 1.4832055568695068, accuracy: 42.9 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 1.485016942024231, accuracy: 43.0 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 1.4862432479858398, accuracy: 42.1 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 1.4739031791687012, accuracy: 45.3 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 1.4747270345687866, accuracy: 44.2 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 1.4674201011657715, accuracy: 45.4 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 1.4668636322021484, accuracy: 45.4 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 1.4655542373657227, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 1.3217, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 1.6120, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 1.5653, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 1.4796, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 1.6085, batch time: 0.07, accuracy:  35.94%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 1.3558, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 1.5211, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 1.3466, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 1.4928, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 1.4799, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 2.04844069480896, accuracy: 28.8 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 1.6777896881103516, accuracy: 34.8 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 1.4559533596038818, accuracy: 45.8 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 1.450664758682251, accuracy: 45.6 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 1.4552277326583862, accuracy: 45.4 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 1.44601309299469, accuracy: 45.9 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 1.4496893882751465, accuracy: 46.1 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 1.4461195468902588, accuracy: 45.7 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 1.4430630207061768, accuracy: 46.2 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 1.4451700448989868, accuracy: 46.4 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 1.5305, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 1.4639, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 1.6789, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 1.6235, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 1.4640, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 1.3995, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 1.5311, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 1.4596, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 1.5617, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 1.5697, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 2.096137285232544, accuracy: 28.2 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 1.5706418752670288, accuracy: 42.3 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 1.5131069421768188, accuracy: 42.4 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 1.5494787693023682, accuracy: 41.2 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 1.5152716636657715, accuracy: 42.2 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 1.505805492401123, accuracy: 43.1 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 1.5080205202102661, accuracy: 42.8 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 1.5061277151107788, accuracy: 42.5 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 1.5046074390411377, accuracy: 42.3 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 1.5032094717025757, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 1.6341, batch time: 0.03, accuracy:  34.38%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 1.6234, batch time: 0.06, accuracy:  37.50%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 1.5810, batch time: 0.03, accuracy:  40.62%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 1.5124, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 1.5202, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 1.5121, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 1.6200, batch time: 0.11, accuracy:  40.62%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 1.4367, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 1.5560, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 1.4340, batch time: 0.04, accuracy:  47.66%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 2.2600252628326416, accuracy: 20.9 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 1.8515100479125977, accuracy: 30.5 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 1.4847294092178345, accuracy: 42.7 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 1.4816043376922607, accuracy: 43.0 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 1.4859129190444946, accuracy: 43.7 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 1.4988908767700195, accuracy: 43.0 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 1.4784873723983765, accuracy: 43.1 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 1.4771777391433716, accuracy: 43.1 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 1.4769463539123535, accuracy: 42.9 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 1.4776862859725952, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 1.3232, batch time: 0.03, accuracy:  53.91%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 1.5024, batch time: 0.08, accuracy:  40.62%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 1.5038, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 1.7476, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 1.4803, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 1.4522, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 1.5510, batch time: 0.04, accuracy:  46.09%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 1.4812, batch time: 0.12, accuracy:  46.09%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 1.3335, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 1.4135, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 2.0158894062042236, accuracy: 26.2 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 1.905788779258728, accuracy: 27.0 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 1.5158166885375977, accuracy: 42.3 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 1.8877627849578857, accuracy: 29.9 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 1.5265792608261108, accuracy: 41.6 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 1.5007209777832031, accuracy: 42.1 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 1.509528398513794, accuracy: 42.1 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 1.4925284385681152, accuracy: 42.7 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 1.4896395206451416, accuracy: 43.1 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 1.4943991899490356, accuracy: 43.3 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 1.4193, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 1.3752, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 1.6843, batch time: 0.07, accuracy:  33.59%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 1.5580, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 1.3501, batch time: 0.07, accuracy:  53.91%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 1.4537, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 1.6321, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 1.4138, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 1.5075, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 1.4906, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 2.0640268325805664, accuracy: 23.8 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 1.8625539541244507, accuracy: 30.6 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 1.4713679552078247, accuracy: 46.0 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 1.4678252935409546, accuracy: 45.2 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 1.4668744802474976, accuracy: 45.0 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 1.4643638134002686, accuracy: 45.9 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 1.4641956090927124, accuracy: 45.8 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 1.4632174968719482, accuracy: 46.2 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 1.466650128364563, accuracy: 45.3 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 1.4633466005325317, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 1.5149, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 1.3959, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 1.4137, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 1.4115, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 1.4124, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 1.5713, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 1.5293, batch time: 0.03, accuracy:  42.97%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 1.5364, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 1.6519, batch time: 0.03, accuracy:  42.19%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 1.3437, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 2.2688169479370117, accuracy: 19.0 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 1.9543650150299072, accuracy: 29.0 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 1.5426661968231201, accuracy: 41.9 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 1.533869743347168, accuracy: 41.2 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 1.5325589179992676, accuracy: 41.6 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 1.5287797451019287, accuracy: 41.7 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 1.5296818017959595, accuracy: 42.1 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 1.5387135744094849, accuracy: 41.3 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 1.5255095958709717, accuracy: 41.9 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 1.525281548500061, accuracy: 41.6 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 1.6106, batch time: 0.03, accuracy:  37.50%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 1.2911, batch time: 0.03, accuracy:  49.22%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 1.3101, batch time: 0.03, accuracy:  51.56%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 1.4247, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 1.4181, batch time: 0.03, accuracy:  50.00%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 1.3103, batch time: 0.03, accuracy:  46.88%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 1.5280, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 1.4618, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 1.4974, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 1.5523, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 2.074080228805542, accuracy: 20.9 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 1.9032334089279175, accuracy: 28.5 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 1.480130672454834, accuracy: 43.5 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 1.4845784902572632, accuracy: 42.5 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 1.4822560548782349, accuracy: 41.9 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 1.4733957052230835, accuracy: 42.9 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 1.4702743291854858, accuracy: 43.6 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 1.4697070121765137, accuracy: 43.2 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 1.468879222869873, accuracy: 43.3 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 1.468622088432312, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 1.5263, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 1.5954, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 1.4637, batch time: 0.03, accuracy:  47.66%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 1.6437, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 1.3863, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 1.5553, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 1.5073, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 1.3858, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 1.3234, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 1.5202, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 2.6080691814422607, accuracy: 13.0 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 1.92775297164917, accuracy: 29.9 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 1.5234073400497437, accuracy: 41.8 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 1.6718907356262207, accuracy: 35.0 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 1.5317083597183228, accuracy: 41.2 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 1.5277005434036255, accuracy: 41.0 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 1.5773379802703857, accuracy: 38.9 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 1.5527362823486328, accuracy: 40.3 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 1.5282087326049805, accuracy: 41.9 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 1.5047725439071655, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 1.4366, batch time: 0.07, accuracy:  48.44%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 1.6684, batch time: 0.07, accuracy:  37.50%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 1.5391, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 1.7415, batch time: 0.03, accuracy:  41.41%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 1.5961, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 1.5042, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 1.6601, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 1.5443, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 1.3551, batch time: 0.07, accuracy:  46.09%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 1.5550, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 2.6074295043945312, accuracy: 14.4 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 1.9381654262542725, accuracy: 30.2 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 1.50522780418396, accuracy: 44.5 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 1.5821428298950195, accuracy: 42.0 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 1.5005818605422974, accuracy: 43.4 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 1.4958280324935913, accuracy: 44.4 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 1.495047926902771, accuracy: 43.7 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 1.4915006160736084, accuracy: 44.2 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 1.4910163879394531, accuracy: 44.4 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 1.494313359260559, accuracy: 43.4 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 1.3146, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 1.7495, batch time: 0.03, accuracy:  35.94%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 1.5257, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 1.5568, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 1.2921, batch time: 0.07, accuracy:  51.56%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 1.5172, batch time: 0.08, accuracy:  47.66%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 1.5876, batch time: 0.08, accuracy:  35.16%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 1.4388, batch time: 0.08, accuracy:  50.00%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 1.5625, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 1.6899, batch time: 0.07, accuracy:  35.16%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 2.4447779655456543, accuracy: 17.5 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 1.8271344900131226, accuracy: 33.1 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 1.4497294425964355, accuracy: 47.2 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 1.4492782354354858, accuracy: 47.1 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 1.4503024816513062, accuracy: 47.7 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 1.4419151544570923, accuracy: 46.0 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 1.4837411642074585, accuracy: 43.0 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 1.4397739171981812, accuracy: 45.7 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 1.4394901990890503, accuracy: 46.2 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 1.4388047456741333, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 1.5054, batch time: 0.03, accuracy:  43.75%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 1.4048, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 1.5367, batch time: 0.08, accuracy:  37.50%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 1.2664, batch time: 0.07, accuracy:  50.78%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 1.5055, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 1.5732, batch time: 0.03, accuracy:  45.31%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 1.4460, batch time: 0.07, accuracy:  49.22%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 1.4915, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 1.5905, batch time: 0.07, accuracy:  36.72%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 1.6282, batch time: 0.04, accuracy:  40.62%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 2.6467316150665283, accuracy: 13.1 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 1.8130584955215454, accuracy: 29.8 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 1.5033456087112427, accuracy: 43.5 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 1.500200629234314, accuracy: 44.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 1.5011951923370361, accuracy: 43.3 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 1.5079774856567383, accuracy: 41.9 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 1.4959989786148071, accuracy: 42.8 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 1.4934136867523193, accuracy: 42.6 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 1.4927324056625366, accuracy: 42.8 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 1.4923714399337769, accuracy: 42.4 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 1.3531, batch time: 0.08, accuracy:  44.53%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 1.4483, batch time: 0.07, accuracy:  45.31%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 1.4293, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 1.5064, batch time: 0.07, accuracy:  42.97%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 1.4292, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 1.5760, batch time: 0.03, accuracy:  38.28%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 1.5234, batch time: 0.07, accuracy:  40.62%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 1.6870, batch time: 0.07, accuracy:  39.84%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 1.6377, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 1.3202, batch time: 0.07, accuracy:  50.00%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 2.4938085079193115, accuracy: 15.7 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 1.8284251689910889, accuracy: 30.8 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 1.543365716934204, accuracy: 41.2 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 1.5477356910705566, accuracy: 41.3 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 1.5466651916503906, accuracy: 41.3 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 1.5388257503509521, accuracy: 41.5 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 1.5586048364639282, accuracy: 41.7 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 1.53384268283844, accuracy: 41.9 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 1.5338170528411865, accuracy: 41.2 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 1.5328832864761353, accuracy: 41.6 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 1.4814, batch time: 0.07, accuracy:  42.19%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 1.3599, batch time: 0.07, accuracy:  46.88%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 1.5117, batch time: 0.06, accuracy:  48.44%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 1.4718, batch time: 0.03, accuracy:  39.84%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 1.4281, batch time: 0.03, accuracy:  44.53%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 1.5439, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 1.4308, batch time: 0.07, accuracy:  39.06%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 1.5078, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 1.5437, batch time: 0.04, accuracy:  34.38%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 1.3878, batch time: 0.04, accuracy:  44.53%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 2.595871686935425, accuracy: 13.7 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 1.7859669923782349, accuracy: 31.2 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 1.4995249509811401, accuracy: 43.6 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 1.4957176446914673, accuracy: 43.4 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 1.498430609703064, accuracy: 43.4 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 1.4915326833724976, accuracy: 44.0 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 1.4922990798950195, accuracy: 43.8 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 1.4898041486740112, accuracy: 44.2 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 1.489529013633728, accuracy: 44.2 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 1.4894274473190308, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 1.3234, batch time: 0.03, accuracy:  50.78%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 1.4300, batch time: 0.03, accuracy:  48.44%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 1.6155, batch time: 0.03, accuracy:  39.06%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 1.4933, batch time: 0.03, accuracy:  46.09%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 1.5455, batch time: 0.07, accuracy:  43.75%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 1.5253, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 1.4639, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 1.5050, batch time: 0.07, accuracy:  44.53%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 1.3465, batch time: 0.07, accuracy:  47.66%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 1.5578, batch time: 0.07, accuracy:  41.41%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 2.1716220378875732, accuracy: 18.3 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 1.7999486923217773, accuracy: 31.3 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 1.5068038702011108, accuracy: 43.1 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 1.6500194072723389, accuracy: 38.1 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 1.4976438283920288, accuracy: 44.5 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 1.4989688396453857, accuracy: 44.0 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 1.4925216436386108, accuracy: 44.4 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 1.4923186302185059, accuracy: 44.6 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 1.491825819015503, accuracy: 44.4 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 53.43%\n",
      "Loss on the train set: 1.34\n",
      "Accuracy on the test set: 51.83%\n",
      "Loss on the test set: 1.38\n",
      "Generalization error: 0.0387733\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
