{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 234, and embedding size = 1287\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"2400.0\" height=\"843.75\" viewBox=\"-35.0 0 1920.0 675.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,475.0 L25,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,525.0 L25,525.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,575.0 L25,575.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,625.0 L25,625.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.563493</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.600264</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.565916</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.788519</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.891894</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.161463</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.271441</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.780619</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.874534</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.473058</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.383907</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.648455</text>\n",
       "<path d=\"M25,425 L53,425 L72,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,444 L97,425 L125,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,475 L53,475 L72,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,456 L97,475 L125,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,443 L100,443 L100,457 L50,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.585367</text>\n",
       "<path d=\"M50,443 L100,443 L100,447 L50,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,450 L103,450 L103,460 L93,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,425 L175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,440 L139,440 L153,410 L144,410 L130,440 L139,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.441132</text>\n",
       "<path d=\"M125,475 L175,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,490 L139,490 L153,460 L144,460 L130,490 L139,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.865908</text>\n",
       "<path d=\"M25,525 L53,525 L72,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,544 L97,525 L125,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,575 L53,575 L72,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,556 L97,575 L125,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,543 L100,543 L100,557 L50,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.210889</text>\n",
       "<path d=\"M50,543 L100,543 L100,547 L50,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,550 L103,550 L103,560 L93,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,525 L175,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,540 L139,540 L153,510 L144,510 L130,540 L139,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.741305</text>\n",
       "<path d=\"M125,575 L175,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,590 L139,590 L153,560 L144,560 L130,590 L139,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.145195</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.21249</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.625908</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.882527</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.284039</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.596485</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.601382</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.477187</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.902479</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.866583</text>\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.995479</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.030073</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.718848</text>\n",
       "<path d=\"M175,475 L203,475 L222,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,494 L247,475 L275,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,525 L203,525 L222,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,506 L247,525 L275,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,493 L250,493 L250,507 L200,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.919581</text>\n",
       "<path d=\"M200,493 L250,493 L250,497 L200,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,500 L253,500 L253,510 L243,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,475 L325,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,490 L289,490 L303,460 L294,460 L280,490 L289,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.751602</text>\n",
       "<path d=\"M275,525 L325,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,540 L289,540 L303,510 L294,510 L280,540 L289,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.008323</text>\n",
       "<path d=\"M25,625.0 L175,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,575 L203,575 L222,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,594 L247,575 L275,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,625 L203,625 L222,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,606 L247,625 L275,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,593 L250,593 L250,607 L200,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.080999</text>\n",
       "<path d=\"M200,593 L250,593 L250,597 L200,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,600 L253,600 L253,610 L243,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,575 L325,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,590 L289,590 L303,560 L294,560 L280,590 L289,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.872342</text>\n",
       "<path d=\"M275,625 L325,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,640 L289,640 L303,610 L294,610 L280,640 L289,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.809124</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.504167</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.310731</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.846903</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.120627</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.149706</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.291668</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.457097</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.358476</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.515865</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.235959</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.913021</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.568127</text>\n",
       "<path d=\"M325,425 L353,425 L372,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,444 L397,425 L425,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,475 L353,475 L372,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,456 L397,475 L425,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,443 L400,443 L400,457 L350,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.294887</text>\n",
       "<path d=\"M350,443 L400,443 L400,447 L350,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,450 L403,450 L403,460 L393,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,425 L475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,440 L439,440 L453,410 L444,410 L430,440 L439,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.028597</text>\n",
       "<path d=\"M425,475 L475,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,490 L439,490 L453,460 L444,460 L430,490 L439,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.819025</text>\n",
       "<path d=\"M325,525 L353,525 L372,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,544 L397,525 L425,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,575 L353,575 L372,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,556 L397,575 L425,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,543 L400,543 L400,557 L350,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.798631</text>\n",
       "<path d=\"M350,543 L400,543 L400,547 L350,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,550 L403,550 L403,560 L393,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,525 L475,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,540 L439,540 L453,510 L444,510 L430,540 L439,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.495888</text>\n",
       "<path d=\"M425,575 L475,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,590 L439,590 L453,560 L444,560 L430,590 L439,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.344966</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.181044</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.814936</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.604254</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.085888</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.02686</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.803053</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.311273</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.057251</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.420181</text>\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.163166</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.306958</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.502604</text>\n",
       "<path d=\"M475,475 L503,475 L522,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,494 L547,475 L575,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,525 L503,525 L522,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,506 L547,525 L575,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,493 L550,493 L550,507 L500,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.64498</text>\n",
       "<path d=\"M500,493 L550,493 L550,497 L500,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,500 L553,500 L553,510 L543,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,475 L625,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,490 L589,490 L603,460 L594,460 L580,490 L589,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.059074</text>\n",
       "<path d=\"M575,525 L625,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,540 L589,540 L603,510 L594,510 L580,540 L589,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.669728</text>\n",
       "<path d=\"M325,625.0 L475,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,575 L503,575 L522,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,594 L547,575 L575,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,625 L503,625 L522,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,606 L547,625 L575,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,593 L550,593 L550,607 L500,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.8014</text>\n",
       "<path d=\"M500,593 L550,593 L550,597 L500,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,600 L553,600 L553,610 L543,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,575 L625,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,590 L589,590 L603,560 L594,560 L580,590 L589,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.123586</text>\n",
       "<path d=\"M575,625 L625,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,640 L589,640 L603,610 L594,610 L580,640 L589,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.171228</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.031349</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.802947</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.344742</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.550306</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.756227</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.647565</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.669696</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.510981</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.451077</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.473441</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.421235</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.997614</text>\n",
       "<path d=\"M625,425 L653,425 L672,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,444 L697,425 L725,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,475 L653,475 L672,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,456 L697,475 L725,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,443 L700,443 L700,457 L650,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.433074</text>\n",
       "<path d=\"M650,443 L700,443 L700,447 L650,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,450 L703,450 L703,460 L693,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,425 L775,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,440 L739,440 L753,410 L744,410 L730,440 L739,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.097466</text>\n",
       "<path d=\"M725,475 L775,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,490 L739,490 L753,460 L744,460 L730,490 L739,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.30283</text>\n",
       "<path d=\"M625,525 L653,525 L672,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,544 L697,525 L725,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,575 L653,575 L672,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,556 L697,575 L725,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,543 L700,543 L700,557 L650,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.585477</text>\n",
       "<path d=\"M650,543 L700,543 L700,547 L650,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,550 L703,550 L703,560 L693,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,525 L775,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,540 L739,540 L753,510 L744,510 L730,540 L739,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.618308</text>\n",
       "<path d=\"M725,575 L775,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,590 L739,590 L753,560 L744,560 L730,590 L739,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.91981</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.8623</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.503508</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.287942</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.390947</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.160039</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.85972</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.939868</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.445806</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.69865</text>\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.979322</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.059305</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.042802</text>\n",
       "<path d=\"M775,475 L803,475 L822,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,494 L847,475 L875,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,525 L803,525 L822,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,506 L847,525 L875,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,493 L850,493 L850,507 L800,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.185354</text>\n",
       "<path d=\"M800,493 L850,493 L850,497 L800,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,500 L853,500 L853,510 L843,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,475 L925,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,490 L889,490 L903,460 L894,460 L880,490 L889,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.654544</text>\n",
       "<path d=\"M875,525 L925,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,540 L889,540 L903,510 L894,510 L880,540 L889,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.773346</text>\n",
       "<path d=\"M625,625.0 L775,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,575 L803,575 L822,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,594 L847,575 L875,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,625 L803,625 L822,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,606 L847,625 L875,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,593 L850,593 L850,607 L800,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.475565</text>\n",
       "<path d=\"M800,593 L850,593 L850,597 L800,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,600 L853,600 L853,610 L843,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,575 L925,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,590 L889,590 L903,560 L894,560 L880,590 L889,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.979588</text>\n",
       "<path d=\"M875,625 L925,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,640 L889,640 L903,610 L894,610 L880,640 L889,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.211121</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.265047</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.610953</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.194404</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.687599</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.60139</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.97579</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.425522</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.185145</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.069487</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.649773</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.643548</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.190894</text>\n",
       "<path d=\"M925,425 L953,425 L972,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,444 L997,425 L1025,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,475 L953,475 L972,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,456 L997,475 L1025,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,443 L1000,443 L1000,457 L950,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.552758</text>\n",
       "<path d=\"M950,443 L1000,443 L1000,447 L950,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,450 L1003,450 L1003,460 L993,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,425 L1075,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,440 L1039,440 L1053,410 L1044,410 L1030,440 L1039,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.253928</text>\n",
       "<path d=\"M1025,475 L1075,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,490 L1039,490 L1053,460 L1044,460 L1030,490 L1039,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.234432</text>\n",
       "<path d=\"M925,525 L953,525 L972,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,544 L997,525 L1025,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,575 L953,575 L972,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,556 L997,575 L1025,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,543 L1000,543 L1000,557 L950,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.839293</text>\n",
       "<path d=\"M950,543 L1000,543 L1000,547 L950,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,550 L1003,550 L1003,560 L993,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,525 L1075,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,540 L1039,540 L1053,510 L1044,510 L1030,540 L1039,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.075038</text>\n",
       "<path d=\"M1025,575 L1075,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,590 L1039,590 L1053,560 L1044,560 L1030,590 L1039,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.693393</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.966131</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.383776</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.944519</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.044044</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.415852</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.316</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.384887</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.719162</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.191907</text>\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.788489</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.716897</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.931009</text>\n",
       "<path d=\"M1075,475 L1103,475 L1122,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,494 L1147,475 L1175,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,525 L1103,525 L1122,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,506 L1147,525 L1175,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,493 L1150,493 L1150,507 L1100,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.746419</text>\n",
       "<path d=\"M1100,493 L1150,493 L1150,497 L1100,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,500 L1153,500 L1153,510 L1143,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,475 L1225,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,490 L1189,490 L1203,460 L1194,460 L1180,490 L1189,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.708178</text>\n",
       "<path d=\"M1175,525 L1225,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,540 L1189,540 L1203,510 L1194,510 L1180,540 L1189,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.096745</text>\n",
       "<path d=\"M925,625.0 L1075,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,575 L1103,575 L1122,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,594 L1147,575 L1175,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,625 L1103,625 L1122,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,606 L1147,625 L1175,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,593 L1150,593 L1150,607 L1100,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.248696</text>\n",
       "<path d=\"M1100,593 L1150,593 L1150,597 L1100,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,600 L1153,600 L1153,610 L1143,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,575 L1225,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,590 L1189,590 L1203,560 L1194,560 L1180,590 L1189,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.603194</text>\n",
       "<path d=\"M1175,625 L1225,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,640 L1189,640 L1203,610 L1194,610 L1180,640 L1189,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.598771</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25 L1253,25 L1272,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,44 L1297,25 L1325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,75 L1253,75 L1272,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,56 L1297,75 L1325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,43 L1300,43 L1300,57 L1250,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.802169</text>\n",
       "<path d=\"M1250,43 L1300,43 L1300,47 L1250,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,50 L1303,50 L1303,60 L1293,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,25 L1375,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,40 L1339,40 L1353,10 L1344,10 L1330,40 L1339,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.582138</text>\n",
       "<path d=\"M1325,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,90 L1339,90 L1353,60 L1344,60 L1330,90 L1339,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.924259</text>\n",
       "<path d=\"M1225,125 L1253,125 L1272,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,144 L1297,125 L1325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,175 L1253,175 L1272,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,156 L1297,175 L1325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,143 L1300,143 L1300,157 L1250,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.569334</text>\n",
       "<path d=\"M1250,143 L1300,143 L1300,147 L1250,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,150 L1303,150 L1303,160 L1293,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,140 L1339,140 L1353,110 L1344,110 L1330,140 L1339,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.149784</text>\n",
       "<path d=\"M1325,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,190 L1339,190 L1353,160 L1344,160 L1330,190 L1339,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.099496</text>\n",
       "<path d=\"M1225,225 L1253,225 L1272,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,244 L1297,225 L1325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,275 L1253,275 L1272,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,256 L1297,275 L1325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,243 L1300,243 L1300,257 L1250,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.283992</text>\n",
       "<path d=\"M1250,243 L1300,243 L1300,247 L1250,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,250 L1303,250 L1303,260 L1293,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,240 L1339,240 L1353,210 L1344,210 L1330,240 L1339,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.886696</text>\n",
       "<path d=\"M1325,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,290 L1339,290 L1353,260 L1344,260 L1330,290 L1339,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.604334</text>\n",
       "<path d=\"M1225,325 L1253,325 L1272,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,344 L1297,325 L1325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,375 L1253,375 L1272,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,356 L1297,375 L1325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,343 L1300,343 L1300,357 L1250,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.013075</text>\n",
       "<path d=\"M1250,343 L1300,343 L1300,347 L1250,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,350 L1303,350 L1303,360 L1293,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,340 L1339,340 L1353,310 L1344,310 L1330,340 L1339,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.964948</text>\n",
       "<path d=\"M1325,375 L1375,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,390 L1339,390 L1353,360 L1344,360 L1330,390 L1339,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.734148</text>\n",
       "<path d=\"M1225,425 L1253,425 L1272,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,444 L1297,425 L1325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,475 L1253,475 L1272,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,456 L1297,475 L1325,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,443 L1300,443 L1300,457 L1250,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.412308</text>\n",
       "<path d=\"M1250,443 L1300,443 L1300,447 L1250,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,450 L1303,450 L1303,460 L1293,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,425 L1375,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,440 L1339,440 L1353,410 L1344,410 L1330,440 L1339,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.158903</text>\n",
       "<path d=\"M1325,475 L1375,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,490 L1339,490 L1353,460 L1344,460 L1330,490 L1339,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.932346</text>\n",
       "<path d=\"M1225,525 L1253,525 L1272,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,544 L1297,525 L1325,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,575 L1253,575 L1272,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,556 L1297,575 L1325,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,543 L1300,543 L1300,557 L1250,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.218106</text>\n",
       "<path d=\"M1250,543 L1300,543 L1300,547 L1250,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,550 L1303,550 L1303,560 L1293,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,525 L1375,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,540 L1339,540 L1353,510 L1344,510 L1330,540 L1339,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.834534</text>\n",
       "<path d=\"M1325,575 L1375,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,590 L1339,590 L1353,560 L1344,560 L1330,590 L1339,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.533735</text>\n",
       "<path d=\"M1375,75 L1403,75 L1422,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,94 L1447,75 L1475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,125 L1403,125 L1422,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,106 L1447,125 L1475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,93 L1450,93 L1450,107 L1400,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.76237</text>\n",
       "<path d=\"M1400,93 L1450,93 L1450,97 L1400,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,100 L1453,100 L1453,110 L1443,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,75 L1525,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,90 L1489,90 L1503,60 L1494,60 L1480,90 L1489,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.791803</text>\n",
       "<path d=\"M1475,125 L1525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,140 L1489,140 L1503,110 L1494,110 L1480,140 L1489,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.651697</text>\n",
       "<path d=\"M1375,175 L1403,175 L1422,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,194 L1447,175 L1475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,225 L1403,225 L1422,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,206 L1447,225 L1475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,193 L1450,193 L1450,207 L1400,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.813456</text>\n",
       "<path d=\"M1400,193 L1450,193 L1450,197 L1400,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,200 L1453,200 L1453,210 L1443,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,175 L1525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,190 L1489,190 L1503,160 L1494,160 L1480,190 L1489,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.122204</text>\n",
       "<path d=\"M1475,225 L1525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,240 L1489,240 L1503,210 L1494,210 L1480,240 L1489,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.011783</text>\n",
       "<path d=\"M1375,275 L1403,275 L1422,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,294 L1447,275 L1475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,325 L1403,325 L1422,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,306 L1447,325 L1475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,293 L1450,293 L1450,307 L1400,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.761211</text>\n",
       "<path d=\"M1400,293 L1450,293 L1450,297 L1400,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,300 L1453,300 L1453,310 L1443,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,275 L1525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,290 L1489,290 L1503,260 L1494,260 L1480,290 L1489,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.401314</text>\n",
       "<path d=\"M1475,325 L1525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,340 L1489,340 L1503,310 L1494,310 L1480,340 L1489,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.322043</text>\n",
       "<path d=\"M1375,375 L1403,375 L1422,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,394 L1447,375 L1475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,425 L1403,425 L1422,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,406 L1447,425 L1475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,393 L1450,393 L1450,407 L1400,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.279013</text>\n",
       "<path d=\"M1400,393 L1450,393 L1450,397 L1400,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,400 L1453,400 L1453,410 L1443,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,375 L1525,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,390 L1489,390 L1503,360 L1494,360 L1480,390 L1489,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.418553</text>\n",
       "<path d=\"M1475,425 L1525,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,440 L1489,440 L1503,410 L1494,410 L1480,440 L1489,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.024764</text>\n",
       "<path d=\"M1375,475 L1403,475 L1422,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,494 L1447,475 L1475,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,525 L1403,525 L1422,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,506 L1447,525 L1475,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,493 L1450,493 L1450,507 L1400,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.304203</text>\n",
       "<path d=\"M1400,493 L1450,493 L1450,497 L1400,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,500 L1453,500 L1453,510 L1443,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,475 L1525,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,490 L1489,490 L1503,460 L1494,460 L1480,490 L1489,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.265404</text>\n",
       "<path d=\"M1475,525 L1525,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,540 L1489,540 L1503,510 L1494,510 L1480,540 L1489,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.651693</text>\n",
       "<path d=\"M1225,625.0 L1375,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,575 L1403,575 L1422,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,594 L1447,575 L1475,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,625 L1403,625 L1422,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,606 L1447,625 L1475,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,593 L1450,593 L1450,607 L1400,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.245983</text>\n",
       "<path d=\"M1400,593 L1450,593 L1450,597 L1400,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,600 L1453,600 L1453,610 L1443,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,575 L1525,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,590 L1489,590 L1503,560 L1494,560 L1480,590 L1489,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.874528</text>\n",
       "<path d=\"M1475,625 L1525,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,640 L1489,640 L1503,610 L1494,610 L1480,640 L1489,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.399396</text>\n",
       "<path d=\"M1375,25.0 L1525,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,25 L1553,25 L1572,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,44 L1597,25 L1625,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,75 L1553,75 L1572,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,56 L1597,75 L1625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,43 L1600,43 L1600,57 L1550,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.356807</text>\n",
       "<path d=\"M1550,43 L1600,43 L1600,47 L1550,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,50 L1603,50 L1603,60 L1593,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,25 L1675,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,40 L1639,40 L1653,10 L1644,10 L1630,40 L1639,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.165946</text>\n",
       "<path d=\"M1625,75 L1675,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,90 L1639,90 L1653,60 L1644,60 L1630,90 L1639,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.959709</text>\n",
       "<path d=\"M1525,125 L1553,125 L1572,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,144 L1597,125 L1625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,175 L1553,175 L1572,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,156 L1597,175 L1625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,143 L1600,143 L1600,157 L1550,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.315687</text>\n",
       "<path d=\"M1550,143 L1600,143 L1600,147 L1550,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,150 L1603,150 L1603,160 L1593,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,125 L1675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,140 L1639,140 L1653,110 L1644,110 L1630,140 L1639,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.221416</text>\n",
       "<path d=\"M1625,175 L1675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,190 L1639,190 L1653,160 L1644,160 L1630,190 L1639,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.892103</text>\n",
       "<path d=\"M1525,225 L1553,225 L1572,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,244 L1597,225 L1625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,275 L1553,275 L1572,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,256 L1597,275 L1625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,243 L1600,243 L1600,257 L1550,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.449965</text>\n",
       "<path d=\"M1550,243 L1600,243 L1600,247 L1550,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,250 L1603,250 L1603,260 L1593,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,225 L1675,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,240 L1639,240 L1653,210 L1644,210 L1630,240 L1639,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.655822</text>\n",
       "<path d=\"M1625,275 L1675,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,290 L1639,290 L1653,260 L1644,260 L1630,290 L1639,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.345748</text>\n",
       "<path d=\"M1525,325 L1553,325 L1572,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,344 L1597,325 L1625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,375 L1553,375 L1572,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,356 L1597,375 L1625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,343 L1600,343 L1600,357 L1550,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.09435</text>\n",
       "<path d=\"M1550,343 L1600,343 L1600,347 L1550,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,350 L1603,350 L1603,360 L1593,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,325 L1675,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,340 L1639,340 L1653,310 L1644,310 L1630,340 L1639,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.180557</text>\n",
       "<path d=\"M1625,375 L1675,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,390 L1639,390 L1653,360 L1644,360 L1630,390 L1639,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.707859</text>\n",
       "<path d=\"M1525,425 L1553,425 L1572,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,444 L1597,425 L1625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,475 L1553,475 L1572,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,456 L1597,475 L1625,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,443 L1600,443 L1600,457 L1550,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.999786</text>\n",
       "<path d=\"M1550,443 L1600,443 L1600,447 L1550,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,450 L1603,450 L1603,460 L1593,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,425 L1675,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,440 L1639,440 L1653,410 L1644,410 L1630,440 L1639,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.351647</text>\n",
       "<path d=\"M1625,475 L1675,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,490 L1639,490 L1653,460 L1644,460 L1630,490 L1639,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.50027</text>\n",
       "<path d=\"M1525,525 L1553,525 L1572,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,544 L1597,525 L1625,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,575 L1553,575 L1572,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,556 L1597,575 L1625,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,543 L1600,543 L1600,557 L1550,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.520729</text>\n",
       "<path d=\"M1550,543 L1600,543 L1600,547 L1550,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,550 L1603,550 L1603,560 L1593,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,525 L1675,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,540 L1639,540 L1653,510 L1644,510 L1630,540 L1639,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.369925</text>\n",
       "<path d=\"M1625,575 L1675,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,590 L1639,590 L1653,560 L1644,560 L1630,590 L1639,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.96426</text>\n",
       "<path d=\"M1675,75 L1703,75 L1722,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,94 L1747,75 L1775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,125 L1703,125 L1722,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,106 L1747,125 L1775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,93 L1750,93 L1750,107 L1700,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.376888</text>\n",
       "<path d=\"M1700,93 L1750,93 L1750,97 L1700,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,100 L1753,100 L1753,110 L1743,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,75 L1825,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,90 L1789,90 L1803,60 L1794,60 L1780,90 L1789,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.379999</text>\n",
       "<path d=\"M1775,125 L1825,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,140 L1789,140 L1803,110 L1794,110 L1780,140 L1789,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.727723</text>\n",
       "<path d=\"M1675,175 L1703,175 L1722,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,194 L1747,175 L1775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,225 L1703,225 L1722,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,206 L1747,225 L1775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,193 L1750,193 L1750,207 L1700,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.59358</text>\n",
       "<path d=\"M1700,193 L1750,193 L1750,197 L1700,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,200 L1753,200 L1753,210 L1743,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,175 L1825,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,190 L1789,190 L1803,160 L1794,160 L1780,190 L1789,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.499848</text>\n",
       "<path d=\"M1775,225 L1825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,240 L1789,240 L1803,210 L1794,210 L1780,240 L1789,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.95868</text>\n",
       "<path d=\"M1675,275 L1703,275 L1722,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,294 L1747,275 L1775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,325 L1703,325 L1722,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,306 L1747,325 L1775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,293 L1750,293 L1750,307 L1700,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.719102</text>\n",
       "<path d=\"M1700,293 L1750,293 L1750,297 L1700,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,300 L1753,300 L1753,310 L1743,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,275 L1825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,290 L1789,290 L1803,260 L1794,260 L1780,290 L1789,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.073718</text>\n",
       "<path d=\"M1775,325 L1825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,340 L1789,340 L1803,310 L1794,310 L1780,340 L1789,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.56181</text>\n",
       "<path d=\"M1675,375 L1703,375 L1722,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,394 L1747,375 L1775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,425 L1703,425 L1722,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,406 L1747,425 L1775,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,393 L1750,393 L1750,407 L1700,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.064013</text>\n",
       "<path d=\"M1700,393 L1750,393 L1750,397 L1700,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,400 L1753,400 L1753,410 L1743,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,375 L1825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,390 L1789,390 L1803,360 L1794,360 L1780,390 L1789,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.10991</text>\n",
       "<path d=\"M1775,425 L1825,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,440 L1789,440 L1803,410 L1794,410 L1780,440 L1789,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.678605</text>\n",
       "<path d=\"M1675,475 L1703,475 L1722,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,494 L1747,475 L1775,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,525 L1703,525 L1722,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,506 L1747,525 L1775,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,493 L1750,493 L1750,507 L1700,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.038817</text>\n",
       "<path d=\"M1700,493 L1750,493 L1750,497 L1700,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,500 L1753,500 L1753,510 L1743,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,475 L1825,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,490 L1789,490 L1803,460 L1794,460 L1780,490 L1789,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.020565</text>\n",
       "<path d=\"M1775,525 L1825,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,540 L1789,540 L1803,510 L1794,510 L1780,540 L1789,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.346841</text>\n",
       "<path d=\"M1525,625.0 L1675,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,575 L1703,575 L1722,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,594 L1747,575 L1775,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,625 L1703,625 L1722,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,606 L1747,625 L1775,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,593 L1750,593 L1750,607 L1700,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.110075</text>\n",
       "<path d=\"M1700,593 L1750,593 L1750,597 L1700,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,600 L1753,600 L1753,610 L1743,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,575 L1825,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,590 L1789,590 L1803,560 L1794,560 L1780,590 L1789,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.047491</text>\n",
       "<path d=\"M1775,625 L1825,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,640 L1789,640 L1803,610 L1794,610 L1780,640 L1789,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.253014</text>\n",
       "<path d=\"M1675,25.0 L1825,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1825,25.0 L1840,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,75.0 L1840,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,125.0 L1840,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,175.0 L1840,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,225.0 L1840,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,275.0 L1840,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,325.0 L1840,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,375.0 L1840,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,425.0 L1840,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,475.0 L1840,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,525.0 L1840,525.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,575.0 L1840,575.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,625.0 L1840,625.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1850\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1850\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1850\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1850\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1850\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1850\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1850\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1850\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1850\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"1850\" y=\"478.0\" font-size=\"10\" text-anchor=\"end\">9</text>\n",
       "<text x=\"1850\" y=\"528.0\" font-size=\"10\" text-anchor=\"end\">10</text>\n",
       "<text x=\"1850\" y=\"578.0\" font-size=\"10\" text-anchor=\"end\">11</text>\n",
       "<text x=\"1850\" y=\"628.0\" font-size=\"10\" text-anchor=\"end\">12</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "<text x=\"0\" y=\"478.0\" font-size=\"10\" text-anchor=\"start\">9</text>\n",
       "<text x=\"0\" y=\"528.0\" font-size=\"10\" text-anchor=\"start\">10</text>\n",
       "<text x=\"0\" y=\"578.0\" font-size=\"10\" text-anchor=\"start\">11</text>\n",
       "<text x=\"0\" y=\"628.0\" font-size=\"10\" text-anchor=\"start\">12</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x70a07b8b7040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs = BosonSampler(m = 13, n = 5, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(165)\n",
    "# res = bs.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(4*4*4, 10)\n",
    "        # self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        # x = self.fc2(x)\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "    #     self.fc1 = nn.Linear(12*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  978\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 43.50%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  978\n",
      "Required qubit number:  10\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [20, 4], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params = qnn_parameters#nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "\n",
    "        device = x.device\n",
    "        res = bs.run(\n",
    "            parameters=self.q_params,\n",
    "            samples=100000\n",
    "        )\n",
    "\n",
    "        trans_res = bs.translate_results(res = res)\n",
    "        trans_res = trans_res/torch.mean(trans_res)\n",
    "        probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # # Fully connected layer 2 parameters\n",
    "        # fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        # fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # # Fully connected 2\n",
    "        # x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  329\n",
      "# of trainable parameter in QNN model:  234\n",
      "# of trainable parameter in full model:  563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(234)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/100], Epoch [1/5], Step [20/47], Loss: 2.3958, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [1/100], Epoch [1/5], Step [40/47], Loss: 2.3328, batch time: 0.09, accuracy:  12.50%\n",
      "Training round [1/100], Epoch [2/5], Step [20/47], Loss: 2.3203, batch time: 0.09, accuracy:  10.94%\n",
      "Training round [1/100], Epoch [2/5], Step [40/47], Loss: 2.3145, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [1/100], Epoch [3/5], Step [20/47], Loss: 2.3070, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [1/100], Epoch [3/5], Step [40/47], Loss: 2.2788, batch time: 0.09, accuracy:  14.84%\n",
      "Training round [1/100], Epoch [4/5], Step [20/47], Loss: 2.2800, batch time: 0.09, accuracy:  8.59%\n",
      "Training round [1/100], Epoch [4/5], Step [40/47], Loss: 2.2641, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [1/100], Epoch [5/5], Step [20/47], Loss: 2.2533, batch time: 0.09, accuracy:  14.06%\n",
      "Training round [1/100], Epoch [5/5], Step [40/47], Loss: 2.2425, batch time: 0.09, accuracy:  11.72%\n",
      "Training round [1/100], qnn_train_step: [100/500], loss: 2.231102705001831, accuracy: 14.7 %\n",
      "Training round [1/100], qnn_train_step: [200/500], loss: 2.203002452850342, accuracy: 16.4 %\n",
      "Training round [1/100], qnn_train_step: [300/500], loss: 2.197854995727539, accuracy: 15.4 %\n",
      "Training round [1/100], qnn_train_step: [400/500], loss: 2.213189125061035, accuracy: 17.3 %\n",
      "Training round [1/100], qnn_train_step: [500/500], loss: 2.177407741546631, accuracy: 19.3 %\n",
      "-----------------------\n",
      "Training round [2/100], Epoch [1/5], Step [20/47], Loss: 2.1649, batch time: 0.09, accuracy:  15.62%\n",
      "Training round [2/100], Epoch [1/5], Step [40/47], Loss: 2.0507, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [2/100], Epoch [2/5], Step [20/47], Loss: 2.1002, batch time: 0.09, accuracy:  24.22%\n",
      "Training round [2/100], Epoch [2/5], Step [40/47], Loss: 2.1307, batch time: 0.09, accuracy:  21.09%\n",
      "Training round [2/100], Epoch [3/5], Step [20/47], Loss: 2.0306, batch time: 0.09, accuracy:  29.69%\n",
      "Training round [2/100], Epoch [3/5], Step [40/47], Loss: 2.1011, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [2/100], Epoch [4/5], Step [20/47], Loss: 2.1706, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [2/100], Epoch [4/5], Step [40/47], Loss: 1.9831, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [2/100], Epoch [5/5], Step [20/47], Loss: 2.0926, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [2/100], Epoch [5/5], Step [40/47], Loss: 1.9914, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [2/100], qnn_train_step: [100/500], loss: 2.0449893474578857, accuracy: 26.9 %\n",
      "Training round [2/100], qnn_train_step: [200/500], loss: 4.256991386413574, accuracy: 13.3 %\n",
      "Training round [2/100], qnn_train_step: [300/500], loss: 2.1238386631011963, accuracy: 18.5 %\n",
      "Training round [2/100], qnn_train_step: [400/500], loss: 2.5001139640808105, accuracy: 22.8 %\n",
      "Training round [2/100], qnn_train_step: [500/500], loss: 2.0104188919067383, accuracy: 29.6 %\n",
      "-----------------------\n",
      "Training round [3/100], Epoch [1/5], Step [20/47], Loss: 1.8523, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [3/100], Epoch [1/5], Step [40/47], Loss: 2.0272, batch time: 0.09, accuracy:  25.78%\n",
      "Training round [3/100], Epoch [2/5], Step [20/47], Loss: 1.9811, batch time: 0.09, accuracy:  25.00%\n",
      "Training round [3/100], Epoch [2/5], Step [40/47], Loss: 1.8704, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [3/100], Epoch [3/5], Step [20/47], Loss: 1.9736, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [3/100], Epoch [3/5], Step [40/47], Loss: 1.8938, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [3/100], Epoch [4/5], Step [20/47], Loss: 1.9152, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [3/100], Epoch [4/5], Step [40/47], Loss: 2.0035, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [3/100], Epoch [5/5], Step [20/47], Loss: 1.9145, batch time: 0.09, accuracy:  31.25%\n",
      "Training round [3/100], Epoch [5/5], Step [40/47], Loss: 2.0260, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [3/100], qnn_train_step: [100/500], loss: 1.998405933380127, accuracy: 30.7 %\n",
      "Training round [3/100], qnn_train_step: [200/500], loss: 4.75255012512207, accuracy: 12.2 %\n",
      "Training round [3/100], qnn_train_step: [300/500], loss: 1.8838677406311035, accuracy: 32.9 %\n",
      "Training round [3/100], qnn_train_step: [400/500], loss: 1.8484011888504028, accuracy: 34.0 %\n",
      "Training round [3/100], qnn_train_step: [500/500], loss: 1.846619963645935, accuracy: 32.2 %\n",
      "-----------------------\n",
      "Training round [4/100], Epoch [1/5], Step [20/47], Loss: 1.8565, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [4/100], Epoch [1/5], Step [40/47], Loss: 2.0059, batch time: 0.13, accuracy:  32.03%\n",
      "Training round [4/100], Epoch [2/5], Step [20/47], Loss: 1.8950, batch time: 0.11, accuracy:  32.81%\n",
      "Training round [4/100], Epoch [2/5], Step [40/47], Loss: 1.8998, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [4/100], Epoch [3/5], Step [20/47], Loss: 1.8153, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [4/100], Epoch [3/5], Step [40/47], Loss: 1.9814, batch time: 0.28, accuracy:  30.47%\n",
      "Training round [4/100], Epoch [4/5], Step [20/47], Loss: 1.8959, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [4/100], Epoch [4/5], Step [40/47], Loss: 1.7926, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [4/100], Epoch [5/5], Step [20/47], Loss: 1.8138, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [4/100], Epoch [5/5], Step [40/47], Loss: 1.7823, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [4/100], qnn_train_step: [100/500], loss: 1.9948973655700684, accuracy: 34.6 %\n",
      "Training round [4/100], qnn_train_step: [200/500], loss: 2.6166739463806152, accuracy: 20.4 %\n",
      "Training round [4/100], qnn_train_step: [300/500], loss: 2.17624568939209, accuracy: 23.6 %\n",
      "Training round [4/100], qnn_train_step: [400/500], loss: 7.339321136474609, accuracy: 11.2 %\n",
      "Training round [4/100], qnn_train_step: [500/500], loss: 1.8627749681472778, accuracy: 36.5 %\n",
      "-----------------------\n",
      "Training round [5/100], Epoch [1/5], Step [20/47], Loss: 1.8704, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [5/100], Epoch [1/5], Step [40/47], Loss: 1.6788, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [5/100], Epoch [2/5], Step [20/47], Loss: 2.0105, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [5/100], Epoch [2/5], Step [40/47], Loss: 1.8725, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [5/100], Epoch [3/5], Step [20/47], Loss: 1.8670, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [5/100], Epoch [3/5], Step [40/47], Loss: 1.7180, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [5/100], Epoch [4/5], Step [20/47], Loss: 1.7045, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [5/100], Epoch [4/5], Step [40/47], Loss: 1.8050, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [5/100], Epoch [5/5], Step [20/47], Loss: 1.8716, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [5/100], Epoch [5/5], Step [40/47], Loss: 1.8426, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [5/100], qnn_train_step: [100/500], loss: 2.0864298343658447, accuracy: 30.5 %\n",
      "Training round [5/100], qnn_train_step: [200/500], loss: 2.0789034366607666, accuracy: 27.6 %\n",
      "Training round [5/100], qnn_train_step: [300/500], loss: 1.7805606126785278, accuracy: 42.1 %\n",
      "Training round [5/100], qnn_train_step: [400/500], loss: 1.7661315202713013, accuracy: 42.4 %\n",
      "Training round [5/100], qnn_train_step: [500/500], loss: 1.75758695602417, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [6/100], Epoch [1/5], Step [20/47], Loss: 1.7415, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [6/100], Epoch [1/5], Step [40/47], Loss: 1.8570, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [6/100], Epoch [2/5], Step [20/47], Loss: 1.7852, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [6/100], Epoch [2/5], Step [40/47], Loss: 1.8742, batch time: 0.21, accuracy:  37.50%\n",
      "Training round [6/100], Epoch [3/5], Step [20/47], Loss: 1.8367, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [6/100], Epoch [3/5], Step [40/47], Loss: 1.9203, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [6/100], Epoch [4/5], Step [20/47], Loss: 1.7294, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [6/100], Epoch [4/5], Step [40/47], Loss: 1.7093, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [6/100], Epoch [5/5], Step [20/47], Loss: 2.0002, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [6/100], Epoch [5/5], Step [40/47], Loss: 1.8961, batch time: 0.12, accuracy:  42.19%\n",
      "Training round [6/100], qnn_train_step: [100/500], loss: 2.1379623413085938, accuracy: 31.0 %\n",
      "Training round [6/100], qnn_train_step: [200/500], loss: 2.6398606300354004, accuracy: 23.3 %\n",
      "Training round [6/100], qnn_train_step: [300/500], loss: 1.8205535411834717, accuracy: 39.3 %\n",
      "Training round [6/100], qnn_train_step: [400/500], loss: 1.7831238508224487, accuracy: 41.3 %\n",
      "Training round [6/100], qnn_train_step: [500/500], loss: 1.7722207307815552, accuracy: 40.4 %\n",
      "-----------------------\n",
      "Training round [7/100], Epoch [1/5], Step [20/47], Loss: 1.8278, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [7/100], Epoch [1/5], Step [40/47], Loss: 1.8081, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [7/100], Epoch [2/5], Step [20/47], Loss: 1.8937, batch time: 0.10, accuracy:  32.81%\n",
      "Training round [7/100], Epoch [2/5], Step [40/47], Loss: 1.6811, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [7/100], Epoch [3/5], Step [20/47], Loss: 1.8294, batch time: 0.12, accuracy:  37.50%\n",
      "Training round [7/100], Epoch [3/5], Step [40/47], Loss: 1.6815, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [7/100], Epoch [4/5], Step [20/47], Loss: 1.7698, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [7/100], Epoch [4/5], Step [40/47], Loss: 1.9377, batch time: 0.28, accuracy:  35.16%\n",
      "Training round [7/100], Epoch [5/5], Step [20/47], Loss: 1.8265, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [7/100], Epoch [5/5], Step [40/47], Loss: 1.7056, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [7/100], qnn_train_step: [100/500], loss: 2.1429502964019775, accuracy: 32.1 %\n",
      "Training round [7/100], qnn_train_step: [200/500], loss: 1.929365873336792, accuracy: 33.1 %\n",
      "Training round [7/100], qnn_train_step: [300/500], loss: 2.2202534675598145, accuracy: 27.4 %\n",
      "Training round [7/100], qnn_train_step: [400/500], loss: 8.032292366027832, accuracy: 11.1 %\n",
      "Training round [7/100], qnn_train_step: [500/500], loss: 1.7950985431671143, accuracy: 41.5 %\n",
      "-----------------------\n",
      "Training round [8/100], Epoch [1/5], Step [20/47], Loss: 1.8090, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [8/100], Epoch [1/5], Step [40/47], Loss: 1.7865, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [8/100], Epoch [2/5], Step [20/47], Loss: 1.7513, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [8/100], Epoch [2/5], Step [40/47], Loss: 1.9147, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [8/100], Epoch [3/5], Step [20/47], Loss: 1.6697, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [8/100], Epoch [3/5], Step [40/47], Loss: 1.6204, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [8/100], Epoch [4/5], Step [20/47], Loss: 1.7494, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [8/100], Epoch [4/5], Step [40/47], Loss: 1.7426, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [8/100], Epoch [5/5], Step [20/47], Loss: 1.6466, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [8/100], Epoch [5/5], Step [40/47], Loss: 1.7458, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [8/100], qnn_train_step: [100/500], loss: 2.115800380706787, accuracy: 31.3 %\n",
      "Training round [8/100], qnn_train_step: [200/500], loss: 1.8356503248214722, accuracy: 35.9 %\n",
      "Training round [8/100], qnn_train_step: [300/500], loss: 1.763843297958374, accuracy: 38.2 %\n",
      "Training round [8/100], qnn_train_step: [400/500], loss: 1.731394648551941, accuracy: 38.8 %\n",
      "Training round [8/100], qnn_train_step: [500/500], loss: 1.7475770711898804, accuracy: 38.4 %\n",
      "-----------------------\n",
      "Training round [9/100], Epoch [1/5], Step [20/47], Loss: 1.7366, batch time: 0.29, accuracy:  46.09%\n",
      "Training round [9/100], Epoch [1/5], Step [40/47], Loss: 1.5284, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [9/100], Epoch [2/5], Step [20/47], Loss: 1.6980, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [9/100], Epoch [2/5], Step [40/47], Loss: 1.7755, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [9/100], Epoch [3/5], Step [20/47], Loss: 1.7492, batch time: 0.25, accuracy:  42.97%\n",
      "Training round [9/100], Epoch [3/5], Step [40/47], Loss: 1.8055, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [9/100], Epoch [4/5], Step [20/47], Loss: 1.5677, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [9/100], Epoch [4/5], Step [40/47], Loss: 1.7490, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [9/100], Epoch [5/5], Step [20/47], Loss: 1.6978, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [9/100], Epoch [5/5], Step [40/47], Loss: 1.8106, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [9/100], qnn_train_step: [100/500], loss: 2.053980588912964, accuracy: 33.6 %\n",
      "Training round [9/100], qnn_train_step: [200/500], loss: 1.8419965505599976, accuracy: 37.1 %\n",
      "Training round [9/100], qnn_train_step: [300/500], loss: 1.7285535335540771, accuracy: 40.8 %\n",
      "Training round [9/100], qnn_train_step: [400/500], loss: 1.7087657451629639, accuracy: 43.6 %\n",
      "Training round [9/100], qnn_train_step: [500/500], loss: 1.698093056678772, accuracy: 42.8 %\n",
      "-----------------------\n",
      "Training round [10/100], Epoch [1/5], Step [20/47], Loss: 1.9489, batch time: 0.10, accuracy:  31.25%\n",
      "Training round [10/100], Epoch [1/5], Step [40/47], Loss: 1.8534, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [10/100], Epoch [2/5], Step [20/47], Loss: 1.6399, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [10/100], Epoch [2/5], Step [40/47], Loss: 1.7181, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [10/100], Epoch [3/5], Step [20/47], Loss: 1.7029, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [10/100], Epoch [3/5], Step [40/47], Loss: 1.8607, batch time: 0.09, accuracy:  32.03%\n",
      "Training round [10/100], Epoch [4/5], Step [20/47], Loss: 1.7842, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [10/100], Epoch [4/5], Step [40/47], Loss: 1.7196, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [10/100], Epoch [5/5], Step [20/47], Loss: 1.5735, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [10/100], Epoch [5/5], Step [40/47], Loss: 1.8695, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [10/100], qnn_train_step: [100/500], loss: 2.1075000762939453, accuracy: 31.1 %\n",
      "Training round [10/100], qnn_train_step: [200/500], loss: 1.9155867099761963, accuracy: 35.8 %\n",
      "Training round [10/100], qnn_train_step: [300/500], loss: 1.8598089218139648, accuracy: 35.2 %\n",
      "Training round [10/100], qnn_train_step: [400/500], loss: 1.773743748664856, accuracy: 38.5 %\n",
      "Training round [10/100], qnn_train_step: [500/500], loss: 1.762199878692627, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [11/100], Epoch [1/5], Step [20/47], Loss: 1.7911, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [11/100], Epoch [1/5], Step [40/47], Loss: 1.7994, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [11/100], Epoch [2/5], Step [20/47], Loss: 1.7668, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [11/100], Epoch [2/5], Step [40/47], Loss: 1.7033, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [11/100], Epoch [3/5], Step [20/47], Loss: 1.8570, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [11/100], Epoch [3/5], Step [40/47], Loss: 1.5994, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [11/100], Epoch [4/5], Step [20/47], Loss: 1.7244, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [11/100], Epoch [4/5], Step [40/47], Loss: 1.6859, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [11/100], Epoch [5/5], Step [20/47], Loss: 1.7454, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [11/100], Epoch [5/5], Step [40/47], Loss: 1.8308, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [11/100], qnn_train_step: [100/500], loss: 2.035897970199585, accuracy: 34.7 %\n",
      "Training round [11/100], qnn_train_step: [200/500], loss: 1.974838137626648, accuracy: 30.9 %\n",
      "Training round [11/100], qnn_train_step: [300/500], loss: 1.7924046516418457, accuracy: 40.8 %\n",
      "Training round [11/100], qnn_train_step: [400/500], loss: 1.7511550188064575, accuracy: 41.2 %\n",
      "Training round [11/100], qnn_train_step: [500/500], loss: 1.7239842414855957, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [12/100], Epoch [1/5], Step [20/47], Loss: 1.7120, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [12/100], Epoch [1/5], Step [40/47], Loss: 1.6095, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [12/100], Epoch [2/5], Step [20/47], Loss: 1.8486, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [12/100], Epoch [2/5], Step [40/47], Loss: 1.6693, batch time: 0.10, accuracy:  37.50%\n",
      "Training round [12/100], Epoch [3/5], Step [20/47], Loss: 1.6083, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [12/100], Epoch [3/5], Step [40/47], Loss: 1.6756, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [12/100], Epoch [4/5], Step [20/47], Loss: 1.7276, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [12/100], Epoch [4/5], Step [40/47], Loss: 1.5206, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [12/100], Epoch [5/5], Step [20/47], Loss: 1.7450, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [12/100], Epoch [5/5], Step [40/47], Loss: 1.6318, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [12/100], qnn_train_step: [100/500], loss: 2.050405740737915, accuracy: 33.6 %\n",
      "Training round [12/100], qnn_train_step: [200/500], loss: 2.0254344940185547, accuracy: 36.2 %\n",
      "Training round [12/100], qnn_train_step: [300/500], loss: 1.7045873403549194, accuracy: 42.3 %\n",
      "Training round [12/100], qnn_train_step: [400/500], loss: 1.6856948137283325, accuracy: 42.2 %\n",
      "Training round [12/100], qnn_train_step: [500/500], loss: 1.6810346841812134, accuracy: 42.6 %\n",
      "-----------------------\n",
      "Training round [13/100], Epoch [1/5], Step [20/47], Loss: 1.5982, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [13/100], Epoch [1/5], Step [40/47], Loss: 1.6889, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [13/100], Epoch [2/5], Step [20/47], Loss: 1.5548, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [13/100], Epoch [2/5], Step [40/47], Loss: 1.5980, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [13/100], Epoch [3/5], Step [20/47], Loss: 1.8100, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [13/100], Epoch [3/5], Step [40/47], Loss: 1.6770, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [13/100], Epoch [4/5], Step [20/47], Loss: 1.6401, batch time: 0.28, accuracy:  44.53%\n",
      "Training round [13/100], Epoch [4/5], Step [40/47], Loss: 1.8003, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [13/100], Epoch [5/5], Step [20/47], Loss: 1.5945, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [13/100], Epoch [5/5], Step [40/47], Loss: 1.5869, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [13/100], qnn_train_step: [100/500], loss: 2.071251153945923, accuracy: 34.4 %\n",
      "Training round [13/100], qnn_train_step: [200/500], loss: 1.969229817390442, accuracy: 39.1 %\n",
      "Training round [13/100], qnn_train_step: [300/500], loss: 1.7019193172454834, accuracy: 40.5 %\n",
      "Training round [13/100], qnn_train_step: [400/500], loss: 1.632914423942566, accuracy: 44.2 %\n",
      "Training round [13/100], qnn_train_step: [500/500], loss: 1.623615026473999, accuracy: 45.0 %\n",
      "-----------------------\n",
      "Training round [14/100], Epoch [1/5], Step [20/47], Loss: 1.7283, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [14/100], Epoch [1/5], Step [40/47], Loss: 1.5658, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [14/100], Epoch [2/5], Step [20/47], Loss: 1.4902, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [14/100], Epoch [2/5], Step [40/47], Loss: 1.5151, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [14/100], Epoch [3/5], Step [20/47], Loss: 1.8325, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [14/100], Epoch [3/5], Step [40/47], Loss: 1.7639, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [14/100], Epoch [4/5], Step [20/47], Loss: 1.6298, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [14/100], Epoch [4/5], Step [40/47], Loss: 1.5968, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [14/100], Epoch [5/5], Step [20/47], Loss: 1.6368, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [14/100], Epoch [5/5], Step [40/47], Loss: 1.5649, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [14/100], qnn_train_step: [100/500], loss: 2.164135456085205, accuracy: 30.6 %\n",
      "Training round [14/100], qnn_train_step: [200/500], loss: 2.09625244140625, accuracy: 33.4 %\n",
      "Training round [14/100], qnn_train_step: [300/500], loss: 1.6994385719299316, accuracy: 42.5 %\n",
      "Training round [14/100], qnn_train_step: [400/500], loss: 1.6848160028457642, accuracy: 43.2 %\n",
      "Training round [14/100], qnn_train_step: [500/500], loss: 1.7700495719909668, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [15/100], Epoch [1/5], Step [20/47], Loss: 1.8243, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [15/100], Epoch [1/5], Step [40/47], Loss: 1.6149, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [15/100], Epoch [2/5], Step [20/47], Loss: 1.5982, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [15/100], Epoch [2/5], Step [40/47], Loss: 1.7014, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [15/100], Epoch [3/5], Step [20/47], Loss: 1.6455, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [15/100], Epoch [3/5], Step [40/47], Loss: 1.5268, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [15/100], Epoch [4/5], Step [20/47], Loss: 1.7352, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [15/100], Epoch [4/5], Step [40/47], Loss: 1.6354, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [15/100], Epoch [5/5], Step [20/47], Loss: 1.6346, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [15/100], Epoch [5/5], Step [40/47], Loss: 1.7014, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [15/100], qnn_train_step: [100/500], loss: 2.005695104598999, accuracy: 32.4 %\n",
      "Training round [15/100], qnn_train_step: [200/500], loss: 2.435969829559326, accuracy: 27.6 %\n",
      "Training round [15/100], qnn_train_step: [300/500], loss: 1.7033108472824097, accuracy: 42.2 %\n",
      "Training round [15/100], qnn_train_step: [400/500], loss: 1.6108956336975098, accuracy: 45.8 %\n",
      "Training round [15/100], qnn_train_step: [500/500], loss: 1.7444932460784912, accuracy: 39.8 %\n",
      "-----------------------\n",
      "Training round [16/100], Epoch [1/5], Step [20/47], Loss: 1.4550, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [16/100], Epoch [1/5], Step [40/47], Loss: 1.7046, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [16/100], Epoch [2/5], Step [20/47], Loss: 1.6458, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [16/100], Epoch [2/5], Step [40/47], Loss: 1.6826, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [16/100], Epoch [3/5], Step [20/47], Loss: 1.4078, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [16/100], Epoch [3/5], Step [40/47], Loss: 1.4607, batch time: 0.09, accuracy:  57.03%\n",
      "Training round [16/100], Epoch [4/5], Step [20/47], Loss: 1.7410, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [16/100], Epoch [4/5], Step [40/47], Loss: 1.8560, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [16/100], Epoch [5/5], Step [20/47], Loss: 1.5818, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [16/100], Epoch [5/5], Step [40/47], Loss: 1.4776, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [16/100], qnn_train_step: [100/500], loss: 2.236224412918091, accuracy: 29.2 %\n",
      "Training round [16/100], qnn_train_step: [200/500], loss: 2.104349374771118, accuracy: 31.2 %\n",
      "Training round [16/100], qnn_train_step: [300/500], loss: 1.6251378059387207, accuracy: 45.2 %\n",
      "Training round [16/100], qnn_train_step: [400/500], loss: 1.7177598476409912, accuracy: 44.7 %\n",
      "Training round [16/100], qnn_train_step: [500/500], loss: 1.568400263786316, accuracy: 47.6 %\n",
      "-----------------------\n",
      "Training round [17/100], Epoch [1/5], Step [20/47], Loss: 1.5470, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [17/100], Epoch [1/5], Step [40/47], Loss: 1.6192, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [17/100], Epoch [2/5], Step [20/47], Loss: 1.5444, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [17/100], Epoch [2/5], Step [40/47], Loss: 1.7362, batch time: 0.14, accuracy:  36.72%\n",
      "Training round [17/100], Epoch [3/5], Step [20/47], Loss: 1.6727, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [17/100], Epoch [3/5], Step [40/47], Loss: 1.4882, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [17/100], Epoch [4/5], Step [20/47], Loss: 1.6269, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [17/100], Epoch [4/5], Step [40/47], Loss: 1.6278, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [17/100], Epoch [5/5], Step [20/47], Loss: 1.6131, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [17/100], Epoch [5/5], Step [40/47], Loss: 1.4695, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [17/100], qnn_train_step: [100/500], loss: 2.003589630126953, accuracy: 37.4 %\n",
      "Training round [17/100], qnn_train_step: [200/500], loss: 2.4742653369903564, accuracy: 24.7 %\n",
      "Training round [17/100], qnn_train_step: [300/500], loss: 1.6737945079803467, accuracy: 43.5 %\n",
      "Training round [17/100], qnn_train_step: [400/500], loss: 1.5806609392166138, accuracy: 46.3 %\n",
      "Training round [17/100], qnn_train_step: [500/500], loss: 1.931178092956543, accuracy: 37.0 %\n",
      "-----------------------\n",
      "Training round [18/100], Epoch [1/5], Step [20/47], Loss: 1.5746, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [18/100], Epoch [1/5], Step [40/47], Loss: 1.5816, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [18/100], Epoch [2/5], Step [20/47], Loss: 1.6627, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [18/100], Epoch [2/5], Step [40/47], Loss: 1.4809, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [18/100], Epoch [3/5], Step [20/47], Loss: 1.7746, batch time: 0.09, accuracy:  35.94%\n",
      "Training round [18/100], Epoch [3/5], Step [40/47], Loss: 1.4508, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [18/100], Epoch [4/5], Step [20/47], Loss: 1.6360, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [18/100], Epoch [4/5], Step [40/47], Loss: 1.6558, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [18/100], Epoch [5/5], Step [20/47], Loss: 1.5733, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [18/100], Epoch [5/5], Step [40/47], Loss: 1.5102, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [18/100], qnn_train_step: [100/500], loss: 1.8826355934143066, accuracy: 39.1 %\n",
      "Training round [18/100], qnn_train_step: [200/500], loss: 2.276897668838501, accuracy: 28.8 %\n",
      "Training round [18/100], qnn_train_step: [300/500], loss: 1.5902926921844482, accuracy: 45.4 %\n",
      "Training round [18/100], qnn_train_step: [400/500], loss: 1.5536075830459595, accuracy: 48.1 %\n",
      "Training round [18/100], qnn_train_step: [500/500], loss: 1.551986575126648, accuracy: 48.6 %\n",
      "-----------------------\n",
      "Training round [19/100], Epoch [1/5], Step [20/47], Loss: 1.4410, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [19/100], Epoch [1/5], Step [40/47], Loss: 1.4963, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [19/100], Epoch [2/5], Step [20/47], Loss: 1.5267, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [19/100], Epoch [2/5], Step [40/47], Loss: 1.7621, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [19/100], Epoch [3/5], Step [20/47], Loss: 1.5026, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [19/100], Epoch [3/5], Step [40/47], Loss: 1.4500, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [19/100], Epoch [4/5], Step [20/47], Loss: 1.5760, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [19/100], Epoch [4/5], Step [40/47], Loss: 1.4164, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [19/100], Epoch [5/5], Step [20/47], Loss: 1.5096, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [19/100], Epoch [5/5], Step [40/47], Loss: 1.4486, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [19/100], qnn_train_step: [100/500], loss: 1.937782883644104, accuracy: 38.8 %\n",
      "Training round [19/100], qnn_train_step: [200/500], loss: 2.2698159217834473, accuracy: 29.2 %\n",
      "Training round [19/100], qnn_train_step: [300/500], loss: 1.7222927808761597, accuracy: 43.2 %\n",
      "Training round [19/100], qnn_train_step: [400/500], loss: 1.5420293807983398, accuracy: 46.4 %\n",
      "Training round [19/100], qnn_train_step: [500/500], loss: 1.567439079284668, accuracy: 47.7 %\n",
      "-----------------------\n",
      "Training round [20/100], Epoch [1/5], Step [20/47], Loss: 1.4952, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [20/100], Epoch [1/5], Step [40/47], Loss: 1.2933, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [20/100], Epoch [2/5], Step [20/47], Loss: 1.4413, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [20/100], Epoch [2/5], Step [40/47], Loss: 1.6281, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [20/100], Epoch [3/5], Step [20/47], Loss: 1.5242, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [20/100], Epoch [3/5], Step [40/47], Loss: 1.5727, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [20/100], Epoch [4/5], Step [20/47], Loss: 1.3985, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [20/100], Epoch [4/5], Step [40/47], Loss: 1.4597, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [20/100], Epoch [5/5], Step [20/47], Loss: 1.4183, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [20/100], Epoch [5/5], Step [40/47], Loss: 1.6961, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [20/100], qnn_train_step: [100/500], loss: 1.9294180870056152, accuracy: 37.9 %\n",
      "Training round [20/100], qnn_train_step: [200/500], loss: 2.1433160305023193, accuracy: 30.9 %\n",
      "Training round [20/100], qnn_train_step: [300/500], loss: 1.6117498874664307, accuracy: 45.5 %\n",
      "Training round [20/100], qnn_train_step: [400/500], loss: 1.672681212425232, accuracy: 44.8 %\n",
      "Training round [20/100], qnn_train_step: [500/500], loss: 1.6264985799789429, accuracy: 40.6 %\n",
      "-----------------------\n",
      "Training round [21/100], Epoch [1/5], Step [20/47], Loss: 1.4871, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [21/100], Epoch [1/5], Step [40/47], Loss: 1.4157, batch time: 0.28, accuracy:  53.91%\n",
      "Training round [21/100], Epoch [2/5], Step [20/47], Loss: 1.4984, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [21/100], Epoch [2/5], Step [40/47], Loss: 1.4802, batch time: 0.09, accuracy:  53.12%\n",
      "Training round [21/100], Epoch [3/5], Step [20/47], Loss: 1.5038, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [21/100], Epoch [3/5], Step [40/47], Loss: 1.5360, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [21/100], Epoch [4/5], Step [20/47], Loss: 1.6425, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [21/100], Epoch [4/5], Step [40/47], Loss: 1.3929, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [21/100], Epoch [5/5], Step [20/47], Loss: 1.5113, batch time: 0.12, accuracy:  50.00%\n",
      "Training round [21/100], Epoch [5/5], Step [40/47], Loss: 1.6265, batch time: 0.11, accuracy:  49.22%\n",
      "Training round [21/100], qnn_train_step: [100/500], loss: 2.076036214828491, accuracy: 36.9 %\n",
      "Training round [21/100], qnn_train_step: [200/500], loss: 2.3315839767456055, accuracy: 31.9 %\n",
      "Training round [21/100], qnn_train_step: [300/500], loss: 1.621211051940918, accuracy: 46.9 %\n",
      "Training round [21/100], qnn_train_step: [400/500], loss: 1.5041921138763428, accuracy: 46.8 %\n",
      "Training round [21/100], qnn_train_step: [500/500], loss: 1.4799747467041016, accuracy: 50.0 %\n",
      "-----------------------\n",
      "Training round [22/100], Epoch [1/5], Step [20/47], Loss: 1.4548, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [22/100], Epoch [1/5], Step [40/47], Loss: 1.2536, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [22/100], Epoch [2/5], Step [20/47], Loss: 1.4755, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [22/100], Epoch [2/5], Step [40/47], Loss: 1.3248, batch time: 0.14, accuracy:  45.31%\n",
      "Training round [22/100], Epoch [3/5], Step [20/47], Loss: 1.4650, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [22/100], Epoch [3/5], Step [40/47], Loss: 1.4461, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [22/100], Epoch [4/5], Step [20/47], Loss: 1.5018, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [22/100], Epoch [4/5], Step [40/47], Loss: 1.4394, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [22/100], Epoch [5/5], Step [20/47], Loss: 1.4361, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [22/100], Epoch [5/5], Step [40/47], Loss: 1.4430, batch time: 0.28, accuracy:  50.78%\n",
      "Training round [22/100], qnn_train_step: [100/500], loss: 2.0618443489074707, accuracy: 37.1 %\n",
      "Training round [22/100], qnn_train_step: [200/500], loss: 2.600917339324951, accuracy: 26.6 %\n",
      "Training round [22/100], qnn_train_step: [300/500], loss: 1.8057925701141357, accuracy: 35.8 %\n",
      "Training round [22/100], qnn_train_step: [400/500], loss: 1.5811413526535034, accuracy: 46.9 %\n",
      "Training round [22/100], qnn_train_step: [500/500], loss: 1.5135703086853027, accuracy: 50.2 %\n",
      "-----------------------\n",
      "Training round [23/100], Epoch [1/5], Step [20/47], Loss: 1.5154, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [23/100], Epoch [1/5], Step [40/47], Loss: 1.5153, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [23/100], Epoch [2/5], Step [20/47], Loss: 1.3930, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [23/100], Epoch [2/5], Step [40/47], Loss: 1.5513, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [23/100], Epoch [3/5], Step [20/47], Loss: 1.3708, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [23/100], Epoch [3/5], Step [40/47], Loss: 1.3964, batch time: 0.29, accuracy:  54.69%\n",
      "Training round [23/100], Epoch [4/5], Step [20/47], Loss: 1.5900, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [23/100], Epoch [4/5], Step [40/47], Loss: 1.4307, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [23/100], Epoch [5/5], Step [20/47], Loss: 1.3214, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [23/100], Epoch [5/5], Step [40/47], Loss: 1.4399, batch time: 0.09, accuracy:  46.09%\n",
      "Training round [23/100], qnn_train_step: [100/500], loss: 2.071739673614502, accuracy: 36.8 %\n",
      "Training round [23/100], qnn_train_step: [200/500], loss: 2.1744322776794434, accuracy: 29.6 %\n",
      "Training round [23/100], qnn_train_step: [300/500], loss: 1.6853790283203125, accuracy: 44.1 %\n",
      "Training round [23/100], qnn_train_step: [400/500], loss: 2.164015293121338, accuracy: 32.5 %\n",
      "Training round [23/100], qnn_train_step: [500/500], loss: 1.5572686195373535, accuracy: 46.3 %\n",
      "-----------------------\n",
      "Training round [24/100], Epoch [1/5], Step [20/47], Loss: 1.5194, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [24/100], Epoch [1/5], Step [40/47], Loss: 1.4051, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [24/100], Epoch [2/5], Step [20/47], Loss: 1.4022, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [24/100], Epoch [2/5], Step [40/47], Loss: 1.2650, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [24/100], Epoch [3/5], Step [20/47], Loss: 1.4808, batch time: 0.29, accuracy:  54.69%\n",
      "Training round [24/100], Epoch [3/5], Step [40/47], Loss: 1.5879, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [24/100], Epoch [4/5], Step [20/47], Loss: 1.4986, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [24/100], Epoch [4/5], Step [40/47], Loss: 1.4508, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [24/100], Epoch [5/5], Step [20/47], Loss: 1.4298, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [24/100], Epoch [5/5], Step [40/47], Loss: 1.5661, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [24/100], qnn_train_step: [100/500], loss: 2.153430700302124, accuracy: 35.8 %\n",
      "Training round [24/100], qnn_train_step: [200/500], loss: 2.31709361076355, accuracy: 29.3 %\n",
      "Training round [24/100], qnn_train_step: [300/500], loss: 1.4739348888397217, accuracy: 51.2 %\n",
      "Training round [24/100], qnn_train_step: [400/500], loss: 1.5215716361999512, accuracy: 45.7 %\n",
      "Training round [24/100], qnn_train_step: [500/500], loss: 1.4633365869522095, accuracy: 50.0 %\n",
      "-----------------------\n",
      "Training round [25/100], Epoch [1/5], Step [20/47], Loss: 1.4417, batch time: 0.21, accuracy:  52.34%\n",
      "Training round [25/100], Epoch [1/5], Step [40/47], Loss: 1.5079, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [25/100], Epoch [2/5], Step [20/47], Loss: 1.4600, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [25/100], Epoch [2/5], Step [40/47], Loss: 1.5594, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [25/100], Epoch [3/5], Step [20/47], Loss: 1.3673, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [25/100], Epoch [3/5], Step [40/47], Loss: 1.4671, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [25/100], Epoch [4/5], Step [20/47], Loss: 1.4263, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [25/100], Epoch [4/5], Step [40/47], Loss: 1.5058, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [25/100], Epoch [5/5], Step [20/47], Loss: 1.5566, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [25/100], Epoch [5/5], Step [40/47], Loss: 1.3445, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [25/100], qnn_train_step: [100/500], loss: 2.0933964252471924, accuracy: 34.4 %\n",
      "Training round [25/100], qnn_train_step: [200/500], loss: 2.3273611068725586, accuracy: 33.6 %\n",
      "Training round [25/100], qnn_train_step: [300/500], loss: 1.49747633934021, accuracy: 50.8 %\n",
      "Training round [25/100], qnn_train_step: [400/500], loss: 1.7939231395721436, accuracy: 40.5 %\n",
      "Training round [25/100], qnn_train_step: [500/500], loss: 1.5151662826538086, accuracy: 50.7 %\n",
      "-----------------------\n",
      "Training round [26/100], Epoch [1/5], Step [20/47], Loss: 1.3255, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [26/100], Epoch [1/5], Step [40/47], Loss: 1.5176, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [26/100], Epoch [2/5], Step [20/47], Loss: 1.3821, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [26/100], Epoch [2/5], Step [40/47], Loss: 1.3059, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [26/100], Epoch [3/5], Step [20/47], Loss: 1.5010, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [26/100], Epoch [3/5], Step [40/47], Loss: 1.4417, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [26/100], Epoch [4/5], Step [20/47], Loss: 1.3586, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [26/100], Epoch [4/5], Step [40/47], Loss: 1.6275, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [26/100], Epoch [5/5], Step [20/47], Loss: 1.3803, batch time: 0.15, accuracy:  53.12%\n",
      "Training round [26/100], Epoch [5/5], Step [40/47], Loss: 1.5373, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [26/100], qnn_train_step: [100/500], loss: 2.1419034004211426, accuracy: 36.0 %\n",
      "Training round [26/100], qnn_train_step: [200/500], loss: 2.4179062843322754, accuracy: 31.1 %\n",
      "Training round [26/100], qnn_train_step: [300/500], loss: 1.5373830795288086, accuracy: 49.3 %\n",
      "Training round [26/100], qnn_train_step: [400/500], loss: 1.6253676414489746, accuracy: 49.6 %\n",
      "Training round [26/100], qnn_train_step: [500/500], loss: 1.4877209663391113, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [27/100], Epoch [1/5], Step [20/47], Loss: 1.4329, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [27/100], Epoch [1/5], Step [40/47], Loss: 1.3970, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [27/100], Epoch [2/5], Step [20/47], Loss: 1.3010, batch time: 0.29, accuracy:  53.12%\n",
      "Training round [27/100], Epoch [2/5], Step [40/47], Loss: 1.2784, batch time: 0.28, accuracy:  60.16%\n",
      "Training round [27/100], Epoch [3/5], Step [20/47], Loss: 1.5533, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [27/100], Epoch [3/5], Step [40/47], Loss: 1.3604, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [27/100], Epoch [4/5], Step [20/47], Loss: 1.5286, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [27/100], Epoch [4/5], Step [40/47], Loss: 1.4941, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [27/100], Epoch [5/5], Step [20/47], Loss: 1.5469, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [27/100], Epoch [5/5], Step [40/47], Loss: 1.4739, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [27/100], qnn_train_step: [100/500], loss: 2.3541152477264404, accuracy: 29.4 %\n",
      "Training round [27/100], qnn_train_step: [200/500], loss: 2.567474126815796, accuracy: 26.8 %\n",
      "Training round [27/100], qnn_train_step: [300/500], loss: 1.5015162229537964, accuracy: 48.9 %\n",
      "Training round [27/100], qnn_train_step: [400/500], loss: 1.4014170169830322, accuracy: 55.2 %\n",
      "Training round [27/100], qnn_train_step: [500/500], loss: 2.201714277267456, accuracy: 37.0 %\n",
      "-----------------------\n",
      "Training round [28/100], Epoch [1/5], Step [20/47], Loss: 1.3787, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [28/100], Epoch [1/5], Step [40/47], Loss: 1.3515, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [28/100], Epoch [2/5], Step [20/47], Loss: 1.4242, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [28/100], Epoch [2/5], Step [40/47], Loss: 1.2839, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [28/100], Epoch [3/5], Step [20/47], Loss: 1.1851, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [28/100], Epoch [3/5], Step [40/47], Loss: 1.6959, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [28/100], Epoch [4/5], Step [20/47], Loss: 1.4048, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [28/100], Epoch [4/5], Step [40/47], Loss: 1.5431, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [28/100], Epoch [5/5], Step [20/47], Loss: 1.4019, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [28/100], Epoch [5/5], Step [40/47], Loss: 1.1491, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [28/100], qnn_train_step: [100/500], loss: 2.3363139629364014, accuracy: 32.3 %\n",
      "Training round [28/100], qnn_train_step: [200/500], loss: 3.4354968070983887, accuracy: 18.3 %\n",
      "Training round [28/100], qnn_train_step: [300/500], loss: 1.3932263851165771, accuracy: 53.8 %\n",
      "Training round [28/100], qnn_train_step: [400/500], loss: 1.8134820461273193, accuracy: 42.4 %\n",
      "Training round [28/100], qnn_train_step: [500/500], loss: 1.3796864748001099, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [29/100], Epoch [1/5], Step [20/47], Loss: 1.4111, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [29/100], Epoch [1/5], Step [40/47], Loss: 1.3907, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [29/100], Epoch [2/5], Step [20/47], Loss: 1.3627, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [29/100], Epoch [2/5], Step [40/47], Loss: 1.3310, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [29/100], Epoch [3/5], Step [20/47], Loss: 1.3579, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [29/100], Epoch [3/5], Step [40/47], Loss: 1.3517, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [29/100], Epoch [4/5], Step [20/47], Loss: 1.2087, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [29/100], Epoch [4/5], Step [40/47], Loss: 1.3409, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [29/100], Epoch [5/5], Step [20/47], Loss: 1.2972, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [29/100], Epoch [5/5], Step [40/47], Loss: 1.2906, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [29/100], qnn_train_step: [100/500], loss: 2.2724995613098145, accuracy: 35.6 %\n",
      "Training round [29/100], qnn_train_step: [200/500], loss: 4.584068775177002, accuracy: 14.3 %\n",
      "Training round [29/100], qnn_train_step: [300/500], loss: 1.3859333992004395, accuracy: 55.8 %\n",
      "Training round [29/100], qnn_train_step: [400/500], loss: 1.7635594606399536, accuracy: 44.9 %\n",
      "Training round [29/100], qnn_train_step: [500/500], loss: 1.528333306312561, accuracy: 47.8 %\n",
      "-----------------------\n",
      "Training round [30/100], Epoch [1/5], Step [20/47], Loss: 1.4078, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [30/100], Epoch [1/5], Step [40/47], Loss: 1.3332, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [30/100], Epoch [2/5], Step [20/47], Loss: 1.3080, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [30/100], Epoch [2/5], Step [40/47], Loss: 1.3105, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [30/100], Epoch [3/5], Step [20/47], Loss: 1.3598, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [30/100], Epoch [3/5], Step [40/47], Loss: 1.3018, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [30/100], Epoch [4/5], Step [20/47], Loss: 1.3336, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [30/100], Epoch [4/5], Step [40/47], Loss: 1.2780, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [30/100], Epoch [5/5], Step [20/47], Loss: 1.3966, batch time: 0.09, accuracy:  54.69%\n",
      "Training round [30/100], Epoch [5/5], Step [40/47], Loss: 1.5258, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [30/100], qnn_train_step: [100/500], loss: 2.261369228363037, accuracy: 33.8 %\n",
      "Training round [30/100], qnn_train_step: [200/500], loss: 3.8208391666412354, accuracy: 16.0 %\n",
      "Training round [30/100], qnn_train_step: [300/500], loss: 1.5904407501220703, accuracy: 47.0 %\n",
      "Training round [30/100], qnn_train_step: [400/500], loss: 3.379049062728882, accuracy: 27.5 %\n",
      "Training round [30/100], qnn_train_step: [500/500], loss: 1.989524245262146, accuracy: 38.1 %\n",
      "-----------------------\n",
      "Training round [31/100], Epoch [1/5], Step [20/47], Loss: 1.3313, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [31/100], Epoch [1/5], Step [40/47], Loss: 1.2991, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [31/100], Epoch [2/5], Step [20/47], Loss: 1.4207, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [31/100], Epoch [2/5], Step [40/47], Loss: 1.3398, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [31/100], Epoch [3/5], Step [20/47], Loss: 1.4955, batch time: 0.29, accuracy:  47.66%\n",
      "Training round [31/100], Epoch [3/5], Step [40/47], Loss: 1.3580, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [31/100], Epoch [4/5], Step [20/47], Loss: 1.2782, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [31/100], Epoch [4/5], Step [40/47], Loss: 1.4264, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [31/100], Epoch [5/5], Step [20/47], Loss: 1.4676, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [31/100], Epoch [5/5], Step [40/47], Loss: 1.5513, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [31/100], qnn_train_step: [100/500], loss: 2.3762047290802, accuracy: 31.2 %\n",
      "Training round [31/100], qnn_train_step: [200/500], loss: 3.4817373752593994, accuracy: 19.7 %\n",
      "Training round [31/100], qnn_train_step: [300/500], loss: 1.5691853761672974, accuracy: 46.9 %\n",
      "Training round [31/100], qnn_train_step: [400/500], loss: 1.3738240003585815, accuracy: 54.8 %\n",
      "Training round [31/100], qnn_train_step: [500/500], loss: 1.3614814281463623, accuracy: 54.8 %\n",
      "-----------------------\n",
      "Training round [32/100], Epoch [1/5], Step [20/47], Loss: 1.4960, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [32/100], Epoch [1/5], Step [40/47], Loss: 1.4178, batch time: 0.17, accuracy:  54.69%\n",
      "Training round [32/100], Epoch [2/5], Step [20/47], Loss: 1.3748, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [32/100], Epoch [2/5], Step [40/47], Loss: 1.3245, batch time: 0.29, accuracy:  53.12%\n",
      "Training round [32/100], Epoch [3/5], Step [20/47], Loss: 1.5546, batch time: 0.29, accuracy:  46.09%\n",
      "Training round [32/100], Epoch [3/5], Step [40/47], Loss: 1.3851, batch time: 0.29, accuracy:  48.44%\n",
      "Training round [32/100], Epoch [4/5], Step [20/47], Loss: 1.4389, batch time: 0.29, accuracy:  44.53%\n",
      "Training round [32/100], Epoch [4/5], Step [40/47], Loss: 1.4095, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [32/100], Epoch [5/5], Step [20/47], Loss: 1.3673, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [32/100], Epoch [5/5], Step [40/47], Loss: 1.5269, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [32/100], qnn_train_step: [100/500], loss: 2.4789507389068604, accuracy: 30.8 %\n",
      "Training round [32/100], qnn_train_step: [200/500], loss: 4.447687149047852, accuracy: 14.6 %\n",
      "Training round [32/100], qnn_train_step: [300/500], loss: 2.0863842964172363, accuracy: 38.4 %\n",
      "Training round [32/100], qnn_train_step: [400/500], loss: 1.8449214696884155, accuracy: 41.3 %\n",
      "Training round [32/100], qnn_train_step: [500/500], loss: 1.4704442024230957, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [33/100], Epoch [1/5], Step [20/47], Loss: 1.2718, batch time: 0.18, accuracy:  57.81%\n",
      "Training round [33/100], Epoch [1/5], Step [40/47], Loss: 1.4984, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [33/100], Epoch [2/5], Step [20/47], Loss: 1.6070, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [33/100], Epoch [2/5], Step [40/47], Loss: 1.4140, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [33/100], Epoch [3/5], Step [20/47], Loss: 1.4076, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [33/100], Epoch [3/5], Step [40/47], Loss: 1.4046, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [33/100], Epoch [4/5], Step [20/47], Loss: 1.3446, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [33/100], Epoch [4/5], Step [40/47], Loss: 1.2925, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [33/100], Epoch [5/5], Step [20/47], Loss: 1.3662, batch time: 0.29, accuracy:  50.00%\n",
      "Training round [33/100], Epoch [5/5], Step [40/47], Loss: 1.3231, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [33/100], qnn_train_step: [100/500], loss: 2.5972206592559814, accuracy: 29.8 %\n",
      "Training round [33/100], qnn_train_step: [200/500], loss: 4.287633895874023, accuracy: 16.7 %\n",
      "Training round [33/100], qnn_train_step: [300/500], loss: 2.2733395099639893, accuracy: 37.1 %\n",
      "Training round [33/100], qnn_train_step: [400/500], loss: 1.571898341178894, accuracy: 49.0 %\n",
      "Training round [33/100], qnn_train_step: [500/500], loss: 2.2478432655334473, accuracy: 36.9 %\n",
      "-----------------------\n",
      "Training round [34/100], Epoch [1/5], Step [20/47], Loss: 1.3748, batch time: 0.29, accuracy:  52.34%\n",
      "Training round [34/100], Epoch [1/5], Step [40/47], Loss: 1.3685, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [34/100], Epoch [2/5], Step [20/47], Loss: 1.4923, batch time: 0.15, accuracy:  53.91%\n",
      "Training round [34/100], Epoch [2/5], Step [40/47], Loss: 1.3447, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [34/100], Epoch [3/5], Step [20/47], Loss: 1.4010, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [34/100], Epoch [3/5], Step [40/47], Loss: 1.2808, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [34/100], Epoch [4/5], Step [20/47], Loss: 1.3836, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [34/100], Epoch [4/5], Step [40/47], Loss: 1.3647, batch time: 0.29, accuracy:  54.69%\n",
      "Training round [34/100], Epoch [5/5], Step [20/47], Loss: 1.3905, batch time: 0.29, accuracy:  47.66%\n",
      "Training round [34/100], Epoch [5/5], Step [40/47], Loss: 1.4995, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [34/100], qnn_train_step: [100/500], loss: 2.191380262374878, accuracy: 38.2 %\n",
      "Training round [34/100], qnn_train_step: [200/500], loss: 3.1664185523986816, accuracy: 21.1 %\n",
      "Training round [34/100], qnn_train_step: [300/500], loss: 1.5043801069259644, accuracy: 51.6 %\n",
      "Training round [34/100], qnn_train_step: [400/500], loss: 1.8336365222930908, accuracy: 40.1 %\n",
      "Training round [34/100], qnn_train_step: [500/500], loss: 1.5057971477508545, accuracy: 51.2 %\n",
      "-----------------------\n",
      "Training round [35/100], Epoch [1/5], Step [20/47], Loss: 1.4879, batch time: 0.12, accuracy:  53.12%\n",
      "Training round [35/100], Epoch [1/5], Step [40/47], Loss: 1.5048, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [35/100], Epoch [2/5], Step [20/47], Loss: 1.3484, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [35/100], Epoch [2/5], Step [40/47], Loss: 1.2564, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [35/100], Epoch [3/5], Step [20/47], Loss: 1.3863, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [35/100], Epoch [3/5], Step [40/47], Loss: 1.2630, batch time: 0.18, accuracy:  62.50%\n",
      "Training round [35/100], Epoch [4/5], Step [20/47], Loss: 1.3781, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [35/100], Epoch [4/5], Step [40/47], Loss: 1.2107, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [35/100], Epoch [5/5], Step [20/47], Loss: 1.4286, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [35/100], Epoch [5/5], Step [40/47], Loss: 1.5294, batch time: 0.29, accuracy:  54.69%\n",
      "Training round [35/100], qnn_train_step: [100/500], loss: 2.568415880203247, accuracy: 32.1 %\n",
      "Training round [35/100], qnn_train_step: [200/500], loss: 2.5951483249664307, accuracy: 28.3 %\n",
      "Training round [35/100], qnn_train_step: [300/500], loss: 1.9137712717056274, accuracy: 39.5 %\n",
      "Training round [35/100], qnn_train_step: [400/500], loss: 1.6108001470565796, accuracy: 50.8 %\n",
      "Training round [35/100], qnn_train_step: [500/500], loss: 1.4301085472106934, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [36/100], Epoch [1/5], Step [20/47], Loss: 1.3645, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [36/100], Epoch [1/5], Step [40/47], Loss: 1.5084, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [36/100], Epoch [2/5], Step [20/47], Loss: 1.4767, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [36/100], Epoch [2/5], Step [40/47], Loss: 1.2932, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [36/100], Epoch [3/5], Step [20/47], Loss: 1.4730, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [36/100], Epoch [3/5], Step [40/47], Loss: 1.5342, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [36/100], Epoch [4/5], Step [20/47], Loss: 1.3853, batch time: 0.15, accuracy:  59.38%\n",
      "Training round [36/100], Epoch [4/5], Step [40/47], Loss: 1.3390, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [36/100], Epoch [5/5], Step [20/47], Loss: 1.2251, batch time: 0.29, accuracy:  50.78%\n",
      "Training round [36/100], Epoch [5/5], Step [40/47], Loss: 1.3903, batch time: 0.29, accuracy:  55.47%\n",
      "Training round [36/100], qnn_train_step: [100/500], loss: 2.5618226528167725, accuracy: 32.6 %\n",
      "Training round [36/100], qnn_train_step: [200/500], loss: 3.448356866836548, accuracy: 17.2 %\n",
      "Training round [36/100], qnn_train_step: [300/500], loss: 1.5244349241256714, accuracy: 50.3 %\n",
      "Training round [36/100], qnn_train_step: [400/500], loss: 1.5528231859207153, accuracy: 51.7 %\n",
      "Training round [36/100], qnn_train_step: [500/500], loss: 1.7061638832092285, accuracy: 45.1 %\n",
      "-----------------------\n",
      "Training round [37/100], Epoch [1/5], Step [20/47], Loss: 1.4424, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [37/100], Epoch [1/5], Step [40/47], Loss: 1.2078, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [37/100], Epoch [2/5], Step [20/47], Loss: 1.2726, batch time: 0.28, accuracy:  58.59%\n",
      "Training round [37/100], Epoch [2/5], Step [40/47], Loss: 1.3948, batch time: 0.29, accuracy:  47.66%\n",
      "Training round [37/100], Epoch [3/5], Step [20/47], Loss: 1.4122, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [37/100], Epoch [3/5], Step [40/47], Loss: 1.7439, batch time: 0.22, accuracy:  45.31%\n",
      "Training round [37/100], Epoch [4/5], Step [20/47], Loss: 1.1221, batch time: 0.09, accuracy:  62.50%\n",
      "Training round [37/100], Epoch [4/5], Step [40/47], Loss: 1.1975, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [37/100], Epoch [5/5], Step [20/47], Loss: 1.4364, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [37/100], Epoch [5/5], Step [40/47], Loss: 1.4752, batch time: 0.29, accuracy:  57.03%\n",
      "Training round [37/100], qnn_train_step: [100/500], loss: 2.947929859161377, accuracy: 27.1 %\n",
      "Training round [37/100], qnn_train_step: [200/500], loss: 4.397768974304199, accuracy: 13.5 %\n",
      "Training round [37/100], qnn_train_step: [300/500], loss: 1.432267665863037, accuracy: 54.2 %\n",
      "Training round [37/100], qnn_train_step: [400/500], loss: 1.349342942237854, accuracy: 55.4 %\n",
      "Training round [37/100], qnn_train_step: [500/500], loss: 1.5370184183120728, accuracy: 49.6 %\n",
      "-----------------------\n",
      "Training round [38/100], Epoch [1/5], Step [20/47], Loss: 1.4376, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [38/100], Epoch [1/5], Step [40/47], Loss: 1.5132, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [38/100], Epoch [2/5], Step [20/47], Loss: 1.2879, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [38/100], Epoch [2/5], Step [40/47], Loss: 1.3503, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [38/100], Epoch [3/5], Step [20/47], Loss: 1.2591, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [38/100], Epoch [3/5], Step [40/47], Loss: 1.2730, batch time: 0.15, accuracy:  58.59%\n",
      "Training round [38/100], Epoch [4/5], Step [20/47], Loss: 1.1790, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [38/100], Epoch [4/5], Step [40/47], Loss: 1.4338, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [38/100], Epoch [5/5], Step [20/47], Loss: 1.2560, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [38/100], Epoch [5/5], Step [40/47], Loss: 1.4686, batch time: 0.30, accuracy:  50.78%\n",
      "Training round [38/100], qnn_train_step: [100/500], loss: 2.6341514587402344, accuracy: 30.9 %\n",
      "Training round [38/100], qnn_train_step: [200/500], loss: 5.622941017150879, accuracy: 11.7 %\n",
      "Training round [38/100], qnn_train_step: [300/500], loss: 1.330148696899414, accuracy: 58.4 %\n",
      "Training round [38/100], qnn_train_step: [400/500], loss: 1.6237066984176636, accuracy: 49.7 %\n",
      "Training round [38/100], qnn_train_step: [500/500], loss: 2.442944049835205, accuracy: 38.6 %\n",
      "-----------------------\n",
      "Training round [39/100], Epoch [1/5], Step [20/47], Loss: 1.3007, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [39/100], Epoch [1/5], Step [40/47], Loss: 1.3766, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [39/100], Epoch [2/5], Step [20/47], Loss: 1.3302, batch time: 0.14, accuracy:  56.25%\n",
      "Training round [39/100], Epoch [2/5], Step [40/47], Loss: 1.4586, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [39/100], Epoch [3/5], Step [20/47], Loss: 1.3499, batch time: 0.16, accuracy:  59.38%\n",
      "Training round [39/100], Epoch [3/5], Step [40/47], Loss: 1.3460, batch time: 0.14, accuracy:  60.16%\n",
      "Training round [39/100], Epoch [4/5], Step [20/47], Loss: 1.3710, batch time: 0.17, accuracy:  57.81%\n",
      "Training round [39/100], Epoch [4/5], Step [40/47], Loss: 1.2877, batch time: 0.12, accuracy:  57.03%\n",
      "Training round [39/100], Epoch [5/5], Step [20/47], Loss: 1.4081, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [39/100], Epoch [5/5], Step [40/47], Loss: 1.4779, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [39/100], qnn_train_step: [100/500], loss: 2.7169930934906006, accuracy: 30.4 %\n",
      "Training round [39/100], qnn_train_step: [200/500], loss: 6.089979648590088, accuracy: 12.0 %\n",
      "Training round [39/100], qnn_train_step: [300/500], loss: 1.428236722946167, accuracy: 55.2 %\n",
      "Training round [39/100], qnn_train_step: [400/500], loss: 1.68837308883667, accuracy: 47.9 %\n",
      "Training round [39/100], qnn_train_step: [500/500], loss: 2.312380075454712, accuracy: 36.8 %\n",
      "-----------------------\n",
      "Training round [40/100], Epoch [1/5], Step [20/47], Loss: 1.4068, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [40/100], Epoch [1/5], Step [40/47], Loss: 1.4044, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [40/100], Epoch [2/5], Step [20/47], Loss: 1.4796, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [40/100], Epoch [2/5], Step [40/47], Loss: 1.2395, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [40/100], Epoch [3/5], Step [20/47], Loss: 1.3692, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [40/100], Epoch [3/5], Step [40/47], Loss: 1.3088, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [40/100], Epoch [4/5], Step [20/47], Loss: 1.2810, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [40/100], Epoch [4/5], Step [40/47], Loss: 1.5405, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [40/100], Epoch [5/5], Step [20/47], Loss: 1.4300, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [40/100], Epoch [5/5], Step [40/47], Loss: 1.4068, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [40/100], qnn_train_step: [100/500], loss: 2.7733590602874756, accuracy: 29.9 %\n",
      "Training round [40/100], qnn_train_step: [200/500], loss: 5.611361503601074, accuracy: 11.5 %\n",
      "Training round [40/100], qnn_train_step: [300/500], loss: 1.3738511800765991, accuracy: 55.5 %\n",
      "Training round [40/100], qnn_train_step: [400/500], loss: 1.5789153575897217, accuracy: 51.8 %\n",
      "Training round [40/100], qnn_train_step: [500/500], loss: 1.5153087377548218, accuracy: 54.1 %\n",
      "-----------------------\n",
      "Training round [41/100], Epoch [1/5], Step [20/47], Loss: 1.1749, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [41/100], Epoch [1/5], Step [40/47], Loss: 1.5211, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [41/100], Epoch [2/5], Step [20/47], Loss: 1.3413, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [41/100], Epoch [2/5], Step [40/47], Loss: 1.2350, batch time: 0.29, accuracy:  55.47%\n",
      "Training round [41/100], Epoch [3/5], Step [20/47], Loss: 1.2772, batch time: 0.17, accuracy:  57.03%\n",
      "Training round [41/100], Epoch [3/5], Step [40/47], Loss: 1.5195, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [41/100], Epoch [4/5], Step [20/47], Loss: 1.1696, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [41/100], Epoch [4/5], Step [40/47], Loss: 1.4461, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [41/100], Epoch [5/5], Step [20/47], Loss: 1.5086, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [41/100], Epoch [5/5], Step [40/47], Loss: 1.3426, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [41/100], qnn_train_step: [100/500], loss: 2.9977521896362305, accuracy: 29.6 %\n",
      "Training round [41/100], qnn_train_step: [200/500], loss: 5.8176398277282715, accuracy: 12.0 %\n",
      "Training round [41/100], qnn_train_step: [300/500], loss: 1.4710499048233032, accuracy: 52.7 %\n",
      "Training round [41/100], qnn_train_step: [400/500], loss: 1.6596139669418335, accuracy: 47.9 %\n",
      "Training round [41/100], qnn_train_step: [500/500], loss: 1.3904529809951782, accuracy: 54.2 %\n",
      "-----------------------\n",
      "Training round [42/100], Epoch [1/5], Step [20/47], Loss: 1.3816, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [42/100], Epoch [1/5], Step [40/47], Loss: 1.2842, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [42/100], Epoch [2/5], Step [20/47], Loss: 1.1360, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [42/100], Epoch [2/5], Step [40/47], Loss: 1.4768, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [42/100], Epoch [3/5], Step [20/47], Loss: 1.3185, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [42/100], Epoch [3/5], Step [40/47], Loss: 1.1741, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [42/100], Epoch [4/5], Step [20/47], Loss: 1.2251, batch time: 0.21, accuracy:  59.38%\n",
      "Training round [42/100], Epoch [4/5], Step [40/47], Loss: 1.3215, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [42/100], Epoch [5/5], Step [20/47], Loss: 1.2605, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [42/100], Epoch [5/5], Step [40/47], Loss: 1.2017, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [42/100], qnn_train_step: [100/500], loss: 2.9645333290100098, accuracy: 29.4 %\n",
      "Training round [42/100], qnn_train_step: [200/500], loss: 3.9071428775787354, accuracy: 18.0 %\n",
      "Training round [42/100], qnn_train_step: [300/500], loss: 1.4182512760162354, accuracy: 53.4 %\n",
      "Training round [42/100], qnn_train_step: [400/500], loss: 1.6787875890731812, accuracy: 50.4 %\n",
      "Training round [42/100], qnn_train_step: [500/500], loss: 1.4975305795669556, accuracy: 52.5 %\n",
      "-----------------------\n",
      "Training round [43/100], Epoch [1/5], Step [20/47], Loss: 1.3281, batch time: 0.29, accuracy:  63.28%\n",
      "Training round [43/100], Epoch [1/5], Step [40/47], Loss: 1.4712, batch time: 0.19, accuracy:  52.34%\n",
      "Training round [43/100], Epoch [2/5], Step [20/47], Loss: 1.4138, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [43/100], Epoch [2/5], Step [40/47], Loss: 1.1804, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [43/100], Epoch [3/5], Step [20/47], Loss: 1.3816, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [43/100], Epoch [3/5], Step [40/47], Loss: 1.3494, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [43/100], Epoch [4/5], Step [20/47], Loss: 1.2451, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [43/100], Epoch [4/5], Step [40/47], Loss: 1.2012, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [43/100], Epoch [5/5], Step [20/47], Loss: 1.2627, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [43/100], Epoch [5/5], Step [40/47], Loss: 1.2693, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [43/100], qnn_train_step: [100/500], loss: 2.75836443901062, accuracy: 30.0 %\n",
      "Training round [43/100], qnn_train_step: [200/500], loss: 4.288431167602539, accuracy: 15.8 %\n",
      "Training round [43/100], qnn_train_step: [300/500], loss: 1.63054621219635, accuracy: 48.4 %\n",
      "Training round [43/100], qnn_train_step: [400/500], loss: 1.4099547863006592, accuracy: 53.7 %\n",
      "Training round [43/100], qnn_train_step: [500/500], loss: 1.3042173385620117, accuracy: 57.8 %\n",
      "-----------------------\n",
      "Training round [44/100], Epoch [1/5], Step [20/47], Loss: 1.4172, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [44/100], Epoch [1/5], Step [40/47], Loss: 1.3906, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [44/100], Epoch [2/5], Step [20/47], Loss: 1.3207, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [44/100], Epoch [2/5], Step [40/47], Loss: 1.3404, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [44/100], Epoch [3/5], Step [20/47], Loss: 1.2629, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [44/100], Epoch [3/5], Step [40/47], Loss: 1.3350, batch time: 0.29, accuracy:  59.38%\n",
      "Training round [44/100], Epoch [4/5], Step [20/47], Loss: 1.3100, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [44/100], Epoch [4/5], Step [40/47], Loss: 1.2438, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [44/100], Epoch [5/5], Step [20/47], Loss: 1.1952, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [44/100], Epoch [5/5], Step [40/47], Loss: 1.2936, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [44/100], qnn_train_step: [100/500], loss: 2.892791509628296, accuracy: 29.2 %\n",
      "Training round [44/100], qnn_train_step: [200/500], loss: 3.7225122451782227, accuracy: 15.7 %\n",
      "Training round [44/100], qnn_train_step: [300/500], loss: 1.721961259841919, accuracy: 48.4 %\n",
      "Training round [44/100], qnn_train_step: [400/500], loss: 2.36306095123291, accuracy: 39.5 %\n",
      "Training round [44/100], qnn_train_step: [500/500], loss: 1.5385501384735107, accuracy: 54.4 %\n",
      "-----------------------\n",
      "Training round [45/100], Epoch [1/5], Step [20/47], Loss: 1.3480, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [45/100], Epoch [1/5], Step [40/47], Loss: 1.2383, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [45/100], Epoch [2/5], Step [20/47], Loss: 1.3923, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [45/100], Epoch [2/5], Step [40/47], Loss: 1.2605, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [45/100], Epoch [3/5], Step [20/47], Loss: 1.3542, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [45/100], Epoch [3/5], Step [40/47], Loss: 1.4089, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [45/100], Epoch [4/5], Step [20/47], Loss: 1.2408, batch time: 0.29, accuracy:  63.28%\n",
      "Training round [45/100], Epoch [4/5], Step [40/47], Loss: 1.3188, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [45/100], Epoch [5/5], Step [20/47], Loss: 1.1828, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [45/100], Epoch [5/5], Step [40/47], Loss: 1.3177, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [45/100], qnn_train_step: [100/500], loss: 2.831566572189331, accuracy: 28.3 %\n",
      "Training round [45/100], qnn_train_step: [200/500], loss: 3.4561991691589355, accuracy: 20.6 %\n",
      "Training round [45/100], qnn_train_step: [300/500], loss: 1.3481929302215576, accuracy: 58.5 %\n",
      "Training round [45/100], qnn_train_step: [400/500], loss: 1.5339502096176147, accuracy: 53.9 %\n",
      "Training round [45/100], qnn_train_step: [500/500], loss: 1.5470854043960571, accuracy: 50.0 %\n",
      "-----------------------\n",
      "Training round [46/100], Epoch [1/5], Step [20/47], Loss: 1.2908, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [46/100], Epoch [1/5], Step [40/47], Loss: 1.1045, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [46/100], Epoch [2/5], Step [20/47], Loss: 1.3414, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [46/100], Epoch [2/5], Step [40/47], Loss: 1.2840, batch time: 0.29, accuracy:  62.50%\n",
      "Training round [46/100], Epoch [3/5], Step [20/47], Loss: 1.3833, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [46/100], Epoch [3/5], Step [40/47], Loss: 1.2862, batch time: 0.26, accuracy:  55.47%\n",
      "Training round [46/100], Epoch [4/5], Step [20/47], Loss: 1.5077, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [46/100], Epoch [4/5], Step [40/47], Loss: 1.2992, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [46/100], Epoch [5/5], Step [20/47], Loss: 1.3388, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [46/100], Epoch [5/5], Step [40/47], Loss: 1.2055, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [46/100], qnn_train_step: [100/500], loss: 2.780426502227783, accuracy: 28.9 %\n",
      "Training round [46/100], qnn_train_step: [200/500], loss: 4.018429279327393, accuracy: 16.4 %\n",
      "Training round [46/100], qnn_train_step: [300/500], loss: 1.7776490449905396, accuracy: 46.4 %\n",
      "Training round [46/100], qnn_train_step: [400/500], loss: 1.543238878250122, accuracy: 51.2 %\n",
      "Training round [46/100], qnn_train_step: [500/500], loss: 1.698606014251709, accuracy: 45.4 %\n",
      "-----------------------\n",
      "Training round [47/100], Epoch [1/5], Step [20/47], Loss: 1.1521, batch time: 0.29, accuracy:  66.41%\n",
      "Training round [47/100], Epoch [1/5], Step [40/47], Loss: 1.1425, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [47/100], Epoch [2/5], Step [20/47], Loss: 1.3009, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [47/100], Epoch [2/5], Step [40/47], Loss: 1.4341, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [47/100], Epoch [3/5], Step [20/47], Loss: 1.2020, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [47/100], Epoch [3/5], Step [40/47], Loss: 1.4682, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [47/100], Epoch [4/5], Step [20/47], Loss: 1.5264, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [47/100], Epoch [4/5], Step [40/47], Loss: 1.3496, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [47/100], Epoch [5/5], Step [20/47], Loss: 1.4180, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [47/100], Epoch [5/5], Step [40/47], Loss: 1.2356, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [47/100], qnn_train_step: [100/500], loss: 2.6216824054718018, accuracy: 29.0 %\n",
      "Training round [47/100], qnn_train_step: [200/500], loss: 5.171442985534668, accuracy: 14.9 %\n",
      "Training round [47/100], qnn_train_step: [300/500], loss: 1.5775296688079834, accuracy: 47.2 %\n",
      "Training round [47/100], qnn_train_step: [400/500], loss: 1.5468361377716064, accuracy: 52.1 %\n",
      "Training round [47/100], qnn_train_step: [500/500], loss: 1.3466522693634033, accuracy: 58.2 %\n",
      "-----------------------\n",
      "Training round [48/100], Epoch [1/5], Step [20/47], Loss: 1.3217, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [48/100], Epoch [1/5], Step [40/47], Loss: 1.2888, batch time: 0.30, accuracy:  58.59%\n",
      "Training round [48/100], Epoch [2/5], Step [20/47], Loss: 1.4541, batch time: 0.29, accuracy:  56.25%\n",
      "Training round [48/100], Epoch [2/5], Step [40/47], Loss: 1.2575, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [48/100], Epoch [3/5], Step [20/47], Loss: 1.4225, batch time: 0.29, accuracy:  50.78%\n",
      "Training round [48/100], Epoch [3/5], Step [40/47], Loss: 1.2067, batch time: 0.29, accuracy:  65.62%\n",
      "Training round [48/100], Epoch [4/5], Step [20/47], Loss: 1.2270, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [48/100], Epoch [4/5], Step [40/47], Loss: 1.4539, batch time: 0.30, accuracy:  51.56%\n",
      "Training round [48/100], Epoch [5/5], Step [20/47], Loss: 1.4196, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [48/100], Epoch [5/5], Step [40/47], Loss: 1.1969, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [48/100], qnn_train_step: [100/500], loss: 2.85632586479187, accuracy: 28.5 %\n",
      "Training round [48/100], qnn_train_step: [200/500], loss: 7.701229095458984, accuracy: 11.8 %\n",
      "Training round [48/100], qnn_train_step: [300/500], loss: 2.3989713191986084, accuracy: 39.9 %\n",
      "Training round [48/100], qnn_train_step: [400/500], loss: 1.4649009704589844, accuracy: 48.2 %\n",
      "Training round [48/100], qnn_train_step: [500/500], loss: 1.2673804759979248, accuracy: 60.2 %\n",
      "-----------------------\n",
      "Training round [49/100], Epoch [1/5], Step [20/47], Loss: 1.2493, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [49/100], Epoch [1/5], Step [40/47], Loss: 1.3344, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [49/100], Epoch [2/5], Step [20/47], Loss: 1.3866, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [49/100], Epoch [2/5], Step [40/47], Loss: 1.3696, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [49/100], Epoch [3/5], Step [20/47], Loss: 1.2276, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [49/100], Epoch [3/5], Step [40/47], Loss: 1.1842, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [49/100], Epoch [4/5], Step [20/47], Loss: 1.2855, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [49/100], Epoch [4/5], Step [40/47], Loss: 1.2250, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [49/100], Epoch [5/5], Step [20/47], Loss: 1.3002, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [49/100], Epoch [5/5], Step [40/47], Loss: 1.3074, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [49/100], qnn_train_step: [100/500], loss: 3.511584997177124, accuracy: 24.6 %\n",
      "Training round [49/100], qnn_train_step: [200/500], loss: 6.429841041564941, accuracy: 12.0 %\n",
      "Training round [49/100], qnn_train_step: [300/500], loss: 1.4368418455123901, accuracy: 55.2 %\n",
      "Training round [49/100], qnn_train_step: [400/500], loss: 1.7904318571090698, accuracy: 51.5 %\n",
      "Training round [49/100], qnn_train_step: [500/500], loss: 1.4362393617630005, accuracy: 57.3 %\n",
      "-----------------------\n",
      "Training round [50/100], Epoch [1/5], Step [20/47], Loss: 1.2620, batch time: 0.31, accuracy:  55.47%\n",
      "Training round [50/100], Epoch [1/5], Step [40/47], Loss: 1.3061, batch time: 0.31, accuracy:  55.47%\n",
      "Training round [50/100], Epoch [2/5], Step [20/47], Loss: 1.4793, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [50/100], Epoch [2/5], Step [40/47], Loss: 1.2648, batch time: 0.29, accuracy:  59.38%\n",
      "Training round [50/100], Epoch [3/5], Step [20/47], Loss: 1.2666, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [50/100], Epoch [3/5], Step [40/47], Loss: 1.1946, batch time: 0.30, accuracy:  64.06%\n",
      "Training round [50/100], Epoch [4/5], Step [20/47], Loss: 1.3795, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [50/100], Epoch [4/5], Step [40/47], Loss: 1.4401, batch time: 0.30, accuracy:  50.00%\n",
      "Training round [50/100], Epoch [5/5], Step [20/47], Loss: 1.1679, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [50/100], Epoch [5/5], Step [40/47], Loss: 1.2479, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [50/100], qnn_train_step: [100/500], loss: 3.3287293910980225, accuracy: 25.1 %\n",
      "Training round [50/100], qnn_train_step: [200/500], loss: 5.255395412445068, accuracy: 14.9 %\n",
      "Training round [50/100], qnn_train_step: [300/500], loss: 1.3856350183486938, accuracy: 57.4 %\n",
      "Training round [50/100], qnn_train_step: [400/500], loss: 1.7438997030258179, accuracy: 51.1 %\n",
      "Training round [50/100], qnn_train_step: [500/500], loss: 1.4574404954910278, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [51/100], Epoch [1/5], Step [20/47], Loss: 1.2940, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [51/100], Epoch [1/5], Step [40/47], Loss: 1.2559, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [51/100], Epoch [2/5], Step [20/47], Loss: 1.4445, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [51/100], Epoch [2/5], Step [40/47], Loss: 1.2351, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [51/100], Epoch [3/5], Step [20/47], Loss: 1.3732, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [51/100], Epoch [3/5], Step [40/47], Loss: 1.3361, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [51/100], Epoch [4/5], Step [20/47], Loss: 1.2762, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [51/100], Epoch [4/5], Step [40/47], Loss: 1.5113, batch time: 0.30, accuracy:  54.69%\n",
      "Training round [51/100], Epoch [5/5], Step [20/47], Loss: 1.2898, batch time: 0.30, accuracy:  60.94%\n",
      "Training round [51/100], Epoch [5/5], Step [40/47], Loss: 1.3061, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [51/100], qnn_train_step: [100/500], loss: 2.8846404552459717, accuracy: 24.9 %\n",
      "Training round [51/100], qnn_train_step: [200/500], loss: 5.37734317779541, accuracy: 14.0 %\n",
      "Training round [51/100], qnn_train_step: [300/500], loss: 1.3212573528289795, accuracy: 56.6 %\n",
      "Training round [51/100], qnn_train_step: [400/500], loss: 1.617362380027771, accuracy: 52.0 %\n",
      "Training round [51/100], qnn_train_step: [500/500], loss: 2.4425597190856934, accuracy: 39.7 %\n",
      "-----------------------\n",
      "Training round [52/100], Epoch [1/5], Step [20/47], Loss: 1.2015, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [52/100], Epoch [1/5], Step [40/47], Loss: 1.3181, batch time: 0.27, accuracy:  58.59%\n",
      "Training round [52/100], Epoch [2/5], Step [20/47], Loss: 1.3698, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [52/100], Epoch [2/5], Step [40/47], Loss: 1.3534, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [52/100], Epoch [3/5], Step [20/47], Loss: 1.4255, batch time: 0.12, accuracy:  57.03%\n",
      "Training round [52/100], Epoch [3/5], Step [40/47], Loss: 1.1610, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [52/100], Epoch [4/5], Step [20/47], Loss: 1.2553, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [52/100], Epoch [4/5], Step [40/47], Loss: 1.2761, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [52/100], Epoch [5/5], Step [20/47], Loss: 1.2977, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [52/100], Epoch [5/5], Step [40/47], Loss: 1.2204, batch time: 0.20, accuracy:  60.94%\n",
      "Training round [52/100], qnn_train_step: [100/500], loss: 3.0702056884765625, accuracy: 23.8 %\n",
      "Training round [52/100], qnn_train_step: [200/500], loss: 5.55773401260376, accuracy: 15.4 %\n",
      "Training round [52/100], qnn_train_step: [300/500], loss: 1.4884566068649292, accuracy: 51.5 %\n",
      "Training round [52/100], qnn_train_step: [400/500], loss: 1.7128716707229614, accuracy: 50.9 %\n",
      "Training round [52/100], qnn_train_step: [500/500], loss: 1.4995156526565552, accuracy: 52.4 %\n",
      "-----------------------\n",
      "Training round [53/100], Epoch [1/5], Step [20/47], Loss: 1.2212, batch time: 0.22, accuracy:  58.59%\n",
      "Training round [53/100], Epoch [1/5], Step [40/47], Loss: 1.5136, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [53/100], Epoch [2/5], Step [20/47], Loss: 1.3104, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [53/100], Epoch [2/5], Step [40/47], Loss: 1.4260, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [53/100], Epoch [3/5], Step [20/47], Loss: 1.3350, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [53/100], Epoch [3/5], Step [40/47], Loss: 1.3365, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [53/100], Epoch [4/5], Step [20/47], Loss: 1.3493, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [53/100], Epoch [4/5], Step [40/47], Loss: 1.3939, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [53/100], Epoch [5/5], Step [20/47], Loss: 1.2060, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [53/100], Epoch [5/5], Step [40/47], Loss: 1.3690, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [53/100], qnn_train_step: [100/500], loss: 3.25146746635437, accuracy: 24.7 %\n",
      "Training round [53/100], qnn_train_step: [200/500], loss: 5.544780731201172, accuracy: 13.3 %\n",
      "Training round [53/100], qnn_train_step: [300/500], loss: 1.4511890411376953, accuracy: 56.5 %\n",
      "Training round [53/100], qnn_train_step: [400/500], loss: 1.485883355140686, accuracy: 50.6 %\n",
      "Training round [53/100], qnn_train_step: [500/500], loss: 1.4404314756393433, accuracy: 57.4 %\n",
      "-----------------------\n",
      "Training round [54/100], Epoch [1/5], Step [20/47], Loss: 1.2175, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [54/100], Epoch [1/5], Step [40/47], Loss: 1.2880, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [54/100], Epoch [2/5], Step [20/47], Loss: 1.3436, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [54/100], Epoch [2/5], Step [40/47], Loss: 1.4486, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [54/100], Epoch [3/5], Step [20/47], Loss: 1.3042, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [54/100], Epoch [3/5], Step [40/47], Loss: 1.3526, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [54/100], Epoch [4/5], Step [20/47], Loss: 1.1202, batch time: 0.28, accuracy:  69.53%\n",
      "Training round [54/100], Epoch [4/5], Step [40/47], Loss: 1.4594, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [54/100], Epoch [5/5], Step [20/47], Loss: 1.2089, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [54/100], Epoch [5/5], Step [40/47], Loss: 1.1669, batch time: 0.23, accuracy:  60.16%\n",
      "Training round [54/100], qnn_train_step: [100/500], loss: 2.6246285438537598, accuracy: 29.1 %\n",
      "Training round [54/100], qnn_train_step: [200/500], loss: 5.772933006286621, accuracy: 13.0 %\n",
      "Training round [54/100], qnn_train_step: [300/500], loss: 1.3261934518814087, accuracy: 59.8 %\n",
      "Training round [54/100], qnn_train_step: [400/500], loss: 5.517709732055664, accuracy: 21.6 %\n",
      "Training round [54/100], qnn_train_step: [500/500], loss: 1.679787516593933, accuracy: 50.3 %\n",
      "-----------------------\n",
      "Training round [55/100], Epoch [1/5], Step [20/47], Loss: 1.0949, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [55/100], Epoch [1/5], Step [40/47], Loss: 1.3606, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [55/100], Epoch [2/5], Step [20/47], Loss: 1.3947, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [55/100], Epoch [2/5], Step [40/47], Loss: 1.2157, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [55/100], Epoch [3/5], Step [20/47], Loss: 1.1893, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [55/100], Epoch [3/5], Step [40/47], Loss: 1.3395, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [55/100], Epoch [4/5], Step [20/47], Loss: 1.3879, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [55/100], Epoch [4/5], Step [40/47], Loss: 1.3886, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [55/100], Epoch [5/5], Step [20/47], Loss: 1.4087, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [55/100], Epoch [5/5], Step [40/47], Loss: 1.2475, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [55/100], qnn_train_step: [100/500], loss: 2.5725395679473877, accuracy: 28.4 %\n",
      "Training round [55/100], qnn_train_step: [200/500], loss: 5.611773490905762, accuracy: 11.1 %\n",
      "Training round [55/100], qnn_train_step: [300/500], loss: 1.6589381694793701, accuracy: 44.8 %\n",
      "Training round [55/100], qnn_train_step: [400/500], loss: 2.0121335983276367, accuracy: 47.1 %\n",
      "Training round [55/100], qnn_train_step: [500/500], loss: 3.288041353225708, accuracy: 33.2 %\n",
      "-----------------------\n",
      "Training round [56/100], Epoch [1/5], Step [20/47], Loss: 1.4497, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [56/100], Epoch [1/5], Step [40/47], Loss: 1.2331, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [56/100], Epoch [2/5], Step [20/47], Loss: 1.3542, batch time: 0.12, accuracy:  55.47%\n",
      "Training round [56/100], Epoch [2/5], Step [40/47], Loss: 1.1063, batch time: 0.31, accuracy:  62.50%\n",
      "Training round [56/100], Epoch [3/5], Step [20/47], Loss: 1.1830, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [56/100], Epoch [3/5], Step [40/47], Loss: 1.3667, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [56/100], Epoch [4/5], Step [20/47], Loss: 1.1667, batch time: 0.12, accuracy:  67.97%\n",
      "Training round [56/100], Epoch [4/5], Step [40/47], Loss: 1.4235, batch time: 0.32, accuracy:  56.25%\n",
      "Training round [56/100], Epoch [5/5], Step [20/47], Loss: 1.2780, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [56/100], Epoch [5/5], Step [40/47], Loss: 1.1911, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [56/100], qnn_train_step: [100/500], loss: 2.504092216491699, accuracy: 28.4 %\n",
      "Training round [56/100], qnn_train_step: [200/500], loss: 3.3639464378356934, accuracy: 22.6 %\n",
      "Training round [56/100], qnn_train_step: [300/500], loss: 3.0528037548065186, accuracy: 29.9 %\n",
      "Training round [56/100], qnn_train_step: [400/500], loss: 1.350572943687439, accuracy: 58.6 %\n",
      "Training round [56/100], qnn_train_step: [500/500], loss: 1.4543789625167847, accuracy: 52.1 %\n",
      "-----------------------\n",
      "Training round [57/100], Epoch [1/5], Step [20/47], Loss: 1.2021, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [57/100], Epoch [1/5], Step [40/47], Loss: 1.3569, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [57/100], Epoch [2/5], Step [20/47], Loss: 1.2031, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [57/100], Epoch [2/5], Step [40/47], Loss: 1.1510, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [57/100], Epoch [3/5], Step [20/47], Loss: 1.4831, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [57/100], Epoch [3/5], Step [40/47], Loss: 1.1532, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [57/100], Epoch [4/5], Step [20/47], Loss: 1.2965, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [57/100], Epoch [4/5], Step [40/47], Loss: 1.2938, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [57/100], Epoch [5/5], Step [20/47], Loss: 1.2361, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [57/100], Epoch [5/5], Step [40/47], Loss: 1.1903, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [57/100], qnn_train_step: [100/500], loss: 2.5991427898406982, accuracy: 27.3 %\n",
      "Training round [57/100], qnn_train_step: [200/500], loss: 5.233565330505371, accuracy: 12.2 %\n",
      "Training round [57/100], qnn_train_step: [300/500], loss: 1.5600123405456543, accuracy: 52.0 %\n",
      "Training round [57/100], qnn_train_step: [400/500], loss: 1.3270505666732788, accuracy: 58.5 %\n",
      "Training round [57/100], qnn_train_step: [500/500], loss: 1.3002692461013794, accuracy: 60.0 %\n",
      "-----------------------\n",
      "Training round [58/100], Epoch [1/5], Step [20/47], Loss: 1.2448, batch time: 0.12, accuracy:  61.72%\n",
      "Training round [58/100], Epoch [1/5], Step [40/47], Loss: 1.2565, batch time: 0.12, accuracy:  58.59%\n",
      "Training round [58/100], Epoch [2/5], Step [20/47], Loss: 1.6683, batch time: 0.17, accuracy:  50.78%\n",
      "Training round [58/100], Epoch [2/5], Step [40/47], Loss: 1.1681, batch time: 0.17, accuracy:  64.84%\n",
      "Training round [58/100], Epoch [3/5], Step [20/47], Loss: 1.2765, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [58/100], Epoch [3/5], Step [40/47], Loss: 1.3083, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [58/100], Epoch [4/5], Step [20/47], Loss: 1.2494, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [58/100], Epoch [4/5], Step [40/47], Loss: 1.2397, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [58/100], Epoch [5/5], Step [20/47], Loss: 1.2386, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [58/100], Epoch [5/5], Step [40/47], Loss: 1.2802, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [58/100], qnn_train_step: [100/500], loss: 2.913182497024536, accuracy: 24.7 %\n",
      "Training round [58/100], qnn_train_step: [200/500], loss: 4.374208450317383, accuracy: 16.6 %\n",
      "Training round [58/100], qnn_train_step: [300/500], loss: 1.5216526985168457, accuracy: 50.9 %\n",
      "Training round [58/100], qnn_train_step: [400/500], loss: 1.2943288087844849, accuracy: 58.9 %\n",
      "Training round [58/100], qnn_train_step: [500/500], loss: 2.6924054622650146, accuracy: 29.8 %\n",
      "-----------------------\n",
      "Training round [59/100], Epoch [1/5], Step [20/47], Loss: 1.1256, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [59/100], Epoch [1/5], Step [40/47], Loss: 1.3521, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [59/100], Epoch [2/5], Step [20/47], Loss: 1.1765, batch time: 0.29, accuracy:  60.16%\n",
      "Training round [59/100], Epoch [2/5], Step [40/47], Loss: 1.1286, batch time: 0.29, accuracy:  64.84%\n",
      "Training round [59/100], Epoch [3/5], Step [20/47], Loss: 1.2301, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [59/100], Epoch [3/5], Step [40/47], Loss: 1.2880, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [59/100], Epoch [4/5], Step [20/47], Loss: 1.4436, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [59/100], Epoch [4/5], Step [40/47], Loss: 1.3355, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [59/100], Epoch [5/5], Step [20/47], Loss: 1.1322, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [59/100], Epoch [5/5], Step [40/47], Loss: 1.1735, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [59/100], qnn_train_step: [100/500], loss: 2.915184736251831, accuracy: 21.7 %\n",
      "Training round [59/100], qnn_train_step: [200/500], loss: 5.193897724151611, accuracy: 15.5 %\n",
      "Training round [59/100], qnn_train_step: [300/500], loss: 1.7686233520507812, accuracy: 48.8 %\n",
      "Training round [59/100], qnn_train_step: [400/500], loss: 6.85608434677124, accuracy: 16.5 %\n",
      "Training round [59/100], qnn_train_step: [500/500], loss: 2.055527925491333, accuracy: 40.1 %\n",
      "-----------------------\n",
      "Training round [60/100], Epoch [1/5], Step [20/47], Loss: 1.3380, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [60/100], Epoch [1/5], Step [40/47], Loss: 1.2964, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [60/100], Epoch [2/5], Step [20/47], Loss: 1.0549, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [60/100], Epoch [2/5], Step [40/47], Loss: 1.3813, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [60/100], Epoch [3/5], Step [20/47], Loss: 1.1886, batch time: 0.21, accuracy:  58.59%\n",
      "Training round [60/100], Epoch [3/5], Step [40/47], Loss: 1.4487, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [60/100], Epoch [4/5], Step [20/47], Loss: 1.2164, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [60/100], Epoch [4/5], Step [40/47], Loss: 1.3934, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [60/100], Epoch [5/5], Step [20/47], Loss: 1.2395, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [60/100], Epoch [5/5], Step [40/47], Loss: 1.4361, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [60/100], qnn_train_step: [100/500], loss: 2.9146997928619385, accuracy: 23.2 %\n",
      "Training round [60/100], qnn_train_step: [200/500], loss: 5.258000373840332, accuracy: 15.5 %\n",
      "Training round [60/100], qnn_train_step: [300/500], loss: 1.3879327774047852, accuracy: 55.8 %\n",
      "Training round [60/100], qnn_train_step: [400/500], loss: 1.4456321001052856, accuracy: 55.4 %\n",
      "Training round [60/100], qnn_train_step: [500/500], loss: 1.9830132722854614, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [61/100], Epoch [1/5], Step [20/47], Loss: 1.2496, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [61/100], Epoch [1/5], Step [40/47], Loss: 1.4358, batch time: 0.12, accuracy:  49.22%\n",
      "Training round [61/100], Epoch [2/5], Step [20/47], Loss: 1.1490, batch time: 0.29, accuracy:  64.84%\n",
      "Training round [61/100], Epoch [2/5], Step [40/47], Loss: 1.3040, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [61/100], Epoch [3/5], Step [20/47], Loss: 1.2814, batch time: 0.10, accuracy:  64.06%\n",
      "Training round [61/100], Epoch [3/5], Step [40/47], Loss: 1.3765, batch time: 0.29, accuracy:  60.94%\n",
      "Training round [61/100], Epoch [4/5], Step [20/47], Loss: 1.2099, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [61/100], Epoch [4/5], Step [40/47], Loss: 1.2552, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [61/100], Epoch [5/5], Step [20/47], Loss: 1.4071, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [61/100], Epoch [5/5], Step [40/47], Loss: 1.3821, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [61/100], qnn_train_step: [100/500], loss: 2.718233823776245, accuracy: 22.4 %\n",
      "Training round [61/100], qnn_train_step: [200/500], loss: 5.631227970123291, accuracy: 14.8 %\n",
      "Training round [61/100], qnn_train_step: [300/500], loss: 1.8216487169265747, accuracy: 47.9 %\n",
      "Training round [61/100], qnn_train_step: [400/500], loss: 1.4304993152618408, accuracy: 53.3 %\n",
      "Training round [61/100], qnn_train_step: [500/500], loss: 1.3812154531478882, accuracy: 55.9 %\n",
      "-----------------------\n",
      "Training round [62/100], Epoch [1/5], Step [20/47], Loss: 1.2568, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [62/100], Epoch [1/5], Step [40/47], Loss: 1.0650, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [62/100], Epoch [2/5], Step [20/47], Loss: 1.0727, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [62/100], Epoch [2/5], Step [40/47], Loss: 1.2053, batch time: 0.10, accuracy:  63.28%\n",
      "Training round [62/100], Epoch [3/5], Step [20/47], Loss: 1.1763, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [62/100], Epoch [3/5], Step [40/47], Loss: 1.0774, batch time: 0.10, accuracy:  64.84%\n",
      "Training round [62/100], Epoch [4/5], Step [20/47], Loss: 1.0279, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [62/100], Epoch [4/5], Step [40/47], Loss: 1.1107, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [62/100], Epoch [5/5], Step [20/47], Loss: 1.2429, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [62/100], Epoch [5/5], Step [40/47], Loss: 1.1441, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [62/100], qnn_train_step: [100/500], loss: 2.8700685501098633, accuracy: 22.2 %\n",
      "Training round [62/100], qnn_train_step: [200/500], loss: 6.349982738494873, accuracy: 13.1 %\n",
      "Training round [62/100], qnn_train_step: [300/500], loss: 1.7890782356262207, accuracy: 49.2 %\n",
      "Training round [62/100], qnn_train_step: [400/500], loss: 1.4244625568389893, accuracy: 56.2 %\n",
      "Training round [62/100], qnn_train_step: [500/500], loss: 1.310518741607666, accuracy: 57.5 %\n",
      "-----------------------\n",
      "Training round [63/100], Epoch [1/5], Step [20/47], Loss: 1.1717, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [63/100], Epoch [1/5], Step [40/47], Loss: 1.2660, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [63/100], Epoch [2/5], Step [20/47], Loss: 1.5862, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [63/100], Epoch [2/5], Step [40/47], Loss: 1.1966, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [63/100], Epoch [3/5], Step [20/47], Loss: 1.3117, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [63/100], Epoch [3/5], Step [40/47], Loss: 1.3326, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [63/100], Epoch [4/5], Step [20/47], Loss: 1.1275, batch time: 0.10, accuracy:  60.94%\n",
      "Training round [63/100], Epoch [4/5], Step [40/47], Loss: 1.3467, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [63/100], Epoch [5/5], Step [20/47], Loss: 1.2811, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [63/100], Epoch [5/5], Step [40/47], Loss: 1.1237, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [63/100], qnn_train_step: [100/500], loss: 2.9428622722625732, accuracy: 22.2 %\n",
      "Training round [63/100], qnn_train_step: [200/500], loss: 6.376959800720215, accuracy: 12.5 %\n",
      "Training round [63/100], qnn_train_step: [300/500], loss: 1.3195704221725464, accuracy: 57.0 %\n",
      "Training round [63/100], qnn_train_step: [400/500], loss: 1.4322525262832642, accuracy: 54.6 %\n",
      "Training round [63/100], qnn_train_step: [500/500], loss: 1.2927058935165405, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [64/100], Epoch [1/5], Step [20/47], Loss: 1.1460, batch time: 0.14, accuracy:  53.91%\n",
      "Training round [64/100], Epoch [1/5], Step [40/47], Loss: 1.2829, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [64/100], Epoch [2/5], Step [20/47], Loss: 1.3115, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [64/100], Epoch [2/5], Step [40/47], Loss: 1.1650, batch time: 0.10, accuracy:  61.72%\n",
      "Training round [64/100], Epoch [3/5], Step [20/47], Loss: 1.3067, batch time: 0.13, accuracy:  52.34%\n",
      "Training round [64/100], Epoch [3/5], Step [40/47], Loss: 1.2313, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [64/100], Epoch [4/5], Step [20/47], Loss: 1.1956, batch time: 0.15, accuracy:  57.81%\n",
      "Training round [64/100], Epoch [4/5], Step [40/47], Loss: 1.4026, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [64/100], Epoch [5/5], Step [20/47], Loss: 1.1446, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [64/100], Epoch [5/5], Step [40/47], Loss: 1.3030, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [64/100], qnn_train_step: [100/500], loss: 2.815619707107544, accuracy: 20.7 %\n",
      "Training round [64/100], qnn_train_step: [200/500], loss: 5.901449680328369, accuracy: 15.2 %\n",
      "Training round [64/100], qnn_train_step: [300/500], loss: 1.8065921068191528, accuracy: 48.7 %\n",
      "Training round [64/100], qnn_train_step: [400/500], loss: 1.423509120941162, accuracy: 55.4 %\n",
      "Training round [64/100], qnn_train_step: [500/500], loss: 1.703452229499817, accuracy: 45.0 %\n",
      "-----------------------\n",
      "Training round [65/100], Epoch [1/5], Step [20/47], Loss: 1.3250, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [65/100], Epoch [1/5], Step [40/47], Loss: 1.1703, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [65/100], Epoch [2/5], Step [20/47], Loss: 1.2550, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [65/100], Epoch [2/5], Step [40/47], Loss: 1.3452, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [65/100], Epoch [3/5], Step [20/47], Loss: 1.0014, batch time: 0.10, accuracy:  65.62%\n",
      "Training round [65/100], Epoch [3/5], Step [40/47], Loss: 1.2147, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [65/100], Epoch [4/5], Step [20/47], Loss: 1.2154, batch time: 0.29, accuracy:  62.50%\n",
      "Training round [65/100], Epoch [4/5], Step [40/47], Loss: 1.4012, batch time: 0.30, accuracy:  53.12%\n",
      "Training round [65/100], Epoch [5/5], Step [20/47], Loss: 1.1195, batch time: 0.12, accuracy:  61.72%\n",
      "Training round [65/100], Epoch [5/5], Step [40/47], Loss: 1.2786, batch time: 0.29, accuracy:  56.25%\n",
      "Training round [65/100], qnn_train_step: [100/500], loss: 2.706758975982666, accuracy: 23.4 %\n",
      "Training round [65/100], qnn_train_step: [200/500], loss: 6.373407363891602, accuracy: 14.1 %\n",
      "Training round [65/100], qnn_train_step: [300/500], loss: 1.35392165184021, accuracy: 55.9 %\n",
      "Training round [65/100], qnn_train_step: [400/500], loss: 1.4137136936187744, accuracy: 53.1 %\n",
      "Training round [65/100], qnn_train_step: [500/500], loss: 1.28630530834198, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [66/100], Epoch [1/5], Step [20/47], Loss: 1.1684, batch time: 0.63, accuracy:  64.84%\n",
      "Training round [66/100], Epoch [1/5], Step [40/47], Loss: 1.3886, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [66/100], Epoch [2/5], Step [20/47], Loss: 1.2387, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [66/100], Epoch [2/5], Step [40/47], Loss: 1.3267, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [66/100], Epoch [3/5], Step [20/47], Loss: 1.3738, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [66/100], Epoch [3/5], Step [40/47], Loss: 1.0805, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [66/100], Epoch [4/5], Step [20/47], Loss: 1.0825, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [66/100], Epoch [4/5], Step [40/47], Loss: 1.2425, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [66/100], Epoch [5/5], Step [20/47], Loss: 1.1002, batch time: 0.10, accuracy:  66.41%\n",
      "Training round [66/100], Epoch [5/5], Step [40/47], Loss: 1.2700, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [66/100], qnn_train_step: [100/500], loss: 2.9628233909606934, accuracy: 23.1 %\n",
      "Training round [66/100], qnn_train_step: [200/500], loss: 6.614177227020264, accuracy: 14.2 %\n",
      "Training round [66/100], qnn_train_step: [300/500], loss: 1.739915370941162, accuracy: 45.8 %\n",
      "Training round [66/100], qnn_train_step: [400/500], loss: 1.5511231422424316, accuracy: 47.9 %\n",
      "Training round [66/100], qnn_train_step: [500/500], loss: 6.155950546264648, accuracy: 15.7 %\n",
      "-----------------------\n",
      "Training round [67/100], Epoch [1/5], Step [20/47], Loss: 1.2644, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [67/100], Epoch [1/5], Step [40/47], Loss: 1.2620, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [67/100], Epoch [2/5], Step [20/47], Loss: 1.2301, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [67/100], Epoch [2/5], Step [40/47], Loss: 1.2329, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [67/100], Epoch [3/5], Step [20/47], Loss: 1.3325, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [67/100], Epoch [3/5], Step [40/47], Loss: 1.1751, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [67/100], Epoch [4/5], Step [20/47], Loss: 1.1582, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [67/100], Epoch [4/5], Step [40/47], Loss: 1.4790, batch time: 0.14, accuracy:  53.91%\n",
      "Training round [67/100], Epoch [5/5], Step [20/47], Loss: 1.3777, batch time: 0.30, accuracy:  57.03%\n",
      "Training round [67/100], Epoch [5/5], Step [40/47], Loss: 1.1947, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [67/100], qnn_train_step: [100/500], loss: 2.9077696800231934, accuracy: 19.7 %\n",
      "Training round [67/100], qnn_train_step: [200/500], loss: 6.214907169342041, accuracy: 11.9 %\n",
      "Training round [67/100], qnn_train_step: [300/500], loss: 7.470096588134766, accuracy: 14.7 %\n",
      "Training round [67/100], qnn_train_step: [400/500], loss: 1.298079252243042, accuracy: 58.1 %\n",
      "Training round [67/100], qnn_train_step: [500/500], loss: 1.361474871635437, accuracy: 56.6 %\n",
      "-----------------------\n",
      "Training round [68/100], Epoch [1/5], Step [20/47], Loss: 1.2797, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [68/100], Epoch [1/5], Step [40/47], Loss: 1.3791, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [68/100], Epoch [2/5], Step [20/47], Loss: 1.2228, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [68/100], Epoch [2/5], Step [40/47], Loss: 1.3561, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [68/100], Epoch [3/5], Step [20/47], Loss: 1.2913, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [68/100], Epoch [3/5], Step [40/47], Loss: 1.1997, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [68/100], Epoch [4/5], Step [20/47], Loss: 1.1149, batch time: 0.30, accuracy:  67.19%\n",
      "Training round [68/100], Epoch [4/5], Step [40/47], Loss: 1.2951, batch time: 0.29, accuracy:  53.91%\n",
      "Training round [68/100], Epoch [5/5], Step [20/47], Loss: 1.2222, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [68/100], Epoch [5/5], Step [40/47], Loss: 1.1263, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [68/100], qnn_train_step: [100/500], loss: 2.7699761390686035, accuracy: 21.8 %\n",
      "Training round [68/100], qnn_train_step: [200/500], loss: 6.073187351226807, accuracy: 10.9 %\n",
      "Training round [68/100], qnn_train_step: [300/500], loss: 1.3048030138015747, accuracy: 59.1 %\n",
      "Training round [68/100], qnn_train_step: [400/500], loss: 1.4215701818466187, accuracy: 55.5 %\n",
      "Training round [68/100], qnn_train_step: [500/500], loss: 3.0130040645599365, accuracy: 26.0 %\n",
      "-----------------------\n",
      "Training round [69/100], Epoch [1/5], Step [20/47], Loss: 1.3375, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [69/100], Epoch [1/5], Step [40/47], Loss: 1.3838, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [69/100], Epoch [2/5], Step [20/47], Loss: 1.3094, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [69/100], Epoch [2/5], Step [40/47], Loss: 1.1516, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [69/100], Epoch [3/5], Step [20/47], Loss: 1.3367, batch time: 0.31, accuracy:  60.16%\n",
      "Training round [69/100], Epoch [3/5], Step [40/47], Loss: 1.3537, batch time: 0.14, accuracy:  56.25%\n",
      "Training round [69/100], Epoch [4/5], Step [20/47], Loss: 1.1164, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [69/100], Epoch [4/5], Step [40/47], Loss: 1.0711, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [69/100], Epoch [5/5], Step [20/47], Loss: 1.3494, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [69/100], Epoch [5/5], Step [40/47], Loss: 1.1749, batch time: 0.17, accuracy:  55.47%\n",
      "Training round [69/100], qnn_train_step: [100/500], loss: 2.5989792346954346, accuracy: 26.1 %\n",
      "Training round [69/100], qnn_train_step: [200/500], loss: 5.577518463134766, accuracy: 11.6 %\n",
      "Training round [69/100], qnn_train_step: [300/500], loss: 1.8087695837020874, accuracy: 48.5 %\n",
      "Training round [69/100], qnn_train_step: [400/500], loss: 1.391433835029602, accuracy: 56.2 %\n",
      "Training round [69/100], qnn_train_step: [500/500], loss: 1.3628250360488892, accuracy: 55.7 %\n",
      "-----------------------\n",
      "Training round [70/100], Epoch [1/5], Step [20/47], Loss: 1.2754, batch time: 0.30, accuracy:  57.03%\n",
      "Training round [70/100], Epoch [1/5], Step [40/47], Loss: 1.1201, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [70/100], Epoch [2/5], Step [20/47], Loss: 1.2508, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [70/100], Epoch [2/5], Step [40/47], Loss: 1.0520, batch time: 0.29, accuracy:  64.06%\n",
      "Training round [70/100], Epoch [3/5], Step [20/47], Loss: 1.3782, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [70/100], Epoch [3/5], Step [40/47], Loss: 1.1736, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [70/100], Epoch [4/5], Step [20/47], Loss: 1.3038, batch time: 0.25, accuracy:  60.16%\n",
      "Training round [70/100], Epoch [4/5], Step [40/47], Loss: 1.2453, batch time: 0.12, accuracy:  56.25%\n",
      "Training round [70/100], Epoch [5/5], Step [20/47], Loss: 1.2090, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [70/100], Epoch [5/5], Step [40/47], Loss: 1.2600, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [70/100], qnn_train_step: [100/500], loss: 2.9799253940582275, accuracy: 22.4 %\n",
      "Training round [70/100], qnn_train_step: [200/500], loss: 5.36879825592041, accuracy: 12.0 %\n",
      "Training round [70/100], qnn_train_step: [300/500], loss: 1.852580189704895, accuracy: 49.9 %\n",
      "Training round [70/100], qnn_train_step: [400/500], loss: 1.4038548469543457, accuracy: 54.7 %\n",
      "Training round [70/100], qnn_train_step: [500/500], loss: 1.966572880744934, accuracy: 41.1 %\n",
      "-----------------------\n",
      "Training round [71/100], Epoch [1/5], Step [20/47], Loss: 1.1475, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [71/100], Epoch [1/5], Step [40/47], Loss: 1.0451, batch time: 0.35, accuracy:  63.28%\n",
      "Training round [71/100], Epoch [2/5], Step [20/47], Loss: 1.1228, batch time: 0.36, accuracy:  66.41%\n",
      "Training round [71/100], Epoch [2/5], Step [40/47], Loss: 1.3424, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [71/100], Epoch [3/5], Step [20/47], Loss: 1.2457, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [71/100], Epoch [3/5], Step [40/47], Loss: 1.1443, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [71/100], Epoch [4/5], Step [20/47], Loss: 1.1579, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [71/100], Epoch [4/5], Step [40/47], Loss: 1.3216, batch time: 0.29, accuracy:  57.81%\n",
      "Training round [71/100], Epoch [5/5], Step [20/47], Loss: 1.3258, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [71/100], Epoch [5/5], Step [40/47], Loss: 1.3331, batch time: 0.11, accuracy:  52.34%\n",
      "Training round [71/100], qnn_train_step: [100/500], loss: 2.8164165019989014, accuracy: 28.9 %\n",
      "Training round [71/100], qnn_train_step: [200/500], loss: 5.671904563903809, accuracy: 11.8 %\n",
      "Training round [71/100], qnn_train_step: [300/500], loss: 1.273837924003601, accuracy: 57.6 %\n",
      "Training round [71/100], qnn_train_step: [400/500], loss: 1.269961953163147, accuracy: 58.6 %\n",
      "Training round [71/100], qnn_train_step: [500/500], loss: 3.2287492752075195, accuracy: 33.6 %\n",
      "-----------------------\n",
      "Training round [72/100], Epoch [1/5], Step [20/47], Loss: 1.3543, batch time: 0.63, accuracy:  58.59%\n",
      "Training round [72/100], Epoch [1/5], Step [40/47], Loss: 1.1634, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [72/100], Epoch [2/5], Step [20/47], Loss: 1.3911, batch time: 0.29, accuracy:  56.25%\n",
      "Training round [72/100], Epoch [2/5], Step [40/47], Loss: 1.3318, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [72/100], Epoch [3/5], Step [20/47], Loss: 1.3058, batch time: 0.30, accuracy:  50.78%\n",
      "Training round [72/100], Epoch [3/5], Step [40/47], Loss: 1.0517, batch time: 0.30, accuracy:  66.41%\n",
      "Training round [72/100], Epoch [4/5], Step [20/47], Loss: 1.1542, batch time: 0.12, accuracy:  60.16%\n",
      "Training round [72/100], Epoch [4/5], Step [40/47], Loss: 1.2022, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [72/100], Epoch [5/5], Step [20/47], Loss: 1.2259, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [72/100], Epoch [5/5], Step [40/47], Loss: 1.3021, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [72/100], qnn_train_step: [100/500], loss: 2.977283477783203, accuracy: 24.9 %\n",
      "Training round [72/100], qnn_train_step: [200/500], loss: 5.292803764343262, accuracy: 10.9 %\n",
      "Training round [72/100], qnn_train_step: [300/500], loss: 1.8675923347473145, accuracy: 48.1 %\n",
      "Training round [72/100], qnn_train_step: [400/500], loss: 1.4352737665176392, accuracy: 53.8 %\n",
      "Training round [72/100], qnn_train_step: [500/500], loss: 1.346445918083191, accuracy: 57.8 %\n",
      "-----------------------\n",
      "Training round [73/100], Epoch [1/5], Step [20/47], Loss: 1.1016, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [73/100], Epoch [1/5], Step [40/47], Loss: 1.2032, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [73/100], Epoch [2/5], Step [20/47], Loss: 1.3538, batch time: 0.12, accuracy:  54.69%\n",
      "Training round [73/100], Epoch [2/5], Step [40/47], Loss: 1.1638, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [73/100], Epoch [3/5], Step [20/47], Loss: 1.3288, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [73/100], Epoch [3/5], Step [40/47], Loss: 1.2478, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [73/100], Epoch [4/5], Step [20/47], Loss: 1.1365, batch time: 0.22, accuracy:  68.75%\n",
      "Training round [73/100], Epoch [4/5], Step [40/47], Loss: 1.1967, batch time: 0.26, accuracy:  61.72%\n",
      "Training round [73/100], Epoch [5/5], Step [20/47], Loss: 1.2658, batch time: 0.30, accuracy:  56.25%\n",
      "Training round [73/100], Epoch [5/5], Step [40/47], Loss: 1.2852, batch time: 0.30, accuracy:  52.34%\n",
      "Training round [73/100], qnn_train_step: [100/500], loss: 2.7221312522888184, accuracy: 26.7 %\n",
      "Training round [73/100], qnn_train_step: [200/500], loss: 5.337873458862305, accuracy: 11.4 %\n",
      "Training round [73/100], qnn_train_step: [300/500], loss: 1.3382418155670166, accuracy: 53.8 %\n",
      "Training round [73/100], qnn_train_step: [400/500], loss: 1.3645927906036377, accuracy: 55.5 %\n",
      "Training round [73/100], qnn_train_step: [500/500], loss: 1.609452486038208, accuracy: 48.9 %\n",
      "-----------------------\n",
      "Training round [74/100], Epoch [1/5], Step [20/47], Loss: 1.0766, batch time: 0.32, accuracy:  60.16%\n",
      "Training round [74/100], Epoch [1/5], Step [40/47], Loss: 1.3083, batch time: 0.33, accuracy:  58.59%\n",
      "Training round [74/100], Epoch [2/5], Step [20/47], Loss: 1.3640, batch time: 0.18, accuracy:  55.47%\n",
      "Training round [74/100], Epoch [2/5], Step [40/47], Loss: 1.0661, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [74/100], Epoch [3/5], Step [20/47], Loss: 1.2052, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [74/100], Epoch [3/5], Step [40/47], Loss: 1.2029, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [74/100], Epoch [4/5], Step [20/47], Loss: 1.1864, batch time: 0.12, accuracy:  62.50%\n",
      "Training round [74/100], Epoch [4/5], Step [40/47], Loss: 1.2221, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [74/100], Epoch [5/5], Step [20/47], Loss: 1.2003, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [74/100], Epoch [5/5], Step [40/47], Loss: 1.1464, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [74/100], qnn_train_step: [100/500], loss: 3.1585075855255127, accuracy: 21.3 %\n",
      "Training round [74/100], qnn_train_step: [200/500], loss: 5.363985061645508, accuracy: 11.7 %\n",
      "Training round [74/100], qnn_train_step: [300/500], loss: 2.473846197128296, accuracy: 37.4 %\n",
      "Training round [74/100], qnn_train_step: [400/500], loss: 2.028770685195923, accuracy: 46.0 %\n",
      "Training round [74/100], qnn_train_step: [500/500], loss: 1.610923171043396, accuracy: 49.8 %\n",
      "-----------------------\n",
      "Training round [75/100], Epoch [1/5], Step [20/47], Loss: 1.3389, batch time: 0.11, accuracy:  50.78%\n",
      "Training round [75/100], Epoch [1/5], Step [40/47], Loss: 1.1728, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [75/100], Epoch [2/5], Step [20/47], Loss: 1.2232, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [75/100], Epoch [2/5], Step [40/47], Loss: 1.1710, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [75/100], Epoch [3/5], Step [20/47], Loss: 1.3105, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [75/100], Epoch [3/5], Step [40/47], Loss: 1.2761, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [75/100], Epoch [4/5], Step [20/47], Loss: 1.1702, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [75/100], Epoch [4/5], Step [40/47], Loss: 1.2071, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [75/100], Epoch [5/5], Step [20/47], Loss: 1.1272, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [75/100], Epoch [5/5], Step [40/47], Loss: 1.3050, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [75/100], qnn_train_step: [100/500], loss: 2.7975924015045166, accuracy: 26.6 %\n",
      "Training round [75/100], qnn_train_step: [200/500], loss: 7.438155651092529, accuracy: 10.1 %\n",
      "Training round [75/100], qnn_train_step: [300/500], loss: 1.1704163551330566, accuracy: 62.9 %\n",
      "Training round [75/100], qnn_train_step: [400/500], loss: 1.3460301160812378, accuracy: 56.1 %\n",
      "Training round [75/100], qnn_train_step: [500/500], loss: 2.652803897857666, accuracy: 30.5 %\n",
      "-----------------------\n",
      "Training round [76/100], Epoch [1/5], Step [20/47], Loss: 1.1821, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [76/100], Epoch [1/5], Step [40/47], Loss: 1.2227, batch time: 0.12, accuracy:  60.94%\n",
      "Training round [76/100], Epoch [2/5], Step [20/47], Loss: 1.4131, batch time: 0.12, accuracy:  56.25%\n",
      "Training round [76/100], Epoch [2/5], Step [40/47], Loss: 1.2554, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [76/100], Epoch [3/5], Step [20/47], Loss: 1.1960, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [76/100], Epoch [3/5], Step [40/47], Loss: 1.1269, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [76/100], Epoch [4/5], Step [20/47], Loss: 1.2991, batch time: 0.12, accuracy:  58.59%\n",
      "Training round [76/100], Epoch [4/5], Step [40/47], Loss: 1.1372, batch time: 0.31, accuracy:  60.94%\n",
      "Training round [76/100], Epoch [5/5], Step [20/47], Loss: 1.2868, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [76/100], Epoch [5/5], Step [40/47], Loss: 1.1382, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [76/100], qnn_train_step: [100/500], loss: 3.1680004596710205, accuracy: 23.2 %\n",
      "Training round [76/100], qnn_train_step: [200/500], loss: 7.8198041915893555, accuracy: 10.6 %\n",
      "Training round [76/100], qnn_train_step: [300/500], loss: 1.3897818326950073, accuracy: 52.0 %\n",
      "Training round [76/100], qnn_train_step: [400/500], loss: 1.4611409902572632, accuracy: 51.3 %\n",
      "Training round [76/100], qnn_train_step: [500/500], loss: 3.068650960922241, accuracy: 34.5 %\n",
      "-----------------------\n",
      "Training round [77/100], Epoch [1/5], Step [20/47], Loss: 1.3155, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [77/100], Epoch [1/5], Step [40/47], Loss: 1.2511, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [77/100], Epoch [2/5], Step [20/47], Loss: 1.4921, batch time: 0.11, accuracy:  51.56%\n",
      "Training round [77/100], Epoch [2/5], Step [40/47], Loss: 1.1454, batch time: 0.37, accuracy:  63.28%\n",
      "Training round [77/100], Epoch [3/5], Step [20/47], Loss: 1.1176, batch time: 0.34, accuracy:  67.19%\n",
      "Training round [77/100], Epoch [3/5], Step [40/47], Loss: 1.2251, batch time: 0.35, accuracy:  57.81%\n",
      "Training round [77/100], Epoch [4/5], Step [20/47], Loss: 1.1537, batch time: 0.35, accuracy:  61.72%\n",
      "Training round [77/100], Epoch [4/5], Step [40/47], Loss: 1.0691, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [77/100], Epoch [5/5], Step [20/47], Loss: 1.1933, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [77/100], Epoch [5/5], Step [40/47], Loss: 1.1559, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [77/100], qnn_train_step: [100/500], loss: 3.150547742843628, accuracy: 22.1 %\n",
      "Training round [77/100], qnn_train_step: [200/500], loss: 8.898977279663086, accuracy: 11.4 %\n",
      "Training round [77/100], qnn_train_step: [300/500], loss: 1.3078007698059082, accuracy: 56.9 %\n",
      "Training round [77/100], qnn_train_step: [400/500], loss: 1.3885478973388672, accuracy: 55.2 %\n",
      "Training round [77/100], qnn_train_step: [500/500], loss: 1.4720232486724854, accuracy: 53.5 %\n",
      "-----------------------\n",
      "Training round [78/100], Epoch [1/5], Step [20/47], Loss: 1.3109, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [78/100], Epoch [1/5], Step [40/47], Loss: 1.1525, batch time: 0.29, accuracy:  61.72%\n",
      "Training round [78/100], Epoch [2/5], Step [20/47], Loss: 1.2447, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [78/100], Epoch [2/5], Step [40/47], Loss: 1.1636, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [78/100], Epoch [3/5], Step [20/47], Loss: 1.3654, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [78/100], Epoch [3/5], Step [40/47], Loss: 1.1378, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [78/100], Epoch [4/5], Step [20/47], Loss: 1.2993, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [78/100], Epoch [4/5], Step [40/47], Loss: 1.1483, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [78/100], Epoch [5/5], Step [20/47], Loss: 1.2137, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [78/100], Epoch [5/5], Step [40/47], Loss: 1.3181, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [78/100], qnn_train_step: [100/500], loss: 3.0234084129333496, accuracy: 22.8 %\n",
      "Training round [78/100], qnn_train_step: [200/500], loss: 8.809547424316406, accuracy: 11.2 %\n",
      "Training round [78/100], qnn_train_step: [300/500], loss: 1.2882328033447266, accuracy: 57.8 %\n",
      "Training round [78/100], qnn_train_step: [400/500], loss: 1.4003596305847168, accuracy: 55.2 %\n",
      "Training round [78/100], qnn_train_step: [500/500], loss: 1.5273077487945557, accuracy: 52.0 %\n",
      "-----------------------\n",
      "Training round [79/100], Epoch [1/5], Step [20/47], Loss: 1.1668, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [79/100], Epoch [1/5], Step [40/47], Loss: 1.1186, batch time: 0.33, accuracy:  64.06%\n",
      "Training round [79/100], Epoch [2/5], Step [20/47], Loss: 1.1812, batch time: 0.32, accuracy:  67.19%\n",
      "Training round [79/100], Epoch [2/5], Step [40/47], Loss: 1.2081, batch time: 0.31, accuracy:  59.38%\n",
      "Training round [79/100], Epoch [3/5], Step [20/47], Loss: 1.0076, batch time: 0.30, accuracy:  64.06%\n",
      "Training round [79/100], Epoch [3/5], Step [40/47], Loss: 1.2660, batch time: 0.30, accuracy:  57.03%\n",
      "Training round [79/100], Epoch [4/5], Step [20/47], Loss: 1.2277, batch time: 0.29, accuracy:  59.38%\n",
      "Training round [79/100], Epoch [4/5], Step [40/47], Loss: 1.0789, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [79/100], Epoch [5/5], Step [20/47], Loss: 1.0923, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [79/100], Epoch [5/5], Step [40/47], Loss: 1.3057, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [79/100], qnn_train_step: [100/500], loss: 3.141721248626709, accuracy: 22.0 %\n",
      "Training round [79/100], qnn_train_step: [200/500], loss: 9.887885093688965, accuracy: 11.1 %\n",
      "Training round [79/100], qnn_train_step: [300/500], loss: 1.4176511764526367, accuracy: 51.6 %\n",
      "Training round [79/100], qnn_train_step: [400/500], loss: 1.3898051977157593, accuracy: 51.8 %\n",
      "Training round [79/100], qnn_train_step: [500/500], loss: 1.941279649734497, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [80/100], Epoch [1/5], Step [20/47], Loss: 1.2127, batch time: 0.33, accuracy:  59.38%\n",
      "Training round [80/100], Epoch [1/5], Step [40/47], Loss: 1.4085, batch time: 0.34, accuracy:  53.12%\n",
      "Training round [80/100], Epoch [2/5], Step [20/47], Loss: 1.3098, batch time: 0.31, accuracy:  57.81%\n",
      "Training round [80/100], Epoch [2/5], Step [40/47], Loss: 1.3771, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [80/100], Epoch [3/5], Step [20/47], Loss: 1.2135, batch time: 0.37, accuracy:  60.16%\n",
      "Training round [80/100], Epoch [3/5], Step [40/47], Loss: 1.3063, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [80/100], Epoch [4/5], Step [20/47], Loss: 1.1680, batch time: 0.15, accuracy:  60.94%\n",
      "Training round [80/100], Epoch [4/5], Step [40/47], Loss: 1.3017, batch time: 0.12, accuracy:  52.34%\n",
      "Training round [80/100], Epoch [5/5], Step [20/47], Loss: 1.3904, batch time: 0.35, accuracy:  52.34%\n",
      "Training round [80/100], Epoch [5/5], Step [40/47], Loss: 1.2285, batch time: 0.32, accuracy:  53.91%\n",
      "Training round [80/100], qnn_train_step: [100/500], loss: 3.5204458236694336, accuracy: 19.6 %\n",
      "Training round [80/100], qnn_train_step: [200/500], loss: 9.315271377563477, accuracy: 10.6 %\n",
      "Training round [80/100], qnn_train_step: [300/500], loss: 1.4069981575012207, accuracy: 53.4 %\n",
      "Training round [80/100], qnn_train_step: [400/500], loss: 1.3806630373001099, accuracy: 54.4 %\n",
      "Training round [80/100], qnn_train_step: [500/500], loss: 2.3765547275543213, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [81/100], Epoch [1/5], Step [20/47], Loss: 1.2238, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [81/100], Epoch [1/5], Step [40/47], Loss: 1.2004, batch time: 0.11, accuracy:  55.47%\n",
      "Training round [81/100], Epoch [2/5], Step [20/47], Loss: 1.1202, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [81/100], Epoch [2/5], Step [40/47], Loss: 0.9880, batch time: 0.30, accuracy:  67.97%\n",
      "Training round [81/100], Epoch [3/5], Step [20/47], Loss: 1.3098, batch time: 0.15, accuracy:  57.03%\n",
      "Training round [81/100], Epoch [3/5], Step [40/47], Loss: 1.0961, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [81/100], Epoch [4/5], Step [20/47], Loss: 1.0410, batch time: 0.30, accuracy:  60.94%\n",
      "Training round [81/100], Epoch [4/5], Step [40/47], Loss: 1.1375, batch time: 0.30, accuracy:  63.28%\n",
      "Training round [81/100], Epoch [5/5], Step [20/47], Loss: 1.1410, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [81/100], Epoch [5/5], Step [40/47], Loss: 1.1963, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [81/100], qnn_train_step: [100/500], loss: 3.762223482131958, accuracy: 19.7 %\n",
      "Training round [81/100], qnn_train_step: [200/500], loss: 8.715914726257324, accuracy: 10.0 %\n",
      "Training round [81/100], qnn_train_step: [300/500], loss: 3.958540916442871, accuracy: 19.5 %\n",
      "Training round [81/100], qnn_train_step: [400/500], loss: 1.3389123678207397, accuracy: 57.3 %\n",
      "Training round [81/100], qnn_train_step: [500/500], loss: 1.2672778367996216, accuracy: 58.5 %\n",
      "-----------------------\n",
      "Training round [82/100], Epoch [1/5], Step [20/47], Loss: 1.0729, batch time: 0.31, accuracy:  60.16%\n",
      "Training round [82/100], Epoch [1/5], Step [40/47], Loss: 1.1911, batch time: 0.31, accuracy:  60.94%\n",
      "Training round [82/100], Epoch [2/5], Step [20/47], Loss: 1.1967, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [82/100], Epoch [2/5], Step [40/47], Loss: 1.3585, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [82/100], Epoch [3/5], Step [20/47], Loss: 1.0386, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [82/100], Epoch [3/5], Step [40/47], Loss: 1.3164, batch time: 0.16, accuracy:  54.69%\n",
      "Training round [82/100], Epoch [4/5], Step [20/47], Loss: 1.1793, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [82/100], Epoch [4/5], Step [40/47], Loss: 1.2278, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [82/100], Epoch [5/5], Step [20/47], Loss: 1.1760, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [82/100], Epoch [5/5], Step [40/47], Loss: 1.2823, batch time: 0.11, accuracy:  56.25%\n",
      "Training round [82/100], qnn_train_step: [100/500], loss: 3.0632224082946777, accuracy: 19.1 %\n",
      "Training round [82/100], qnn_train_step: [200/500], loss: 9.921475410461426, accuracy: 11.2 %\n",
      "Training round [82/100], qnn_train_step: [300/500], loss: 1.5836553573608398, accuracy: 51.5 %\n",
      "Training round [82/100], qnn_train_step: [400/500], loss: 1.3942110538482666, accuracy: 54.1 %\n",
      "Training round [82/100], qnn_train_step: [500/500], loss: 3.202988386154175, accuracy: 29.2 %\n",
      "-----------------------\n",
      "Training round [83/100], Epoch [1/5], Step [20/47], Loss: 1.0501, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [83/100], Epoch [1/5], Step [40/47], Loss: 1.1228, batch time: 0.21, accuracy:  62.50%\n",
      "Training round [83/100], Epoch [2/5], Step [20/47], Loss: 1.3885, batch time: 0.15, accuracy:  55.47%\n",
      "Training round [83/100], Epoch [2/5], Step [40/47], Loss: 0.9777, batch time: 0.12, accuracy:  71.88%\n",
      "Training round [83/100], Epoch [3/5], Step [20/47], Loss: 1.2487, batch time: 0.11, accuracy:  53.12%\n",
      "Training round [83/100], Epoch [3/5], Step [40/47], Loss: 1.2958, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [83/100], Epoch [4/5], Step [20/47], Loss: 1.0816, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [83/100], Epoch [4/5], Step [40/47], Loss: 1.3425, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [83/100], Epoch [5/5], Step [20/47], Loss: 1.3030, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [83/100], Epoch [5/5], Step [40/47], Loss: 1.2384, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [83/100], qnn_train_step: [100/500], loss: 3.1327898502349854, accuracy: 18.2 %\n",
      "Training round [83/100], qnn_train_step: [200/500], loss: 10.722540855407715, accuracy: 9.2 %\n",
      "Training round [83/100], qnn_train_step: [300/500], loss: 1.5943076610565186, accuracy: 50.9 %\n",
      "Training round [83/100], qnn_train_step: [400/500], loss: 1.462231159210205, accuracy: 53.5 %\n",
      "Training round [83/100], qnn_train_step: [500/500], loss: 1.3542559146881104, accuracy: 57.1 %\n",
      "-----------------------\n",
      "Training round [84/100], Epoch [1/5], Step [20/47], Loss: 1.0451, batch time: 0.12, accuracy:  61.72%\n",
      "Training round [84/100], Epoch [1/5], Step [40/47], Loss: 1.2963, batch time: 0.12, accuracy:  57.03%\n",
      "Training round [84/100], Epoch [2/5], Step [20/47], Loss: 1.1727, batch time: 0.18, accuracy:  58.59%\n",
      "Training round [84/100], Epoch [2/5], Step [40/47], Loss: 1.0885, batch time: 0.29, accuracy:  62.50%\n",
      "Training round [84/100], Epoch [3/5], Step [20/47], Loss: 1.3651, batch time: 0.29, accuracy:  55.47%\n",
      "Training round [84/100], Epoch [3/5], Step [40/47], Loss: 1.1737, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [84/100], Epoch [4/5], Step [20/47], Loss: 1.1420, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [84/100], Epoch [4/5], Step [40/47], Loss: 1.1831, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [84/100], Epoch [5/5], Step [20/47], Loss: 1.1886, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [84/100], Epoch [5/5], Step [40/47], Loss: 1.0413, batch time: 0.29, accuracy:  64.06%\n",
      "Training round [84/100], qnn_train_step: [100/500], loss: 3.4645676612854004, accuracy: 17.6 %\n",
      "Training round [84/100], qnn_train_step: [200/500], loss: 10.726338386535645, accuracy: 10.4 %\n",
      "Training round [84/100], qnn_train_step: [300/500], loss: 1.6624295711517334, accuracy: 49.9 %\n",
      "Training round [84/100], qnn_train_step: [400/500], loss: 1.474487066268921, accuracy: 52.0 %\n",
      "Training round [84/100], qnn_train_step: [500/500], loss: 1.781996488571167, accuracy: 45.8 %\n",
      "-----------------------\n",
      "Training round [85/100], Epoch [1/5], Step [20/47], Loss: 1.1130, batch time: 0.30, accuracy:  60.94%\n",
      "Training round [85/100], Epoch [1/5], Step [40/47], Loss: 1.0402, batch time: 0.31, accuracy:  70.31%\n",
      "Training round [85/100], Epoch [2/5], Step [20/47], Loss: 1.1903, batch time: 0.30, accuracy:  57.03%\n",
      "Training round [85/100], Epoch [2/5], Step [40/47], Loss: 1.2672, batch time: 0.30, accuracy:  58.59%\n",
      "Training round [85/100], Epoch [3/5], Step [20/47], Loss: 1.2222, batch time: 0.29, accuracy:  67.19%\n",
      "Training round [85/100], Epoch [3/5], Step [40/47], Loss: 1.0948, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [85/100], Epoch [4/5], Step [20/47], Loss: 1.2833, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [85/100], Epoch [4/5], Step [40/47], Loss: 1.1099, batch time: 0.31, accuracy:  61.72%\n",
      "Training round [85/100], Epoch [5/5], Step [20/47], Loss: 1.3526, batch time: 0.30, accuracy:  53.12%\n",
      "Training round [85/100], Epoch [5/5], Step [40/47], Loss: 1.0904, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [85/100], qnn_train_step: [100/500], loss: 3.6996004581451416, accuracy: 16.6 %\n",
      "Training round [85/100], qnn_train_step: [200/500], loss: 10.627447128295898, accuracy: 10.7 %\n",
      "Training round [85/100], qnn_train_step: [300/500], loss: 1.6240520477294922, accuracy: 51.4 %\n",
      "Training round [85/100], qnn_train_step: [400/500], loss: 1.4273130893707275, accuracy: 54.3 %\n",
      "Training round [85/100], qnn_train_step: [500/500], loss: 1.6550767421722412, accuracy: 48.7 %\n",
      "-----------------------\n",
      "Training round [86/100], Epoch [1/5], Step [20/47], Loss: 1.3707, batch time: 0.36, accuracy:  51.56%\n",
      "Training round [86/100], Epoch [1/5], Step [40/47], Loss: 1.0965, batch time: 0.36, accuracy:  68.75%\n",
      "Training round [86/100], Epoch [2/5], Step [20/47], Loss: 1.2724, batch time: 0.37, accuracy:  62.50%\n",
      "Training round [86/100], Epoch [2/5], Step [40/47], Loss: 1.3509, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [86/100], Epoch [3/5], Step [20/47], Loss: 1.1163, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [86/100], Epoch [3/5], Step [40/47], Loss: 1.0598, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [86/100], Epoch [4/5], Step [20/47], Loss: 1.1796, batch time: 0.12, accuracy:  60.94%\n",
      "Training round [86/100], Epoch [4/5], Step [40/47], Loss: 1.1254, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [86/100], Epoch [5/5], Step [20/47], Loss: 1.1175, batch time: 0.31, accuracy:  64.06%\n",
      "Training round [86/100], Epoch [5/5], Step [40/47], Loss: 1.1564, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [86/100], qnn_train_step: [100/500], loss: 3.5814778804779053, accuracy: 14.3 %\n",
      "Training round [86/100], qnn_train_step: [200/500], loss: 11.469817161560059, accuracy: 11.0 %\n",
      "Training round [86/100], qnn_train_step: [300/500], loss: 1.913834571838379, accuracy: 48.3 %\n",
      "Training round [86/100], qnn_train_step: [400/500], loss: 1.5663031339645386, accuracy: 52.2 %\n",
      "Training round [86/100], qnn_train_step: [500/500], loss: 1.245185375213623, accuracy: 59.1 %\n",
      "-----------------------\n",
      "Training round [87/100], Epoch [1/5], Step [20/47], Loss: 1.0554, batch time: 0.20, accuracy:  63.28%\n",
      "Training round [87/100], Epoch [1/5], Step [40/47], Loss: 1.2431, batch time: 0.13, accuracy:  60.16%\n",
      "Training round [87/100], Epoch [2/5], Step [20/47], Loss: 1.2590, batch time: 0.30, accuracy:  64.84%\n",
      "Training round [87/100], Epoch [2/5], Step [40/47], Loss: 1.2070, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [87/100], Epoch [3/5], Step [20/47], Loss: 1.2745, batch time: 0.30, accuracy:  60.94%\n",
      "Training round [87/100], Epoch [3/5], Step [40/47], Loss: 1.1903, batch time: 0.29, accuracy:  58.59%\n",
      "Training round [87/100], Epoch [4/5], Step [20/47], Loss: 1.3270, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [87/100], Epoch [4/5], Step [40/47], Loss: 1.0829, batch time: 0.30, accuracy:  65.62%\n",
      "Training round [87/100], Epoch [5/5], Step [20/47], Loss: 1.0645, batch time: 0.30, accuracy:  64.06%\n",
      "Training round [87/100], Epoch [5/5], Step [40/47], Loss: 1.2024, batch time: 0.30, accuracy:  63.28%\n",
      "Training round [87/100], qnn_train_step: [100/500], loss: 2.6033706665039062, accuracy: 24.7 %\n",
      "Training round [87/100], qnn_train_step: [200/500], loss: 10.770678520202637, accuracy: 10.9 %\n",
      "Training round [87/100], qnn_train_step: [300/500], loss: 1.8931773900985718, accuracy: 43.0 %\n",
      "Training round [87/100], qnn_train_step: [400/500], loss: 1.331977367401123, accuracy: 57.1 %\n",
      "Training round [87/100], qnn_train_step: [500/500], loss: 1.3999537229537964, accuracy: 57.2 %\n",
      "-----------------------\n",
      "Training round [88/100], Epoch [1/5], Step [20/47], Loss: 1.2053, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [88/100], Epoch [1/5], Step [40/47], Loss: 1.2607, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [88/100], Epoch [2/5], Step [20/47], Loss: 1.2260, batch time: 0.31, accuracy:  54.69%\n",
      "Training round [88/100], Epoch [2/5], Step [40/47], Loss: 1.1976, batch time: 0.30, accuracy:  64.06%\n",
      "Training round [88/100], Epoch [3/5], Step [20/47], Loss: 1.2231, batch time: 0.30, accuracy:  57.81%\n",
      "Training round [88/100], Epoch [3/5], Step [40/47], Loss: 1.2524, batch time: 0.30, accuracy:  63.28%\n",
      "Training round [88/100], Epoch [4/5], Step [20/47], Loss: 1.2600, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [88/100], Epoch [4/5], Step [40/47], Loss: 1.3060, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [88/100], Epoch [5/5], Step [20/47], Loss: 1.0776, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [88/100], Epoch [5/5], Step [40/47], Loss: 1.2247, batch time: 0.31, accuracy:  55.47%\n",
      "Training round [88/100], qnn_train_step: [100/500], loss: 2.7513468265533447, accuracy: 24.7 %\n",
      "Training round [88/100], qnn_train_step: [200/500], loss: 11.136064529418945, accuracy: 10.5 %\n",
      "Training round [88/100], qnn_train_step: [300/500], loss: 3.721890449523926, accuracy: 31.4 %\n",
      "Training round [88/100], qnn_train_step: [400/500], loss: 1.3296703100204468, accuracy: 54.0 %\n",
      "Training round [88/100], qnn_train_step: [500/500], loss: 1.201514720916748, accuracy: 59.6 %\n",
      "-----------------------\n",
      "Training round [89/100], Epoch [1/5], Step [20/47], Loss: 1.4209, batch time: 0.31, accuracy:  50.00%\n",
      "Training round [89/100], Epoch [1/5], Step [40/47], Loss: 1.1868, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [89/100], Epoch [2/5], Step [20/47], Loss: 1.0487, batch time: 0.12, accuracy:  63.28%\n",
      "Training round [89/100], Epoch [2/5], Step [40/47], Loss: 1.1183, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [89/100], Epoch [3/5], Step [20/47], Loss: 1.1581, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [89/100], Epoch [3/5], Step [40/47], Loss: 1.1296, batch time: 0.11, accuracy:  67.97%\n",
      "Training round [89/100], Epoch [4/5], Step [20/47], Loss: 1.3037, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [89/100], Epoch [4/5], Step [40/47], Loss: 0.9764, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [89/100], Epoch [5/5], Step [20/47], Loss: 1.1801, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [89/100], Epoch [5/5], Step [40/47], Loss: 1.6056, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [89/100], qnn_train_step: [100/500], loss: 2.591012716293335, accuracy: 25.6 %\n",
      "Training round [89/100], qnn_train_step: [200/500], loss: 10.228811264038086, accuracy: 11.3 %\n",
      "Training round [89/100], qnn_train_step: [300/500], loss: 1.762415885925293, accuracy: 50.0 %\n",
      "Training round [89/100], qnn_train_step: [400/500], loss: 1.3381186723709106, accuracy: 57.6 %\n",
      "Training round [89/100], qnn_train_step: [500/500], loss: 1.7063262462615967, accuracy: 50.3 %\n",
      "-----------------------\n",
      "Training round [90/100], Epoch [1/5], Step [20/47], Loss: 1.3844, batch time: 0.35, accuracy:  51.56%\n",
      "Training round [90/100], Epoch [1/5], Step [40/47], Loss: 1.2681, batch time: 0.35, accuracy:  57.03%\n",
      "Training round [90/100], Epoch [2/5], Step [20/47], Loss: 1.3025, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [90/100], Epoch [2/5], Step [40/47], Loss: 1.2624, batch time: 0.13, accuracy:  56.25%\n",
      "Training round [90/100], Epoch [3/5], Step [20/47], Loss: 1.0081, batch time: 0.31, accuracy:  67.19%\n",
      "Training round [90/100], Epoch [3/5], Step [40/47], Loss: 1.0137, batch time: 0.29, accuracy:  71.09%\n",
      "Training round [90/100], Epoch [4/5], Step [20/47], Loss: 1.1223, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [90/100], Epoch [4/5], Step [40/47], Loss: 1.3030, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [90/100], Epoch [5/5], Step [20/47], Loss: 1.1452, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [90/100], Epoch [5/5], Step [40/47], Loss: 1.1662, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [90/100], qnn_train_step: [100/500], loss: 2.6518828868865967, accuracy: 22.2 %\n",
      "Training round [90/100], qnn_train_step: [200/500], loss: 9.984468460083008, accuracy: 10.3 %\n",
      "Training round [90/100], qnn_train_step: [300/500], loss: 1.5422474145889282, accuracy: 51.8 %\n",
      "Training round [90/100], qnn_train_step: [400/500], loss: 1.3422417640686035, accuracy: 55.9 %\n",
      "Training round [90/100], qnn_train_step: [500/500], loss: 1.4905916452407837, accuracy: 54.7 %\n",
      "-----------------------\n",
      "Training round [91/100], Epoch [1/5], Step [20/47], Loss: 1.1155, batch time: 0.30, accuracy:  64.06%\n",
      "Training round [91/100], Epoch [1/5], Step [40/47], Loss: 1.1780, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [91/100], Epoch [2/5], Step [20/47], Loss: 0.9885, batch time: 0.11, accuracy:  71.09%\n",
      "Training round [91/100], Epoch [2/5], Step [40/47], Loss: 1.2749, batch time: 0.12, accuracy:  57.81%\n",
      "Training round [91/100], Epoch [3/5], Step [20/47], Loss: 1.2588, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [91/100], Epoch [3/5], Step [40/47], Loss: 1.1970, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [91/100], Epoch [4/5], Step [20/47], Loss: 1.0304, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [91/100], Epoch [4/5], Step [40/47], Loss: 1.1312, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [91/100], Epoch [5/5], Step [20/47], Loss: 1.1624, batch time: 0.12, accuracy:  62.50%\n",
      "Training round [91/100], Epoch [5/5], Step [40/47], Loss: 1.2319, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [91/100], qnn_train_step: [100/500], loss: 2.7558975219726562, accuracy: 22.8 %\n",
      "Training round [91/100], qnn_train_step: [200/500], loss: 9.9801607131958, accuracy: 11.5 %\n",
      "Training round [91/100], qnn_train_step: [300/500], loss: 1.1407147645950317, accuracy: 62.6 %\n",
      "Training round [91/100], qnn_train_step: [400/500], loss: 1.1782993078231812, accuracy: 59.8 %\n",
      "Training round [91/100], qnn_train_step: [500/500], loss: 1.0975618362426758, accuracy: 64.2 %\n",
      "-----------------------\n",
      "Training round [92/100], Epoch [1/5], Step [20/47], Loss: 1.2738, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [92/100], Epoch [1/5], Step [40/47], Loss: 1.0431, batch time: 0.25, accuracy:  67.19%\n",
      "Training round [92/100], Epoch [2/5], Step [20/47], Loss: 1.2530, batch time: 0.11, accuracy:  66.41%\n",
      "Training round [92/100], Epoch [2/5], Step [40/47], Loss: 1.2504, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [92/100], Epoch [3/5], Step [20/47], Loss: 1.1542, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [92/100], Epoch [3/5], Step [40/47], Loss: 1.0689, batch time: 0.30, accuracy:  60.16%\n",
      "Training round [92/100], Epoch [4/5], Step [20/47], Loss: 1.1972, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [92/100], Epoch [4/5], Step [40/47], Loss: 1.1036, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [92/100], Epoch [5/5], Step [20/47], Loss: 1.0448, batch time: 0.30, accuracy:  65.62%\n",
      "Training round [92/100], Epoch [5/5], Step [40/47], Loss: 1.2899, batch time: 0.30, accuracy:  60.16%\n",
      "Training round [92/100], qnn_train_step: [100/500], loss: 2.747460126876831, accuracy: 26.2 %\n",
      "Training round [92/100], qnn_train_step: [200/500], loss: 10.985373497009277, accuracy: 9.6 %\n",
      "Training round [92/100], qnn_train_step: [300/500], loss: 1.7347570657730103, accuracy: 49.5 %\n",
      "Training round [92/100], qnn_train_step: [400/500], loss: 1.2378902435302734, accuracy: 59.6 %\n",
      "Training round [92/100], qnn_train_step: [500/500], loss: 1.2876548767089844, accuracy: 59.0 %\n",
      "-----------------------\n",
      "Training round [93/100], Epoch [1/5], Step [20/47], Loss: 1.1204, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [93/100], Epoch [1/5], Step [40/47], Loss: 1.1488, batch time: 0.30, accuracy:  61.72%\n",
      "Training round [93/100], Epoch [2/5], Step [20/47], Loss: 1.2034, batch time: 0.30, accuracy:  60.16%\n",
      "Training round [93/100], Epoch [2/5], Step [40/47], Loss: 1.0321, batch time: 0.29, accuracy:  64.84%\n",
      "Training round [93/100], Epoch [3/5], Step [20/47], Loss: 1.2796, batch time: 0.32, accuracy:  60.94%\n",
      "Training round [93/100], Epoch [3/5], Step [40/47], Loss: 1.1212, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [93/100], Epoch [4/5], Step [20/47], Loss: 1.2627, batch time: 0.43, accuracy:  58.59%\n",
      "Training round [93/100], Epoch [4/5], Step [40/47], Loss: 1.1525, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [93/100], Epoch [5/5], Step [20/47], Loss: 1.0302, batch time: 0.16, accuracy:  65.62%\n",
      "Training round [93/100], Epoch [5/5], Step [40/47], Loss: 1.1910, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [93/100], qnn_train_step: [100/500], loss: 2.7598977088928223, accuracy: 25.0 %\n",
      "Training round [93/100], qnn_train_step: [200/500], loss: 10.727119445800781, accuracy: 10.8 %\n",
      "Training round [93/100], qnn_train_step: [300/500], loss: 1.697898268699646, accuracy: 49.8 %\n",
      "Training round [93/100], qnn_train_step: [400/500], loss: 1.3424031734466553, accuracy: 55.2 %\n",
      "Training round [93/100], qnn_train_step: [500/500], loss: 1.400171160697937, accuracy: 52.1 %\n",
      "-----------------------\n",
      "Training round [94/100], Epoch [1/5], Step [20/47], Loss: 1.0706, batch time: 0.12, accuracy:  68.75%\n",
      "Training round [94/100], Epoch [1/5], Step [40/47], Loss: 1.0284, batch time: 0.12, accuracy:  64.84%\n",
      "Training round [94/100], Epoch [2/5], Step [20/47], Loss: 1.1133, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [94/100], Epoch [2/5], Step [40/47], Loss: 1.1441, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [94/100], Epoch [3/5], Step [20/47], Loss: 1.1484, batch time: 0.13, accuracy:  59.38%\n",
      "Training round [94/100], Epoch [3/5], Step [40/47], Loss: 1.3489, batch time: 0.12, accuracy:  60.16%\n",
      "Training round [94/100], Epoch [4/5], Step [20/47], Loss: 1.1195, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [94/100], Epoch [4/5], Step [40/47], Loss: 1.2410, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [94/100], Epoch [5/5], Step [20/47], Loss: 1.1607, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [94/100], Epoch [5/5], Step [40/47], Loss: 1.1083, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [94/100], qnn_train_step: [100/500], loss: 2.833331823348999, accuracy: 28.3 %\n",
      "Training round [94/100], qnn_train_step: [200/500], loss: 11.797525405883789, accuracy: 10.5 %\n",
      "Training round [94/100], qnn_train_step: [300/500], loss: 1.848796010017395, accuracy: 47.9 %\n",
      "Training round [94/100], qnn_train_step: [400/500], loss: 1.400453805923462, accuracy: 55.3 %\n",
      "Training round [94/100], qnn_train_step: [500/500], loss: 1.4007618427276611, accuracy: 54.9 %\n",
      "-----------------------\n",
      "Training round [95/100], Epoch [1/5], Step [20/47], Loss: 1.3919, batch time: 0.33, accuracy:  56.25%\n",
      "Training round [95/100], Epoch [1/5], Step [40/47], Loss: 1.3362, batch time: 0.30, accuracy:  53.91%\n",
      "Training round [95/100], Epoch [2/5], Step [20/47], Loss: 1.1494, batch time: 0.12, accuracy:  58.59%\n",
      "Training round [95/100], Epoch [2/5], Step [40/47], Loss: 1.2256, batch time: 0.12, accuracy:  58.59%\n",
      "Training round [95/100], Epoch [3/5], Step [20/47], Loss: 1.2572, batch time: 0.11, accuracy:  57.03%\n",
      "Training round [95/100], Epoch [3/5], Step [40/47], Loss: 1.0758, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [95/100], Epoch [4/5], Step [20/47], Loss: 1.3347, batch time: 0.13, accuracy:  62.50%\n",
      "Training round [95/100], Epoch [4/5], Step [40/47], Loss: 1.2045, batch time: 0.12, accuracy:  64.84%\n",
      "Training round [95/100], Epoch [5/5], Step [20/47], Loss: 1.1675, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [95/100], Epoch [5/5], Step [40/47], Loss: 1.2992, batch time: 0.11, accuracy:  54.69%\n",
      "Training round [95/100], qnn_train_step: [100/500], loss: 2.9341065883636475, accuracy: 26.6 %\n",
      "Training round [95/100], qnn_train_step: [200/500], loss: 11.520818710327148, accuracy: 10.4 %\n",
      "Training round [95/100], qnn_train_step: [300/500], loss: 1.8115215301513672, accuracy: 48.0 %\n",
      "Training round [95/100], qnn_train_step: [400/500], loss: 1.2556984424591064, accuracy: 57.8 %\n",
      "Training round [95/100], qnn_train_step: [500/500], loss: 1.6679795980453491, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [96/100], Epoch [1/5], Step [20/47], Loss: 1.0398, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [96/100], Epoch [1/5], Step [40/47], Loss: 1.0871, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [96/100], Epoch [2/5], Step [20/47], Loss: 1.1590, batch time: 0.11, accuracy:  59.38%\n",
      "Training round [96/100], Epoch [2/5], Step [40/47], Loss: 1.1124, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [96/100], Epoch [3/5], Step [20/47], Loss: 1.1999, batch time: 0.30, accuracy:  60.94%\n",
      "Training round [96/100], Epoch [3/5], Step [40/47], Loss: 1.2229, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [96/100], Epoch [4/5], Step [20/47], Loss: 1.0464, batch time: 0.23, accuracy:  63.28%\n",
      "Training round [96/100], Epoch [4/5], Step [40/47], Loss: 1.1473, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [96/100], Epoch [5/5], Step [20/47], Loss: 1.1721, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [96/100], Epoch [5/5], Step [40/47], Loss: 1.1864, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [96/100], qnn_train_step: [100/500], loss: 2.730311870574951, accuracy: 28.7 %\n",
      "Training round [96/100], qnn_train_step: [200/500], loss: 12.504371643066406, accuracy: 10.8 %\n",
      "Training round [96/100], qnn_train_step: [300/500], loss: 1.9878089427947998, accuracy: 45.9 %\n",
      "Training round [96/100], qnn_train_step: [400/500], loss: 1.4146658182144165, accuracy: 55.5 %\n",
      "Training round [96/100], qnn_train_step: [500/500], loss: 1.9515936374664307, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [97/100], Epoch [1/5], Step [20/47], Loss: 1.0496, batch time: 0.32, accuracy:  59.38%\n",
      "Training round [97/100], Epoch [1/5], Step [40/47], Loss: 0.9010, batch time: 0.32, accuracy:  68.75%\n",
      "Training round [97/100], Epoch [2/5], Step [20/47], Loss: 1.2190, batch time: 0.31, accuracy:  60.16%\n",
      "Training round [97/100], Epoch [2/5], Step [40/47], Loss: 1.1333, batch time: 0.30, accuracy:  62.50%\n",
      "Training round [97/100], Epoch [3/5], Step [20/47], Loss: 1.1510, batch time: 0.32, accuracy:  63.28%\n",
      "Training round [97/100], Epoch [3/5], Step [40/47], Loss: 1.1287, batch time: 0.31, accuracy:  57.03%\n",
      "Training round [97/100], Epoch [4/5], Step [20/47], Loss: 1.3178, batch time: 0.31, accuracy:  57.03%\n",
      "Training round [97/100], Epoch [4/5], Step [40/47], Loss: 1.3862, batch time: 0.11, accuracy:  50.00%\n",
      "Training round [97/100], Epoch [5/5], Step [20/47], Loss: 1.0289, batch time: 0.29, accuracy:  68.75%\n",
      "Training round [97/100], Epoch [5/5], Step [40/47], Loss: 1.1988, batch time: 0.11, accuracy:  62.50%\n",
      "Training round [97/100], qnn_train_step: [100/500], loss: 2.8669235706329346, accuracy: 27.6 %\n",
      "Training round [97/100], qnn_train_step: [200/500], loss: 12.768220901489258, accuracy: 10.4 %\n",
      "Training round [97/100], qnn_train_step: [300/500], loss: 1.761035442352295, accuracy: 49.9 %\n",
      "Training round [97/100], qnn_train_step: [400/500], loss: 1.3728927373886108, accuracy: 56.5 %\n",
      "Training round [97/100], qnn_train_step: [500/500], loss: 2.4748947620391846, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [98/100], Epoch [1/5], Step [20/47], Loss: 1.0865, batch time: 0.11, accuracy:  63.28%\n",
      "Training round [98/100], Epoch [1/5], Step [40/47], Loss: 1.1475, batch time: 0.14, accuracy:  51.56%\n",
      "Training round [98/100], Epoch [2/5], Step [20/47], Loss: 1.0821, batch time: 0.41, accuracy:  57.81%\n",
      "Training round [98/100], Epoch [2/5], Step [40/47], Loss: 1.1685, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [98/100], Epoch [3/5], Step [20/47], Loss: 1.0506, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [98/100], Epoch [3/5], Step [40/47], Loss: 1.0215, batch time: 0.12, accuracy:  67.97%\n",
      "Training round [98/100], Epoch [4/5], Step [20/47], Loss: 1.1510, batch time: 0.11, accuracy:  67.19%\n",
      "Training round [98/100], Epoch [4/5], Step [40/47], Loss: 1.2799, batch time: 0.11, accuracy:  53.91%\n",
      "Training round [98/100], Epoch [5/5], Step [20/47], Loss: 1.1716, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [98/100], Epoch [5/5], Step [40/47], Loss: 1.2637, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [98/100], qnn_train_step: [100/500], loss: 2.8706114292144775, accuracy: 27.1 %\n",
      "Training round [98/100], qnn_train_step: [200/500], loss: 12.702028274536133, accuracy: 10.2 %\n",
      "Training round [98/100], qnn_train_step: [300/500], loss: 1.8382972478866577, accuracy: 47.5 %\n",
      "Training round [98/100], qnn_train_step: [400/500], loss: 1.5326472520828247, accuracy: 51.1 %\n",
      "Training round [98/100], qnn_train_step: [500/500], loss: 1.2440303564071655, accuracy: 59.7 %\n",
      "-----------------------\n",
      "Training round [99/100], Epoch [1/5], Step [20/47], Loss: 0.9939, batch time: 0.31, accuracy:  65.62%\n",
      "Training round [99/100], Epoch [1/5], Step [40/47], Loss: 1.1627, batch time: 0.11, accuracy:  60.94%\n",
      "Training round [99/100], Epoch [2/5], Step [20/47], Loss: 1.1332, batch time: 0.21, accuracy:  59.38%\n",
      "Training round [99/100], Epoch [2/5], Step [40/47], Loss: 1.1828, batch time: 0.30, accuracy:  57.81%\n",
      "Training round [99/100], Epoch [3/5], Step [20/47], Loss: 1.0669, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [99/100], Epoch [3/5], Step [40/47], Loss: 1.0529, batch time: 0.11, accuracy:  64.84%\n",
      "Training round [99/100], Epoch [4/5], Step [20/47], Loss: 1.2742, batch time: 0.12, accuracy:  58.59%\n",
      "Training round [99/100], Epoch [4/5], Step [40/47], Loss: 1.0873, batch time: 0.11, accuracy:  64.06%\n",
      "Training round [99/100], Epoch [5/5], Step [20/47], Loss: 1.0725, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [99/100], Epoch [5/5], Step [40/47], Loss: 1.2025, batch time: 0.11, accuracy:  60.16%\n",
      "Training round [99/100], qnn_train_step: [100/500], loss: 2.817798614501953, accuracy: 25.8 %\n",
      "Training round [99/100], qnn_train_step: [200/500], loss: 12.076180458068848, accuracy: 9.4 %\n",
      "Training round [99/100], qnn_train_step: [300/500], loss: 1.8184154033660889, accuracy: 43.6 %\n",
      "Training round [99/100], qnn_train_step: [400/500], loss: 1.6672571897506714, accuracy: 50.0 %\n",
      "Training round [99/100], qnn_train_step: [500/500], loss: 1.7193164825439453, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [100/100], Epoch [1/5], Step [20/47], Loss: 1.2952, batch time: 0.32, accuracy:  56.25%\n",
      "Training round [100/100], Epoch [1/5], Step [40/47], Loss: 1.2323, batch time: 0.32, accuracy:  60.16%\n",
      "Training round [100/100], Epoch [2/5], Step [20/47], Loss: 1.2646, batch time: 0.11, accuracy:  58.59%\n",
      "Training round [100/100], Epoch [2/5], Step [40/47], Loss: 0.9496, batch time: 0.11, accuracy:  69.53%\n",
      "Training round [100/100], Epoch [3/5], Step [20/47], Loss: 1.1436, batch time: 0.11, accuracy:  57.81%\n",
      "Training round [100/100], Epoch [3/5], Step [40/47], Loss: 0.9652, batch time: 0.11, accuracy:  68.75%\n",
      "Training round [100/100], Epoch [4/5], Step [20/47], Loss: 1.1981, batch time: 0.30, accuracy:  59.38%\n",
      "Training round [100/100], Epoch [4/5], Step [40/47], Loss: 1.2187, batch time: 0.29, accuracy:  59.38%\n",
      "Training round [100/100], Epoch [5/5], Step [20/47], Loss: 1.0296, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [100/100], Epoch [5/5], Step [40/47], Loss: 0.9669, batch time: 0.11, accuracy:  65.62%\n",
      "Training round [100/100], qnn_train_step: [100/500], loss: 2.8967456817626953, accuracy: 28.9 %\n",
      "Training round [100/100], qnn_train_step: [200/500], loss: 12.395615577697754, accuracy: 11.4 %\n",
      "Training round [100/100], qnn_train_step: [300/500], loss: 1.8455233573913574, accuracy: 49.3 %\n",
      "Training round [100/100], qnn_train_step: [400/500], loss: 1.3067502975463867, accuracy: 56.6 %\n",
      "Training round [100/100], qnn_train_step: [500/500], loss: 1.4981377124786377, accuracy: 50.1 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 100\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{500}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 500, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 61.22%\n",
      "Loss on the train set: 1.13\n",
      "Accuracy on the test set: 60.33%\n",
      "Loss on the test set: 1.20\n",
      "Generalization error: 0.063090205\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
