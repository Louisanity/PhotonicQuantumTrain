{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from torchmps import MPS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 108, and embedding size = 126\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1637.5\" height=\"593.75\" viewBox=\"-30.0 0 1310.0 475.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.408802</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.946257</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.759292</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.216915</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.027821</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.847083</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.474968</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.557728</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.925226</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.857281</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.931271</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.600526</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.135617</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.862477</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.524817</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.83155</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.398947</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.565672</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.927797</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.103252</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.858537</text>\n",
       "<path d=\"M25,425.0 L175,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.78042</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.681226</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.090876</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.932186</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.121155</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.107538</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.414419</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.418862</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.113154</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.015132</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.649311</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.237538</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.478895</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.50053</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.858094</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.572651</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.395833</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.620865</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.130448</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.390221</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.551868</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.261858</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.559286</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.578696</text>\n",
       "<path d=\"M325,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.388446</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.686648</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.510402</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.499367</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.851942</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.550692</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.194316</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.709471</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.615846</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.787192</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.211713</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.878105</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.440749</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.240349</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.278543</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.846725</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.397579</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.301726</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.276433</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.459463</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.273291</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.97729</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.375076</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.195223</text>\n",
       "<path d=\"M625,425.0 L775,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.406759</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.950325</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.196054</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.406982</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.079386</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.826791</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.509535</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.553025</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.684674</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.48826</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.639936</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.954346</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.311138</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.154105</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.294738</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.513009</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.837402</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.376553</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.926314</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.447471</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.067209</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.938225</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.268036</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.436356</text>\n",
       "<path d=\"M925,425.0 L1075,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.189396</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.771157</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.850896</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25.0 L1240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,75.0 L1240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,125.0 L1240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,175.0 L1240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,225.0 L1240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,275.0 L1240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,325.0 L1240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,375.0 L1240,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1225,425.0 L1240,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1250\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1250\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1250\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1250\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1250\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1250\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1250\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1250\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1250\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x77207613f400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs_1 = BosonSampler(m = 9, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_1.nb_parameters}, and embedding size = {bs_1.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_1.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 84, and embedding size = 70\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1448.75\" height=\"531.25\" viewBox=\"-29.5 0 1159.0 425.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.964032</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.276527</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.65215</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.198143</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.759284</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.344371</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.503908</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.077542</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.928096</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.875296</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.415536</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.609204</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.129566</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.846438</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.108198</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.036059</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.700774</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.28845</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.67084</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.17071</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.606117</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.072735</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.218763</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.343366</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.815648</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.257558</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.348239</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.090893</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.604005</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.341717</text>\n",
       "<path d=\"M175,375.0 L325,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.740737</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.229617</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.78937</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.566069</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.064948</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.976006</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.886066</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.75003</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.261986</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.14191</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.954033</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.8205</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.745019</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.032451</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.804543</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.966166</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.474275</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.708286</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.141781</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.052969</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.322405</text>\n",
       "<path d=\"M475,375.0 L625,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.779901</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.151681</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.704639</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.969121</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.410466</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.078726</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.682465</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.587782</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.379552</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.178479</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.449386</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.331463</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.836309</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.411641</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.896313</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.341666</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.363586</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.599108</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.475807</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.716725</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.625216</text>\n",
       "<path d=\"M775,375.0 L925,375.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.422476</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.5624</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.959694</text>\n",
       "<path d=\"M1075,25.0 L1090,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,75.0 L1090,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,125.0 L1090,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,175.0 L1090,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,225.0 L1090,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,275.0 L1090,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,325.0 L1090,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1075,375.0 L1090,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1100\" y=\"28.0\" font-size=\"9\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1100\" y=\"78.0\" font-size=\"9\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1100\" y=\"128.0\" font-size=\"9\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1100\" y=\"178.0\" font-size=\"9\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1100\" y=\"228.0\" font-size=\"9\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1100\" y=\"278.0\" font-size=\"9\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1100\" y=\"328.0\" font-size=\"9\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1100\" y=\"378.0\" font-size=\"9\" text-anchor=\"end\">7</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"9\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"9\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"9\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"9\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"9\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"9\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"9\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"9\" text-anchor=\"start\">7</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x772076055850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_2 = BosonSampler(m = 8, n = 4, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs_2.nb_parameters}, and embedding size = {bs_2.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs_2.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126 * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(84)\n",
    "# res = bs_2.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs_2.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "    #     self.fc1 = nn.Linear(4*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  6690\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.zeros(126)[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    # class MappingModel(nn.Module):\n",
    "    #     def __init__(self, input_size, hidden_sizes, output_size):\n",
    "    #         super().__init__()\n",
    "    #         # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "    #         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "    #         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "    #         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "    #     def forward(self, X):\n",
    "    #         # Ensure the input tensor is the same type as the weights\n",
    "    #         X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "    #         # Input layer with ReLU activation\n",
    "    #         X = self.input_layer(X)\n",
    "\n",
    "    #         # Hidden layers with ReLU activation\n",
    "    #         for hidden in self.hidden_layers:\n",
    "    #             X = hidden(X)\n",
    "\n",
    "    #         # Output layer with linear activation\n",
    "    #         output = self.output_layer(X)\n",
    "    #         # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "    #         return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        self.MappingNetwork = MPS(input_dim=n_qubit+1, output_dim=1, bond_dim=9)\n",
    "\n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params_1 = qnn_parameters[:108] #nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "        self.q_params_2 = qnn_parameters[108:]\n",
    "        device = x.device\n",
    "        \n",
    "        res_1 = bs_1.run(\n",
    "            parameters=self.q_params_1,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_1 = bs_1.translate_results(res = res_1)\n",
    "        trans_res_1 = trans_res_1/torch.mean(trans_res_1)\n",
    "        probs_1 = trans_res_1.to(device)  \n",
    "        \n",
    "        res_2 = bs_2.run(\n",
    "            parameters=self.q_params_2,\n",
    "            samples=100000\n",
    "        )\n",
    "        trans_res_2 = bs_2.translate_results(res = res_2)\n",
    "        trans_res_2 = trans_res_2/torch.mean(trans_res_2)\n",
    "        probs_2 = trans_res_2.to(device)  \n",
    "\n",
    "        probs_ = torch.ger(probs_1, probs_2).flatten().reshape(126 * 70,1)  \n",
    "        \n",
    "        # probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  2511\n",
      "# of trainable parameter in QNN model:  192\n",
      "# of trainable parameter in full model:  2703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(108+84)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs_1.nb_parameters + bs_2.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs_1.nb_parameters + bs_2.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/200], Epoch [1/5], Step [20/47], Loss: 2.3006, batch time: 0.10, accuracy:  7.81%\n",
      "Training round [1/200], Epoch [1/5], Step [40/47], Loss: 2.2419, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [2/5], Step [20/47], Loss: 2.1806, batch time: 0.04, accuracy:  21.09%\n",
      "Training round [1/200], Epoch [2/5], Step [40/47], Loss: 2.0296, batch time: 0.04, accuracy:  23.44%\n",
      "Training round [1/200], Epoch [3/5], Step [20/47], Loss: 1.9087, batch time: 0.04, accuracy:  28.91%\n",
      "Training round [1/200], Epoch [3/5], Step [40/47], Loss: 1.6159, batch time: 0.04, accuracy:  39.84%\n",
      "Training round [1/200], Epoch [4/5], Step [20/47], Loss: 1.7220, batch time: 0.04, accuracy:  35.94%\n",
      "Training round [1/200], Epoch [4/5], Step [40/47], Loss: 1.6849, batch time: 0.04, accuracy:  43.75%\n",
      "Training round [1/200], Epoch [5/5], Step [20/47], Loss: 1.4127, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [1/200], Epoch [5/5], Step [40/47], Loss: 1.3696, batch time: 0.04, accuracy:  50.00%\n",
      "Training round [1/200], qnn_train_step: [100/1000], loss: 1.1185696125030518, accuracy: 62.3 %\n",
      "Training round [1/200], qnn_train_step: [200/1000], loss: 4.756222248077393, accuracy: 30.5 %\n",
      "Training round [1/200], qnn_train_step: [300/1000], loss: 1.0977345705032349, accuracy: 61.4 %\n",
      "Training round [1/200], qnn_train_step: [400/1000], loss: 1.1571507453918457, accuracy: 61.7 %\n",
      "Training round [1/200], qnn_train_step: [500/1000], loss: 1.1001720428466797, accuracy: 63.1 %\n",
      "Training round [1/200], qnn_train_step: [600/1000], loss: 1.0831468105316162, accuracy: 62.5 %\n",
      "Training round [1/200], qnn_train_step: [700/1000], loss: 1.5166972875595093, accuracy: 56.2 %\n",
      "Training round [1/200], qnn_train_step: [800/1000], loss: 1.1027182340621948, accuracy: 64.7 %\n",
      "Training round [1/200], qnn_train_step: [900/1000], loss: 1.0539486408233643, accuracy: 63.9 %\n",
      "Training round [1/200], qnn_train_step: [1000/1000], loss: 1.105911135673523, accuracy: 64.0 %\n",
      "-----------------------\n",
      "Training round [2/200], Epoch [1/5], Step [20/47], Loss: 1.1133, batch time: 0.10, accuracy:  67.19%\n",
      "Training round [2/200], Epoch [1/5], Step [40/47], Loss: 1.0194, batch time: 0.05, accuracy:  64.06%\n",
      "Training round [2/200], Epoch [2/5], Step [20/47], Loss: 0.9263, batch time: 0.05, accuracy:  68.75%\n",
      "Training round [2/200], Epoch [2/5], Step [40/47], Loss: 0.8523, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [2/200], Epoch [3/5], Step [20/47], Loss: 0.8041, batch time: 0.05, accuracy:  73.44%\n",
      "Training round [2/200], Epoch [3/5], Step [40/47], Loss: 0.5695, batch time: 0.05, accuracy:  79.69%\n",
      "Training round [2/200], Epoch [4/5], Step [20/47], Loss: 0.9028, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [2/200], Epoch [4/5], Step [40/47], Loss: 0.6816, batch time: 0.05, accuracy:  78.12%\n",
      "Training round [2/200], Epoch [5/5], Step [20/47], Loss: 0.5766, batch time: 0.05, accuracy:  81.25%\n",
      "Training round [2/200], Epoch [5/5], Step [40/47], Loss: 0.8366, batch time: 0.05, accuracy:  77.34%\n",
      "Training round [2/200], qnn_train_step: [100/1000], loss: 0.5850424766540527, accuracy: 81.9 %\n",
      "Training round [2/200], qnn_train_step: [200/1000], loss: 4.460184574127197, accuracy: 35.2 %\n",
      "Training round [2/200], qnn_train_step: [300/1000], loss: 0.5994521379470825, accuracy: 81.9 %\n",
      "Training round [2/200], qnn_train_step: [400/1000], loss: 0.5795348286628723, accuracy: 82.8 %\n",
      "Training round [2/200], qnn_train_step: [500/1000], loss: 0.5928587317466736, accuracy: 82.7 %\n",
      "Training round [2/200], qnn_train_step: [600/1000], loss: 0.5866081714630127, accuracy: 82.3 %\n",
      "Training round [2/200], qnn_train_step: [700/1000], loss: 0.6188439726829529, accuracy: 79.8 %\n",
      "Training round [2/200], qnn_train_step: [800/1000], loss: 0.6130437850952148, accuracy: 82.2 %\n",
      "Training round [2/200], qnn_train_step: [900/1000], loss: 0.5885787010192871, accuracy: 80.7 %\n",
      "Training round [2/200], qnn_train_step: [1000/1000], loss: 0.5557963252067566, accuracy: 82.9 %\n",
      "-----------------------\n",
      "Training round [3/200], Epoch [1/5], Step [20/47], Loss: 0.7406, batch time: 0.05, accuracy:  71.88%\n",
      "Training round [3/200], Epoch [1/5], Step [40/47], Loss: 0.6106, batch time: 0.05, accuracy:  80.47%\n",
      "Training round [3/200], Epoch [2/5], Step [20/47], Loss: 0.6505, batch time: 0.04, accuracy:  82.81%\n",
      "Training round [3/200], Epoch [2/5], Step [40/47], Loss: 0.5434, batch time: 0.04, accuracy:  84.38%\n",
      "Training round [3/200], Epoch [3/5], Step [20/47], Loss: 0.5983, batch time: 0.05, accuracy:  82.81%\n",
      "Training round [3/200], Epoch [3/5], Step [40/47], Loss: 0.5576, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [3/200], Epoch [4/5], Step [20/47], Loss: 0.6406, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [3/200], Epoch [4/5], Step [40/47], Loss: 0.4331, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [3/200], Epoch [5/5], Step [20/47], Loss: 0.5525, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [3/200], Epoch [5/5], Step [40/47], Loss: 0.4381, batch time: 0.04, accuracy:  88.28%\n",
      "Training round [3/200], qnn_train_step: [100/1000], loss: 0.44369935989379883, accuracy: 88.1 %\n",
      "Training round [3/200], qnn_train_step: [200/1000], loss: 2.2566370964050293, accuracy: 50.8 %\n",
      "Training round [3/200], qnn_train_step: [300/1000], loss: 0.4488857090473175, accuracy: 86.1 %\n",
      "Training round [3/200], qnn_train_step: [400/1000], loss: 0.4319564998149872, accuracy: 87.0 %\n",
      "Training round [3/200], qnn_train_step: [500/1000], loss: 0.47424983978271484, accuracy: 85.1 %\n",
      "Training round [3/200], qnn_train_step: [600/1000], loss: 0.4244103729724884, accuracy: 86.8 %\n",
      "Training round [3/200], qnn_train_step: [700/1000], loss: 0.6405994892120361, accuracy: 76.1 %\n",
      "Training round [3/200], qnn_train_step: [800/1000], loss: 0.419207364320755, accuracy: 88.4 %\n",
      "Training round [3/200], qnn_train_step: [900/1000], loss: 0.43215835094451904, accuracy: 87.9 %\n",
      "Training round [3/200], qnn_train_step: [1000/1000], loss: 0.6342126131057739, accuracy: 79.0 %\n",
      "-----------------------\n",
      "Training round [4/200], Epoch [1/5], Step [20/47], Loss: 0.4994, batch time: 0.11, accuracy:  87.50%\n",
      "Training round [4/200], Epoch [1/5], Step [40/47], Loss: 0.5001, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [4/200], Epoch [2/5], Step [20/47], Loss: 0.3750, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [4/200], Epoch [2/5], Step [40/47], Loss: 0.4273, batch time: 0.05, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [3/5], Step [20/47], Loss: 0.3834, batch time: 0.05, accuracy:  86.72%\n",
      "Training round [4/200], Epoch [3/5], Step [40/47], Loss: 0.5881, batch time: 0.10, accuracy:  82.81%\n",
      "Training round [4/200], Epoch [4/5], Step [20/47], Loss: 0.4285, batch time: 0.10, accuracy:  85.16%\n",
      "Training round [4/200], Epoch [4/5], Step [40/47], Loss: 0.5218, batch time: 0.05, accuracy:  83.59%\n",
      "Training round [4/200], Epoch [5/5], Step [20/47], Loss: 0.4760, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [4/200], Epoch [5/5], Step [40/47], Loss: 0.6055, batch time: 0.05, accuracy:  82.03%\n",
      "Training round [4/200], qnn_train_step: [100/1000], loss: 0.4154004752635956, accuracy: 87.7 %\n",
      "Training round [4/200], qnn_train_step: [200/1000], loss: 0.6205989122390747, accuracy: 81.5 %\n",
      "Training round [4/200], qnn_train_step: [300/1000], loss: 0.42309364676475525, accuracy: 88.0 %\n",
      "Training round [4/200], qnn_train_step: [400/1000], loss: 0.41055139899253845, accuracy: 88.9 %\n",
      "Training round [4/200], qnn_train_step: [500/1000], loss: 0.4300960302352905, accuracy: 87.1 %\n",
      "Training round [4/200], qnn_train_step: [600/1000], loss: 0.41843241453170776, accuracy: 88.5 %\n",
      "Training round [4/200], qnn_train_step: [700/1000], loss: 0.40769362449645996, accuracy: 87.5 %\n",
      "Training round [4/200], qnn_train_step: [800/1000], loss: 0.4006529450416565, accuracy: 88.4 %\n",
      "Training round [4/200], qnn_train_step: [900/1000], loss: 0.4055664539337158, accuracy: 87.7 %\n",
      "Training round [4/200], qnn_train_step: [1000/1000], loss: 0.3932695984840393, accuracy: 88.2 %\n",
      "-----------------------\n",
      "Training round [5/200], Epoch [1/5], Step [20/47], Loss: 0.4602, batch time: 0.11, accuracy:  89.06%\n",
      "Training round [5/200], Epoch [1/5], Step [40/47], Loss: 0.2452, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [5/200], Epoch [2/5], Step [20/47], Loss: 0.4266, batch time: 0.11, accuracy:  85.16%\n",
      "Training round [5/200], Epoch [2/5], Step [40/47], Loss: 0.3613, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [5/200], Epoch [3/5], Step [20/47], Loss: 0.4133, batch time: 0.07, accuracy:  91.41%\n",
      "Training round [5/200], Epoch [3/5], Step [40/47], Loss: 0.4570, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [5/200], Epoch [4/5], Step [20/47], Loss: 0.5785, batch time: 0.11, accuracy:  83.59%\n",
      "Training round [5/200], Epoch [4/5], Step [40/47], Loss: 0.4607, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [5/200], Epoch [5/5], Step [20/47], Loss: 0.4353, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [5/200], Epoch [5/5], Step [40/47], Loss: 0.2525, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [5/200], qnn_train_step: [100/1000], loss: 0.33963972330093384, accuracy: 90.7 %\n",
      "Training round [5/200], qnn_train_step: [200/1000], loss: 0.33807191252708435, accuracy: 90.8 %\n",
      "Training round [5/200], qnn_train_step: [300/1000], loss: 0.3292774260044098, accuracy: 91.4 %\n",
      "Training round [5/200], qnn_train_step: [400/1000], loss: 0.3244701325893402, accuracy: 91.2 %\n",
      "Training round [5/200], qnn_train_step: [500/1000], loss: 0.32185089588165283, accuracy: 91.0 %\n",
      "Training round [5/200], qnn_train_step: [600/1000], loss: 0.32181140780448914, accuracy: 91.1 %\n",
      "Training round [5/200], qnn_train_step: [700/1000], loss: 0.4020790159702301, accuracy: 88.0 %\n",
      "Training round [5/200], qnn_train_step: [800/1000], loss: 0.33896973729133606, accuracy: 90.1 %\n",
      "Training round [5/200], qnn_train_step: [900/1000], loss: 0.3592562675476074, accuracy: 89.7 %\n",
      "Training round [5/200], qnn_train_step: [1000/1000], loss: 0.3152529001235962, accuracy: 91.1 %\n",
      "-----------------------\n",
      "Training round [6/200], Epoch [1/5], Step [20/47], Loss: 0.2765, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [6/200], Epoch [1/5], Step [40/47], Loss: 0.2048, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [6/200], Epoch [2/5], Step [20/47], Loss: 0.2211, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [6/200], Epoch [2/5], Step [40/47], Loss: 0.4258, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [6/200], Epoch [3/5], Step [20/47], Loss: 0.3847, batch time: 0.08, accuracy:  85.16%\n",
      "Training round [6/200], Epoch [3/5], Step [40/47], Loss: 0.3843, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [6/200], Epoch [4/5], Step [20/47], Loss: 0.2615, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [6/200], Epoch [4/5], Step [40/47], Loss: 0.2688, batch time: 0.05, accuracy:  89.06%\n",
      "Training round [6/200], Epoch [5/5], Step [20/47], Loss: 0.5275, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [6/200], Epoch [5/5], Step [40/47], Loss: 0.4836, batch time: 0.05, accuracy:  85.94%\n",
      "Training round [6/200], qnn_train_step: [100/1000], loss: 0.2818472385406494, accuracy: 93.0 %\n",
      "Training round [6/200], qnn_train_step: [200/1000], loss: 0.27934888005256653, accuracy: 92.9 %\n",
      "Training round [6/200], qnn_train_step: [300/1000], loss: 0.27753812074661255, accuracy: 92.7 %\n",
      "Training round [6/200], qnn_train_step: [400/1000], loss: 0.26731008291244507, accuracy: 92.3 %\n",
      "Training round [6/200], qnn_train_step: [500/1000], loss: 0.32867008447647095, accuracy: 89.6 %\n",
      "Training round [6/200], qnn_train_step: [600/1000], loss: 0.2700027823448181, accuracy: 92.3 %\n",
      "Training round [6/200], qnn_train_step: [700/1000], loss: 0.26403898000717163, accuracy: 92.5 %\n",
      "Training round [6/200], qnn_train_step: [800/1000], loss: 0.2746167480945587, accuracy: 92.1 %\n",
      "Training round [6/200], qnn_train_step: [900/1000], loss: 0.3119405508041382, accuracy: 91.1 %\n",
      "Training round [6/200], qnn_train_step: [1000/1000], loss: 0.25821471214294434, accuracy: 92.1 %\n",
      "-----------------------\n",
      "Training round [7/200], Epoch [1/5], Step [20/47], Loss: 0.5102, batch time: 0.10, accuracy:  87.50%\n",
      "Training round [7/200], Epoch [1/5], Step [40/47], Loss: 0.3682, batch time: 0.10, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [2/5], Step [20/47], Loss: 0.3380, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [7/200], Epoch [2/5], Step [40/47], Loss: 0.2972, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [7/200], Epoch [3/5], Step [20/47], Loss: 0.2972, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [7/200], Epoch [3/5], Step [40/47], Loss: 0.3642, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [4/5], Step [20/47], Loss: 0.3413, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [7/200], Epoch [4/5], Step [40/47], Loss: 0.3582, batch time: 0.10, accuracy:  86.72%\n",
      "Training round [7/200], Epoch [5/5], Step [20/47], Loss: 0.4065, batch time: 0.11, accuracy:  88.28%\n",
      "Training round [7/200], Epoch [5/5], Step [40/47], Loss: 0.3279, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [7/200], qnn_train_step: [100/1000], loss: 0.256870836019516, accuracy: 92.6 %\n",
      "Training round [7/200], qnn_train_step: [200/1000], loss: 0.24874456226825714, accuracy: 92.9 %\n",
      "Training round [7/200], qnn_train_step: [300/1000], loss: 0.24806803464889526, accuracy: 93.1 %\n",
      "Training round [7/200], qnn_train_step: [400/1000], loss: 0.22628939151763916, accuracy: 93.3 %\n",
      "Training round [7/200], qnn_train_step: [500/1000], loss: 0.227317675948143, accuracy: 93.6 %\n",
      "Training round [7/200], qnn_train_step: [600/1000], loss: 0.21580827236175537, accuracy: 93.8 %\n",
      "Training round [7/200], qnn_train_step: [700/1000], loss: 0.21688176691532135, accuracy: 94.0 %\n",
      "Training round [7/200], qnn_train_step: [800/1000], loss: 0.21320495009422302, accuracy: 93.6 %\n",
      "Training round [7/200], qnn_train_step: [900/1000], loss: 0.2662068009376526, accuracy: 91.0 %\n",
      "Training round [7/200], qnn_train_step: [1000/1000], loss: 0.25550296902656555, accuracy: 92.6 %\n",
      "-----------------------\n",
      "Training round [8/200], Epoch [1/5], Step [20/47], Loss: 0.3507, batch time: 0.10, accuracy:  85.94%\n",
      "Training round [8/200], Epoch [1/5], Step [40/47], Loss: 0.2677, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [8/200], Epoch [2/5], Step [20/47], Loss: 0.1792, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [8/200], Epoch [2/5], Step [40/47], Loss: 0.3200, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [8/200], Epoch [3/5], Step [20/47], Loss: 0.2949, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [8/200], Epoch [3/5], Step [40/47], Loss: 0.2295, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [8/200], Epoch [4/5], Step [20/47], Loss: 0.1469, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [8/200], Epoch [4/5], Step [40/47], Loss: 0.3844, batch time: 0.11, accuracy:  90.62%\n",
      "Training round [8/200], Epoch [5/5], Step [20/47], Loss: 0.3432, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [8/200], Epoch [5/5], Step [40/47], Loss: 0.2949, batch time: 0.10, accuracy:  89.06%\n",
      "Training round [8/200], qnn_train_step: [100/1000], loss: 0.25606590509414673, accuracy: 92.7 %\n",
      "Training round [8/200], qnn_train_step: [200/1000], loss: 0.4821062684059143, accuracy: 84.5 %\n",
      "Training round [8/200], qnn_train_step: [300/1000], loss: 0.2845551371574402, accuracy: 91.9 %\n",
      "Training round [8/200], qnn_train_step: [400/1000], loss: 0.241069495677948, accuracy: 93.3 %\n",
      "Training round [8/200], qnn_train_step: [500/1000], loss: 0.2512837052345276, accuracy: 93.0 %\n",
      "Training round [8/200], qnn_train_step: [600/1000], loss: 0.24051445722579956, accuracy: 93.4 %\n",
      "Training round [8/200], qnn_train_step: [700/1000], loss: 0.24695000052452087, accuracy: 92.4 %\n",
      "Training round [8/200], qnn_train_step: [800/1000], loss: 0.24103155732154846, accuracy: 92.1 %\n",
      "Training round [8/200], qnn_train_step: [900/1000], loss: 0.249570831656456, accuracy: 92.6 %\n",
      "Training round [8/200], qnn_train_step: [1000/1000], loss: 0.22508181631565094, accuracy: 93.4 %\n",
      "-----------------------\n",
      "Training round [9/200], Epoch [1/5], Step [20/47], Loss: 0.3400, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [9/200], Epoch [1/5], Step [40/47], Loss: 0.2122, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [9/200], Epoch [2/5], Step [20/47], Loss: 0.2710, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [9/200], Epoch [2/5], Step [40/47], Loss: 0.4846, batch time: 0.05, accuracy:  87.50%\n",
      "Training round [9/200], Epoch [3/5], Step [20/47], Loss: 0.2426, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [9/200], Epoch [3/5], Step [40/47], Loss: 0.2169, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [9/200], Epoch [4/5], Step [20/47], Loss: 0.2245, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [9/200], Epoch [4/5], Step [40/47], Loss: 0.1843, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [9/200], Epoch [5/5], Step [20/47], Loss: 0.1261, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [9/200], Epoch [5/5], Step [40/47], Loss: 0.2688, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [9/200], qnn_train_step: [100/1000], loss: 0.19057320058345795, accuracy: 94.8 %\n",
      "Training round [9/200], qnn_train_step: [200/1000], loss: 0.6110481023788452, accuracy: 80.9 %\n",
      "Training round [9/200], qnn_train_step: [300/1000], loss: 0.22629967331886292, accuracy: 93.5 %\n",
      "Training round [9/200], qnn_train_step: [400/1000], loss: 0.18514129519462585, accuracy: 94.7 %\n",
      "Training round [9/200], qnn_train_step: [500/1000], loss: 0.19120395183563232, accuracy: 94.3 %\n",
      "Training round [9/200], qnn_train_step: [600/1000], loss: 0.18229974806308746, accuracy: 95.1 %\n",
      "Training round [9/200], qnn_train_step: [700/1000], loss: 0.18222245573997498, accuracy: 94.7 %\n",
      "Training round [9/200], qnn_train_step: [800/1000], loss: 0.18043531477451324, accuracy: 95.0 %\n",
      "Training round [9/200], qnn_train_step: [900/1000], loss: 0.17973117530345917, accuracy: 94.8 %\n",
      "Training round [9/200], qnn_train_step: [1000/1000], loss: 0.1790471225976944, accuracy: 94.8 %\n",
      "-----------------------\n",
      "Training round [10/200], Epoch [1/5], Step [20/47], Loss: 0.1945, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [10/200], Epoch [1/5], Step [40/47], Loss: 0.1485, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [10/200], Epoch [2/5], Step [20/47], Loss: 0.1810, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [10/200], Epoch [2/5], Step [40/47], Loss: 0.2471, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [10/200], Epoch [3/5], Step [20/47], Loss: 0.2599, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [10/200], Epoch [3/5], Step [40/47], Loss: 0.3557, batch time: 0.05, accuracy:  88.28%\n",
      "Training round [10/200], Epoch [4/5], Step [20/47], Loss: 0.1864, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [10/200], Epoch [4/5], Step [40/47], Loss: 0.1693, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [10/200], Epoch [5/5], Step [20/47], Loss: 0.1910, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [10/200], Epoch [5/5], Step [40/47], Loss: 0.1720, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [10/200], qnn_train_step: [100/1000], loss: 0.13115574419498444, accuracy: 95.2 %\n",
      "Training round [10/200], qnn_train_step: [200/1000], loss: 0.13874933123588562, accuracy: 95.4 %\n",
      "Training round [10/200], qnn_train_step: [300/1000], loss: 0.11712166666984558, accuracy: 96.1 %\n",
      "Training round [10/200], qnn_train_step: [400/1000], loss: 0.12141885608434677, accuracy: 95.9 %\n",
      "Training round [10/200], qnn_train_step: [500/1000], loss: 0.1195703074336052, accuracy: 95.7 %\n",
      "Training round [10/200], qnn_train_step: [600/1000], loss: 0.12629501521587372, accuracy: 95.3 %\n",
      "Training round [10/200], qnn_train_step: [700/1000], loss: 0.11211348325014114, accuracy: 96.0 %\n",
      "Training round [10/200], qnn_train_step: [800/1000], loss: 0.11136464029550552, accuracy: 96.3 %\n",
      "Training round [10/200], qnn_train_step: [900/1000], loss: 0.11442884057760239, accuracy: 95.8 %\n",
      "Training round [10/200], qnn_train_step: [1000/1000], loss: 0.10782090574502945, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [11/200], Epoch [1/5], Step [20/47], Loss: 0.2348, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [1/5], Step [40/47], Loss: 0.1689, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [11/200], Epoch [2/5], Step [20/47], Loss: 0.2204, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [11/200], Epoch [2/5], Step [40/47], Loss: 0.1729, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [11/200], Epoch [3/5], Step [20/47], Loss: 0.2218, batch time: 0.05, accuracy:  89.84%\n",
      "Training round [11/200], Epoch [3/5], Step [40/47], Loss: 0.3282, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [4/5], Step [20/47], Loss: 0.3447, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [11/200], Epoch [4/5], Step [40/47], Loss: 0.1812, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [5/5], Step [20/47], Loss: 0.1930, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [11/200], Epoch [5/5], Step [40/47], Loss: 0.1146, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [11/200], qnn_train_step: [100/1000], loss: 0.23128388822078705, accuracy: 92.9 %\n",
      "Training round [11/200], qnn_train_step: [200/1000], loss: 0.23987659811973572, accuracy: 92.2 %\n",
      "Training round [11/200], qnn_train_step: [300/1000], loss: 0.22131289541721344, accuracy: 93.7 %\n",
      "Training round [11/200], qnn_train_step: [400/1000], loss: 0.202043816447258, accuracy: 93.3 %\n",
      "Training round [11/200], qnn_train_step: [500/1000], loss: 0.2111300528049469, accuracy: 93.2 %\n",
      "Training round [11/200], qnn_train_step: [600/1000], loss: 0.21043822169303894, accuracy: 94.0 %\n",
      "Training round [11/200], qnn_train_step: [700/1000], loss: 0.2252097874879837, accuracy: 92.8 %\n",
      "Training round [11/200], qnn_train_step: [800/1000], loss: 0.18988221883773804, accuracy: 94.3 %\n",
      "Training round [11/200], qnn_train_step: [900/1000], loss: 0.19762742519378662, accuracy: 93.7 %\n",
      "Training round [11/200], qnn_train_step: [1000/1000], loss: 0.1976560801267624, accuracy: 94.2 %\n",
      "-----------------------\n",
      "Training round [12/200], Epoch [1/5], Step [20/47], Loss: 0.2441, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [1/5], Step [40/47], Loss: 0.1933, batch time: 0.04, accuracy:  92.97%\n",
      "Training round [12/200], Epoch [2/5], Step [20/47], Loss: 0.3286, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [12/200], Epoch [2/5], Step [40/47], Loss: 0.1859, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [12/200], Epoch [3/5], Step [20/47], Loss: 0.1954, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [12/200], Epoch [3/5], Step [40/47], Loss: 0.1843, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [12/200], Epoch [4/5], Step [20/47], Loss: 0.2605, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [12/200], Epoch [4/5], Step [40/47], Loss: 0.2015, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [12/200], Epoch [5/5], Step [20/47], Loss: 0.1655, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [12/200], Epoch [5/5], Step [40/47], Loss: 0.2333, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [12/200], qnn_train_step: [100/1000], loss: 0.22874245047569275, accuracy: 92.6 %\n",
      "Training round [12/200], qnn_train_step: [200/1000], loss: 0.22595252096652985, accuracy: 93.4 %\n",
      "Training round [12/200], qnn_train_step: [300/1000], loss: 0.2191896289587021, accuracy: 93.3 %\n",
      "Training round [12/200], qnn_train_step: [400/1000], loss: 0.21902763843536377, accuracy: 93.3 %\n",
      "Training round [12/200], qnn_train_step: [500/1000], loss: 0.2522434890270233, accuracy: 91.5 %\n",
      "Training round [12/200], qnn_train_step: [600/1000], loss: 0.22503463923931122, accuracy: 93.2 %\n",
      "Training round [12/200], qnn_train_step: [700/1000], loss: 0.22071437537670135, accuracy: 93.6 %\n",
      "Training round [12/200], qnn_train_step: [800/1000], loss: 0.21969982981681824, accuracy: 93.3 %\n",
      "Training round [12/200], qnn_train_step: [900/1000], loss: 0.2114744931459427, accuracy: 93.5 %\n",
      "Training round [12/200], qnn_train_step: [1000/1000], loss: 0.20620191097259521, accuracy: 93.7 %\n",
      "-----------------------\n",
      "Training round [13/200], Epoch [1/5], Step [20/47], Loss: 0.2679, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [13/200], Epoch [1/5], Step [40/47], Loss: 0.2760, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [13/200], Epoch [2/5], Step [20/47], Loss: 0.2146, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [2/5], Step [40/47], Loss: 0.2145, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [3/5], Step [20/47], Loss: 0.1537, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [3/5], Step [40/47], Loss: 0.1323, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [4/5], Step [20/47], Loss: 0.1329, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [4/5], Step [40/47], Loss: 0.1543, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [13/200], Epoch [5/5], Step [20/47], Loss: 0.2600, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [13/200], Epoch [5/5], Step [40/47], Loss: 0.0824, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [13/200], qnn_train_step: [100/1000], loss: 0.1992587149143219, accuracy: 93.0 %\n",
      "Training round [13/200], qnn_train_step: [200/1000], loss: 0.3286786377429962, accuracy: 89.4 %\n",
      "Training round [13/200], qnn_train_step: [300/1000], loss: 0.19780486822128296, accuracy: 93.4 %\n",
      "Training round [13/200], qnn_train_step: [400/1000], loss: 0.1906789243221283, accuracy: 93.5 %\n",
      "Training round [13/200], qnn_train_step: [500/1000], loss: 0.20328794419765472, accuracy: 93.4 %\n",
      "Training round [13/200], qnn_train_step: [600/1000], loss: 0.18271473050117493, accuracy: 94.1 %\n",
      "Training round [13/200], qnn_train_step: [700/1000], loss: 0.18108902871608734, accuracy: 94.2 %\n",
      "Training round [13/200], qnn_train_step: [800/1000], loss: 0.18668711185455322, accuracy: 93.6 %\n",
      "Training round [13/200], qnn_train_step: [900/1000], loss: 0.179435595870018, accuracy: 94.5 %\n",
      "Training round [13/200], qnn_train_step: [1000/1000], loss: 0.17745603621006012, accuracy: 94.3 %\n",
      "-----------------------\n",
      "Training round [14/200], Epoch [1/5], Step [20/47], Loss: 0.2547, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [14/200], Epoch [1/5], Step [40/47], Loss: 0.1446, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [14/200], Epoch [2/5], Step [20/47], Loss: 0.2594, batch time: 0.10, accuracy:  89.84%\n",
      "Training round [14/200], Epoch [2/5], Step [40/47], Loss: 0.1384, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [14/200], Epoch [3/5], Step [20/47], Loss: 0.2520, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [14/200], Epoch [3/5], Step [40/47], Loss: 0.1219, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [14/200], Epoch [4/5], Step [20/47], Loss: 0.1084, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [14/200], Epoch [4/5], Step [40/47], Loss: 0.2115, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [14/200], Epoch [5/5], Step [20/47], Loss: 0.1269, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [14/200], Epoch [5/5], Step [40/47], Loss: 0.1510, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [14/200], qnn_train_step: [100/1000], loss: 0.18713638186454773, accuracy: 94.2 %\n",
      "Training round [14/200], qnn_train_step: [200/1000], loss: 0.18825523555278778, accuracy: 94.5 %\n",
      "Training round [14/200], qnn_train_step: [300/1000], loss: 0.19130399823188782, accuracy: 93.4 %\n",
      "Training round [14/200], qnn_train_step: [400/1000], loss: 0.17705212533473969, accuracy: 95.0 %\n",
      "Training round [14/200], qnn_train_step: [500/1000], loss: 0.17678967118263245, accuracy: 95.2 %\n",
      "Training round [14/200], qnn_train_step: [600/1000], loss: 0.18019473552703857, accuracy: 94.9 %\n",
      "Training round [14/200], qnn_train_step: [700/1000], loss: 0.1894906461238861, accuracy: 94.4 %\n",
      "Training round [14/200], qnn_train_step: [800/1000], loss: 0.1740807443857193, accuracy: 94.9 %\n",
      "Training round [14/200], qnn_train_step: [900/1000], loss: 0.18759354948997498, accuracy: 94.8 %\n",
      "Training round [14/200], qnn_train_step: [1000/1000], loss: 0.1708424836397171, accuracy: 95.2 %\n",
      "-----------------------\n",
      "Training round [15/200], Epoch [1/5], Step [20/47], Loss: 0.1211, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [15/200], Epoch [1/5], Step [40/47], Loss: 0.2134, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [2/5], Step [20/47], Loss: 0.2371, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [2/5], Step [40/47], Loss: 0.0913, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [15/200], Epoch [3/5], Step [20/47], Loss: 0.1899, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [15/200], Epoch [3/5], Step [40/47], Loss: 0.2383, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [15/200], Epoch [4/5], Step [20/47], Loss: 0.1971, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [4/5], Step [40/47], Loss: 0.1863, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], Epoch [5/5], Step [20/47], Loss: 0.1999, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [15/200], Epoch [5/5], Step [40/47], Loss: 0.2748, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [15/200], qnn_train_step: [100/1000], loss: 0.1614208072423935, accuracy: 94.2 %\n",
      "Training round [15/200], qnn_train_step: [200/1000], loss: 0.1717810481786728, accuracy: 93.6 %\n",
      "Training round [15/200], qnn_train_step: [300/1000], loss: 0.1550332009792328, accuracy: 94.5 %\n",
      "Training round [15/200], qnn_train_step: [400/1000], loss: 0.1481621414422989, accuracy: 94.7 %\n",
      "Training round [15/200], qnn_train_step: [500/1000], loss: 0.152782142162323, accuracy: 94.3 %\n",
      "Training round [15/200], qnn_train_step: [600/1000], loss: 0.1583324670791626, accuracy: 93.9 %\n",
      "Training round [15/200], qnn_train_step: [700/1000], loss: 0.14508332312107086, accuracy: 94.6 %\n",
      "Training round [15/200], qnn_train_step: [800/1000], loss: 0.18589869141578674, accuracy: 93.9 %\n",
      "Training round [15/200], qnn_train_step: [900/1000], loss: 0.15678828954696655, accuracy: 94.4 %\n",
      "Training round [15/200], qnn_train_step: [1000/1000], loss: 0.14844049513339996, accuracy: 94.6 %\n",
      "-----------------------\n",
      "Training round [16/200], Epoch [1/5], Step [20/47], Loss: 0.1583, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [16/200], Epoch [1/5], Step [40/47], Loss: 0.1159, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [16/200], Epoch [2/5], Step [20/47], Loss: 0.2101, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [16/200], Epoch [2/5], Step [40/47], Loss: 0.1088, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [16/200], Epoch [3/5], Step [20/47], Loss: 0.1471, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [16/200], Epoch [3/5], Step [40/47], Loss: 0.1354, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [16/200], Epoch [4/5], Step [20/47], Loss: 0.1202, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [16/200], Epoch [4/5], Step [40/47], Loss: 0.2446, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [16/200], Epoch [5/5], Step [20/47], Loss: 0.1498, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [16/200], Epoch [5/5], Step [40/47], Loss: 0.1833, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [16/200], qnn_train_step: [100/1000], loss: 0.16592368483543396, accuracy: 93.9 %\n",
      "Training round [16/200], qnn_train_step: [200/1000], loss: 0.16662363708019257, accuracy: 94.3 %\n",
      "Training round [16/200], qnn_train_step: [300/1000], loss: 0.18213070929050446, accuracy: 94.3 %\n",
      "Training round [16/200], qnn_train_step: [400/1000], loss: 0.15147294104099274, accuracy: 95.0 %\n",
      "Training round [16/200], qnn_train_step: [500/1000], loss: 0.153126522898674, accuracy: 94.8 %\n",
      "Training round [16/200], qnn_train_step: [600/1000], loss: 0.1501663327217102, accuracy: 95.2 %\n",
      "Training round [16/200], qnn_train_step: [700/1000], loss: 0.1510562151670456, accuracy: 95.1 %\n",
      "Training round [16/200], qnn_train_step: [800/1000], loss: 0.1419309377670288, accuracy: 95.7 %\n",
      "Training round [16/200], qnn_train_step: [900/1000], loss: 0.1397837996482849, accuracy: 95.5 %\n",
      "Training round [16/200], qnn_train_step: [1000/1000], loss: 0.1425069123506546, accuracy: 95.4 %\n",
      "-----------------------\n",
      "Training round [17/200], Epoch [1/5], Step [20/47], Loss: 0.2696, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [17/200], Epoch [1/5], Step [40/47], Loss: 0.2323, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [17/200], Epoch [2/5], Step [20/47], Loss: 0.1207, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [2/5], Step [40/47], Loss: 0.2846, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [3/5], Step [20/47], Loss: 0.1652, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [17/200], Epoch [3/5], Step [40/47], Loss: 0.1971, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [17/200], Epoch [4/5], Step [20/47], Loss: 0.1205, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [17/200], Epoch [4/5], Step [40/47], Loss: 0.2554, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [17/200], Epoch [5/5], Step [20/47], Loss: 0.1635, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [17/200], Epoch [5/5], Step [40/47], Loss: 0.1185, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [17/200], qnn_train_step: [100/1000], loss: 0.17620985209941864, accuracy: 94.6 %\n",
      "Training round [17/200], qnn_train_step: [200/1000], loss: 0.32530662417411804, accuracy: 90.1 %\n",
      "Training round [17/200], qnn_train_step: [300/1000], loss: 0.18171508610248566, accuracy: 94.2 %\n",
      "Training round [17/200], qnn_train_step: [400/1000], loss: 0.1619175672531128, accuracy: 94.7 %\n",
      "Training round [17/200], qnn_train_step: [500/1000], loss: 0.18359707295894623, accuracy: 94.4 %\n",
      "Training round [17/200], qnn_train_step: [600/1000], loss: 0.16654646396636963, accuracy: 94.7 %\n",
      "Training round [17/200], qnn_train_step: [700/1000], loss: 0.15985719859600067, accuracy: 95.4 %\n",
      "Training round [17/200], qnn_train_step: [800/1000], loss: 0.20551595091819763, accuracy: 93.7 %\n",
      "Training round [17/200], qnn_train_step: [900/1000], loss: 0.1588049679994583, accuracy: 95.2 %\n",
      "Training round [17/200], qnn_train_step: [1000/1000], loss: 0.16592933237552643, accuracy: 95.0 %\n",
      "-----------------------\n",
      "Training round [18/200], Epoch [1/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [18/200], Epoch [1/5], Step [40/47], Loss: 0.1499, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [2/5], Step [20/47], Loss: 0.1472, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [18/200], Epoch [2/5], Step [40/47], Loss: 0.3047, batch time: 0.11, accuracy:  89.84%\n",
      "Training round [18/200], Epoch [3/5], Step [20/47], Loss: 0.1133, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [18/200], Epoch [3/5], Step [40/47], Loss: 0.0809, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [4/5], Step [20/47], Loss: 0.1653, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [18/200], Epoch [4/5], Step [40/47], Loss: 0.0912, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [5/5], Step [20/47], Loss: 0.1813, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [18/200], Epoch [5/5], Step [40/47], Loss: 0.0987, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [18/200], qnn_train_step: [100/1000], loss: 0.16064156591892242, accuracy: 95.3 %\n",
      "Training round [18/200], qnn_train_step: [200/1000], loss: 0.2502876818180084, accuracy: 92.1 %\n",
      "Training round [18/200], qnn_train_step: [300/1000], loss: 0.14343422651290894, accuracy: 96.1 %\n",
      "Training round [18/200], qnn_train_step: [400/1000], loss: 0.13684740662574768, accuracy: 96.2 %\n",
      "Training round [18/200], qnn_train_step: [500/1000], loss: 0.13427771627902985, accuracy: 96.3 %\n",
      "Training round [18/200], qnn_train_step: [600/1000], loss: 0.13551877439022064, accuracy: 96.3 %\n",
      "Training round [18/200], qnn_train_step: [700/1000], loss: 0.14598557353019714, accuracy: 95.6 %\n",
      "Training round [18/200], qnn_train_step: [800/1000], loss: 0.12889590859413147, accuracy: 96.0 %\n",
      "Training round [18/200], qnn_train_step: [900/1000], loss: 0.12782178819179535, accuracy: 96.0 %\n",
      "Training round [18/200], qnn_train_step: [1000/1000], loss: 0.1295672357082367, accuracy: 95.8 %\n",
      "-----------------------\n",
      "Training round [19/200], Epoch [1/5], Step [20/47], Loss: 0.1755, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [1/5], Step [40/47], Loss: 0.1496, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [19/200], Epoch [2/5], Step [20/47], Loss: 0.1155, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [2/5], Step [40/47], Loss: 0.1347, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [3/5], Step [20/47], Loss: 0.1726, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [19/200], Epoch [3/5], Step [40/47], Loss: 0.1309, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [19/200], Epoch [4/5], Step [20/47], Loss: 0.2734, batch time: 0.10, accuracy:  90.62%\n",
      "Training round [19/200], Epoch [4/5], Step [40/47], Loss: 0.1873, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [19/200], Epoch [5/5], Step [20/47], Loss: 0.2061, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [19/200], Epoch [5/5], Step [40/47], Loss: 0.2257, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [19/200], qnn_train_step: [100/1000], loss: 0.11923833191394806, accuracy: 96.7 %\n",
      "Training round [19/200], qnn_train_step: [200/1000], loss: 0.12156298011541367, accuracy: 96.5 %\n",
      "Training round [19/200], qnn_train_step: [300/1000], loss: 0.10964930802583694, accuracy: 97.1 %\n",
      "Training round [19/200], qnn_train_step: [400/1000], loss: 0.10876088589429855, accuracy: 97.1 %\n",
      "Training round [19/200], qnn_train_step: [500/1000], loss: 0.107900470495224, accuracy: 97.4 %\n",
      "Training round [19/200], qnn_train_step: [600/1000], loss: 0.11919982731342316, accuracy: 96.1 %\n",
      "Training round [19/200], qnn_train_step: [700/1000], loss: 0.10814642906188965, accuracy: 97.2 %\n",
      "Training round [19/200], qnn_train_step: [800/1000], loss: 0.10541478544473648, accuracy: 97.4 %\n",
      "Training round [19/200], qnn_train_step: [900/1000], loss: 0.1044396236538887, accuracy: 97.2 %\n",
      "Training round [19/200], qnn_train_step: [1000/1000], loss: 0.10328543931245804, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [20/200], Epoch [1/5], Step [20/47], Loss: 0.2218, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [20/200], Epoch [1/5], Step [40/47], Loss: 0.1681, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [20/200], Epoch [2/5], Step [20/47], Loss: 0.1110, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [20/200], Epoch [2/5], Step [40/47], Loss: 0.2076, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [3/5], Step [20/47], Loss: 0.1917, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [3/5], Step [40/47], Loss: 0.2005, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [20/200], Epoch [4/5], Step [20/47], Loss: 0.0726, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [20/200], Epoch [4/5], Step [40/47], Loss: 0.1759, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [20/200], Epoch [5/5], Step [20/47], Loss: 0.1711, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [20/200], Epoch [5/5], Step [40/47], Loss: 0.1866, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [20/200], qnn_train_step: [100/1000], loss: 0.1346399039030075, accuracy: 96.1 %\n",
      "Training round [20/200], qnn_train_step: [200/1000], loss: 0.14599201083183289, accuracy: 95.8 %\n",
      "Training round [20/200], qnn_train_step: [300/1000], loss: 0.1328430324792862, accuracy: 96.1 %\n",
      "Training round [20/200], qnn_train_step: [400/1000], loss: 0.1256762146949768, accuracy: 96.6 %\n",
      "Training round [20/200], qnn_train_step: [500/1000], loss: 0.13791844248771667, accuracy: 95.8 %\n",
      "Training round [20/200], qnn_train_step: [600/1000], loss: 0.12184956669807434, accuracy: 96.7 %\n",
      "Training round [20/200], qnn_train_step: [700/1000], loss: 0.12144281715154648, accuracy: 96.7 %\n",
      "Training round [20/200], qnn_train_step: [800/1000], loss: 0.12070968747138977, accuracy: 96.7 %\n",
      "Training round [20/200], qnn_train_step: [900/1000], loss: 0.1204029768705368, accuracy: 96.8 %\n",
      "Training round [20/200], qnn_train_step: [1000/1000], loss: 0.11934266239404678, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [21/200], Epoch [1/5], Step [20/47], Loss: 0.1490, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [21/200], Epoch [1/5], Step [40/47], Loss: 0.1534, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [21/200], Epoch [2/5], Step [20/47], Loss: 0.1049, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [2/5], Step [40/47], Loss: 0.2501, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [3/5], Step [20/47], Loss: 0.1856, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [21/200], Epoch [3/5], Step [40/47], Loss: 0.1494, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [4/5], Step [20/47], Loss: 0.1259, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [4/5], Step [40/47], Loss: 0.1966, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [21/200], Epoch [5/5], Step [20/47], Loss: 0.1664, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [21/200], Epoch [5/5], Step [40/47], Loss: 0.1150, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [21/200], qnn_train_step: [100/1000], loss: 0.13730701804161072, accuracy: 95.4 %\n",
      "Training round [21/200], qnn_train_step: [200/1000], loss: 0.27788978815078735, accuracy: 91.0 %\n",
      "Training round [21/200], qnn_train_step: [300/1000], loss: 0.1254352480173111, accuracy: 95.8 %\n",
      "Training round [21/200], qnn_train_step: [400/1000], loss: 0.1245318055152893, accuracy: 96.2 %\n",
      "Training round [21/200], qnn_train_step: [500/1000], loss: 0.12164546549320221, accuracy: 96.1 %\n",
      "Training round [21/200], qnn_train_step: [600/1000], loss: 0.12272640317678452, accuracy: 95.9 %\n",
      "Training round [21/200], qnn_train_step: [700/1000], loss: 0.12591375410556793, accuracy: 95.9 %\n",
      "Training round [21/200], qnn_train_step: [800/1000], loss: 0.12269951403141022, accuracy: 95.9 %\n",
      "Training round [21/200], qnn_train_step: [900/1000], loss: 0.12705525755882263, accuracy: 95.7 %\n",
      "Training round [21/200], qnn_train_step: [1000/1000], loss: 0.12889070808887482, accuracy: 95.9 %\n",
      "-----------------------\n",
      "Training round [22/200], Epoch [1/5], Step [20/47], Loss: 0.1036, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [1/5], Step [40/47], Loss: 0.2580, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [22/200], Epoch [2/5], Step [20/47], Loss: 0.0859, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [22/200], Epoch [2/5], Step [40/47], Loss: 0.2180, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [3/5], Step [20/47], Loss: 0.1393, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [22/200], Epoch [3/5], Step [40/47], Loss: 0.1310, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [22/200], Epoch [4/5], Step [20/47], Loss: 0.0859, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [22/200], Epoch [4/5], Step [40/47], Loss: 0.1256, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [22/200], Epoch [5/5], Step [20/47], Loss: 0.0568, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [22/200], Epoch [5/5], Step [40/47], Loss: 0.1413, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [22/200], qnn_train_step: [100/1000], loss: 0.13123711943626404, accuracy: 94.9 %\n",
      "Training round [22/200], qnn_train_step: [200/1000], loss: 0.1528262346982956, accuracy: 95.3 %\n",
      "Training round [22/200], qnn_train_step: [300/1000], loss: 0.11629730463027954, accuracy: 96.4 %\n",
      "Training round [22/200], qnn_train_step: [400/1000], loss: 0.1067790538072586, accuracy: 96.6 %\n",
      "Training round [22/200], qnn_train_step: [500/1000], loss: 0.11715851724147797, accuracy: 95.7 %\n",
      "Training round [22/200], qnn_train_step: [600/1000], loss: 0.1042681410908699, accuracy: 96.2 %\n",
      "Training round [22/200], qnn_train_step: [700/1000], loss: 0.10962892323732376, accuracy: 96.5 %\n",
      "Training round [22/200], qnn_train_step: [800/1000], loss: 0.10632776468992233, accuracy: 96.4 %\n",
      "Training round [22/200], qnn_train_step: [900/1000], loss: 0.10518233478069305, accuracy: 96.6 %\n",
      "Training round [22/200], qnn_train_step: [1000/1000], loss: 0.09997553378343582, accuracy: 96.8 %\n",
      "-----------------------\n",
      "Training round [23/200], Epoch [1/5], Step [20/47], Loss: 0.1338, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [1/5], Step [40/47], Loss: 0.0984, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [2/5], Step [20/47], Loss: 0.1884, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [23/200], Epoch [2/5], Step [40/47], Loss: 0.1205, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [23/200], Epoch [3/5], Step [20/47], Loss: 0.1515, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [3/5], Step [40/47], Loss: 0.1465, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [23/200], Epoch [4/5], Step [20/47], Loss: 0.2756, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [4/5], Step [40/47], Loss: 0.3613, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [23/200], Epoch [5/5], Step [20/47], Loss: 0.0891, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [23/200], Epoch [5/5], Step [40/47], Loss: 0.1297, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [23/200], qnn_train_step: [100/1000], loss: 0.11806415766477585, accuracy: 95.8 %\n",
      "Training round [23/200], qnn_train_step: [200/1000], loss: 1.2538068294525146, accuracy: 67.3 %\n",
      "Training round [23/200], qnn_train_step: [300/1000], loss: 0.11259686201810837, accuracy: 96.2 %\n",
      "Training round [23/200], qnn_train_step: [400/1000], loss: 0.11106446385383606, accuracy: 96.4 %\n",
      "Training round [23/200], qnn_train_step: [500/1000], loss: 0.1127612292766571, accuracy: 96.3 %\n",
      "Training round [23/200], qnn_train_step: [600/1000], loss: 0.10743089020252228, accuracy: 96.1 %\n",
      "Training round [23/200], qnn_train_step: [700/1000], loss: 0.10934081673622131, accuracy: 96.1 %\n",
      "Training round [23/200], qnn_train_step: [800/1000], loss: 0.103342205286026, accuracy: 96.4 %\n",
      "Training round [23/200], qnn_train_step: [900/1000], loss: 0.10197615623474121, accuracy: 96.5 %\n",
      "Training round [23/200], qnn_train_step: [1000/1000], loss: 0.10101685672998428, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [24/200], Epoch [1/5], Step [20/47], Loss: 0.1559, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [24/200], Epoch [1/5], Step [40/47], Loss: 0.1056, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [24/200], Epoch [2/5], Step [20/47], Loss: 0.1667, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [2/5], Step [40/47], Loss: 0.2281, batch time: 0.04, accuracy:  89.84%\n",
      "Training round [24/200], Epoch [3/5], Step [20/47], Loss: 0.2217, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [24/200], Epoch [3/5], Step [40/47], Loss: 0.1369, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [24/200], Epoch [4/5], Step [20/47], Loss: 0.1756, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [4/5], Step [40/47], Loss: 0.1079, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [24/200], Epoch [5/5], Step [20/47], Loss: 0.1710, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [24/200], Epoch [5/5], Step [40/47], Loss: 0.2486, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [24/200], qnn_train_step: [100/1000], loss: 0.10065371543169022, accuracy: 97.0 %\n",
      "Training round [24/200], qnn_train_step: [200/1000], loss: 0.1990039199590683, accuracy: 94.5 %\n",
      "Training round [24/200], qnn_train_step: [300/1000], loss: 0.09594891965389252, accuracy: 96.7 %\n",
      "Training round [24/200], qnn_train_step: [400/1000], loss: 0.09534706175327301, accuracy: 96.8 %\n",
      "Training round [24/200], qnn_train_step: [500/1000], loss: 0.09985528141260147, accuracy: 96.3 %\n",
      "Training round [24/200], qnn_train_step: [600/1000], loss: 0.09621365368366241, accuracy: 96.6 %\n",
      "Training round [24/200], qnn_train_step: [700/1000], loss: 0.09475262463092804, accuracy: 96.3 %\n",
      "Training round [24/200], qnn_train_step: [800/1000], loss: 0.08595435321331024, accuracy: 97.1 %\n",
      "Training round [24/200], qnn_train_step: [900/1000], loss: 0.08541601896286011, accuracy: 97.1 %\n",
      "Training round [24/200], qnn_train_step: [1000/1000], loss: 0.0850776731967926, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [25/200], Epoch [1/5], Step [20/47], Loss: 0.1794, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [25/200], Epoch [1/5], Step [40/47], Loss: 0.0980, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [25/200], Epoch [2/5], Step [20/47], Loss: 0.1224, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [25/200], Epoch [2/5], Step [40/47], Loss: 0.2218, batch time: 0.07, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [3/5], Step [20/47], Loss: 0.1483, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [25/200], Epoch [3/5], Step [40/47], Loss: 0.1553, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [4/5], Step [20/47], Loss: 0.1574, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [25/200], Epoch [4/5], Step [40/47], Loss: 0.1137, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [25/200], Epoch [5/5], Step [20/47], Loss: 0.1068, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [25/200], Epoch [5/5], Step [40/47], Loss: 0.1354, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [25/200], qnn_train_step: [100/1000], loss: 0.1291828155517578, accuracy: 96.1 %\n",
      "Training round [25/200], qnn_train_step: [200/1000], loss: 0.44249483942985535, accuracy: 84.0 %\n",
      "Training round [25/200], qnn_train_step: [300/1000], loss: 0.12216532975435257, accuracy: 96.6 %\n",
      "Training round [25/200], qnn_train_step: [400/1000], loss: 0.11496727913618088, accuracy: 96.6 %\n",
      "Training round [25/200], qnn_train_step: [500/1000], loss: 0.11128687113523483, accuracy: 97.0 %\n",
      "Training round [25/200], qnn_train_step: [600/1000], loss: 0.11681466549634933, accuracy: 96.3 %\n",
      "Training round [25/200], qnn_train_step: [700/1000], loss: 0.11284978687763214, accuracy: 96.2 %\n",
      "Training round [25/200], qnn_train_step: [800/1000], loss: 0.11206746101379395, accuracy: 96.6 %\n",
      "Training round [25/200], qnn_train_step: [900/1000], loss: 0.10695591568946838, accuracy: 96.7 %\n",
      "Training round [25/200], qnn_train_step: [1000/1000], loss: 0.11102259904146194, accuracy: 96.9 %\n",
      "-----------------------\n",
      "Training round [26/200], Epoch [1/5], Step [20/47], Loss: 0.1588, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [26/200], Epoch [1/5], Step [40/47], Loss: 0.1313, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [2/5], Step [20/47], Loss: 0.1363, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [2/5], Step [40/47], Loss: 0.0630, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [26/200], Epoch [3/5], Step [20/47], Loss: 0.0697, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [26/200], Epoch [3/5], Step [40/47], Loss: 0.1392, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [4/5], Step [20/47], Loss: 0.1818, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [26/200], Epoch [4/5], Step [40/47], Loss: 0.1142, batch time: 0.09, accuracy:  94.53%\n",
      "Training round [26/200], Epoch [5/5], Step [20/47], Loss: 0.0730, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [26/200], Epoch [5/5], Step [40/47], Loss: 0.0462, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [26/200], qnn_train_step: [100/1000], loss: 0.16593505442142487, accuracy: 95.2 %\n",
      "Training round [26/200], qnn_train_step: [200/1000], loss: 0.1663644015789032, accuracy: 94.9 %\n",
      "Training round [26/200], qnn_train_step: [300/1000], loss: 0.15478208661079407, accuracy: 94.7 %\n",
      "Training round [26/200], qnn_train_step: [400/1000], loss: 0.14956854283809662, accuracy: 95.2 %\n",
      "Training round [26/200], qnn_train_step: [500/1000], loss: 0.15899892151355743, accuracy: 94.7 %\n",
      "Training round [26/200], qnn_train_step: [600/1000], loss: 0.1560431569814682, accuracy: 95.2 %\n",
      "Training round [26/200], qnn_train_step: [700/1000], loss: 0.14698754251003265, accuracy: 95.3 %\n",
      "Training round [26/200], qnn_train_step: [800/1000], loss: 0.15596197545528412, accuracy: 95.0 %\n",
      "Training round [26/200], qnn_train_step: [900/1000], loss: 0.15025153756141663, accuracy: 95.2 %\n",
      "Training round [26/200], qnn_train_step: [1000/1000], loss: 0.1495215743780136, accuracy: 95.6 %\n",
      "-----------------------\n",
      "Training round [27/200], Epoch [1/5], Step [20/47], Loss: 0.0838, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [27/200], Epoch [1/5], Step [40/47], Loss: 0.1241, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [2/5], Step [20/47], Loss: 0.1271, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [27/200], Epoch [2/5], Step [40/47], Loss: 0.1019, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [3/5], Step [20/47], Loss: 0.1324, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [27/200], Epoch [3/5], Step [40/47], Loss: 0.0890, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [27/200], Epoch [4/5], Step [20/47], Loss: 0.1250, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [27/200], Epoch [4/5], Step [40/47], Loss: 0.1023, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [27/200], Epoch [5/5], Step [20/47], Loss: 0.2008, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [27/200], Epoch [5/5], Step [40/47], Loss: 0.0746, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [27/200], qnn_train_step: [100/1000], loss: 0.13658791780471802, accuracy: 95.1 %\n",
      "Training round [27/200], qnn_train_step: [200/1000], loss: 0.14236031472682953, accuracy: 94.9 %\n",
      "Training round [27/200], qnn_train_step: [300/1000], loss: 0.15374091267585754, accuracy: 95.3 %\n",
      "Training round [27/200], qnn_train_step: [400/1000], loss: 0.11992457509040833, accuracy: 96.0 %\n",
      "Training round [27/200], qnn_train_step: [500/1000], loss: 0.12177206575870514, accuracy: 96.1 %\n",
      "Training round [27/200], qnn_train_step: [600/1000], loss: 0.11746290326118469, accuracy: 95.9 %\n",
      "Training round [27/200], qnn_train_step: [700/1000], loss: 0.12890812754631042, accuracy: 95.8 %\n",
      "Training round [27/200], qnn_train_step: [800/1000], loss: 0.12121570855379105, accuracy: 95.6 %\n",
      "Training round [27/200], qnn_train_step: [900/1000], loss: 0.11843643337488174, accuracy: 95.8 %\n",
      "Training round [27/200], qnn_train_step: [1000/1000], loss: 0.11571018397808075, accuracy: 95.7 %\n",
      "-----------------------\n",
      "Training round [28/200], Epoch [1/5], Step [20/47], Loss: 0.1507, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [1/5], Step [40/47], Loss: 0.1422, batch time: 0.04, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [2/5], Step [20/47], Loss: 0.1056, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [2/5], Step [40/47], Loss: 0.1673, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [3/5], Step [20/47], Loss: 0.1075, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [3/5], Step [40/47], Loss: 0.1342, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [28/200], Epoch [4/5], Step [20/47], Loss: 0.0709, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [28/200], Epoch [4/5], Step [40/47], Loss: 0.1038, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [28/200], Epoch [5/5], Step [20/47], Loss: 0.1750, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [28/200], Epoch [5/5], Step [40/47], Loss: 0.0650, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [28/200], qnn_train_step: [100/1000], loss: 0.12219387292861938, accuracy: 96.4 %\n",
      "Training round [28/200], qnn_train_step: [200/1000], loss: 0.1325279027223587, accuracy: 95.9 %\n",
      "Training round [28/200], qnn_train_step: [300/1000], loss: 0.13041074573993683, accuracy: 96.3 %\n",
      "Training round [28/200], qnn_train_step: [400/1000], loss: 0.1177200898528099, accuracy: 96.5 %\n",
      "Training round [28/200], qnn_train_step: [500/1000], loss: 0.12071547657251358, accuracy: 96.4 %\n",
      "Training round [28/200], qnn_train_step: [600/1000], loss: 0.12240973860025406, accuracy: 96.8 %\n",
      "Training round [28/200], qnn_train_step: [700/1000], loss: 0.11417420953512192, accuracy: 96.6 %\n",
      "Training round [28/200], qnn_train_step: [800/1000], loss: 0.11224230378866196, accuracy: 96.9 %\n",
      "Training round [28/200], qnn_train_step: [900/1000], loss: 0.1115446388721466, accuracy: 97.1 %\n",
      "Training round [28/200], qnn_train_step: [1000/1000], loss: 0.11301484704017639, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [29/200], Epoch [1/5], Step [20/47], Loss: 0.2039, batch time: 0.10, accuracy:  91.41%\n",
      "Training round [29/200], Epoch [1/5], Step [40/47], Loss: 0.1216, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [29/200], Epoch [2/5], Step [20/47], Loss: 0.0822, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [29/200], Epoch [2/5], Step [40/47], Loss: 0.1475, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [29/200], Epoch [3/5], Step [20/47], Loss: 0.0367, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [29/200], Epoch [3/5], Step [40/47], Loss: 0.1892, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [29/200], Epoch [4/5], Step [20/47], Loss: 0.1128, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [29/200], Epoch [4/5], Step [40/47], Loss: 0.1288, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [29/200], Epoch [5/5], Step [20/47], Loss: 0.0820, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [29/200], Epoch [5/5], Step [40/47], Loss: 0.1677, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [29/200], qnn_train_step: [100/1000], loss: 0.11069094389677048, accuracy: 97.5 %\n",
      "Training round [29/200], qnn_train_step: [200/1000], loss: 0.11762447655200958, accuracy: 97.0 %\n",
      "Training round [29/200], qnn_train_step: [300/1000], loss: 0.11560535430908203, accuracy: 97.3 %\n",
      "Training round [29/200], qnn_train_step: [400/1000], loss: 0.10838235169649124, accuracy: 97.3 %\n",
      "Training round [29/200], qnn_train_step: [500/1000], loss: 0.10707926005125046, accuracy: 97.4 %\n",
      "Training round [29/200], qnn_train_step: [600/1000], loss: 0.11118191480636597, accuracy: 97.1 %\n",
      "Training round [29/200], qnn_train_step: [700/1000], loss: 0.11640141904354095, accuracy: 96.6 %\n",
      "Training round [29/200], qnn_train_step: [800/1000], loss: 0.10318441689014435, accuracy: 97.5 %\n",
      "Training round [29/200], qnn_train_step: [900/1000], loss: 0.10222253203392029, accuracy: 97.5 %\n",
      "Training round [29/200], qnn_train_step: [1000/1000], loss: 0.10154413431882858, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [30/200], Epoch [1/5], Step [20/47], Loss: 0.1632, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [1/5], Step [40/47], Loss: 0.0471, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [30/200], Epoch [2/5], Step [20/47], Loss: 0.2032, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [30/200], Epoch [2/5], Step [40/47], Loss: 0.0597, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [3/5], Step [20/47], Loss: 0.0663, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [30/200], Epoch [3/5], Step [40/47], Loss: 0.1140, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [30/200], Epoch [4/5], Step [20/47], Loss: 0.1652, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [30/200], Epoch [4/5], Step [40/47], Loss: 0.1017, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [5/5], Step [20/47], Loss: 0.1285, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [30/200], Epoch [5/5], Step [40/47], Loss: 0.0743, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [30/200], qnn_train_step: [100/1000], loss: 0.08719739317893982, accuracy: 97.2 %\n",
      "Training round [30/200], qnn_train_step: [200/1000], loss: 2.004732370376587, accuracy: 67.1 %\n",
      "Training round [30/200], qnn_train_step: [300/1000], loss: 0.08292250335216522, accuracy: 97.4 %\n",
      "Training round [30/200], qnn_train_step: [400/1000], loss: 0.07833842933177948, accuracy: 97.9 %\n",
      "Training round [30/200], qnn_train_step: [500/1000], loss: 0.07760820537805557, accuracy: 97.9 %\n",
      "Training round [30/200], qnn_train_step: [600/1000], loss: 0.08488992601633072, accuracy: 97.6 %\n",
      "Training round [30/200], qnn_train_step: [700/1000], loss: 0.10049573332071304, accuracy: 97.1 %\n",
      "Training round [30/200], qnn_train_step: [800/1000], loss: 0.07560700923204422, accuracy: 97.9 %\n",
      "Training round [30/200], qnn_train_step: [900/1000], loss: 0.07581920176744461, accuracy: 97.8 %\n",
      "Training round [30/200], qnn_train_step: [1000/1000], loss: 0.07462252676486969, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [31/200], Epoch [1/5], Step [20/47], Loss: 0.0608, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [1/5], Step [40/47], Loss: 0.1002, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [2/5], Step [20/47], Loss: 0.1708, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [31/200], Epoch [2/5], Step [40/47], Loss: 0.2573, batch time: 0.05, accuracy:  91.41%\n",
      "Training round [31/200], Epoch [3/5], Step [20/47], Loss: 0.2441, batch time: 0.05, accuracy:  90.62%\n",
      "Training round [31/200], Epoch [3/5], Step [40/47], Loss: 0.0978, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [31/200], Epoch [4/5], Step [20/47], Loss: 0.1129, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [31/200], Epoch [4/5], Step [40/47], Loss: 0.1131, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [31/200], Epoch [5/5], Step [20/47], Loss: 0.0973, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [31/200], Epoch [5/5], Step [40/47], Loss: 0.0906, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [31/200], qnn_train_step: [100/1000], loss: 0.10223665088415146, accuracy: 96.9 %\n",
      "Training round [31/200], qnn_train_step: [200/1000], loss: 1.0437507629394531, accuracy: 77.3 %\n",
      "Training round [31/200], qnn_train_step: [300/1000], loss: 0.09107362478971481, accuracy: 97.1 %\n",
      "Training round [31/200], qnn_train_step: [400/1000], loss: 0.09038764238357544, accuracy: 97.0 %\n",
      "Training round [31/200], qnn_train_step: [500/1000], loss: 0.09181170910596848, accuracy: 97.2 %\n",
      "Training round [31/200], qnn_train_step: [600/1000], loss: 0.08561336249113083, accuracy: 97.5 %\n",
      "Training round [31/200], qnn_train_step: [700/1000], loss: 0.16545546054840088, accuracy: 94.5 %\n",
      "Training round [31/200], qnn_train_step: [800/1000], loss: 0.08284331858158112, accuracy: 97.5 %\n",
      "Training round [31/200], qnn_train_step: [900/1000], loss: 0.0794006809592247, accuracy: 97.8 %\n",
      "Training round [31/200], qnn_train_step: [1000/1000], loss: 0.07800746709108353, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [32/200], Epoch [1/5], Step [20/47], Loss: 0.1237, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [1/5], Step [40/47], Loss: 0.1472, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [32/200], Epoch [2/5], Step [20/47], Loss: 0.1759, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [32/200], Epoch [2/5], Step [40/47], Loss: 0.1580, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [3/5], Step [20/47], Loss: 0.0654, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [32/200], Epoch [3/5], Step [40/47], Loss: 0.0759, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [4/5], Step [20/47], Loss: 0.1092, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [32/200], Epoch [4/5], Step [40/47], Loss: 0.0683, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [32/200], Epoch [5/5], Step [20/47], Loss: 0.1096, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [32/200], Epoch [5/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [32/200], qnn_train_step: [100/1000], loss: 0.13473446667194366, accuracy: 95.3 %\n",
      "Training round [32/200], qnn_train_step: [200/1000], loss: 0.2939471900463104, accuracy: 89.9 %\n",
      "Training round [32/200], qnn_train_step: [300/1000], loss: 0.12684139609336853, accuracy: 95.4 %\n",
      "Training round [32/200], qnn_train_step: [400/1000], loss: 0.12294688075780869, accuracy: 96.2 %\n",
      "Training round [32/200], qnn_train_step: [500/1000], loss: 0.11992082744836807, accuracy: 96.3 %\n",
      "Training round [32/200], qnn_train_step: [600/1000], loss: 0.11967279762029648, accuracy: 96.1 %\n",
      "Training round [32/200], qnn_train_step: [700/1000], loss: 0.1281919777393341, accuracy: 95.6 %\n",
      "Training round [32/200], qnn_train_step: [800/1000], loss: 0.19529753923416138, accuracy: 93.9 %\n",
      "Training round [32/200], qnn_train_step: [900/1000], loss: 0.13262909650802612, accuracy: 95.4 %\n",
      "Training round [32/200], qnn_train_step: [1000/1000], loss: 0.11143714934587479, accuracy: 96.6 %\n",
      "-----------------------\n",
      "Training round [33/200], Epoch [1/5], Step [20/47], Loss: 0.0755, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [33/200], Epoch [1/5], Step [40/47], Loss: 0.0950, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [33/200], Epoch [2/5], Step [20/47], Loss: 0.1223, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [33/200], Epoch [2/5], Step [40/47], Loss: 0.1048, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [33/200], Epoch [3/5], Step [20/47], Loss: 0.0645, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [33/200], Epoch [3/5], Step [40/47], Loss: 0.1239, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [33/200], Epoch [4/5], Step [20/47], Loss: 0.0588, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [33/200], Epoch [4/5], Step [40/47], Loss: 0.1809, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [33/200], Epoch [5/5], Step [20/47], Loss: 0.1171, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [33/200], Epoch [5/5], Step [40/47], Loss: 0.0972, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [33/200], qnn_train_step: [100/1000], loss: 0.08163099735975266, accuracy: 97.8 %\n",
      "Training round [33/200], qnn_train_step: [200/1000], loss: 1.1182329654693604, accuracy: 70.6 %\n",
      "Training round [33/200], qnn_train_step: [300/1000], loss: 0.08011986315250397, accuracy: 97.9 %\n",
      "Training round [33/200], qnn_train_step: [400/1000], loss: 0.07932137697935104, accuracy: 98.0 %\n",
      "Training round [33/200], qnn_train_step: [500/1000], loss: 0.0858037993311882, accuracy: 97.7 %\n",
      "Training round [33/200], qnn_train_step: [600/1000], loss: 0.0790882259607315, accuracy: 97.6 %\n",
      "Training round [33/200], qnn_train_step: [700/1000], loss: 0.07773489505052567, accuracy: 97.5 %\n",
      "Training round [33/200], qnn_train_step: [800/1000], loss: 0.0889320820569992, accuracy: 97.6 %\n",
      "Training round [33/200], qnn_train_step: [900/1000], loss: 0.07322455197572708, accuracy: 98.0 %\n",
      "Training round [33/200], qnn_train_step: [1000/1000], loss: 0.07259443402290344, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [34/200], Epoch [1/5], Step [20/47], Loss: 0.1701, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [1/5], Step [40/47], Loss: 0.1202, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [2/5], Step [20/47], Loss: 0.1761, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [34/200], Epoch [2/5], Step [40/47], Loss: 0.1084, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [34/200], Epoch [3/5], Step [20/47], Loss: 0.0933, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [34/200], Epoch [3/5], Step [40/47], Loss: 0.1966, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [34/200], Epoch [4/5], Step [20/47], Loss: 0.0361, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [34/200], Epoch [4/5], Step [40/47], Loss: 0.1662, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [34/200], Epoch [5/5], Step [20/47], Loss: 0.0448, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [34/200], Epoch [5/5], Step [40/47], Loss: 0.1810, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [34/200], qnn_train_step: [100/1000], loss: 0.10190749913454056, accuracy: 97.1 %\n",
      "Training round [34/200], qnn_train_step: [200/1000], loss: 0.4638359248638153, accuracy: 84.2 %\n",
      "Training round [34/200], qnn_train_step: [300/1000], loss: 0.09659219533205032, accuracy: 97.3 %\n",
      "Training round [34/200], qnn_train_step: [400/1000], loss: 0.09574712812900543, accuracy: 96.9 %\n",
      "Training round [34/200], qnn_train_step: [500/1000], loss: 0.09503700584173203, accuracy: 97.3 %\n",
      "Training round [34/200], qnn_train_step: [600/1000], loss: 0.10744419693946838, accuracy: 96.4 %\n",
      "Training round [34/200], qnn_train_step: [700/1000], loss: 0.09836914390325546, accuracy: 97.4 %\n",
      "Training round [34/200], qnn_train_step: [800/1000], loss: 0.09245222061872482, accuracy: 97.4 %\n",
      "Training round [34/200], qnn_train_step: [900/1000], loss: 0.09279567003250122, accuracy: 97.2 %\n",
      "Training round [34/200], qnn_train_step: [1000/1000], loss: 0.08833925426006317, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [35/200], Epoch [1/5], Step [20/47], Loss: 0.0858, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [1/5], Step [40/47], Loss: 0.0509, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [35/200], Epoch [2/5], Step [20/47], Loss: 0.1871, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [2/5], Step [40/47], Loss: 0.0947, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [35/200], Epoch [3/5], Step [20/47], Loss: 0.0968, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [35/200], Epoch [3/5], Step [40/47], Loss: 0.1446, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [4/5], Step [20/47], Loss: 0.0978, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [35/200], Epoch [4/5], Step [40/47], Loss: 0.1257, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [35/200], Epoch [5/5], Step [20/47], Loss: 0.3444, batch time: 0.10, accuracy:  92.19%\n",
      "Training round [35/200], Epoch [5/5], Step [40/47], Loss: 0.0541, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [35/200], qnn_train_step: [100/1000], loss: 0.10995935648679733, accuracy: 96.2 %\n",
      "Training round [35/200], qnn_train_step: [200/1000], loss: 0.10649524629116058, accuracy: 96.1 %\n",
      "Training round [35/200], qnn_train_step: [300/1000], loss: 0.1137605682015419, accuracy: 95.3 %\n",
      "Training round [35/200], qnn_train_step: [400/1000], loss: 0.101988784968853, accuracy: 96.5 %\n",
      "Training round [35/200], qnn_train_step: [500/1000], loss: 0.10155440121889114, accuracy: 96.5 %\n",
      "Training round [35/200], qnn_train_step: [600/1000], loss: 0.10101872682571411, accuracy: 96.4 %\n",
      "Training round [35/200], qnn_train_step: [700/1000], loss: 0.09789389371871948, accuracy: 96.2 %\n",
      "Training round [35/200], qnn_train_step: [800/1000], loss: 0.11295270174741745, accuracy: 95.5 %\n",
      "Training round [35/200], qnn_train_step: [900/1000], loss: 0.09934365749359131, accuracy: 96.2 %\n",
      "Training round [35/200], qnn_train_step: [1000/1000], loss: 0.09804587811231613, accuracy: 96.0 %\n",
      "-----------------------\n",
      "Training round [36/200], Epoch [1/5], Step [20/47], Loss: 0.1551, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [36/200], Epoch [1/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [2/5], Step [20/47], Loss: 0.0793, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [36/200], Epoch [2/5], Step [40/47], Loss: 0.1394, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [36/200], Epoch [3/5], Step [20/47], Loss: 0.1322, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [3/5], Step [40/47], Loss: 0.1527, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [4/5], Step [20/47], Loss: 0.0224, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [36/200], Epoch [4/5], Step [40/47], Loss: 0.1223, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [36/200], Epoch [5/5], Step [20/47], Loss: 0.2180, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [36/200], Epoch [5/5], Step [40/47], Loss: 0.1085, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [36/200], qnn_train_step: [100/1000], loss: 0.1068320944905281, accuracy: 96.9 %\n",
      "Training round [36/200], qnn_train_step: [200/1000], loss: 0.415459543466568, accuracy: 86.9 %\n",
      "Training round [36/200], qnn_train_step: [300/1000], loss: 0.1674010157585144, accuracy: 94.5 %\n",
      "Training round [36/200], qnn_train_step: [400/1000], loss: 0.09534395486116409, accuracy: 97.4 %\n",
      "Training round [36/200], qnn_train_step: [500/1000], loss: 0.09547857195138931, accuracy: 97.0 %\n",
      "Training round [36/200], qnn_train_step: [600/1000], loss: 0.08709225058555603, accuracy: 97.8 %\n",
      "Training round [36/200], qnn_train_step: [700/1000], loss: 0.08643806725740433, accuracy: 97.8 %\n",
      "Training round [36/200], qnn_train_step: [800/1000], loss: 0.09348665177822113, accuracy: 96.7 %\n",
      "Training round [36/200], qnn_train_step: [900/1000], loss: 0.09021980315446854, accuracy: 97.6 %\n",
      "Training round [36/200], qnn_train_step: [1000/1000], loss: 0.0862913429737091, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [37/200], Epoch [1/5], Step [20/47], Loss: 0.0914, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [1/5], Step [40/47], Loss: 0.0873, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [2/5], Step [20/47], Loss: 0.1808, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [2/5], Step [40/47], Loss: 0.0929, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [3/5], Step [20/47], Loss: 0.1038, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [37/200], Epoch [3/5], Step [40/47], Loss: 0.1190, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [37/200], Epoch [4/5], Step [20/47], Loss: 0.1002, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [37/200], Epoch [4/5], Step [40/47], Loss: 0.3344, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [37/200], Epoch [5/5], Step [20/47], Loss: 0.0803, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [37/200], Epoch [5/5], Step [40/47], Loss: 0.1261, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [37/200], qnn_train_step: [100/1000], loss: 0.12788908183574677, accuracy: 96.7 %\n",
      "Training round [37/200], qnn_train_step: [200/1000], loss: 0.22176101803779602, accuracy: 92.9 %\n",
      "Training round [37/200], qnn_train_step: [300/1000], loss: 0.125958651304245, accuracy: 96.6 %\n",
      "Training round [37/200], qnn_train_step: [400/1000], loss: 0.11165821552276611, accuracy: 96.5 %\n",
      "Training round [37/200], qnn_train_step: [500/1000], loss: 0.11089865863323212, accuracy: 96.9 %\n",
      "Training round [37/200], qnn_train_step: [600/1000], loss: 0.11166098713874817, accuracy: 96.8 %\n",
      "Training round [37/200], qnn_train_step: [700/1000], loss: 0.17663516104221344, accuracy: 94.9 %\n",
      "Training round [37/200], qnn_train_step: [800/1000], loss: 0.10418955981731415, accuracy: 97.0 %\n",
      "Training round [37/200], qnn_train_step: [900/1000], loss: 0.10256297886371613, accuracy: 97.3 %\n",
      "Training round [37/200], qnn_train_step: [1000/1000], loss: 0.10149945318698883, accuracy: 97.2 %\n",
      "-----------------------\n",
      "Training round [38/200], Epoch [1/5], Step [20/47], Loss: 0.1199, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [1/5], Step [40/47], Loss: 0.1486, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [2/5], Step [20/47], Loss: 0.2707, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [2/5], Step [40/47], Loss: 0.1835, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [3/5], Step [20/47], Loss: 0.0495, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [38/200], Epoch [3/5], Step [40/47], Loss: 0.2017, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [38/200], Epoch [4/5], Step [20/47], Loss: 0.0808, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [4/5], Step [40/47], Loss: 0.1561, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [38/200], Epoch [5/5], Step [20/47], Loss: 0.1298, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [38/200], Epoch [5/5], Step [40/47], Loss: 0.1822, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [38/200], qnn_train_step: [100/1000], loss: 0.09407265484333038, accuracy: 96.8 %\n",
      "Training round [38/200], qnn_train_step: [200/1000], loss: 0.10152263939380646, accuracy: 96.5 %\n",
      "Training round [38/200], qnn_train_step: [300/1000], loss: 0.0957820862531662, accuracy: 97.0 %\n",
      "Training round [38/200], qnn_train_step: [400/1000], loss: 0.08916317671537399, accuracy: 97.2 %\n",
      "Training round [38/200], qnn_train_step: [500/1000], loss: 0.08759251981973648, accuracy: 96.6 %\n",
      "Training round [38/200], qnn_train_step: [600/1000], loss: 0.08533699810504913, accuracy: 97.1 %\n",
      "Training round [38/200], qnn_train_step: [700/1000], loss: 0.08395852148532867, accuracy: 96.9 %\n",
      "Training round [38/200], qnn_train_step: [800/1000], loss: 0.0893491804599762, accuracy: 97.1 %\n",
      "Training round [38/200], qnn_train_step: [900/1000], loss: 0.08676253259181976, accuracy: 97.5 %\n",
      "Training round [38/200], qnn_train_step: [1000/1000], loss: 0.07799933850765228, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [39/200], Epoch [1/5], Step [20/47], Loss: 0.1300, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [39/200], Epoch [1/5], Step [40/47], Loss: 0.0949, batch time: 0.31, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [2/5], Step [20/47], Loss: 0.2337, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [39/200], Epoch [2/5], Step [40/47], Loss: 0.0455, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [39/200], Epoch [3/5], Step [20/47], Loss: 0.0825, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [3/5], Step [40/47], Loss: 0.2169, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [39/200], Epoch [4/5], Step [20/47], Loss: 0.1342, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [4/5], Step [40/47], Loss: 0.1583, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [5/5], Step [20/47], Loss: 0.0890, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [39/200], Epoch [5/5], Step [40/47], Loss: 0.0921, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [39/200], qnn_train_step: [100/1000], loss: 0.09663177281618118, accuracy: 96.7 %\n",
      "Training round [39/200], qnn_train_step: [200/1000], loss: 0.3978953957557678, accuracy: 90.0 %\n",
      "Training round [39/200], qnn_train_step: [300/1000], loss: 0.10235045850276947, accuracy: 96.5 %\n",
      "Training round [39/200], qnn_train_step: [400/1000], loss: 0.0989065021276474, accuracy: 97.5 %\n",
      "Training round [39/200], qnn_train_step: [500/1000], loss: 0.09973958879709244, accuracy: 97.4 %\n",
      "Training round [39/200], qnn_train_step: [600/1000], loss: 0.0919819325208664, accuracy: 97.5 %\n",
      "Training round [39/200], qnn_train_step: [700/1000], loss: 0.08289344608783722, accuracy: 97.8 %\n",
      "Training round [39/200], qnn_train_step: [800/1000], loss: 0.09408868849277496, accuracy: 96.8 %\n",
      "Training round [39/200], qnn_train_step: [900/1000], loss: 0.11626104265451431, accuracy: 95.3 %\n",
      "Training round [39/200], qnn_train_step: [1000/1000], loss: 0.07902894914150238, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [40/200], Epoch [1/5], Step [20/47], Loss: 0.0524, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [40/200], Epoch [1/5], Step [40/47], Loss: 0.1597, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [40/200], Epoch [2/5], Step [20/47], Loss: 0.0774, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [40/200], Epoch [2/5], Step [40/47], Loss: 0.1828, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [40/200], Epoch [3/5], Step [20/47], Loss: 0.0711, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [40/200], Epoch [3/5], Step [40/47], Loss: 0.0985, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [4/5], Step [20/47], Loss: 0.1397, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [40/200], Epoch [4/5], Step [40/47], Loss: 0.1227, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [40/200], Epoch [5/5], Step [20/47], Loss: 0.1442, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [40/200], Epoch [5/5], Step [40/47], Loss: 0.1111, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [40/200], qnn_train_step: [100/1000], loss: 0.10810098797082901, accuracy: 96.7 %\n",
      "Training round [40/200], qnn_train_step: [200/1000], loss: 0.2736019492149353, accuracy: 93.1 %\n",
      "Training round [40/200], qnn_train_step: [300/1000], loss: 0.10525000095367432, accuracy: 96.5 %\n",
      "Training round [40/200], qnn_train_step: [400/1000], loss: 0.09810753911733627, accuracy: 97.2 %\n",
      "Training round [40/200], qnn_train_step: [500/1000], loss: 0.09960058331489563, accuracy: 97.4 %\n",
      "Training round [40/200], qnn_train_step: [600/1000], loss: 0.1016957238316536, accuracy: 96.9 %\n",
      "Training round [40/200], qnn_train_step: [700/1000], loss: 0.10706310719251633, accuracy: 97.1 %\n",
      "Training round [40/200], qnn_train_step: [800/1000], loss: 0.09560196846723557, accuracy: 97.4 %\n",
      "Training round [40/200], qnn_train_step: [900/1000], loss: 0.09365539252758026, accuracy: 97.3 %\n",
      "Training round [40/200], qnn_train_step: [1000/1000], loss: 0.09288290143013, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [41/200], Epoch [1/5], Step [20/47], Loss: 0.1620, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [1/5], Step [40/47], Loss: 0.1819, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [41/200], Epoch [2/5], Step [20/47], Loss: 0.1736, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [41/200], Epoch [2/5], Step [40/47], Loss: 0.0220, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [41/200], Epoch [3/5], Step [20/47], Loss: 0.1512, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [3/5], Step [40/47], Loss: 0.1369, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [41/200], Epoch [4/5], Step [20/47], Loss: 0.0950, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [41/200], Epoch [4/5], Step [40/47], Loss: 0.2258, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [41/200], Epoch [5/5], Step [20/47], Loss: 0.0531, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [41/200], Epoch [5/5], Step [40/47], Loss: 0.0380, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [41/200], qnn_train_step: [100/1000], loss: 0.07969202101230621, accuracy: 97.7 %\n",
      "Training round [41/200], qnn_train_step: [200/1000], loss: 0.09202754497528076, accuracy: 97.1 %\n",
      "Training round [41/200], qnn_train_step: [300/1000], loss: 0.07920423895120621, accuracy: 98.0 %\n",
      "Training round [41/200], qnn_train_step: [400/1000], loss: 0.07425123453140259, accuracy: 98.2 %\n",
      "Training round [41/200], qnn_train_step: [500/1000], loss: 0.07426148653030396, accuracy: 98.2 %\n",
      "Training round [41/200], qnn_train_step: [600/1000], loss: 0.08094091713428497, accuracy: 97.2 %\n",
      "Training round [41/200], qnn_train_step: [700/1000], loss: 0.07892210781574249, accuracy: 97.3 %\n",
      "Training round [41/200], qnn_train_step: [800/1000], loss: 0.06950318813323975, accuracy: 98.2 %\n",
      "Training round [41/200], qnn_train_step: [900/1000], loss: 0.06822450459003448, accuracy: 98.3 %\n",
      "Training round [41/200], qnn_train_step: [1000/1000], loss: 0.0748993456363678, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [42/200], Epoch [1/5], Step [20/47], Loss: 0.0684, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [1/5], Step [40/47], Loss: 0.1659, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [42/200], Epoch [2/5], Step [20/47], Loss: 0.1787, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [42/200], Epoch [2/5], Step [40/47], Loss: 0.1317, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [42/200], Epoch [3/5], Step [20/47], Loss: 0.0554, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [42/200], Epoch [3/5], Step [40/47], Loss: 0.0906, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [42/200], Epoch [4/5], Step [20/47], Loss: 0.0662, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [4/5], Step [40/47], Loss: 0.0471, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [42/200], Epoch [5/5], Step [20/47], Loss: 0.1599, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [42/200], Epoch [5/5], Step [40/47], Loss: 0.0935, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [42/200], qnn_train_step: [100/1000], loss: 0.12380465120077133, accuracy: 96.3 %\n",
      "Training round [42/200], qnn_train_step: [200/1000], loss: 0.5775508880615234, accuracy: 85.0 %\n",
      "Training round [42/200], qnn_train_step: [300/1000], loss: 0.1139865443110466, accuracy: 96.5 %\n",
      "Training round [42/200], qnn_train_step: [400/1000], loss: 0.10657910257577896, accuracy: 96.7 %\n",
      "Training round [42/200], qnn_train_step: [500/1000], loss: 0.11726956069469452, accuracy: 96.0 %\n",
      "Training round [42/200], qnn_train_step: [600/1000], loss: 0.1107557937502861, accuracy: 96.3 %\n",
      "Training round [42/200], qnn_train_step: [700/1000], loss: 0.10166658461093903, accuracy: 96.8 %\n",
      "Training round [42/200], qnn_train_step: [800/1000], loss: 0.10983758419752121, accuracy: 96.9 %\n",
      "Training round [42/200], qnn_train_step: [900/1000], loss: 0.10687447339296341, accuracy: 96.4 %\n",
      "Training round [42/200], qnn_train_step: [1000/1000], loss: 0.10505146533250809, accuracy: 96.1 %\n",
      "-----------------------\n",
      "Training round [43/200], Epoch [1/5], Step [20/47], Loss: 0.0627, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [1/5], Step [40/47], Loss: 0.1828, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [43/200], Epoch [2/5], Step [20/47], Loss: 0.0965, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [2/5], Step [40/47], Loss: 0.1273, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [3/5], Step [20/47], Loss: 0.0803, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [3/5], Step [40/47], Loss: 0.0435, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [43/200], Epoch [4/5], Step [20/47], Loss: 0.1108, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [43/200], Epoch [4/5], Step [40/47], Loss: 0.0524, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [43/200], Epoch [5/5], Step [20/47], Loss: 0.0889, batch time: 0.31, accuracy:  96.09%\n",
      "Training round [43/200], Epoch [5/5], Step [40/47], Loss: 0.1274, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [43/200], qnn_train_step: [100/1000], loss: 0.11680945754051208, accuracy: 96.3 %\n",
      "Training round [43/200], qnn_train_step: [200/1000], loss: 0.11729072034358978, accuracy: 96.2 %\n",
      "Training round [43/200], qnn_train_step: [300/1000], loss: 0.10217247158288956, accuracy: 97.2 %\n",
      "Training round [43/200], qnn_train_step: [400/1000], loss: 0.0998382493853569, accuracy: 96.6 %\n",
      "Training round [43/200], qnn_train_step: [500/1000], loss: 0.10809431225061417, accuracy: 96.6 %\n",
      "Training round [43/200], qnn_train_step: [600/1000], loss: 0.1048087626695633, accuracy: 97.0 %\n",
      "Training round [43/200], qnn_train_step: [700/1000], loss: 0.10267063975334167, accuracy: 96.7 %\n",
      "Training round [43/200], qnn_train_step: [800/1000], loss: 0.09098466485738754, accuracy: 97.7 %\n",
      "Training round [43/200], qnn_train_step: [900/1000], loss: 0.08836042881011963, accuracy: 97.6 %\n",
      "Training round [43/200], qnn_train_step: [1000/1000], loss: 0.08762120455503464, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [44/200], Epoch [1/5], Step [20/47], Loss: 0.0484, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [44/200], Epoch [1/5], Step [40/47], Loss: 0.1622, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [2/5], Step [20/47], Loss: 0.0873, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [2/5], Step [40/47], Loss: 0.0575, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [44/200], Epoch [3/5], Step [20/47], Loss: 0.0738, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [44/200], Epoch [3/5], Step [40/47], Loss: 0.1112, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [4/5], Step [20/47], Loss: 0.1126, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [4/5], Step [40/47], Loss: 0.1569, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [44/200], Epoch [5/5], Step [20/47], Loss: 0.1394, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [44/200], Epoch [5/5], Step [40/47], Loss: 0.0730, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [44/200], qnn_train_step: [100/1000], loss: 0.08518137037754059, accuracy: 97.4 %\n",
      "Training round [44/200], qnn_train_step: [200/1000], loss: 0.08843301981687546, accuracy: 97.3 %\n",
      "Training round [44/200], qnn_train_step: [300/1000], loss: 0.08077150583267212, accuracy: 97.5 %\n",
      "Training round [44/200], qnn_train_step: [400/1000], loss: 0.0805835872888565, accuracy: 97.4 %\n",
      "Training round [44/200], qnn_train_step: [500/1000], loss: 0.07927156239748001, accuracy: 97.5 %\n",
      "Training round [44/200], qnn_train_step: [600/1000], loss: 0.0821576863527298, accuracy: 97.6 %\n",
      "Training round [44/200], qnn_train_step: [700/1000], loss: 0.07523509860038757, accuracy: 97.9 %\n",
      "Training round [44/200], qnn_train_step: [800/1000], loss: 0.09386186301708221, accuracy: 97.2 %\n",
      "Training round [44/200], qnn_train_step: [900/1000], loss: 0.07237047702074051, accuracy: 97.9 %\n",
      "Training round [44/200], qnn_train_step: [1000/1000], loss: 0.07170535624027252, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [45/200], Epoch [1/5], Step [20/47], Loss: 0.0931, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [1/5], Step [40/47], Loss: 0.2147, batch time: 0.06, accuracy:  92.97%\n",
      "Training round [45/200], Epoch [2/5], Step [20/47], Loss: 0.0353, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [45/200], Epoch [2/5], Step [40/47], Loss: 0.0643, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [45/200], Epoch [3/5], Step [20/47], Loss: 0.0312, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [45/200], Epoch [3/5], Step [40/47], Loss: 0.0832, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [4/5], Step [20/47], Loss: 0.1358, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [45/200], Epoch [4/5], Step [40/47], Loss: 0.1408, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [45/200], Epoch [5/5], Step [20/47], Loss: 0.1352, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [45/200], Epoch [5/5], Step [40/47], Loss: 0.0672, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [45/200], qnn_train_step: [100/1000], loss: 0.12800446152687073, accuracy: 96.1 %\n",
      "Training round [45/200], qnn_train_step: [200/1000], loss: 0.133268341422081, accuracy: 95.7 %\n",
      "Training round [45/200], qnn_train_step: [300/1000], loss: 0.12028613686561584, accuracy: 96.1 %\n",
      "Training round [45/200], qnn_train_step: [400/1000], loss: 0.10891116410493851, accuracy: 96.6 %\n",
      "Training round [45/200], qnn_train_step: [500/1000], loss: 0.11208132654428482, accuracy: 96.6 %\n",
      "Training round [45/200], qnn_train_step: [600/1000], loss: 0.10956516116857529, accuracy: 96.4 %\n",
      "Training round [45/200], qnn_train_step: [700/1000], loss: 0.10839509218931198, accuracy: 96.8 %\n",
      "Training round [45/200], qnn_train_step: [800/1000], loss: 0.11373001337051392, accuracy: 96.6 %\n",
      "Training round [45/200], qnn_train_step: [900/1000], loss: 0.10459955036640167, accuracy: 96.2 %\n",
      "Training round [45/200], qnn_train_step: [1000/1000], loss: 0.10344674438238144, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [46/200], Epoch [1/5], Step [20/47], Loss: 0.0974, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [46/200], Epoch [1/5], Step [40/47], Loss: 0.0638, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [2/5], Step [20/47], Loss: 0.0657, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [2/5], Step [40/47], Loss: 0.0670, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [3/5], Step [20/47], Loss: 0.2208, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [46/200], Epoch [3/5], Step [40/47], Loss: 0.1084, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [4/5], Step [20/47], Loss: 0.0676, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [4/5], Step [40/47], Loss: 0.1007, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [46/200], Epoch [5/5], Step [20/47], Loss: 0.0391, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [46/200], Epoch [5/5], Step [40/47], Loss: 0.0691, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [46/200], qnn_train_step: [100/1000], loss: 0.08797313272953033, accuracy: 97.1 %\n",
      "Training round [46/200], qnn_train_step: [200/1000], loss: 0.092788927257061, accuracy: 96.9 %\n",
      "Training round [46/200], qnn_train_step: [300/1000], loss: 0.09576252847909927, accuracy: 96.7 %\n",
      "Training round [46/200], qnn_train_step: [400/1000], loss: 0.0915428027510643, accuracy: 97.1 %\n",
      "Training round [46/200], qnn_train_step: [500/1000], loss: 0.07878107577562332, accuracy: 97.8 %\n",
      "Training round [46/200], qnn_train_step: [600/1000], loss: 0.07478509098291397, accuracy: 97.8 %\n",
      "Training round [46/200], qnn_train_step: [700/1000], loss: 0.07336141914129257, accuracy: 98.0 %\n",
      "Training round [46/200], qnn_train_step: [800/1000], loss: 0.07123085111379623, accuracy: 97.9 %\n",
      "Training round [46/200], qnn_train_step: [900/1000], loss: 0.07065829634666443, accuracy: 97.9 %\n",
      "Training round [46/200], qnn_train_step: [1000/1000], loss: 0.06906108558177948, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [47/200], Epoch [1/5], Step [20/47], Loss: 0.1366, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [1/5], Step [40/47], Loss: 0.0963, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [2/5], Step [20/47], Loss: 0.0549, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [47/200], Epoch [2/5], Step [40/47], Loss: 0.1140, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [3/5], Step [20/47], Loss: 0.1837, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [47/200], Epoch [3/5], Step [40/47], Loss: 0.1175, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [47/200], Epoch [4/5], Step [20/47], Loss: 0.1966, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [47/200], Epoch [4/5], Step [40/47], Loss: 0.1592, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [47/200], Epoch [5/5], Step [20/47], Loss: 0.0563, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [47/200], Epoch [5/5], Step [40/47], Loss: 0.0781, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [47/200], qnn_train_step: [100/1000], loss: 0.09165094792842865, accuracy: 97.5 %\n",
      "Training round [47/200], qnn_train_step: [200/1000], loss: 0.10031439363956451, accuracy: 97.0 %\n",
      "Training round [47/200], qnn_train_step: [300/1000], loss: 0.08303551375865936, accuracy: 97.4 %\n",
      "Training round [47/200], qnn_train_step: [400/1000], loss: 0.0798577144742012, accuracy: 97.7 %\n",
      "Training round [47/200], qnn_train_step: [500/1000], loss: 0.08500158786773682, accuracy: 97.5 %\n",
      "Training round [47/200], qnn_train_step: [600/1000], loss: 0.08831897377967834, accuracy: 97.5 %\n",
      "Training round [47/200], qnn_train_step: [700/1000], loss: 0.09527911990880966, accuracy: 97.0 %\n",
      "Training round [47/200], qnn_train_step: [800/1000], loss: 0.0896027460694313, accuracy: 97.1 %\n",
      "Training round [47/200], qnn_train_step: [900/1000], loss: 0.08663298189640045, accuracy: 97.3 %\n",
      "Training round [47/200], qnn_train_step: [1000/1000], loss: 0.07360129803419113, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [48/200], Epoch [1/5], Step [20/47], Loss: 0.1577, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [1/5], Step [40/47], Loss: 0.1661, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [2/5], Step [20/47], Loss: 0.0772, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [48/200], Epoch [2/5], Step [40/47], Loss: 0.0401, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [48/200], Epoch [3/5], Step [20/47], Loss: 0.1607, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [3/5], Step [40/47], Loss: 0.1361, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [48/200], Epoch [4/5], Step [20/47], Loss: 0.0176, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [48/200], Epoch [4/5], Step [40/47], Loss: 0.0671, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [48/200], Epoch [5/5], Step [20/47], Loss: 0.1197, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [48/200], Epoch [5/5], Step [40/47], Loss: 0.0512, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [48/200], qnn_train_step: [100/1000], loss: 0.07607722282409668, accuracy: 97.7 %\n",
      "Training round [48/200], qnn_train_step: [200/1000], loss: 0.07976105809211731, accuracy: 97.2 %\n",
      "Training round [48/200], qnn_train_step: [300/1000], loss: 0.07521095871925354, accuracy: 97.5 %\n",
      "Training round [48/200], qnn_train_step: [400/1000], loss: 0.06910939514636993, accuracy: 97.9 %\n",
      "Training round [48/200], qnn_train_step: [500/1000], loss: 0.0699523389339447, accuracy: 97.8 %\n",
      "Training round [48/200], qnn_train_step: [600/1000], loss: 0.06349436193704605, accuracy: 98.1 %\n",
      "Training round [48/200], qnn_train_step: [700/1000], loss: 0.06350606679916382, accuracy: 98.0 %\n",
      "Training round [48/200], qnn_train_step: [800/1000], loss: 0.07034950703382492, accuracy: 97.9 %\n",
      "Training round [48/200], qnn_train_step: [900/1000], loss: 0.06196051836013794, accuracy: 98.4 %\n",
      "Training round [48/200], qnn_train_step: [1000/1000], loss: 0.06043947488069534, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [49/200], Epoch [1/5], Step [20/47], Loss: 0.0429, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [49/200], Epoch [1/5], Step [40/47], Loss: 0.1426, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [2/5], Step [20/47], Loss: 0.1198, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [2/5], Step [40/47], Loss: 0.0954, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [49/200], Epoch [3/5], Step [20/47], Loss: 0.0538, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [3/5], Step [40/47], Loss: 0.0990, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [49/200], Epoch [4/5], Step [20/47], Loss: 0.1917, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [49/200], Epoch [4/5], Step [40/47], Loss: 0.0708, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [49/200], Epoch [5/5], Step [20/47], Loss: 0.1273, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [49/200], Epoch [5/5], Step [40/47], Loss: 0.1094, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [49/200], qnn_train_step: [100/1000], loss: 0.09765882790088654, accuracy: 96.9 %\n",
      "Training round [49/200], qnn_train_step: [200/1000], loss: 0.19325189292430878, accuracy: 93.3 %\n",
      "Training round [49/200], qnn_train_step: [300/1000], loss: 0.09277654439210892, accuracy: 97.3 %\n",
      "Training round [49/200], qnn_train_step: [400/1000], loss: 0.0956282839179039, accuracy: 97.0 %\n",
      "Training round [49/200], qnn_train_step: [500/1000], loss: 0.09626986086368561, accuracy: 97.0 %\n",
      "Training round [49/200], qnn_train_step: [600/1000], loss: 0.09459658712148666, accuracy: 97.1 %\n",
      "Training round [49/200], qnn_train_step: [700/1000], loss: 0.08889174461364746, accuracy: 97.2 %\n",
      "Training round [49/200], qnn_train_step: [800/1000], loss: 0.14254075288772583, accuracy: 95.6 %\n",
      "Training round [49/200], qnn_train_step: [900/1000], loss: 0.08913543820381165, accuracy: 97.3 %\n",
      "Training round [49/200], qnn_train_step: [1000/1000], loss: 0.11071763932704926, accuracy: 96.3 %\n",
      "-----------------------\n",
      "Training round [50/200], Epoch [1/5], Step [20/47], Loss: 0.0987, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [1/5], Step [40/47], Loss: 0.1521, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [50/200], Epoch [2/5], Step [20/47], Loss: 0.0319, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [2/5], Step [40/47], Loss: 0.1250, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [50/200], Epoch [3/5], Step [20/47], Loss: 0.0876, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [3/5], Step [40/47], Loss: 0.0596, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [50/200], Epoch [4/5], Step [20/47], Loss: 0.0888, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [50/200], Epoch [4/5], Step [40/47], Loss: 0.1666, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [50/200], Epoch [5/5], Step [20/47], Loss: 0.0694, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [50/200], Epoch [5/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [50/200], qnn_train_step: [100/1000], loss: 0.08352558314800262, accuracy: 97.7 %\n",
      "Training round [50/200], qnn_train_step: [200/1000], loss: 0.21370859444141388, accuracy: 94.6 %\n",
      "Training round [50/200], qnn_train_step: [300/1000], loss: 0.09346362203359604, accuracy: 97.5 %\n",
      "Training round [50/200], qnn_train_step: [400/1000], loss: 0.0753258466720581, accuracy: 97.9 %\n",
      "Training round [50/200], qnn_train_step: [500/1000], loss: 0.07470697909593582, accuracy: 98.0 %\n",
      "Training round [50/200], qnn_train_step: [600/1000], loss: 0.07879900932312012, accuracy: 97.9 %\n",
      "Training round [50/200], qnn_train_step: [700/1000], loss: 0.07092281430959702, accuracy: 98.2 %\n",
      "Training round [50/200], qnn_train_step: [800/1000], loss: 0.0733795240521431, accuracy: 98.2 %\n",
      "Training round [50/200], qnn_train_step: [900/1000], loss: 0.06829437613487244, accuracy: 98.4 %\n",
      "Training round [50/200], qnn_train_step: [1000/1000], loss: 0.06750037521123886, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [51/200], Epoch [1/5], Step [20/47], Loss: 0.1243, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [51/200], Epoch [1/5], Step [40/47], Loss: 0.1628, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [2/5], Step [20/47], Loss: 0.0254, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [51/200], Epoch [2/5], Step [40/47], Loss: 0.0585, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [51/200], Epoch [3/5], Step [20/47], Loss: 0.0832, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [51/200], Epoch [3/5], Step [40/47], Loss: 0.0460, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [51/200], Epoch [4/5], Step [20/47], Loss: 0.0650, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [51/200], Epoch [4/5], Step [40/47], Loss: 0.0734, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [51/200], Epoch [5/5], Step [20/47], Loss: 0.0408, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [51/200], Epoch [5/5], Step [40/47], Loss: 0.2018, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [51/200], qnn_train_step: [100/1000], loss: 0.07374382019042969, accuracy: 97.4 %\n",
      "Training round [51/200], qnn_train_step: [200/1000], loss: 0.2589980959892273, accuracy: 91.8 %\n",
      "Training round [51/200], qnn_train_step: [300/1000], loss: 0.0648173838853836, accuracy: 97.6 %\n",
      "Training round [51/200], qnn_train_step: [400/1000], loss: 0.06133738160133362, accuracy: 98.3 %\n",
      "Training round [51/200], qnn_train_step: [500/1000], loss: 0.0765857845544815, accuracy: 97.8 %\n",
      "Training round [51/200], qnn_train_step: [600/1000], loss: 0.05828341469168663, accuracy: 98.4 %\n",
      "Training round [51/200], qnn_train_step: [700/1000], loss: 0.06459210813045502, accuracy: 97.9 %\n",
      "Training round [51/200], qnn_train_step: [800/1000], loss: 0.05520986020565033, accuracy: 98.6 %\n",
      "Training round [51/200], qnn_train_step: [900/1000], loss: 0.05403156206011772, accuracy: 98.7 %\n",
      "Training round [51/200], qnn_train_step: [1000/1000], loss: 0.05346865579485893, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [52/200], Epoch [1/5], Step [20/47], Loss: 0.1386, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [1/5], Step [40/47], Loss: 0.1108, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [52/200], Epoch [2/5], Step [20/47], Loss: 0.0981, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [2/5], Step [40/47], Loss: 0.1778, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [52/200], Epoch [3/5], Step [20/47], Loss: 0.1072, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [52/200], Epoch [3/5], Step [40/47], Loss: 0.0477, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [52/200], Epoch [4/5], Step [20/47], Loss: 0.1648, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [52/200], Epoch [4/5], Step [40/47], Loss: 0.1065, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [5/5], Step [20/47], Loss: 0.1378, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [52/200], Epoch [5/5], Step [40/47], Loss: 0.1771, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [52/200], qnn_train_step: [100/1000], loss: 0.11520766466856003, accuracy: 95.7 %\n",
      "Training round [52/200], qnn_train_step: [200/1000], loss: 0.11170487850904465, accuracy: 96.2 %\n",
      "Training round [52/200], qnn_train_step: [300/1000], loss: 0.08594805002212524, accuracy: 97.0 %\n",
      "Training round [52/200], qnn_train_step: [400/1000], loss: 0.07450158149003983, accuracy: 97.5 %\n",
      "Training round [52/200], qnn_train_step: [500/1000], loss: 0.07191543281078339, accuracy: 97.4 %\n",
      "Training round [52/200], qnn_train_step: [600/1000], loss: 0.07157812267541885, accuracy: 97.7 %\n",
      "Training round [52/200], qnn_train_step: [700/1000], loss: 0.06367598474025726, accuracy: 97.8 %\n",
      "Training round [52/200], qnn_train_step: [800/1000], loss: 0.07248940318822861, accuracy: 97.4 %\n",
      "Training round [52/200], qnn_train_step: [900/1000], loss: 0.06342390924692154, accuracy: 98.3 %\n",
      "Training round [52/200], qnn_train_step: [1000/1000], loss: 0.07832491397857666, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [53/200], Epoch [1/5], Step [20/47], Loss: 0.1740, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [53/200], Epoch [1/5], Step [40/47], Loss: 0.0730, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [53/200], Epoch [2/5], Step [20/47], Loss: 0.1037, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [53/200], Epoch [2/5], Step [40/47], Loss: 0.1005, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [3/5], Step [20/47], Loss: 0.0686, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [53/200], Epoch [3/5], Step [40/47], Loss: 0.0697, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [53/200], Epoch [4/5], Step [20/47], Loss: 0.0531, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [53/200], Epoch [4/5], Step [40/47], Loss: 0.1299, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [53/200], Epoch [5/5], Step [20/47], Loss: 0.0393, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [53/200], Epoch [5/5], Step [40/47], Loss: 0.1601, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [53/200], qnn_train_step: [100/1000], loss: 0.08807023614645004, accuracy: 97.9 %\n",
      "Training round [53/200], qnn_train_step: [200/1000], loss: 0.08563406020402908, accuracy: 97.6 %\n",
      "Training round [53/200], qnn_train_step: [300/1000], loss: 0.08172105997800827, accuracy: 97.9 %\n",
      "Training round [53/200], qnn_train_step: [400/1000], loss: 0.0794726014137268, accuracy: 97.9 %\n",
      "Training round [53/200], qnn_train_step: [500/1000], loss: 0.1331890970468521, accuracy: 95.0 %\n",
      "Training round [53/200], qnn_train_step: [600/1000], loss: 0.07575355470180511, accuracy: 97.6 %\n",
      "Training round [53/200], qnn_train_step: [700/1000], loss: 0.08120092004537582, accuracy: 97.7 %\n",
      "Training round [53/200], qnn_train_step: [800/1000], loss: 0.07474535703659058, accuracy: 98.1 %\n",
      "Training round [53/200], qnn_train_step: [900/1000], loss: 0.07442055642604828, accuracy: 97.7 %\n",
      "Training round [53/200], qnn_train_step: [1000/1000], loss: 0.0930657833814621, accuracy: 96.7 %\n",
      "-----------------------\n",
      "Training round [54/200], Epoch [1/5], Step [20/47], Loss: 0.0897, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [54/200], Epoch [1/5], Step [40/47], Loss: 0.1256, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [2/5], Step [20/47], Loss: 0.0948, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [2/5], Step [40/47], Loss: 0.0231, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [54/200], Epoch [3/5], Step [20/47], Loss: 0.0578, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [54/200], Epoch [3/5], Step [40/47], Loss: 0.0413, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [54/200], Epoch [4/5], Step [20/47], Loss: 0.1556, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [4/5], Step [40/47], Loss: 0.1825, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [54/200], Epoch [5/5], Step [20/47], Loss: 0.0697, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [54/200], Epoch [5/5], Step [40/47], Loss: 0.2176, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [54/200], qnn_train_step: [100/1000], loss: 0.08237051218748093, accuracy: 97.5 %\n",
      "Training round [54/200], qnn_train_step: [200/1000], loss: 0.08159896731376648, accuracy: 97.6 %\n",
      "Training round [54/200], qnn_train_step: [300/1000], loss: 0.07726363837718964, accuracy: 97.8 %\n",
      "Training round [54/200], qnn_train_step: [400/1000], loss: 0.07355941087007523, accuracy: 97.7 %\n",
      "Training round [54/200], qnn_train_step: [500/1000], loss: 0.07764635235071182, accuracy: 97.6 %\n",
      "Training round [54/200], qnn_train_step: [600/1000], loss: 0.07573781162500381, accuracy: 97.7 %\n",
      "Training round [54/200], qnn_train_step: [700/1000], loss: 0.07145285606384277, accuracy: 97.7 %\n",
      "Training round [54/200], qnn_train_step: [800/1000], loss: 0.07157190144062042, accuracy: 97.8 %\n",
      "Training round [54/200], qnn_train_step: [900/1000], loss: 0.06813938915729523, accuracy: 98.2 %\n",
      "Training round [54/200], qnn_train_step: [1000/1000], loss: 0.07934678345918655, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [55/200], Epoch [1/5], Step [20/47], Loss: 0.1595, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [1/5], Step [40/47], Loss: 0.0459, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [55/200], Epoch [2/5], Step [20/47], Loss: 0.0647, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [55/200], Epoch [2/5], Step [40/47], Loss: 0.0543, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [55/200], Epoch [3/5], Step [20/47], Loss: 0.1258, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [55/200], Epoch [3/5], Step [40/47], Loss: 0.0699, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [4/5], Step [20/47], Loss: 0.0743, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [55/200], Epoch [4/5], Step [40/47], Loss: 0.2099, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [5/5], Step [20/47], Loss: 0.1185, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [55/200], Epoch [5/5], Step [40/47], Loss: 0.0940, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [55/200], qnn_train_step: [100/1000], loss: 0.058938510715961456, accuracy: 98.1 %\n",
      "Training round [55/200], qnn_train_step: [200/1000], loss: 0.062381286174058914, accuracy: 98.1 %\n",
      "Training round [55/200], qnn_train_step: [300/1000], loss: 0.06097051873803139, accuracy: 98.3 %\n",
      "Training round [55/200], qnn_train_step: [400/1000], loss: 0.05310172960162163, accuracy: 98.8 %\n",
      "Training round [55/200], qnn_train_step: [500/1000], loss: 0.05632366985082626, accuracy: 98.6 %\n",
      "Training round [55/200], qnn_train_step: [600/1000], loss: 0.06243576481938362, accuracy: 98.3 %\n",
      "Training round [55/200], qnn_train_step: [700/1000], loss: 0.05489162728190422, accuracy: 98.6 %\n",
      "Training round [55/200], qnn_train_step: [800/1000], loss: 0.05219369754195213, accuracy: 98.9 %\n",
      "Training round [55/200], qnn_train_step: [900/1000], loss: 0.06187385693192482, accuracy: 98.5 %\n",
      "Training round [55/200], qnn_train_step: [1000/1000], loss: 0.05816005915403366, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [56/200], Epoch [1/5], Step [20/47], Loss: 0.1669, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [56/200], Epoch [1/5], Step [40/47], Loss: 0.1044, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [56/200], Epoch [2/5], Step [20/47], Loss: 0.1206, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [56/200], Epoch [2/5], Step [40/47], Loss: 0.0609, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [56/200], Epoch [3/5], Step [20/47], Loss: 0.0671, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], Epoch [3/5], Step [40/47], Loss: 0.0560, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], Epoch [4/5], Step [20/47], Loss: 0.0770, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [56/200], Epoch [4/5], Step [40/47], Loss: 0.1034, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [56/200], Epoch [5/5], Step [20/47], Loss: 0.0706, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [56/200], Epoch [5/5], Step [40/47], Loss: 0.0669, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [56/200], qnn_train_step: [100/1000], loss: 0.11225670576095581, accuracy: 96.4 %\n",
      "Training round [56/200], qnn_train_step: [200/1000], loss: 0.11783333122730255, accuracy: 96.2 %\n",
      "Training round [56/200], qnn_train_step: [300/1000], loss: 0.10550148785114288, accuracy: 96.4 %\n",
      "Training round [56/200], qnn_train_step: [400/1000], loss: 0.10024955123662949, accuracy: 96.5 %\n",
      "Training round [56/200], qnn_train_step: [500/1000], loss: 0.10309982299804688, accuracy: 96.5 %\n",
      "Training round [56/200], qnn_train_step: [600/1000], loss: 0.10669432580471039, accuracy: 96.8 %\n",
      "Training round [56/200], qnn_train_step: [700/1000], loss: 0.09726538509130478, accuracy: 96.8 %\n",
      "Training round [56/200], qnn_train_step: [800/1000], loss: 0.10271336883306503, accuracy: 96.4 %\n",
      "Training round [56/200], qnn_train_step: [900/1000], loss: 0.09869472682476044, accuracy: 96.3 %\n",
      "Training round [56/200], qnn_train_step: [1000/1000], loss: 0.097925566136837, accuracy: 96.5 %\n",
      "-----------------------\n",
      "Training round [57/200], Epoch [1/5], Step [20/47], Loss: 0.0373, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [57/200], Epoch [1/5], Step [40/47], Loss: 0.0514, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [2/5], Step [20/47], Loss: 0.0465, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [57/200], Epoch [2/5], Step [40/47], Loss: 0.0690, batch time: 0.26, accuracy:  97.66%\n",
      "Training round [57/200], Epoch [3/5], Step [20/47], Loss: 0.1067, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [57/200], Epoch [3/5], Step [40/47], Loss: 0.0783, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [57/200], Epoch [4/5], Step [20/47], Loss: 0.1199, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [57/200], Epoch [4/5], Step [40/47], Loss: 0.0996, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [57/200], Epoch [5/5], Step [20/47], Loss: 0.0803, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [57/200], Epoch [5/5], Step [40/47], Loss: 0.0910, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [57/200], qnn_train_step: [100/1000], loss: 0.076158806681633, accuracy: 97.9 %\n",
      "Training round [57/200], qnn_train_step: [200/1000], loss: 0.12091447412967682, accuracy: 96.3 %\n",
      "Training round [57/200], qnn_train_step: [300/1000], loss: 0.1365533024072647, accuracy: 95.3 %\n",
      "Training round [57/200], qnn_train_step: [400/1000], loss: 0.06942081451416016, accuracy: 98.5 %\n",
      "Training round [57/200], qnn_train_step: [500/1000], loss: 0.08365243673324585, accuracy: 97.3 %\n",
      "Training round [57/200], qnn_train_step: [600/1000], loss: 0.1198856383562088, accuracy: 95.9 %\n",
      "Training round [57/200], qnn_train_step: [700/1000], loss: 0.07068593055009842, accuracy: 98.2 %\n",
      "Training round [57/200], qnn_train_step: [800/1000], loss: 0.07014614343643188, accuracy: 97.7 %\n",
      "Training round [57/200], qnn_train_step: [900/1000], loss: 0.062069110572338104, accuracy: 98.2 %\n",
      "Training round [57/200], qnn_train_step: [1000/1000], loss: 0.05940961092710495, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [58/200], Epoch [1/5], Step [20/47], Loss: 0.0954, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [1/5], Step [40/47], Loss: 0.0694, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [2/5], Step [20/47], Loss: 0.2349, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [2/5], Step [40/47], Loss: 0.0993, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [3/5], Step [20/47], Loss: 0.1338, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [58/200], Epoch [3/5], Step [40/47], Loss: 0.0865, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [58/200], Epoch [4/5], Step [20/47], Loss: 0.1007, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [58/200], Epoch [4/5], Step [40/47], Loss: 0.0902, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [58/200], Epoch [5/5], Step [20/47], Loss: 0.1017, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [58/200], Epoch [5/5], Step [40/47], Loss: 0.1267, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [58/200], qnn_train_step: [100/1000], loss: 0.06423556804656982, accuracy: 98.2 %\n",
      "Training round [58/200], qnn_train_step: [200/1000], loss: 0.06482955813407898, accuracy: 98.1 %\n",
      "Training round [58/200], qnn_train_step: [300/1000], loss: 0.05866873264312744, accuracy: 98.6 %\n",
      "Training round [58/200], qnn_train_step: [400/1000], loss: 0.056404974311590195, accuracy: 98.6 %\n",
      "Training round [58/200], qnn_train_step: [500/1000], loss: 0.06379441916942596, accuracy: 98.1 %\n",
      "Training round [58/200], qnn_train_step: [600/1000], loss: 0.05456966534256935, accuracy: 98.6 %\n",
      "Training round [58/200], qnn_train_step: [700/1000], loss: 0.0518733374774456, accuracy: 98.8 %\n",
      "Training round [58/200], qnn_train_step: [800/1000], loss: 0.050933606922626495, accuracy: 98.8 %\n",
      "Training round [58/200], qnn_train_step: [900/1000], loss: 0.049802202731370926, accuracy: 99.2 %\n",
      "Training round [58/200], qnn_train_step: [1000/1000], loss: 0.049734994769096375, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [59/200], Epoch [1/5], Step [20/47], Loss: 0.0396, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [59/200], Epoch [1/5], Step [40/47], Loss: 0.0434, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [59/200], Epoch [2/5], Step [20/47], Loss: 0.0893, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [2/5], Step [40/47], Loss: 0.1700, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [59/200], Epoch [3/5], Step [20/47], Loss: 0.0541, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [59/200], Epoch [3/5], Step [40/47], Loss: 0.1111, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [59/200], Epoch [4/5], Step [20/47], Loss: 0.1056, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [4/5], Step [40/47], Loss: 0.0447, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [59/200], Epoch [5/5], Step [20/47], Loss: 0.1254, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [59/200], Epoch [5/5], Step [40/47], Loss: 0.0544, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [59/200], qnn_train_step: [100/1000], loss: 0.08041875064373016, accuracy: 97.3 %\n",
      "Training round [59/200], qnn_train_step: [200/1000], loss: 0.20531806349754333, accuracy: 93.3 %\n",
      "Training round [59/200], qnn_train_step: [300/1000], loss: 0.07585657387971878, accuracy: 97.5 %\n",
      "Training round [59/200], qnn_train_step: [400/1000], loss: 0.07015859335660934, accuracy: 97.8 %\n",
      "Training round [59/200], qnn_train_step: [500/1000], loss: 0.07101165503263474, accuracy: 97.8 %\n",
      "Training round [59/200], qnn_train_step: [600/1000], loss: 0.071577288210392, accuracy: 97.8 %\n",
      "Training round [59/200], qnn_train_step: [700/1000], loss: 0.06608790159225464, accuracy: 98.0 %\n",
      "Training round [59/200], qnn_train_step: [800/1000], loss: 0.06479251384735107, accuracy: 98.4 %\n",
      "Training round [59/200], qnn_train_step: [900/1000], loss: 0.06457693874835968, accuracy: 98.3 %\n",
      "Training round [59/200], qnn_train_step: [1000/1000], loss: 0.06391645222902298, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [60/200], Epoch [1/5], Step [20/47], Loss: 0.0673, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [60/200], Epoch [1/5], Step [40/47], Loss: 0.1391, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [60/200], Epoch [2/5], Step [20/47], Loss: 0.0364, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [60/200], Epoch [2/5], Step [40/47], Loss: 0.0843, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [3/5], Step [20/47], Loss: 0.0812, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [60/200], Epoch [3/5], Step [40/47], Loss: 0.0382, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [60/200], Epoch [4/5], Step [20/47], Loss: 0.1663, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [60/200], Epoch [4/5], Step [40/47], Loss: 0.0661, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [60/200], Epoch [5/5], Step [20/47], Loss: 0.0380, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [60/200], Epoch [5/5], Step [40/47], Loss: 0.1056, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [60/200], qnn_train_step: [100/1000], loss: 0.08676166087388992, accuracy: 96.7 %\n",
      "Training round [60/200], qnn_train_step: [200/1000], loss: 0.20110160112380981, accuracy: 92.8 %\n",
      "Training round [60/200], qnn_train_step: [300/1000], loss: 1.1941174268722534, accuracy: 77.0 %\n",
      "Training round [60/200], qnn_train_step: [400/1000], loss: 0.07310989499092102, accuracy: 97.6 %\n",
      "Training round [60/200], qnn_train_step: [500/1000], loss: 0.06918035447597504, accuracy: 97.9 %\n",
      "Training round [60/200], qnn_train_step: [600/1000], loss: 0.06791265308856964, accuracy: 97.5 %\n",
      "Training round [60/200], qnn_train_step: [700/1000], loss: 0.0818147361278534, accuracy: 97.3 %\n",
      "Training round [60/200], qnn_train_step: [800/1000], loss: 0.06009431555867195, accuracy: 98.6 %\n",
      "Training round [60/200], qnn_train_step: [900/1000], loss: 0.06320224702358246, accuracy: 97.4 %\n",
      "Training round [60/200], qnn_train_step: [1000/1000], loss: 0.07687219232320786, accuracy: 97.1 %\n",
      "-----------------------\n",
      "Training round [61/200], Epoch [1/5], Step [20/47], Loss: 0.0707, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [1/5], Step [40/47], Loss: 0.0660, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], Epoch [2/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [2/5], Step [40/47], Loss: 0.1019, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [3/5], Step [20/47], Loss: 0.0273, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [3/5], Step [40/47], Loss: 0.1395, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [4/5], Step [20/47], Loss: 0.1507, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [61/200], Epoch [4/5], Step [40/47], Loss: 0.0941, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [61/200], Epoch [5/5], Step [20/47], Loss: 0.0885, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [61/200], Epoch [5/5], Step [40/47], Loss: 0.0930, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [61/200], qnn_train_step: [100/1000], loss: 0.06954878568649292, accuracy: 97.7 %\n",
      "Training round [61/200], qnn_train_step: [200/1000], loss: 0.07573099434375763, accuracy: 97.9 %\n",
      "Training round [61/200], qnn_train_step: [300/1000], loss: 0.08212786912918091, accuracy: 97.4 %\n",
      "Training round [61/200], qnn_train_step: [400/1000], loss: 0.06530541926622391, accuracy: 98.1 %\n",
      "Training round [61/200], qnn_train_step: [500/1000], loss: 0.06598372757434845, accuracy: 98.2 %\n",
      "Training round [61/200], qnn_train_step: [600/1000], loss: 0.06269432604312897, accuracy: 98.4 %\n",
      "Training round [61/200], qnn_train_step: [700/1000], loss: 0.06224855035543442, accuracy: 98.3 %\n",
      "Training round [61/200], qnn_train_step: [800/1000], loss: 0.061246857047080994, accuracy: 98.3 %\n",
      "Training round [61/200], qnn_train_step: [900/1000], loss: 0.06072131171822548, accuracy: 98.5 %\n",
      "Training round [61/200], qnn_train_step: [1000/1000], loss: 0.06016949936747551, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [62/200], Epoch [1/5], Step [20/47], Loss: 0.0409, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [1/5], Step [40/47], Loss: 0.0756, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [2/5], Step [20/47], Loss: 0.0598, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [2/5], Step [40/47], Loss: 0.0906, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [3/5], Step [20/47], Loss: 0.0628, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [3/5], Step [40/47], Loss: 0.1352, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [62/200], Epoch [4/5], Step [20/47], Loss: 0.0624, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [62/200], Epoch [4/5], Step [40/47], Loss: 0.0677, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [62/200], Epoch [5/5], Step [20/47], Loss: 0.0477, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [62/200], Epoch [5/5], Step [40/47], Loss: 0.0420, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [62/200], qnn_train_step: [100/1000], loss: 0.06790117919445038, accuracy: 98.1 %\n",
      "Training round [62/200], qnn_train_step: [200/1000], loss: 0.08985164761543274, accuracy: 97.7 %\n",
      "Training round [62/200], qnn_train_step: [300/1000], loss: 0.0646333321928978, accuracy: 98.2 %\n",
      "Training round [62/200], qnn_train_step: [400/1000], loss: 0.06372128427028656, accuracy: 98.0 %\n",
      "Training round [62/200], qnn_train_step: [500/1000], loss: 0.05619286373257637, accuracy: 98.3 %\n",
      "Training round [62/200], qnn_train_step: [600/1000], loss: 0.05837845429778099, accuracy: 98.5 %\n",
      "Training round [62/200], qnn_train_step: [700/1000], loss: 0.05735940486192703, accuracy: 98.2 %\n",
      "Training round [62/200], qnn_train_step: [800/1000], loss: 0.06411152333021164, accuracy: 98.3 %\n",
      "Training round [62/200], qnn_train_step: [900/1000], loss: 0.055211495608091354, accuracy: 98.3 %\n",
      "Training round [62/200], qnn_train_step: [1000/1000], loss: 0.05198691785335541, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [63/200], Epoch [1/5], Step [20/47], Loss: 0.0307, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [63/200], Epoch [1/5], Step [40/47], Loss: 0.0517, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [63/200], Epoch [2/5], Step [20/47], Loss: 0.0852, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [2/5], Step [40/47], Loss: 0.0493, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [63/200], Epoch [3/5], Step [20/47], Loss: 0.0159, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [63/200], Epoch [3/5], Step [40/47], Loss: 0.1233, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [63/200], Epoch [4/5], Step [20/47], Loss: 0.1117, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [63/200], Epoch [4/5], Step [40/47], Loss: 0.1110, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [63/200], Epoch [5/5], Step [20/47], Loss: 0.0584, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [63/200], Epoch [5/5], Step [40/47], Loss: 0.0519, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [63/200], qnn_train_step: [100/1000], loss: 0.06267629563808441, accuracy: 97.4 %\n",
      "Training round [63/200], qnn_train_step: [200/1000], loss: 0.0642077624797821, accuracy: 97.6 %\n",
      "Training round [63/200], qnn_train_step: [300/1000], loss: 0.05560759827494621, accuracy: 98.1 %\n",
      "Training round [63/200], qnn_train_step: [400/1000], loss: 0.05140293762087822, accuracy: 97.9 %\n",
      "Training round [63/200], qnn_train_step: [500/1000], loss: 0.05276882275938988, accuracy: 97.9 %\n",
      "Training round [63/200], qnn_train_step: [600/1000], loss: 0.05329671874642372, accuracy: 97.8 %\n",
      "Training round [63/200], qnn_train_step: [700/1000], loss: 0.049554094672203064, accuracy: 97.9 %\n",
      "Training round [63/200], qnn_train_step: [800/1000], loss: 0.05320797860622406, accuracy: 97.9 %\n",
      "Training round [63/200], qnn_train_step: [900/1000], loss: 0.045470014214515686, accuracy: 98.0 %\n",
      "Training round [63/200], qnn_train_step: [1000/1000], loss: 0.04502253234386444, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [64/200], Epoch [1/5], Step [20/47], Loss: 0.0860, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [1/5], Step [40/47], Loss: 0.1392, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [20/47], Loss: 0.1353, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [2/5], Step [40/47], Loss: 0.0646, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [64/200], Epoch [3/5], Step [20/47], Loss: 0.0260, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [64/200], Epoch [3/5], Step [40/47], Loss: 0.0191, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [64/200], Epoch [4/5], Step [20/47], Loss: 0.0637, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [4/5], Step [40/47], Loss: 0.1212, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [64/200], Epoch [5/5], Step [20/47], Loss: 0.1321, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [64/200], Epoch [5/5], Step [40/47], Loss: 0.1210, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [64/200], qnn_train_step: [100/1000], loss: 0.0994146317243576, accuracy: 96.8 %\n",
      "Training round [64/200], qnn_train_step: [200/1000], loss: 0.10817974805831909, accuracy: 96.2 %\n",
      "Training round [64/200], qnn_train_step: [300/1000], loss: 0.09516967087984085, accuracy: 97.3 %\n",
      "Training round [64/200], qnn_train_step: [400/1000], loss: 0.08912064135074615, accuracy: 97.4 %\n",
      "Training round [64/200], qnn_train_step: [500/1000], loss: 0.0919656977057457, accuracy: 97.0 %\n",
      "Training round [64/200], qnn_train_step: [600/1000], loss: 0.08531661331653595, accuracy: 97.3 %\n",
      "Training round [64/200], qnn_train_step: [700/1000], loss: 0.08729356527328491, accuracy: 97.5 %\n",
      "Training round [64/200], qnn_train_step: [800/1000], loss: 0.08199157565832138, accuracy: 97.7 %\n",
      "Training round [64/200], qnn_train_step: [900/1000], loss: 0.08093187212944031, accuracy: 97.8 %\n",
      "Training round [64/200], qnn_train_step: [1000/1000], loss: 0.08023843914270401, accuracy: 97.6 %\n",
      "-----------------------\n",
      "Training round [65/200], Epoch [1/5], Step [20/47], Loss: 0.0890, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [1/5], Step [40/47], Loss: 0.1188, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [2/5], Step [20/47], Loss: 0.0825, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [2/5], Step [40/47], Loss: 0.0542, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [3/5], Step [20/47], Loss: 0.0857, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [65/200], Epoch [3/5], Step [40/47], Loss: 0.1169, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [65/200], Epoch [4/5], Step [20/47], Loss: 0.0471, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [65/200], Epoch [4/5], Step [40/47], Loss: 0.0800, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [65/200], Epoch [5/5], Step [20/47], Loss: 0.1284, batch time: 0.04, accuracy:  94.53%\n",
      "Training round [65/200], Epoch [5/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [65/200], qnn_train_step: [100/1000], loss: 0.04951149970293045, accuracy: 98.3 %\n",
      "Training round [65/200], qnn_train_step: [200/1000], loss: 0.05690054967999458, accuracy: 97.8 %\n",
      "Training round [65/200], qnn_train_step: [300/1000], loss: 0.04406944289803505, accuracy: 98.7 %\n",
      "Training round [65/200], qnn_train_step: [400/1000], loss: 0.05197565257549286, accuracy: 98.0 %\n",
      "Training round [65/200], qnn_train_step: [500/1000], loss: 0.04099129140377045, accuracy: 98.7 %\n",
      "Training round [65/200], qnn_train_step: [600/1000], loss: 0.03883407264947891, accuracy: 98.9 %\n",
      "Training round [65/200], qnn_train_step: [700/1000], loss: 0.038561269640922546, accuracy: 98.9 %\n",
      "Training round [65/200], qnn_train_step: [800/1000], loss: 0.0379907488822937, accuracy: 99.0 %\n",
      "Training round [65/200], qnn_train_step: [900/1000], loss: 0.037262000143527985, accuracy: 99.1 %\n",
      "Training round [65/200], qnn_train_step: [1000/1000], loss: 0.037157997488975525, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [66/200], Epoch [1/5], Step [20/47], Loss: 0.0894, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [66/200], Epoch [1/5], Step [40/47], Loss: 0.0637, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [66/200], Epoch [2/5], Step [20/47], Loss: 0.0943, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [2/5], Step [40/47], Loss: 0.0609, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [66/200], Epoch [3/5], Step [20/47], Loss: 0.0337, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [66/200], Epoch [3/5], Step [40/47], Loss: 0.1304, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [4/5], Step [20/47], Loss: 0.0994, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [66/200], Epoch [4/5], Step [40/47], Loss: 0.0443, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [66/200], Epoch [5/5], Step [20/47], Loss: 0.1168, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [66/200], Epoch [5/5], Step [40/47], Loss: 0.0942, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [66/200], qnn_train_step: [100/1000], loss: 0.04414748772978783, accuracy: 99.0 %\n",
      "Training round [66/200], qnn_train_step: [200/1000], loss: 0.1097089871764183, accuracy: 96.9 %\n",
      "Training round [66/200], qnn_train_step: [300/1000], loss: 0.03692355379462242, accuracy: 99.1 %\n",
      "Training round [66/200], qnn_train_step: [400/1000], loss: 0.03706509992480278, accuracy: 99.4 %\n",
      "Training round [66/200], qnn_train_step: [500/1000], loss: 0.040139831602573395, accuracy: 99.2 %\n",
      "Training round [66/200], qnn_train_step: [600/1000], loss: 0.03803856298327446, accuracy: 99.4 %\n",
      "Training round [66/200], qnn_train_step: [700/1000], loss: 0.03445380553603172, accuracy: 99.4 %\n",
      "Training round [66/200], qnn_train_step: [800/1000], loss: 0.03404220566153526, accuracy: 99.2 %\n",
      "Training round [66/200], qnn_train_step: [900/1000], loss: 0.032317373901605606, accuracy: 99.4 %\n",
      "Training round [66/200], qnn_train_step: [1000/1000], loss: 0.031330205500125885, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [67/200], Epoch [1/5], Step [20/47], Loss: 0.0508, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [1/5], Step [40/47], Loss: 0.1659, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [67/200], Epoch [2/5], Step [20/47], Loss: 0.1707, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [2/5], Step [40/47], Loss: 0.0881, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [3/5], Step [20/47], Loss: 0.0241, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [67/200], Epoch [3/5], Step [40/47], Loss: 0.1030, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [67/200], Epoch [4/5], Step [20/47], Loss: 0.0247, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [67/200], Epoch [4/5], Step [40/47], Loss: 0.0735, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [5/5], Step [20/47], Loss: 0.0774, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [67/200], Epoch [5/5], Step [40/47], Loss: 0.1022, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [67/200], qnn_train_step: [100/1000], loss: 0.05002396181225777, accuracy: 98.8 %\n",
      "Training round [67/200], qnn_train_step: [200/1000], loss: 0.052427757531404495, accuracy: 98.8 %\n",
      "Training round [67/200], qnn_train_step: [300/1000], loss: 0.046150386333465576, accuracy: 98.8 %\n",
      "Training round [67/200], qnn_train_step: [400/1000], loss: 0.045312508940696716, accuracy: 98.8 %\n",
      "Training round [67/200], qnn_train_step: [500/1000], loss: 0.043779078871011734, accuracy: 99.1 %\n",
      "Training round [67/200], qnn_train_step: [600/1000], loss: 0.04319312795996666, accuracy: 98.6 %\n",
      "Training round [67/200], qnn_train_step: [700/1000], loss: 0.04280860349535942, accuracy: 98.8 %\n",
      "Training round [67/200], qnn_train_step: [800/1000], loss: 0.0431729219853878, accuracy: 99.0 %\n",
      "Training round [67/200], qnn_train_step: [900/1000], loss: 0.04356549680233002, accuracy: 99.0 %\n",
      "Training round [67/200], qnn_train_step: [1000/1000], loss: 0.04169827327132225, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [68/200], Epoch [1/5], Step [20/47], Loss: 0.0662, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [1/5], Step [40/47], Loss: 0.1499, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [2/5], Step [20/47], Loss: 0.1216, batch time: 0.24, accuracy:  93.75%\n",
      "Training round [68/200], Epoch [2/5], Step [40/47], Loss: 0.1606, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [3/5], Step [20/47], Loss: 0.0999, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [68/200], Epoch [3/5], Step [40/47], Loss: 0.0684, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [4/5], Step [20/47], Loss: 0.0472, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [68/200], Epoch [4/5], Step [40/47], Loss: 0.1345, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [68/200], Epoch [5/5], Step [20/47], Loss: 0.0434, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [68/200], Epoch [5/5], Step [40/47], Loss: 0.1004, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [68/200], qnn_train_step: [100/1000], loss: 0.059200700372457504, accuracy: 98.2 %\n",
      "Training round [68/200], qnn_train_step: [200/1000], loss: 0.06482165306806564, accuracy: 98.1 %\n",
      "Training round [68/200], qnn_train_step: [300/1000], loss: 0.05546833574771881, accuracy: 98.3 %\n",
      "Training round [68/200], qnn_train_step: [400/1000], loss: 0.05307291820645332, accuracy: 98.3 %\n",
      "Training round [68/200], qnn_train_step: [500/1000], loss: 0.0557982511818409, accuracy: 98.5 %\n",
      "Training round [68/200], qnn_train_step: [600/1000], loss: 0.053259748965501785, accuracy: 98.6 %\n",
      "Training round [68/200], qnn_train_step: [700/1000], loss: 0.05288488045334816, accuracy: 98.2 %\n",
      "Training round [68/200], qnn_train_step: [800/1000], loss: 0.05031810700893402, accuracy: 98.5 %\n",
      "Training round [68/200], qnn_train_step: [900/1000], loss: 0.050024956464767456, accuracy: 98.4 %\n",
      "Training round [68/200], qnn_train_step: [1000/1000], loss: 0.04969008266925812, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [69/200], Epoch [1/5], Step [20/47], Loss: 0.0486, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [1/5], Step [40/47], Loss: 0.1028, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [69/200], Epoch [2/5], Step [20/47], Loss: 0.1014, batch time: 0.07, accuracy:  96.09%\n",
      "Training round [69/200], Epoch [2/5], Step [40/47], Loss: 0.0445, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [69/200], Epoch [3/5], Step [20/47], Loss: 0.0154, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [69/200], Epoch [3/5], Step [40/47], Loss: 0.0641, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [4/5], Step [20/47], Loss: 0.0309, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [4/5], Step [40/47], Loss: 0.1135, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [5/5], Step [20/47], Loss: 0.0672, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [69/200], Epoch [5/5], Step [40/47], Loss: 0.2365, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [69/200], qnn_train_step: [100/1000], loss: 0.07696492224931717, accuracy: 97.6 %\n",
      "Training round [69/200], qnn_train_step: [200/1000], loss: 0.10119211673736572, accuracy: 96.7 %\n",
      "Training round [69/200], qnn_train_step: [300/1000], loss: 0.09080725908279419, accuracy: 97.1 %\n",
      "Training round [69/200], qnn_train_step: [400/1000], loss: 0.0700574591755867, accuracy: 98.0 %\n",
      "Training round [69/200], qnn_train_step: [500/1000], loss: 0.0648370012640953, accuracy: 97.9 %\n",
      "Training round [69/200], qnn_train_step: [600/1000], loss: 0.06289935111999512, accuracy: 97.8 %\n",
      "Training round [69/200], qnn_train_step: [700/1000], loss: 0.062259212136268616, accuracy: 97.8 %\n",
      "Training round [69/200], qnn_train_step: [800/1000], loss: 0.06065165624022484, accuracy: 97.9 %\n",
      "Training round [69/200], qnn_train_step: [900/1000], loss: 0.0615621842443943, accuracy: 98.0 %\n",
      "Training round [69/200], qnn_train_step: [1000/1000], loss: 0.060854483395814896, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [70/200], Epoch [1/5], Step [20/47], Loss: 0.0756, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [1/5], Step [40/47], Loss: 0.1054, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [70/200], Epoch [2/5], Step [20/47], Loss: 0.0652, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [2/5], Step [40/47], Loss: 0.1155, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [3/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [70/200], Epoch [3/5], Step [40/47], Loss: 0.1107, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [70/200], Epoch [4/5], Step [20/47], Loss: 0.0851, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [70/200], Epoch [4/5], Step [40/47], Loss: 0.0615, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [70/200], Epoch [5/5], Step [20/47], Loss: 0.1306, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [70/200], Epoch [5/5], Step [40/47], Loss: 0.0676, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [70/200], qnn_train_step: [100/1000], loss: 0.06232760474085808, accuracy: 98.4 %\n",
      "Training round [70/200], qnn_train_step: [200/1000], loss: 0.06622271984815598, accuracy: 98.2 %\n",
      "Training round [70/200], qnn_train_step: [300/1000], loss: 0.05617842823266983, accuracy: 98.6 %\n",
      "Training round [70/200], qnn_train_step: [400/1000], loss: 0.0583481527864933, accuracy: 98.5 %\n",
      "Training round [70/200], qnn_train_step: [500/1000], loss: 0.05203751102089882, accuracy: 98.5 %\n",
      "Training round [70/200], qnn_train_step: [600/1000], loss: 0.05126594379544258, accuracy: 98.6 %\n",
      "Training round [70/200], qnn_train_step: [700/1000], loss: 0.05121181532740593, accuracy: 98.7 %\n",
      "Training round [70/200], qnn_train_step: [800/1000], loss: 0.050276268273591995, accuracy: 98.7 %\n",
      "Training round [70/200], qnn_train_step: [900/1000], loss: 0.05102188140153885, accuracy: 98.6 %\n",
      "Training round [70/200], qnn_train_step: [1000/1000], loss: 0.05170724168419838, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [71/200], Epoch [1/5], Step [20/47], Loss: 0.1640, batch time: 0.08, accuracy:  95.31%\n",
      "Training round [71/200], Epoch [1/5], Step [40/47], Loss: 0.0536, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [71/200], Epoch [2/5], Step [20/47], Loss: 0.0704, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [2/5], Step [40/47], Loss: 0.0189, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [71/200], Epoch [3/5], Step [20/47], Loss: 0.0644, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [71/200], Epoch [3/5], Step [40/47], Loss: 0.0826, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [71/200], Epoch [4/5], Step [20/47], Loss: 0.1404, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [4/5], Step [40/47], Loss: 0.0980, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [71/200], Epoch [5/5], Step [20/47], Loss: 0.0488, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [71/200], Epoch [5/5], Step [40/47], Loss: 0.1006, batch time: 0.06, accuracy:  95.31%\n",
      "Training round [71/200], qnn_train_step: [100/1000], loss: 0.05973820388317108, accuracy: 98.2 %\n",
      "Training round [71/200], qnn_train_step: [200/1000], loss: 0.14547286927700043, accuracy: 94.0 %\n",
      "Training round [71/200], qnn_train_step: [300/1000], loss: 0.10112176090478897, accuracy: 96.6 %\n",
      "Training round [71/200], qnn_train_step: [400/1000], loss: 0.048654425889253616, accuracy: 98.4 %\n",
      "Training round [71/200], qnn_train_step: [500/1000], loss: 0.043990980833768845, accuracy: 98.8 %\n",
      "Training round [71/200], qnn_train_step: [600/1000], loss: 0.049835190176963806, accuracy: 98.1 %\n",
      "Training round [71/200], qnn_train_step: [700/1000], loss: 0.04538682475686073, accuracy: 98.5 %\n",
      "Training round [71/200], qnn_train_step: [800/1000], loss: 0.04348922148346901, accuracy: 98.5 %\n",
      "Training round [71/200], qnn_train_step: [900/1000], loss: 0.05024450644850731, accuracy: 98.4 %\n",
      "Training round [71/200], qnn_train_step: [1000/1000], loss: 0.03903543949127197, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [72/200], Epoch [1/5], Step [20/47], Loss: 0.0442, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [72/200], Epoch [1/5], Step [40/47], Loss: 0.0994, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [2/5], Step [20/47], Loss: 0.2240, batch time: 0.08, accuracy:  95.31%\n",
      "Training round [72/200], Epoch [2/5], Step [40/47], Loss: 0.0712, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [3/5], Step [20/47], Loss: 0.0946, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [72/200], Epoch [3/5], Step [40/47], Loss: 0.0511, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], Epoch [4/5], Step [20/47], Loss: 0.0291, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [72/200], Epoch [4/5], Step [40/47], Loss: 0.0698, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [72/200], Epoch [5/5], Step [20/47], Loss: 0.1381, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [72/200], Epoch [5/5], Step [40/47], Loss: 0.0475, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [72/200], qnn_train_step: [100/1000], loss: 0.06051752343773842, accuracy: 97.9 %\n",
      "Training round [72/200], qnn_train_step: [200/1000], loss: 0.06154964864253998, accuracy: 97.9 %\n",
      "Training round [72/200], qnn_train_step: [300/1000], loss: 0.0642056092619896, accuracy: 98.0 %\n",
      "Training round [72/200], qnn_train_step: [400/1000], loss: 0.05711081624031067, accuracy: 98.3 %\n",
      "Training round [72/200], qnn_train_step: [500/1000], loss: 0.058275651186704636, accuracy: 98.3 %\n",
      "Training round [72/200], qnn_train_step: [600/1000], loss: 0.05614832788705826, accuracy: 98.4 %\n",
      "Training round [72/200], qnn_train_step: [700/1000], loss: 0.05478468909859657, accuracy: 98.4 %\n",
      "Training round [72/200], qnn_train_step: [800/1000], loss: 0.05144205689430237, accuracy: 98.5 %\n",
      "Training round [72/200], qnn_train_step: [900/1000], loss: 0.05073750019073486, accuracy: 98.4 %\n",
      "Training round [72/200], qnn_train_step: [1000/1000], loss: 0.05023850500583649, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [73/200], Epoch [1/5], Step [20/47], Loss: 0.0895, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [1/5], Step [40/47], Loss: 0.0943, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [73/200], Epoch [2/5], Step [20/47], Loss: 0.1556, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [2/5], Step [40/47], Loss: 0.0919, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [3/5], Step [20/47], Loss: 0.0237, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [73/200], Epoch [3/5], Step [40/47], Loss: 0.1307, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [4/5], Step [20/47], Loss: 0.0845, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [73/200], Epoch [4/5], Step [40/47], Loss: 0.0887, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [73/200], Epoch [5/5], Step [20/47], Loss: 0.0681, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [73/200], Epoch [5/5], Step [40/47], Loss: 0.0302, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [73/200], qnn_train_step: [100/1000], loss: 0.057679980993270874, accuracy: 98.5 %\n",
      "Training round [73/200], qnn_train_step: [200/1000], loss: 0.14113584160804749, accuracy: 94.5 %\n",
      "Training round [73/200], qnn_train_step: [300/1000], loss: 0.05171016603708267, accuracy: 98.8 %\n",
      "Training round [73/200], qnn_train_step: [400/1000], loss: 0.05026322975754738, accuracy: 98.8 %\n",
      "Training round [73/200], qnn_train_step: [500/1000], loss: 0.04822603613138199, accuracy: 98.7 %\n",
      "Training round [73/200], qnn_train_step: [600/1000], loss: 0.04787289723753929, accuracy: 98.8 %\n",
      "Training round [73/200], qnn_train_step: [700/1000], loss: 0.047267381101846695, accuracy: 98.7 %\n",
      "Training round [73/200], qnn_train_step: [800/1000], loss: 0.049938224256038666, accuracy: 98.6 %\n",
      "Training round [73/200], qnn_train_step: [900/1000], loss: 0.046387139707803726, accuracy: 98.7 %\n",
      "Training round [73/200], qnn_train_step: [1000/1000], loss: 0.047888435423374176, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [74/200], Epoch [1/5], Step [20/47], Loss: 0.0411, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [74/200], Epoch [1/5], Step [40/47], Loss: 0.0781, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [2/5], Step [20/47], Loss: 0.1314, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [74/200], Epoch [2/5], Step [40/47], Loss: 0.0223, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [74/200], Epoch [3/5], Step [20/47], Loss: 0.0404, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [74/200], Epoch [3/5], Step [40/47], Loss: 0.1312, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [4/5], Step [20/47], Loss: 0.0992, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [74/200], Epoch [4/5], Step [40/47], Loss: 0.0481, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [74/200], Epoch [5/5], Step [20/47], Loss: 0.0225, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [74/200], Epoch [5/5], Step [40/47], Loss: 0.0830, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [74/200], qnn_train_step: [100/1000], loss: 0.06275876611471176, accuracy: 97.6 %\n",
      "Training round [74/200], qnn_train_step: [200/1000], loss: 0.42826539278030396, accuracy: 87.4 %\n",
      "Training round [74/200], qnn_train_step: [300/1000], loss: 0.12787304818630219, accuracy: 95.3 %\n",
      "Training round [74/200], qnn_train_step: [400/1000], loss: 0.21748514473438263, accuracy: 92.6 %\n",
      "Training round [74/200], qnn_train_step: [500/1000], loss: 0.050781600177288055, accuracy: 98.3 %\n",
      "Training round [74/200], qnn_train_step: [600/1000], loss: 0.04886222258210182, accuracy: 98.3 %\n",
      "Training round [74/200], qnn_train_step: [700/1000], loss: 0.0485101118683815, accuracy: 98.4 %\n",
      "Training round [74/200], qnn_train_step: [800/1000], loss: 0.047101739794015884, accuracy: 98.6 %\n",
      "Training round [74/200], qnn_train_step: [900/1000], loss: 0.04710585996508598, accuracy: 98.8 %\n",
      "Training round [74/200], qnn_train_step: [1000/1000], loss: 0.04639612138271332, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [75/200], Epoch [1/5], Step [20/47], Loss: 0.1285, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [1/5], Step [40/47], Loss: 0.0923, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [2/5], Step [20/47], Loss: 0.0183, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [75/200], Epoch [2/5], Step [40/47], Loss: 0.1466, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [3/5], Step [20/47], Loss: 0.0330, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [75/200], Epoch [3/5], Step [40/47], Loss: 0.0373, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [4/5], Step [20/47], Loss: 0.1587, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [75/200], Epoch [4/5], Step [40/47], Loss: 0.0516, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [75/200], Epoch [5/5], Step [20/47], Loss: 0.1777, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [75/200], Epoch [5/5], Step [40/47], Loss: 0.0524, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [75/200], qnn_train_step: [100/1000], loss: 0.05734271556138992, accuracy: 98.4 %\n",
      "Training round [75/200], qnn_train_step: [200/1000], loss: 0.28889089822769165, accuracy: 90.0 %\n",
      "Training round [75/200], qnn_train_step: [300/1000], loss: 0.0550379753112793, accuracy: 98.5 %\n",
      "Training round [75/200], qnn_train_step: [400/1000], loss: 0.05024150386452675, accuracy: 98.5 %\n",
      "Training round [75/200], qnn_train_step: [500/1000], loss: 0.052746403962373734, accuracy: 98.4 %\n",
      "Training round [75/200], qnn_train_step: [600/1000], loss: 0.05057567358016968, accuracy: 98.5 %\n",
      "Training round [75/200], qnn_train_step: [700/1000], loss: 0.04061312973499298, accuracy: 99.1 %\n",
      "Training round [75/200], qnn_train_step: [800/1000], loss: 0.03881656751036644, accuracy: 99.0 %\n",
      "Training round [75/200], qnn_train_step: [900/1000], loss: 0.03975750133395195, accuracy: 99.0 %\n",
      "Training round [75/200], qnn_train_step: [1000/1000], loss: 0.037404242902994156, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [76/200], Epoch [1/5], Step [20/47], Loss: 0.1648, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [1/5], Step [40/47], Loss: 0.1372, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [2/5], Step [20/47], Loss: 0.0696, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [2/5], Step [40/47], Loss: 0.0947, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [3/5], Step [20/47], Loss: 0.1045, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [76/200], Epoch [3/5], Step [40/47], Loss: 0.1214, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [76/200], Epoch [4/5], Step [20/47], Loss: 0.1919, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [76/200], Epoch [4/5], Step [40/47], Loss: 0.2377, batch time: 0.11, accuracy:  91.41%\n",
      "Training round [76/200], Epoch [5/5], Step [20/47], Loss: 0.1156, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [76/200], Epoch [5/5], Step [40/47], Loss: 0.0722, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [76/200], qnn_train_step: [100/1000], loss: 0.12889322638511658, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [200/1000], loss: 0.11901172995567322, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [300/1000], loss: 0.2376142144203186, accuracy: 92.7 %\n",
      "Training round [76/200], qnn_train_step: [400/1000], loss: 0.10539958626031876, accuracy: 96.5 %\n",
      "Training round [76/200], qnn_train_step: [500/1000], loss: 0.08753328025341034, accuracy: 97.4 %\n",
      "Training round [76/200], qnn_train_step: [600/1000], loss: 0.08513026684522629, accuracy: 97.4 %\n",
      "Training round [76/200], qnn_train_step: [700/1000], loss: 0.08036713302135468, accuracy: 97.7 %\n",
      "Training round [76/200], qnn_train_step: [800/1000], loss: 0.08754318207502365, accuracy: 97.2 %\n",
      "Training round [76/200], qnn_train_step: [900/1000], loss: 0.07738590985536575, accuracy: 97.8 %\n",
      "Training round [76/200], qnn_train_step: [1000/1000], loss: 0.07405368983745575, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [77/200], Epoch [1/5], Step [20/47], Loss: 0.0627, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [1/5], Step [40/47], Loss: 0.1152, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [2/5], Step [20/47], Loss: 0.0787, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [77/200], Epoch [2/5], Step [40/47], Loss: 0.0605, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [3/5], Step [20/47], Loss: 0.0802, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [77/200], Epoch [3/5], Step [40/47], Loss: 0.0512, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [4/5], Step [20/47], Loss: 0.1293, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [77/200], Epoch [4/5], Step [40/47], Loss: 0.0505, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [5/5], Step [20/47], Loss: 0.0613, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [77/200], Epoch [5/5], Step [40/47], Loss: 0.0450, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [77/200], qnn_train_step: [100/1000], loss: 0.056617941707372665, accuracy: 98.3 %\n",
      "Training round [77/200], qnn_train_step: [200/1000], loss: 0.3375883400440216, accuracy: 88.9 %\n",
      "Training round [77/200], qnn_train_step: [300/1000], loss: 0.08096039295196533, accuracy: 97.0 %\n",
      "Training round [77/200], qnn_train_step: [400/1000], loss: 0.04637300223112106, accuracy: 98.7 %\n",
      "Training round [77/200], qnn_train_step: [500/1000], loss: 0.04524940252304077, accuracy: 98.6 %\n",
      "Training round [77/200], qnn_train_step: [600/1000], loss: 0.051264725625514984, accuracy: 98.5 %\n",
      "Training round [77/200], qnn_train_step: [700/1000], loss: 0.0513894185423851, accuracy: 98.4 %\n",
      "Training round [77/200], qnn_train_step: [800/1000], loss: 0.0425613597035408, accuracy: 98.7 %\n",
      "Training round [77/200], qnn_train_step: [900/1000], loss: 0.0420900359749794, accuracy: 98.7 %\n",
      "Training round [77/200], qnn_train_step: [1000/1000], loss: 0.04102478176355362, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [78/200], Epoch [1/5], Step [20/47], Loss: 0.0678, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [78/200], Epoch [1/5], Step [40/47], Loss: 0.0932, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [78/200], Epoch [2/5], Step [20/47], Loss: 0.1752, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [78/200], Epoch [2/5], Step [40/47], Loss: 0.0872, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [3/5], Step [20/47], Loss: 0.0310, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [78/200], Epoch [3/5], Step [40/47], Loss: 0.1069, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [78/200], Epoch [4/5], Step [20/47], Loss: 0.0380, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [4/5], Step [40/47], Loss: 0.0910, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [78/200], Epoch [5/5], Step [20/47], Loss: 0.0201, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [78/200], Epoch [5/5], Step [40/47], Loss: 0.1497, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [78/200], qnn_train_step: [100/1000], loss: 0.05261828005313873, accuracy: 98.6 %\n",
      "Training round [78/200], qnn_train_step: [200/1000], loss: 0.26642313599586487, accuracy: 90.5 %\n",
      "Training round [78/200], qnn_train_step: [300/1000], loss: 0.13908621668815613, accuracy: 95.1 %\n",
      "Training round [78/200], qnn_train_step: [400/1000], loss: 0.04651263728737831, accuracy: 99.0 %\n",
      "Training round [78/200], qnn_train_step: [500/1000], loss: 0.04729308560490608, accuracy: 98.7 %\n",
      "Training round [78/200], qnn_train_step: [600/1000], loss: 0.04277367517352104, accuracy: 98.9 %\n",
      "Training round [78/200], qnn_train_step: [700/1000], loss: 0.045734893530607224, accuracy: 98.5 %\n",
      "Training round [78/200], qnn_train_step: [800/1000], loss: 0.04056953266263008, accuracy: 99.0 %\n",
      "Training round [78/200], qnn_train_step: [900/1000], loss: 0.038734279572963715, accuracy: 99.0 %\n",
      "Training round [78/200], qnn_train_step: [1000/1000], loss: 0.03862014785408974, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [79/200], Epoch [1/5], Step [20/47], Loss: 0.0721, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [1/5], Step [40/47], Loss: 0.0627, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [79/200], Epoch [2/5], Step [20/47], Loss: 0.0427, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [79/200], Epoch [2/5], Step [40/47], Loss: 0.0592, batch time: 0.08, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [3/5], Step [20/47], Loss: 0.1479, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [79/200], Epoch [3/5], Step [40/47], Loss: 0.0473, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [79/200], Epoch [4/5], Step [20/47], Loss: 0.0525, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [79/200], Epoch [4/5], Step [40/47], Loss: 0.1081, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [79/200], Epoch [5/5], Step [20/47], Loss: 0.1445, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [79/200], Epoch [5/5], Step [40/47], Loss: 0.0813, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [79/200], qnn_train_step: [100/1000], loss: 0.05857544019818306, accuracy: 98.1 %\n",
      "Training round [79/200], qnn_train_step: [200/1000], loss: 0.13436652719974518, accuracy: 95.0 %\n",
      "Training round [79/200], qnn_train_step: [300/1000], loss: 0.12653061747550964, accuracy: 95.8 %\n",
      "Training round [79/200], qnn_train_step: [400/1000], loss: 0.056741878390312195, accuracy: 98.3 %\n",
      "Training round [79/200], qnn_train_step: [500/1000], loss: 0.048889100551605225, accuracy: 98.6 %\n",
      "Training round [79/200], qnn_train_step: [600/1000], loss: 0.04603518918156624, accuracy: 98.7 %\n",
      "Training round [79/200], qnn_train_step: [700/1000], loss: 0.044002749025821686, accuracy: 99.1 %\n",
      "Training round [79/200], qnn_train_step: [800/1000], loss: 0.04698855057358742, accuracy: 99.0 %\n",
      "Training round [79/200], qnn_train_step: [900/1000], loss: 0.043372172862291336, accuracy: 99.2 %\n",
      "Training round [79/200], qnn_train_step: [1000/1000], loss: 0.04227777570486069, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [80/200], Epoch [1/5], Step [20/47], Loss: 0.0565, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [80/200], Epoch [1/5], Step [40/47], Loss: 0.1721, batch time: 0.10, accuracy:  92.97%\n",
      "Training round [80/200], Epoch [2/5], Step [20/47], Loss: 0.1029, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [80/200], Epoch [2/5], Step [40/47], Loss: 0.0587, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [3/5], Step [20/47], Loss: 0.2033, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [80/200], Epoch [3/5], Step [40/47], Loss: 0.0687, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [80/200], Epoch [4/5], Step [20/47], Loss: 0.0768, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [4/5], Step [40/47], Loss: 0.0819, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [80/200], Epoch [5/5], Step [20/47], Loss: 0.0293, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [80/200], Epoch [5/5], Step [40/47], Loss: 0.0490, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [80/200], qnn_train_step: [100/1000], loss: 0.06681819260120392, accuracy: 98.5 %\n",
      "Training round [80/200], qnn_train_step: [200/1000], loss: 0.55787593126297, accuracy: 79.4 %\n",
      "Training round [80/200], qnn_train_step: [300/1000], loss: 0.061020053923130035, accuracy: 98.5 %\n",
      "Training round [80/200], qnn_train_step: [400/1000], loss: 0.05827467143535614, accuracy: 98.6 %\n",
      "Training round [80/200], qnn_train_step: [500/1000], loss: 0.055901285260915756, accuracy: 98.7 %\n",
      "Training round [80/200], qnn_train_step: [600/1000], loss: 0.05372608080506325, accuracy: 99.0 %\n",
      "Training round [80/200], qnn_train_step: [700/1000], loss: 0.0566425696015358, accuracy: 98.8 %\n",
      "Training round [80/200], qnn_train_step: [800/1000], loss: 0.05165553465485573, accuracy: 99.1 %\n",
      "Training round [80/200], qnn_train_step: [900/1000], loss: 0.05238598957657814, accuracy: 99.1 %\n",
      "Training round [80/200], qnn_train_step: [1000/1000], loss: 0.0538596548140049, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [81/200], Epoch [1/5], Step [20/47], Loss: 0.0667, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [1/5], Step [40/47], Loss: 0.0333, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [2/5], Step [20/47], Loss: 0.0523, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [2/5], Step [40/47], Loss: 0.1007, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [81/200], Epoch [3/5], Step [20/47], Loss: 0.0695, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [3/5], Step [40/47], Loss: 0.0458, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [4/5], Step [20/47], Loss: 0.0379, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [81/200], Epoch [4/5], Step [40/47], Loss: 0.1256, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [5/5], Step [20/47], Loss: 0.0594, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [81/200], Epoch [5/5], Step [40/47], Loss: 0.0829, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [81/200], qnn_train_step: [100/1000], loss: 0.07593043148517609, accuracy: 97.3 %\n",
      "Training round [81/200], qnn_train_step: [200/1000], loss: 0.40771567821502686, accuracy: 86.7 %\n",
      "Training round [81/200], qnn_train_step: [300/1000], loss: 0.0686340406537056, accuracy: 97.9 %\n",
      "Training round [81/200], qnn_train_step: [400/1000], loss: 0.08503316342830658, accuracy: 96.9 %\n",
      "Training round [81/200], qnn_train_step: [500/1000], loss: 0.06052892282605171, accuracy: 97.9 %\n",
      "Training round [81/200], qnn_train_step: [600/1000], loss: 0.06138819456100464, accuracy: 97.6 %\n",
      "Training round [81/200], qnn_train_step: [700/1000], loss: 0.06025678664445877, accuracy: 98.1 %\n",
      "Training round [81/200], qnn_train_step: [800/1000], loss: 0.059017740190029144, accuracy: 98.1 %\n",
      "Training round [81/200], qnn_train_step: [900/1000], loss: 0.06548188626766205, accuracy: 98.1 %\n",
      "Training round [81/200], qnn_train_step: [1000/1000], loss: 0.05730853229761124, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [82/200], Epoch [1/5], Step [20/47], Loss: 0.0588, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [1/5], Step [40/47], Loss: 0.0357, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [82/200], Epoch [2/5], Step [20/47], Loss: 0.1552, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [2/5], Step [40/47], Loss: 0.0492, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [3/5], Step [20/47], Loss: 0.1081, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [82/200], Epoch [3/5], Step [40/47], Loss: 0.1144, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [4/5], Step [20/47], Loss: 0.1454, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [82/200], Epoch [4/5], Step [40/47], Loss: 0.2355, batch time: 0.11, accuracy:  92.19%\n",
      "Training round [82/200], Epoch [5/5], Step [20/47], Loss: 0.1733, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [82/200], Epoch [5/5], Step [40/47], Loss: 0.0281, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [82/200], qnn_train_step: [100/1000], loss: 0.06945765018463135, accuracy: 97.9 %\n",
      "Training round [82/200], qnn_train_step: [200/1000], loss: 0.06999297440052032, accuracy: 97.7 %\n",
      "Training round [82/200], qnn_train_step: [300/1000], loss: 0.06205422431230545, accuracy: 97.8 %\n",
      "Training round [82/200], qnn_train_step: [400/1000], loss: 0.055325236171483994, accuracy: 98.6 %\n",
      "Training round [82/200], qnn_train_step: [500/1000], loss: 0.05242319032549858, accuracy: 98.6 %\n",
      "Training round [82/200], qnn_train_step: [600/1000], loss: 0.052154749631881714, accuracy: 98.8 %\n",
      "Training round [82/200], qnn_train_step: [700/1000], loss: 0.057199329137802124, accuracy: 97.7 %\n",
      "Training round [82/200], qnn_train_step: [800/1000], loss: 0.05818244814872742, accuracy: 98.2 %\n",
      "Training round [82/200], qnn_train_step: [900/1000], loss: 0.04946110397577286, accuracy: 98.3 %\n",
      "Training round [82/200], qnn_train_step: [1000/1000], loss: 0.0681636780500412, accuracy: 97.4 %\n",
      "-----------------------\n",
      "Training round [83/200], Epoch [1/5], Step [20/47], Loss: 0.0767, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [83/200], Epoch [1/5], Step [40/47], Loss: 0.0445, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [2/5], Step [20/47], Loss: 0.0817, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [2/5], Step [40/47], Loss: 0.0947, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [3/5], Step [20/47], Loss: 0.0660, batch time: 0.06, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [3/5], Step [40/47], Loss: 0.1123, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [83/200], Epoch [4/5], Step [20/47], Loss: 0.0498, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [83/200], Epoch [4/5], Step [40/47], Loss: 0.0913, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], Epoch [5/5], Step [20/47], Loss: 0.0260, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [83/200], Epoch [5/5], Step [40/47], Loss: 0.0922, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [83/200], qnn_train_step: [100/1000], loss: 0.06835387647151947, accuracy: 98.1 %\n",
      "Training round [83/200], qnn_train_step: [200/1000], loss: 0.16400282084941864, accuracy: 93.1 %\n",
      "Training round [83/200], qnn_train_step: [300/1000], loss: 0.060577910393476486, accuracy: 98.5 %\n",
      "Training round [83/200], qnn_train_step: [400/1000], loss: 0.0594603531062603, accuracy: 98.3 %\n",
      "Training round [83/200], qnn_train_step: [500/1000], loss: 0.06010856479406357, accuracy: 98.1 %\n",
      "Training round [83/200], qnn_train_step: [600/1000], loss: 0.059479665011167526, accuracy: 98.1 %\n",
      "Training round [83/200], qnn_train_step: [700/1000], loss: 0.0529061034321785, accuracy: 98.6 %\n",
      "Training round [83/200], qnn_train_step: [800/1000], loss: 0.05081711336970329, accuracy: 98.7 %\n",
      "Training round [83/200], qnn_train_step: [900/1000], loss: 0.06055540218949318, accuracy: 98.0 %\n",
      "Training round [83/200], qnn_train_step: [1000/1000], loss: 0.057882413268089294, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [84/200], Epoch [1/5], Step [20/47], Loss: 0.0530, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [1/5], Step [40/47], Loss: 0.0738, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [2/5], Step [20/47], Loss: 0.1042, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [84/200], Epoch [2/5], Step [40/47], Loss: 0.1043, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [3/5], Step [20/47], Loss: 0.0358, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [3/5], Step [40/47], Loss: 0.0725, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [84/200], Epoch [4/5], Step [20/47], Loss: 0.0352, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [84/200], Epoch [4/5], Step [40/47], Loss: 0.0795, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [84/200], Epoch [5/5], Step [20/47], Loss: 0.0757, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [84/200], Epoch [5/5], Step [40/47], Loss: 0.1423, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [84/200], qnn_train_step: [100/1000], loss: 0.04988289996981621, accuracy: 98.7 %\n",
      "Training round [84/200], qnn_train_step: [200/1000], loss: 0.12042734771966934, accuracy: 95.5 %\n",
      "Training round [84/200], qnn_train_step: [300/1000], loss: 0.06926970928907394, accuracy: 97.7 %\n",
      "Training round [84/200], qnn_train_step: [400/1000], loss: 0.04369211196899414, accuracy: 98.6 %\n",
      "Training round [84/200], qnn_train_step: [500/1000], loss: 0.05617446079850197, accuracy: 98.0 %\n",
      "Training round [84/200], qnn_train_step: [600/1000], loss: 0.047420259565114975, accuracy: 98.5 %\n",
      "Training round [84/200], qnn_train_step: [700/1000], loss: 0.0498330295085907, accuracy: 98.4 %\n",
      "Training round [84/200], qnn_train_step: [800/1000], loss: 0.04424421489238739, accuracy: 98.8 %\n",
      "Training round [84/200], qnn_train_step: [900/1000], loss: 0.043936412781476974, accuracy: 98.8 %\n",
      "Training round [84/200], qnn_train_step: [1000/1000], loss: 0.04367634654045105, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [85/200], Epoch [1/5], Step [20/47], Loss: 0.0210, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [1/5], Step [40/47], Loss: 0.0662, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [2/5], Step [20/47], Loss: 0.1087, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [2/5], Step [40/47], Loss: 0.1256, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [3/5], Step [20/47], Loss: 0.0286, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [85/200], Epoch [3/5], Step [40/47], Loss: 0.0334, batch time: 0.08, accuracy:  100.00%\n",
      "Training round [85/200], Epoch [4/5], Step [20/47], Loss: 0.0559, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [4/5], Step [40/47], Loss: 0.1430, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [85/200], Epoch [5/5], Step [20/47], Loss: 0.0531, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [85/200], Epoch [5/5], Step [40/47], Loss: 0.0702, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [85/200], qnn_train_step: [100/1000], loss: 0.10022564977407455, accuracy: 97.5 %\n",
      "Training round [85/200], qnn_train_step: [200/1000], loss: 0.2779795229434967, accuracy: 90.8 %\n",
      "Training round [85/200], qnn_train_step: [300/1000], loss: 0.11447855085134506, accuracy: 96.5 %\n",
      "Training round [85/200], qnn_train_step: [400/1000], loss: 0.08060769736766815, accuracy: 97.7 %\n",
      "Training round [85/200], qnn_train_step: [500/1000], loss: 0.07160794734954834, accuracy: 97.8 %\n",
      "Training round [85/200], qnn_train_step: [600/1000], loss: 0.07071942090988159, accuracy: 97.5 %\n",
      "Training round [85/200], qnn_train_step: [700/1000], loss: 0.0762658342719078, accuracy: 97.4 %\n",
      "Training round [85/200], qnn_train_step: [800/1000], loss: 0.07057241350412369, accuracy: 98.0 %\n",
      "Training round [85/200], qnn_train_step: [900/1000], loss: 0.0679253488779068, accuracy: 97.9 %\n",
      "Training round [85/200], qnn_train_step: [1000/1000], loss: 0.0697721391916275, accuracy: 97.7 %\n",
      "-----------------------\n",
      "Training round [86/200], Epoch [1/5], Step [20/47], Loss: 0.0374, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [86/200], Epoch [1/5], Step [40/47], Loss: 0.1512, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [86/200], Epoch [2/5], Step [20/47], Loss: 0.0726, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [2/5], Step [40/47], Loss: 0.0977, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [86/200], Epoch [3/5], Step [20/47], Loss: 0.1401, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [86/200], Epoch [3/5], Step [40/47], Loss: 0.0310, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [86/200], Epoch [4/5], Step [20/47], Loss: 0.0278, batch time: 0.27, accuracy:  99.22%\n",
      "Training round [86/200], Epoch [4/5], Step [40/47], Loss: 0.1083, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [86/200], Epoch [5/5], Step [20/47], Loss: 0.0550, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [86/200], Epoch [5/5], Step [40/47], Loss: 0.0565, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [86/200], qnn_train_step: [100/1000], loss: 0.05022766813635826, accuracy: 98.4 %\n",
      "Training round [86/200], qnn_train_step: [200/1000], loss: 0.375569611787796, accuracy: 89.1 %\n",
      "Training round [86/200], qnn_train_step: [300/1000], loss: 0.04448039084672928, accuracy: 98.9 %\n",
      "Training round [86/200], qnn_train_step: [400/1000], loss: 0.04160059615969658, accuracy: 98.8 %\n",
      "Training round [86/200], qnn_train_step: [500/1000], loss: 0.0406087189912796, accuracy: 98.7 %\n",
      "Training round [86/200], qnn_train_step: [600/1000], loss: 0.04030316695570946, accuracy: 98.9 %\n",
      "Training round [86/200], qnn_train_step: [700/1000], loss: 0.0392586775124073, accuracy: 98.7 %\n",
      "Training round [86/200], qnn_train_step: [800/1000], loss: 0.03895644471049309, accuracy: 98.6 %\n",
      "Training round [86/200], qnn_train_step: [900/1000], loss: 0.03847212716937065, accuracy: 98.8 %\n",
      "Training round [86/200], qnn_train_step: [1000/1000], loss: 0.03820927068591118, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [87/200], Epoch [1/5], Step [20/47], Loss: 0.0793, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [1/5], Step [40/47], Loss: 0.0910, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [2/5], Step [20/47], Loss: 0.0395, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [87/200], Epoch [2/5], Step [40/47], Loss: 0.1667, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [87/200], Epoch [3/5], Step [20/47], Loss: 0.0617, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [3/5], Step [40/47], Loss: 0.0978, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [87/200], Epoch [4/5], Step [20/47], Loss: 0.0175, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [87/200], Epoch [4/5], Step [40/47], Loss: 0.0299, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [87/200], Epoch [5/5], Step [20/47], Loss: 0.0644, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [87/200], Epoch [5/5], Step [40/47], Loss: 0.0653, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [87/200], qnn_train_step: [100/1000], loss: 0.05089278146624565, accuracy: 98.9 %\n",
      "Training round [87/200], qnn_train_step: [200/1000], loss: 0.21868345141410828, accuracy: 93.8 %\n",
      "Training round [87/200], qnn_train_step: [300/1000], loss: 0.05978592857718468, accuracy: 98.4 %\n",
      "Training round [87/200], qnn_train_step: [400/1000], loss: 0.0468413308262825, accuracy: 99.0 %\n",
      "Training round [87/200], qnn_train_step: [500/1000], loss: 0.045848630368709564, accuracy: 99.1 %\n",
      "Training round [87/200], qnn_train_step: [600/1000], loss: 0.04588054120540619, accuracy: 99.0 %\n",
      "Training round [87/200], qnn_train_step: [700/1000], loss: 0.0462874174118042, accuracy: 98.8 %\n",
      "Training round [87/200], qnn_train_step: [800/1000], loss: 0.047782547771930695, accuracy: 98.9 %\n",
      "Training round [87/200], qnn_train_step: [900/1000], loss: 0.04380545765161514, accuracy: 99.1 %\n",
      "Training round [87/200], qnn_train_step: [1000/1000], loss: 0.04326465353369713, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [88/200], Epoch [1/5], Step [20/47], Loss: 0.0840, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [88/200], Epoch [1/5], Step [40/47], Loss: 0.0629, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [88/200], Epoch [2/5], Step [20/47], Loss: 0.0981, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [2/5], Step [40/47], Loss: 0.0529, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [88/200], Epoch [3/5], Step [20/47], Loss: 0.0637, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [88/200], Epoch [3/5], Step [40/47], Loss: 0.0992, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [88/200], Epoch [4/5], Step [20/47], Loss: 0.1774, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [88/200], Epoch [4/5], Step [40/47], Loss: 0.0358, batch time: 0.08, accuracy:  99.22%\n",
      "Training round [88/200], Epoch [5/5], Step [20/47], Loss: 0.0127, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [88/200], Epoch [5/5], Step [40/47], Loss: 0.0267, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [88/200], qnn_train_step: [100/1000], loss: 0.04987413063645363, accuracy: 98.8 %\n",
      "Training round [88/200], qnn_train_step: [200/1000], loss: 0.04883027821779251, accuracy: 98.5 %\n",
      "Training round [88/200], qnn_train_step: [300/1000], loss: 0.04501985386013985, accuracy: 98.6 %\n",
      "Training round [88/200], qnn_train_step: [400/1000], loss: 0.043268945068120956, accuracy: 98.5 %\n",
      "Training round [88/200], qnn_train_step: [500/1000], loss: 0.038565389811992645, accuracy: 99.1 %\n",
      "Training round [88/200], qnn_train_step: [600/1000], loss: 0.04004715383052826, accuracy: 98.9 %\n",
      "Training round [88/200], qnn_train_step: [700/1000], loss: 0.05139909312129021, accuracy: 98.3 %\n",
      "Training round [88/200], qnn_train_step: [800/1000], loss: 0.034973111003637314, accuracy: 99.0 %\n",
      "Training round [88/200], qnn_train_step: [900/1000], loss: 0.034224558621644974, accuracy: 99.2 %\n",
      "Training round [88/200], qnn_train_step: [1000/1000], loss: 0.034068599343299866, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [89/200], Epoch [1/5], Step [20/47], Loss: 0.1184, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [89/200], Epoch [1/5], Step [40/47], Loss: 0.0666, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [2/5], Step [20/47], Loss: 0.0328, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [2/5], Step [40/47], Loss: 0.0531, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [89/200], Epoch [3/5], Step [20/47], Loss: 0.0906, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [89/200], Epoch [3/5], Step [40/47], Loss: 0.0571, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [89/200], Epoch [4/5], Step [20/47], Loss: 0.0408, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [89/200], Epoch [4/5], Step [40/47], Loss: 0.0829, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [89/200], Epoch [5/5], Step [20/47], Loss: 0.0456, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [89/200], Epoch [5/5], Step [40/47], Loss: 0.1613, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [89/200], qnn_train_step: [100/1000], loss: 0.060702838003635406, accuracy: 97.5 %\n",
      "Training round [89/200], qnn_train_step: [200/1000], loss: 0.05912883207201958, accuracy: 97.8 %\n",
      "Training round [89/200], qnn_train_step: [300/1000], loss: 0.08196672052145004, accuracy: 96.6 %\n",
      "Training round [89/200], qnn_train_step: [400/1000], loss: 0.05105260759592056, accuracy: 98.0 %\n",
      "Training round [89/200], qnn_train_step: [500/1000], loss: 0.08312628418207169, accuracy: 96.8 %\n",
      "Training round [89/200], qnn_train_step: [600/1000], loss: 0.04518400877714157, accuracy: 98.2 %\n",
      "Training round [89/200], qnn_train_step: [700/1000], loss: 0.04327267408370972, accuracy: 98.3 %\n",
      "Training round [89/200], qnn_train_step: [800/1000], loss: 0.040097542107105255, accuracy: 98.6 %\n",
      "Training round [89/200], qnn_train_step: [900/1000], loss: 0.04785143956542015, accuracy: 98.2 %\n",
      "Training round [89/200], qnn_train_step: [1000/1000], loss: 0.036525122821331024, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [90/200], Epoch [1/5], Step [20/47], Loss: 0.0362, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [1/5], Step [40/47], Loss: 0.0587, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [90/200], Epoch [2/5], Step [20/47], Loss: 0.1071, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [90/200], Epoch [2/5], Step [40/47], Loss: 0.0702, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [3/5], Step [20/47], Loss: 0.1010, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [3/5], Step [40/47], Loss: 0.0314, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [90/200], Epoch [4/5], Step [20/47], Loss: 0.1965, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [4/5], Step [40/47], Loss: 0.0269, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [90/200], Epoch [5/5], Step [20/47], Loss: 0.0738, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [90/200], Epoch [5/5], Step [40/47], Loss: 0.0730, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [90/200], qnn_train_step: [100/1000], loss: 0.05454256013035774, accuracy: 98.8 %\n",
      "Training round [90/200], qnn_train_step: [200/1000], loss: 0.8839676976203918, accuracy: 84.2 %\n",
      "Training round [90/200], qnn_train_step: [300/1000], loss: 0.0514676459133625, accuracy: 98.3 %\n",
      "Training round [90/200], qnn_train_step: [400/1000], loss: 0.04979217052459717, accuracy: 98.9 %\n",
      "Training round [90/200], qnn_train_step: [500/1000], loss: 0.055323995649814606, accuracy: 98.7 %\n",
      "Training round [90/200], qnn_train_step: [600/1000], loss: 0.04914962500333786, accuracy: 98.9 %\n",
      "Training round [90/200], qnn_train_step: [700/1000], loss: 0.04630862921476364, accuracy: 98.8 %\n",
      "Training round [90/200], qnn_train_step: [800/1000], loss: 0.04123314842581749, accuracy: 98.9 %\n",
      "Training round [90/200], qnn_train_step: [900/1000], loss: 0.04019680991768837, accuracy: 99.3 %\n",
      "Training round [90/200], qnn_train_step: [1000/1000], loss: 0.03948245197534561, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [91/200], Epoch [1/5], Step [20/47], Loss: 0.0253, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [91/200], Epoch [1/5], Step [40/47], Loss: 0.0604, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [2/5], Step [20/47], Loss: 0.1292, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [91/200], Epoch [2/5], Step [40/47], Loss: 0.1101, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [91/200], Epoch [3/5], Step [20/47], Loss: 0.0486, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [91/200], Epoch [3/5], Step [40/47], Loss: 0.0357, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [91/200], Epoch [4/5], Step [20/47], Loss: 0.1351, batch time: 0.06, accuracy:  94.53%\n",
      "Training round [91/200], Epoch [4/5], Step [40/47], Loss: 0.0217, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [91/200], Epoch [5/5], Step [20/47], Loss: 0.1189, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [91/200], Epoch [5/5], Step [40/47], Loss: 0.0166, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [91/200], qnn_train_step: [100/1000], loss: 0.06808371841907501, accuracy: 98.2 %\n",
      "Training round [91/200], qnn_train_step: [200/1000], loss: 0.06779074668884277, accuracy: 98.4 %\n",
      "Training round [91/200], qnn_train_step: [300/1000], loss: 0.06690138578414917, accuracy: 98.4 %\n",
      "Training round [91/200], qnn_train_step: [400/1000], loss: 0.06091843917965889, accuracy: 98.8 %\n",
      "Training round [91/200], qnn_train_step: [500/1000], loss: 0.0677051767706871, accuracy: 98.4 %\n",
      "Training round [91/200], qnn_train_step: [600/1000], loss: 0.057487405836582184, accuracy: 98.8 %\n",
      "Training round [91/200], qnn_train_step: [700/1000], loss: 0.05537257716059685, accuracy: 98.8 %\n",
      "Training round [91/200], qnn_train_step: [800/1000], loss: 0.05875705927610397, accuracy: 98.5 %\n",
      "Training round [91/200], qnn_train_step: [900/1000], loss: 0.05796708166599274, accuracy: 98.9 %\n",
      "Training round [91/200], qnn_train_step: [1000/1000], loss: 0.05749617889523506, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [92/200], Epoch [1/5], Step [20/47], Loss: 0.0606, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [1/5], Step [40/47], Loss: 0.1047, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [2/5], Step [20/47], Loss: 0.0650, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [2/5], Step [40/47], Loss: 0.0389, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [3/5], Step [20/47], Loss: 0.1069, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [3/5], Step [40/47], Loss: 0.0645, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [4/5], Step [20/47], Loss: 0.0961, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [92/200], Epoch [4/5], Step [40/47], Loss: 0.1188, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [92/200], Epoch [5/5], Step [20/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], Epoch [5/5], Step [40/47], Loss: 0.0806, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [92/200], qnn_train_step: [100/1000], loss: 0.07624422758817673, accuracy: 97.3 %\n",
      "Training round [92/200], qnn_train_step: [200/1000], loss: 0.07828313857316971, accuracy: 97.4 %\n",
      "Training round [92/200], qnn_train_step: [300/1000], loss: 0.07690076529979706, accuracy: 97.4 %\n",
      "Training round [92/200], qnn_train_step: [400/1000], loss: 0.06202542036771774, accuracy: 98.4 %\n",
      "Training round [92/200], qnn_train_step: [500/1000], loss: 0.06207133084535599, accuracy: 98.5 %\n",
      "Training round [92/200], qnn_train_step: [600/1000], loss: 0.06403444707393646, accuracy: 98.4 %\n",
      "Training round [92/200], qnn_train_step: [700/1000], loss: 0.06157350167632103, accuracy: 98.2 %\n",
      "Training round [92/200], qnn_train_step: [800/1000], loss: 0.061170630156993866, accuracy: 98.4 %\n",
      "Training round [92/200], qnn_train_step: [900/1000], loss: 0.0686139166355133, accuracy: 97.9 %\n",
      "Training round [92/200], qnn_train_step: [1000/1000], loss: 0.0592186339199543, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [93/200], Epoch [1/5], Step [20/47], Loss: 0.1035, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [93/200], Epoch [1/5], Step [40/47], Loss: 0.1088, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [93/200], Epoch [2/5], Step [20/47], Loss: 0.0690, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [2/5], Step [40/47], Loss: 0.0354, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [3/5], Step [20/47], Loss: 0.0507, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [93/200], Epoch [3/5], Step [40/47], Loss: 0.0182, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [93/200], Epoch [4/5], Step [20/47], Loss: 0.0181, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [4/5], Step [40/47], Loss: 0.0352, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [93/200], Epoch [5/5], Step [20/47], Loss: 0.0416, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [93/200], Epoch [5/5], Step [40/47], Loss: 0.0229, batch time: 0.08, accuracy:  100.00%\n",
      "Training round [93/200], qnn_train_step: [100/1000], loss: 0.052866511046886444, accuracy: 98.0 %\n",
      "Training round [93/200], qnn_train_step: [200/1000], loss: 0.2347346842288971, accuracy: 93.0 %\n",
      "Training round [93/200], qnn_train_step: [300/1000], loss: 0.04765477403998375, accuracy: 98.3 %\n",
      "Training round [93/200], qnn_train_step: [400/1000], loss: 0.04508915916085243, accuracy: 98.7 %\n",
      "Training round [93/200], qnn_train_step: [500/1000], loss: 0.044175878167152405, accuracy: 98.5 %\n",
      "Training round [93/200], qnn_train_step: [600/1000], loss: 0.04257393255829811, accuracy: 98.7 %\n",
      "Training round [93/200], qnn_train_step: [700/1000], loss: 0.04488390311598778, accuracy: 98.5 %\n",
      "Training round [93/200], qnn_train_step: [800/1000], loss: 0.042954184114933014, accuracy: 98.6 %\n",
      "Training round [93/200], qnn_train_step: [900/1000], loss: 0.04421551898121834, accuracy: 98.6 %\n",
      "Training round [93/200], qnn_train_step: [1000/1000], loss: 0.0783504918217659, accuracy: 97.3 %\n",
      "-----------------------\n",
      "Training round [94/200], Epoch [1/5], Step [20/47], Loss: 0.0398, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [1/5], Step [40/47], Loss: 0.1007, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [94/200], Epoch [2/5], Step [20/47], Loss: 0.0932, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [2/5], Step [40/47], Loss: 0.1641, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [3/5], Step [20/47], Loss: 0.0804, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [3/5], Step [40/47], Loss: 0.0535, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [94/200], Epoch [4/5], Step [20/47], Loss: 0.0270, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [94/200], Epoch [4/5], Step [40/47], Loss: 0.0754, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [94/200], Epoch [5/5], Step [20/47], Loss: 0.0839, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [94/200], Epoch [5/5], Step [40/47], Loss: 0.0369, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [94/200], qnn_train_step: [100/1000], loss: 0.04579445719718933, accuracy: 98.2 %\n",
      "Training round [94/200], qnn_train_step: [200/1000], loss: 0.28489091992378235, accuracy: 91.2 %\n",
      "Training round [94/200], qnn_train_step: [300/1000], loss: 0.045696210116147995, accuracy: 98.4 %\n",
      "Training round [94/200], qnn_train_step: [400/1000], loss: 0.03895643725991249, accuracy: 98.4 %\n",
      "Training round [94/200], qnn_train_step: [500/1000], loss: 0.041032057255506516, accuracy: 98.5 %\n",
      "Training round [94/200], qnn_train_step: [600/1000], loss: 0.041594069451093674, accuracy: 98.6 %\n",
      "Training round [94/200], qnn_train_step: [700/1000], loss: 0.03670426830649376, accuracy: 98.9 %\n",
      "Training round [94/200], qnn_train_step: [800/1000], loss: 0.05441226065158844, accuracy: 98.0 %\n",
      "Training round [94/200], qnn_train_step: [900/1000], loss: 0.037039149552583694, accuracy: 98.9 %\n",
      "Training round [94/200], qnn_train_step: [1000/1000], loss: 0.033080361783504486, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [95/200], Epoch [1/5], Step [20/47], Loss: 0.1273, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [1/5], Step [40/47], Loss: 0.1240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [95/200], Epoch [2/5], Step [20/47], Loss: 0.1535, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [2/5], Step [40/47], Loss: 0.1288, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [3/5], Step [20/47], Loss: 0.0544, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [95/200], Epoch [3/5], Step [40/47], Loss: 0.0899, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [95/200], Epoch [4/5], Step [20/47], Loss: 0.0237, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [95/200], Epoch [4/5], Step [40/47], Loss: 0.0638, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [95/200], Epoch [5/5], Step [20/47], Loss: 0.1275, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [95/200], Epoch [5/5], Step [40/47], Loss: 0.1066, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [95/200], qnn_train_step: [100/1000], loss: 0.09041103720664978, accuracy: 96.8 %\n",
      "Training round [95/200], qnn_train_step: [200/1000], loss: 0.4999191164970398, accuracy: 87.7 %\n",
      "Training round [95/200], qnn_train_step: [300/1000], loss: 0.10795146226882935, accuracy: 96.1 %\n",
      "Training round [95/200], qnn_train_step: [400/1000], loss: 0.07351341843605042, accuracy: 97.2 %\n",
      "Training round [95/200], qnn_train_step: [500/1000], loss: 0.07122069597244263, accuracy: 97.3 %\n",
      "Training round [95/200], qnn_train_step: [600/1000], loss: 0.06388392299413681, accuracy: 97.9 %\n",
      "Training round [95/200], qnn_train_step: [700/1000], loss: 0.06326038390398026, accuracy: 97.9 %\n",
      "Training round [95/200], qnn_train_step: [800/1000], loss: 0.061943020671606064, accuracy: 97.9 %\n",
      "Training round [95/200], qnn_train_step: [900/1000], loss: 0.059687886387109756, accuracy: 98.3 %\n",
      "Training round [95/200], qnn_train_step: [1000/1000], loss: 0.06310153752565384, accuracy: 98.0 %\n",
      "-----------------------\n",
      "Training round [96/200], Epoch [1/5], Step [20/47], Loss: 0.0653, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [96/200], Epoch [1/5], Step [40/47], Loss: 0.1038, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [96/200], Epoch [2/5], Step [20/47], Loss: 0.0561, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [2/5], Step [40/47], Loss: 0.0356, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [96/200], Epoch [3/5], Step [20/47], Loss: 0.1548, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [96/200], Epoch [3/5], Step [40/47], Loss: 0.0480, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [4/5], Step [20/47], Loss: 0.1010, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [96/200], Epoch [4/5], Step [40/47], Loss: 0.0924, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [96/200], Epoch [5/5], Step [20/47], Loss: 0.0725, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [96/200], Epoch [5/5], Step [40/47], Loss: 0.0404, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [96/200], qnn_train_step: [100/1000], loss: 0.050052691251039505, accuracy: 98.2 %\n",
      "Training round [96/200], qnn_train_step: [200/1000], loss: 0.23204714059829712, accuracy: 92.5 %\n",
      "Training round [96/200], qnn_train_step: [300/1000], loss: 0.3414672315120697, accuracy: 92.8 %\n",
      "Training round [96/200], qnn_train_step: [400/1000], loss: 0.045553743839263916, accuracy: 98.7 %\n",
      "Training round [96/200], qnn_train_step: [500/1000], loss: 0.04237563908100128, accuracy: 98.8 %\n",
      "Training round [96/200], qnn_train_step: [600/1000], loss: 0.04209427163004875, accuracy: 98.7 %\n",
      "Training round [96/200], qnn_train_step: [700/1000], loss: 0.04080897942185402, accuracy: 98.8 %\n",
      "Training round [96/200], qnn_train_step: [800/1000], loss: 0.038788244128227234, accuracy: 98.8 %\n",
      "Training round [96/200], qnn_train_step: [900/1000], loss: 0.043571893125772476, accuracy: 98.5 %\n",
      "Training round [96/200], qnn_train_step: [1000/1000], loss: 0.040936317294836044, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [97/200], Epoch [1/5], Step [20/47], Loss: 0.0202, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [1/5], Step [40/47], Loss: 0.0491, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [97/200], Epoch [2/5], Step [20/47], Loss: 0.1241, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [2/5], Step [40/47], Loss: 0.0858, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [97/200], Epoch [3/5], Step [20/47], Loss: 0.0739, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [97/200], Epoch [3/5], Step [40/47], Loss: 0.0476, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [97/200], Epoch [4/5], Step [20/47], Loss: 0.1331, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [4/5], Step [40/47], Loss: 0.0458, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [5/5], Step [20/47], Loss: 0.0471, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [97/200], Epoch [5/5], Step [40/47], Loss: 0.1176, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [97/200], qnn_train_step: [100/1000], loss: 0.048631418496370316, accuracy: 98.9 %\n",
      "Training round [97/200], qnn_train_step: [200/1000], loss: 0.05051035434007645, accuracy: 99.0 %\n",
      "Training round [97/200], qnn_train_step: [300/1000], loss: 0.045879464596509933, accuracy: 98.9 %\n",
      "Training round [97/200], qnn_train_step: [400/1000], loss: 0.04529380053281784, accuracy: 98.8 %\n",
      "Training round [97/200], qnn_train_step: [500/1000], loss: 0.04991351068019867, accuracy: 99.1 %\n",
      "Training round [97/200], qnn_train_step: [600/1000], loss: 0.04507109522819519, accuracy: 99.2 %\n",
      "Training round [97/200], qnn_train_step: [700/1000], loss: 0.0434420146048069, accuracy: 98.9 %\n",
      "Training round [97/200], qnn_train_step: [800/1000], loss: 0.04442935809493065, accuracy: 99.4 %\n",
      "Training round [97/200], qnn_train_step: [900/1000], loss: 0.04476706311106682, accuracy: 98.7 %\n",
      "Training round [97/200], qnn_train_step: [1000/1000], loss: 0.043344706296920776, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [98/200], Epoch [1/5], Step [20/47], Loss: 0.0344, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [1/5], Step [40/47], Loss: 0.1504, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [2/5], Step [20/47], Loss: 0.1747, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [98/200], Epoch [2/5], Step [40/47], Loss: 0.0425, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [98/200], Epoch [3/5], Step [20/47], Loss: 0.0955, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [98/200], Epoch [3/5], Step [40/47], Loss: 0.0213, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [4/5], Step [20/47], Loss: 0.0373, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [4/5], Step [40/47], Loss: 0.0936, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [98/200], Epoch [5/5], Step [20/47], Loss: 0.0337, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [98/200], Epoch [5/5], Step [40/47], Loss: 0.0341, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [98/200], qnn_train_step: [100/1000], loss: 0.06881063431501389, accuracy: 98.0 %\n",
      "Training round [98/200], qnn_train_step: [200/1000], loss: 0.2827624976634979, accuracy: 90.7 %\n",
      "Training round [98/200], qnn_train_step: [300/1000], loss: 0.0676635205745697, accuracy: 97.8 %\n",
      "Training round [98/200], qnn_train_step: [400/1000], loss: 0.06470277905464172, accuracy: 98.2 %\n",
      "Training round [98/200], qnn_train_step: [500/1000], loss: 0.06416294723749161, accuracy: 98.2 %\n",
      "Training round [98/200], qnn_train_step: [600/1000], loss: 0.06214648857712746, accuracy: 98.3 %\n",
      "Training round [98/200], qnn_train_step: [700/1000], loss: 0.06139353662729263, accuracy: 98.4 %\n",
      "Training round [98/200], qnn_train_step: [800/1000], loss: 0.06403543800115585, accuracy: 98.5 %\n",
      "Training round [98/200], qnn_train_step: [900/1000], loss: 0.06317410618066788, accuracy: 98.4 %\n",
      "Training round [98/200], qnn_train_step: [1000/1000], loss: 0.06088907644152641, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [99/200], Epoch [1/5], Step [20/47], Loss: 0.0484, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [1/5], Step [40/47], Loss: 0.0996, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [2/5], Step [20/47], Loss: 0.2130, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [99/200], Epoch [2/5], Step [40/47], Loss: 0.0631, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [3/5], Step [20/47], Loss: 0.0797, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [99/200], Epoch [3/5], Step [40/47], Loss: 0.0927, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [99/200], Epoch [4/5], Step [20/47], Loss: 0.0480, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [99/200], Epoch [4/5], Step [40/47], Loss: 0.0312, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [5/5], Step [20/47], Loss: 0.0231, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [99/200], Epoch [5/5], Step [40/47], Loss: 0.0428, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [99/200], qnn_train_step: [100/1000], loss: 0.034275900572538376, accuracy: 99.2 %\n",
      "Training round [99/200], qnn_train_step: [200/1000], loss: 0.05706864967942238, accuracy: 97.7 %\n",
      "Training round [99/200], qnn_train_step: [300/1000], loss: 0.31853389739990234, accuracy: 89.5 %\n",
      "Training round [99/200], qnn_train_step: [400/1000], loss: 0.035010743886232376, accuracy: 99.2 %\n",
      "Training round [99/200], qnn_train_step: [500/1000], loss: 0.03409694880247116, accuracy: 99.1 %\n",
      "Training round [99/200], qnn_train_step: [600/1000], loss: 0.03540388494729996, accuracy: 99.1 %\n",
      "Training round [99/200], qnn_train_step: [700/1000], loss: 0.03054124116897583, accuracy: 99.5 %\n",
      "Training round [99/200], qnn_train_step: [800/1000], loss: 0.03246970847249031, accuracy: 99.2 %\n",
      "Training round [99/200], qnn_train_step: [900/1000], loss: 0.0547572523355484, accuracy: 98.3 %\n",
      "Training round [99/200], qnn_train_step: [1000/1000], loss: 0.02855965867638588, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [100/200], Epoch [1/5], Step [20/47], Loss: 0.0707, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [1/5], Step [40/47], Loss: 0.0785, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [2/5], Step [20/47], Loss: 0.0912, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [2/5], Step [40/47], Loss: 0.1025, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [100/200], Epoch [3/5], Step [20/47], Loss: 0.0853, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [3/5], Step [40/47], Loss: 0.0647, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [4/5], Step [20/47], Loss: 0.0930, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [4/5], Step [40/47], Loss: 0.0678, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [100/200], Epoch [5/5], Step [20/47], Loss: 0.0768, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [100/200], Epoch [5/5], Step [40/47], Loss: 0.0597, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [100/200], qnn_train_step: [100/1000], loss: 0.06944708526134491, accuracy: 98.1 %\n",
      "Training round [100/200], qnn_train_step: [200/1000], loss: 0.11969034373760223, accuracy: 96.9 %\n",
      "Training round [100/200], qnn_train_step: [300/1000], loss: 0.11295104771852493, accuracy: 96.8 %\n",
      "Training round [100/200], qnn_train_step: [400/1000], loss: 0.06301575154066086, accuracy: 98.4 %\n",
      "Training round [100/200], qnn_train_step: [500/1000], loss: 0.057998836040496826, accuracy: 98.7 %\n",
      "Training round [100/200], qnn_train_step: [600/1000], loss: 0.05964008346199989, accuracy: 98.6 %\n",
      "Training round [100/200], qnn_train_step: [700/1000], loss: 0.05950789898633957, accuracy: 98.9 %\n",
      "Training round [100/200], qnn_train_step: [800/1000], loss: 0.05587463825941086, accuracy: 98.9 %\n",
      "Training round [100/200], qnn_train_step: [900/1000], loss: 0.05924064666032791, accuracy: 98.7 %\n",
      "Training round [100/200], qnn_train_step: [1000/1000], loss: 0.05504324659705162, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [101/200], Epoch [1/5], Step [20/47], Loss: 0.0266, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [101/200], Epoch [1/5], Step [40/47], Loss: 0.0453, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [101/200], Epoch [2/5], Step [20/47], Loss: 0.2052, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [101/200], Epoch [2/5], Step [40/47], Loss: 0.1103, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [101/200], Epoch [3/5], Step [20/47], Loss: 0.0855, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [101/200], Epoch [3/5], Step [40/47], Loss: 0.0596, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [101/200], Epoch [4/5], Step [20/47], Loss: 0.0295, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [101/200], Epoch [4/5], Step [40/47], Loss: 0.1181, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [101/200], Epoch [5/5], Step [20/47], Loss: 0.0897, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [101/200], Epoch [5/5], Step [40/47], Loss: 0.0352, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [101/200], qnn_train_step: [100/1000], loss: 0.045260313898324966, accuracy: 98.7 %\n",
      "Training round [101/200], qnn_train_step: [200/1000], loss: 0.2102806568145752, accuracy: 92.6 %\n",
      "Training round [101/200], qnn_train_step: [300/1000], loss: 0.0870039090514183, accuracy: 97.0 %\n",
      "Training round [101/200], qnn_train_step: [400/1000], loss: 0.04068576917052269, accuracy: 98.5 %\n",
      "Training round [101/200], qnn_train_step: [500/1000], loss: 0.041513752192258835, accuracy: 98.4 %\n",
      "Training round [101/200], qnn_train_step: [600/1000], loss: 0.06094629317522049, accuracy: 97.5 %\n",
      "Training round [101/200], qnn_train_step: [700/1000], loss: 0.040108487010002136, accuracy: 98.2 %\n",
      "Training round [101/200], qnn_train_step: [800/1000], loss: 0.03717699646949768, accuracy: 98.6 %\n",
      "Training round [101/200], qnn_train_step: [900/1000], loss: 0.03894957900047302, accuracy: 98.6 %\n",
      "Training round [101/200], qnn_train_step: [1000/1000], loss: 0.03995783254504204, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [102/200], Epoch [1/5], Step [20/47], Loss: 0.0275, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [102/200], Epoch [1/5], Step [40/47], Loss: 0.0707, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [2/5], Step [20/47], Loss: 0.0354, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [2/5], Step [40/47], Loss: 0.0686, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [3/5], Step [20/47], Loss: 0.0614, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [3/5], Step [40/47], Loss: 0.0572, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [102/200], Epoch [4/5], Step [20/47], Loss: 0.1253, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [102/200], Epoch [4/5], Step [40/47], Loss: 0.0947, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [102/200], Epoch [5/5], Step [20/47], Loss: 0.0598, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [102/200], Epoch [5/5], Step [40/47], Loss: 0.0344, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [102/200], qnn_train_step: [100/1000], loss: 0.04546315595507622, accuracy: 98.8 %\n",
      "Training round [102/200], qnn_train_step: [200/1000], loss: 0.23878508806228638, accuracy: 91.2 %\n",
      "Training round [102/200], qnn_train_step: [300/1000], loss: 0.04689120501279831, accuracy: 98.8 %\n",
      "Training round [102/200], qnn_train_step: [400/1000], loss: 0.039809875190258026, accuracy: 98.9 %\n",
      "Training round [102/200], qnn_train_step: [500/1000], loss: 0.04069892317056656, accuracy: 98.7 %\n",
      "Training round [102/200], qnn_train_step: [600/1000], loss: 0.0399656780064106, accuracy: 99.2 %\n",
      "Training round [102/200], qnn_train_step: [700/1000], loss: 0.043088171631097794, accuracy: 99.0 %\n",
      "Training round [102/200], qnn_train_step: [800/1000], loss: 0.05483042821288109, accuracy: 98.8 %\n",
      "Training round [102/200], qnn_train_step: [900/1000], loss: 0.03771169111132622, accuracy: 99.3 %\n",
      "Training round [102/200], qnn_train_step: [1000/1000], loss: 0.04684055224061012, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [103/200], Epoch [1/5], Step [20/47], Loss: 0.0158, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [103/200], Epoch [1/5], Step [40/47], Loss: 0.1133, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [2/5], Step [20/47], Loss: 0.0119, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [103/200], Epoch [2/5], Step [40/47], Loss: 0.0307, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [3/5], Step [20/47], Loss: 0.0550, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], Epoch [3/5], Step [40/47], Loss: 0.0529, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [103/200], Epoch [4/5], Step [20/47], Loss: 0.0426, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [103/200], Epoch [4/5], Step [40/47], Loss: 0.0553, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [103/200], Epoch [5/5], Step [20/47], Loss: 0.0082, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [103/200], Epoch [5/5], Step [40/47], Loss: 0.1051, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [103/200], qnn_train_step: [100/1000], loss: 0.049386221915483475, accuracy: 98.7 %\n",
      "Training round [103/200], qnn_train_step: [200/1000], loss: 0.17890949547290802, accuracy: 94.0 %\n",
      "Training round [103/200], qnn_train_step: [300/1000], loss: 0.04884374886751175, accuracy: 98.5 %\n",
      "Training round [103/200], qnn_train_step: [400/1000], loss: 0.046511419117450714, accuracy: 98.9 %\n",
      "Training round [103/200], qnn_train_step: [500/1000], loss: 0.04459992051124573, accuracy: 98.5 %\n",
      "Training round [103/200], qnn_train_step: [600/1000], loss: 0.04450811818242073, accuracy: 98.7 %\n",
      "Training round [103/200], qnn_train_step: [700/1000], loss: 0.041137102991342545, accuracy: 98.5 %\n",
      "Training round [103/200], qnn_train_step: [800/1000], loss: 0.04512942582368851, accuracy: 98.2 %\n",
      "Training round [103/200], qnn_train_step: [900/1000], loss: 0.044362593442201614, accuracy: 98.7 %\n",
      "Training round [103/200], qnn_train_step: [1000/1000], loss: 0.04055356606841087, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [104/200], Epoch [1/5], Step [20/47], Loss: 0.0229, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [1/5], Step [40/47], Loss: 0.2213, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [104/200], Epoch [2/5], Step [20/47], Loss: 0.0961, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [104/200], Epoch [2/5], Step [40/47], Loss: 0.1519, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [104/200], Epoch [3/5], Step [20/47], Loss: 0.0448, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [104/200], Epoch [3/5], Step [40/47], Loss: 0.0259, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [4/5], Step [20/47], Loss: 0.0697, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [104/200], Epoch [4/5], Step [40/47], Loss: 0.2473, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [104/200], Epoch [5/5], Step [20/47], Loss: 0.0337, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [104/200], Epoch [5/5], Step [40/47], Loss: 0.1176, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [104/200], qnn_train_step: [100/1000], loss: 0.047569114714860916, accuracy: 98.5 %\n",
      "Training round [104/200], qnn_train_step: [200/1000], loss: 0.20212692022323608, accuracy: 92.8 %\n",
      "Training round [104/200], qnn_train_step: [300/1000], loss: 0.041541919112205505, accuracy: 98.8 %\n",
      "Training round [104/200], qnn_train_step: [400/1000], loss: 0.03858783468604088, accuracy: 99.1 %\n",
      "Training round [104/200], qnn_train_step: [500/1000], loss: 0.038255542516708374, accuracy: 99.1 %\n",
      "Training round [104/200], qnn_train_step: [600/1000], loss: 0.03946058452129364, accuracy: 98.9 %\n",
      "Training round [104/200], qnn_train_step: [700/1000], loss: 0.03914528340101242, accuracy: 99.1 %\n",
      "Training round [104/200], qnn_train_step: [800/1000], loss: 0.037242092192173004, accuracy: 99.2 %\n",
      "Training round [104/200], qnn_train_step: [900/1000], loss: 0.03992457687854767, accuracy: 99.0 %\n",
      "Training round [104/200], qnn_train_step: [1000/1000], loss: 0.03616888448596001, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [105/200], Epoch [1/5], Step [20/47], Loss: 0.0992, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [105/200], Epoch [1/5], Step [40/47], Loss: 0.1060, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [2/5], Step [20/47], Loss: 0.0931, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [2/5], Step [40/47], Loss: 0.1427, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [105/200], Epoch [3/5], Step [20/47], Loss: 0.0372, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [105/200], Epoch [3/5], Step [40/47], Loss: 0.0881, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [105/200], Epoch [4/5], Step [20/47], Loss: 0.0864, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [105/200], Epoch [4/5], Step [40/47], Loss: 0.0874, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [105/200], Epoch [5/5], Step [20/47], Loss: 0.0323, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [105/200], Epoch [5/5], Step [40/47], Loss: 0.1144, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [105/200], qnn_train_step: [100/1000], loss: 0.05267811939120293, accuracy: 98.2 %\n",
      "Training round [105/200], qnn_train_step: [200/1000], loss: 0.10911446809768677, accuracy: 95.8 %\n",
      "Training round [105/200], qnn_train_step: [300/1000], loss: 0.06545201689004898, accuracy: 97.8 %\n",
      "Training round [105/200], qnn_train_step: [400/1000], loss: 0.0481436587870121, accuracy: 98.4 %\n",
      "Training round [105/200], qnn_train_step: [500/1000], loss: 0.045384667813777924, accuracy: 98.3 %\n",
      "Training round [105/200], qnn_train_step: [600/1000], loss: 0.04536043107509613, accuracy: 98.5 %\n",
      "Training round [105/200], qnn_train_step: [700/1000], loss: 0.04401310905814171, accuracy: 98.8 %\n",
      "Training round [105/200], qnn_train_step: [800/1000], loss: 0.0436185747385025, accuracy: 98.8 %\n",
      "Training round [105/200], qnn_train_step: [900/1000], loss: 0.041565991938114166, accuracy: 98.9 %\n",
      "Training round [105/200], qnn_train_step: [1000/1000], loss: 0.04098004102706909, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [106/200], Epoch [1/5], Step [20/47], Loss: 0.1015, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [106/200], Epoch [1/5], Step [40/47], Loss: 0.1033, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [2/5], Step [20/47], Loss: 0.0662, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [2/5], Step [40/47], Loss: 0.0475, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [106/200], Epoch [3/5], Step [20/47], Loss: 0.0200, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [106/200], Epoch [3/5], Step [40/47], Loss: 0.0418, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [106/200], Epoch [4/5], Step [20/47], Loss: 0.0258, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [106/200], Epoch [4/5], Step [40/47], Loss: 0.0591, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [106/200], Epoch [5/5], Step [20/47], Loss: 0.1363, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [106/200], Epoch [5/5], Step [40/47], Loss: 0.0444, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [106/200], qnn_train_step: [100/1000], loss: 0.055572688579559326, accuracy: 98.1 %\n",
      "Training round [106/200], qnn_train_step: [200/1000], loss: 0.18302778899669647, accuracy: 94.1 %\n",
      "Training round [106/200], qnn_train_step: [300/1000], loss: 0.04735516384243965, accuracy: 98.4 %\n",
      "Training round [106/200], qnn_train_step: [400/1000], loss: 0.04681337997317314, accuracy: 98.4 %\n",
      "Training round [106/200], qnn_train_step: [500/1000], loss: 0.04848432168364525, accuracy: 98.1 %\n",
      "Training round [106/200], qnn_train_step: [600/1000], loss: 0.04896929860115051, accuracy: 98.6 %\n",
      "Training round [106/200], qnn_train_step: [700/1000], loss: 0.050954706966876984, accuracy: 98.1 %\n",
      "Training round [106/200], qnn_train_step: [800/1000], loss: 0.06587035953998566, accuracy: 97.6 %\n",
      "Training round [106/200], qnn_train_step: [900/1000], loss: 0.04443012923002243, accuracy: 98.4 %\n",
      "Training round [106/200], qnn_train_step: [1000/1000], loss: 0.04770777001976967, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [107/200], Epoch [1/5], Step [20/47], Loss: 0.0567, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [107/200], Epoch [1/5], Step [40/47], Loss: 0.1283, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [107/200], Epoch [2/5], Step [20/47], Loss: 0.0351, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [107/200], Epoch [2/5], Step [40/47], Loss: 0.0994, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [3/5], Step [20/47], Loss: 0.0741, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [3/5], Step [40/47], Loss: 0.0775, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [107/200], Epoch [4/5], Step [20/47], Loss: 0.1017, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [4/5], Step [40/47], Loss: 0.0729, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [107/200], Epoch [5/5], Step [20/47], Loss: 0.1123, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [107/200], Epoch [5/5], Step [40/47], Loss: 0.0474, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [107/200], qnn_train_step: [100/1000], loss: 0.06249258667230606, accuracy: 98.5 %\n",
      "Training round [107/200], qnn_train_step: [200/1000], loss: 0.11766671389341354, accuracy: 96.2 %\n",
      "Training round [107/200], qnn_train_step: [300/1000], loss: 0.061237335205078125, accuracy: 98.3 %\n",
      "Training round [107/200], qnn_train_step: [400/1000], loss: 0.05853050574660301, accuracy: 98.6 %\n",
      "Training round [107/200], qnn_train_step: [500/1000], loss: 0.0530557706952095, accuracy: 99.0 %\n",
      "Training round [107/200], qnn_train_step: [600/1000], loss: 0.05205762758851051, accuracy: 99.0 %\n",
      "Training round [107/200], qnn_train_step: [700/1000], loss: 0.05556080862879753, accuracy: 98.8 %\n",
      "Training round [107/200], qnn_train_step: [800/1000], loss: 0.060169968754053116, accuracy: 98.3 %\n",
      "Training round [107/200], qnn_train_step: [900/1000], loss: 0.05173534154891968, accuracy: 98.9 %\n",
      "Training round [107/200], qnn_train_step: [1000/1000], loss: 0.054090362042188644, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [108/200], Epoch [1/5], Step [20/47], Loss: 0.0132, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [108/200], Epoch [1/5], Step [40/47], Loss: 0.1382, batch time: 0.10, accuracy:  94.53%\n",
      "Training round [108/200], Epoch [2/5], Step [20/47], Loss: 0.0892, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [2/5], Step [40/47], Loss: 0.1073, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [108/200], Epoch [3/5], Step [20/47], Loss: 0.0496, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [108/200], Epoch [3/5], Step [40/47], Loss: 0.1528, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [4/5], Step [20/47], Loss: 0.0556, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [108/200], Epoch [4/5], Step [40/47], Loss: 0.0999, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [108/200], Epoch [5/5], Step [20/47], Loss: 0.1135, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [108/200], Epoch [5/5], Step [40/47], Loss: 0.0701, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [108/200], qnn_train_step: [100/1000], loss: 0.05308752879500389, accuracy: 98.2 %\n",
      "Training round [108/200], qnn_train_step: [200/1000], loss: 0.27011534571647644, accuracy: 90.8 %\n",
      "Training round [108/200], qnn_train_step: [300/1000], loss: 0.04877062886953354, accuracy: 98.1 %\n",
      "Training round [108/200], qnn_train_step: [400/1000], loss: 0.04262334853410721, accuracy: 98.6 %\n",
      "Training round [108/200], qnn_train_step: [500/1000], loss: 0.042697474360466, accuracy: 98.4 %\n",
      "Training round [108/200], qnn_train_step: [600/1000], loss: 0.04089709743857384, accuracy: 98.5 %\n",
      "Training round [108/200], qnn_train_step: [700/1000], loss: 0.04205940291285515, accuracy: 98.7 %\n",
      "Training round [108/200], qnn_train_step: [800/1000], loss: 0.0426810160279274, accuracy: 98.5 %\n",
      "Training round [108/200], qnn_train_step: [900/1000], loss: 0.0396566204726696, accuracy: 98.6 %\n",
      "Training round [108/200], qnn_train_step: [1000/1000], loss: 0.03990999609231949, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [109/200], Epoch [1/5], Step [20/47], Loss: 0.1141, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [109/200], Epoch [1/5], Step [40/47], Loss: 0.0431, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [109/200], Epoch [2/5], Step [20/47], Loss: 0.0649, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [2/5], Step [40/47], Loss: 0.0328, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [109/200], Epoch [3/5], Step [20/47], Loss: 0.0703, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [3/5], Step [40/47], Loss: 0.1345, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [4/5], Step [20/47], Loss: 0.0762, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [109/200], Epoch [4/5], Step [40/47], Loss: 0.1317, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [109/200], Epoch [5/5], Step [20/47], Loss: 0.0785, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [109/200], Epoch [5/5], Step [40/47], Loss: 0.0261, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [109/200], qnn_train_step: [100/1000], loss: 0.04727592691779137, accuracy: 98.7 %\n",
      "Training round [109/200], qnn_train_step: [200/1000], loss: 0.1413186490535736, accuracy: 94.4 %\n",
      "Training round [109/200], qnn_train_step: [300/1000], loss: 0.04860357195138931, accuracy: 98.4 %\n",
      "Training round [109/200], qnn_train_step: [400/1000], loss: 0.04286656528711319, accuracy: 98.9 %\n",
      "Training round [109/200], qnn_train_step: [500/1000], loss: 0.04265664890408516, accuracy: 98.6 %\n",
      "Training round [109/200], qnn_train_step: [600/1000], loss: 0.04110307991504669, accuracy: 98.8 %\n",
      "Training round [109/200], qnn_train_step: [700/1000], loss: 0.03950992971658707, accuracy: 99.0 %\n",
      "Training round [109/200], qnn_train_step: [800/1000], loss: 0.03894799202680588, accuracy: 99.0 %\n",
      "Training round [109/200], qnn_train_step: [900/1000], loss: 0.03964204341173172, accuracy: 98.7 %\n",
      "Training round [109/200], qnn_train_step: [1000/1000], loss: 0.039429545402526855, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [110/200], Epoch [1/5], Step [20/47], Loss: 0.0350, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [1/5], Step [40/47], Loss: 0.0580, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [2/5], Step [20/47], Loss: 0.0839, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [2/5], Step [40/47], Loss: 0.0189, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [110/200], Epoch [3/5], Step [20/47], Loss: 0.0639, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [110/200], Epoch [3/5], Step [40/47], Loss: 0.1259, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [4/5], Step [20/47], Loss: 0.0719, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [110/200], Epoch [4/5], Step [40/47], Loss: 0.1169, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [110/200], Epoch [5/5], Step [20/47], Loss: 0.0138, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [110/200], Epoch [5/5], Step [40/47], Loss: 0.0227, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [110/200], qnn_train_step: [100/1000], loss: 0.05083722993731499, accuracy: 98.1 %\n",
      "Training round [110/200], qnn_train_step: [200/1000], loss: 0.19162219762802124, accuracy: 93.1 %\n",
      "Training round [110/200], qnn_train_step: [300/1000], loss: 0.1961759328842163, accuracy: 94.3 %\n",
      "Training round [110/200], qnn_train_step: [400/1000], loss: 0.041000016033649445, accuracy: 98.7 %\n",
      "Training round [110/200], qnn_train_step: [500/1000], loss: 0.04083801433444023, accuracy: 98.2 %\n",
      "Training round [110/200], qnn_train_step: [600/1000], loss: 0.03522856533527374, accuracy: 98.8 %\n",
      "Training round [110/200], qnn_train_step: [700/1000], loss: 0.035689786076545715, accuracy: 98.6 %\n",
      "Training round [110/200], qnn_train_step: [800/1000], loss: 0.03345862776041031, accuracy: 98.9 %\n",
      "Training round [110/200], qnn_train_step: [900/1000], loss: 0.03498576208949089, accuracy: 98.8 %\n",
      "Training round [110/200], qnn_train_step: [1000/1000], loss: 0.03275931999087334, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [111/200], Epoch [1/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [1/5], Step [40/47], Loss: 0.0809, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [2/5], Step [20/47], Loss: 0.1684, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [111/200], Epoch [2/5], Step [40/47], Loss: 0.0398, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], Epoch [3/5], Step [20/47], Loss: 0.0382, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [111/200], Epoch [3/5], Step [40/47], Loss: 0.0348, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [111/200], Epoch [4/5], Step [20/47], Loss: 0.1629, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [111/200], Epoch [4/5], Step [40/47], Loss: 0.2275, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [111/200], Epoch [5/5], Step [20/47], Loss: 0.0597, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [111/200], Epoch [5/5], Step [40/47], Loss: 0.0918, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [111/200], qnn_train_step: [100/1000], loss: 0.04867485910654068, accuracy: 98.6 %\n",
      "Training round [111/200], qnn_train_step: [200/1000], loss: 0.18046784400939941, accuracy: 92.8 %\n",
      "Training round [111/200], qnn_train_step: [300/1000], loss: 0.04392603039741516, accuracy: 98.9 %\n",
      "Training round [111/200], qnn_train_step: [400/1000], loss: 0.042197518050670624, accuracy: 98.8 %\n",
      "Training round [111/200], qnn_train_step: [500/1000], loss: 0.04347260668873787, accuracy: 98.5 %\n",
      "Training round [111/200], qnn_train_step: [600/1000], loss: 0.03942753002047539, accuracy: 98.9 %\n",
      "Training round [111/200], qnn_train_step: [700/1000], loss: 0.03765265271067619, accuracy: 98.7 %\n",
      "Training round [111/200], qnn_train_step: [800/1000], loss: 0.036298755556344986, accuracy: 98.9 %\n",
      "Training round [111/200], qnn_train_step: [900/1000], loss: 0.036587029695510864, accuracy: 98.8 %\n",
      "Training round [111/200], qnn_train_step: [1000/1000], loss: 0.03922487422823906, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [112/200], Epoch [1/5], Step [20/47], Loss: 0.0478, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [1/5], Step [40/47], Loss: 0.1321, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [2/5], Step [20/47], Loss: 0.0315, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [2/5], Step [40/47], Loss: 0.0778, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [3/5], Step [20/47], Loss: 0.0370, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [112/200], Epoch [3/5], Step [40/47], Loss: 0.0550, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [4/5], Step [20/47], Loss: 0.1836, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [112/200], Epoch [4/5], Step [40/47], Loss: 0.0836, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [5/5], Step [20/47], Loss: 0.0364, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], Epoch [5/5], Step [40/47], Loss: 0.0522, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [112/200], qnn_train_step: [100/1000], loss: 0.05830579251050949, accuracy: 98.6 %\n",
      "Training round [112/200], qnn_train_step: [200/1000], loss: 0.11414569616317749, accuracy: 96.4 %\n",
      "Training round [112/200], qnn_train_step: [300/1000], loss: 0.10801119357347488, accuracy: 96.9 %\n",
      "Training round [112/200], qnn_train_step: [400/1000], loss: 0.055309515446424484, accuracy: 98.5 %\n",
      "Training round [112/200], qnn_train_step: [500/1000], loss: 0.06381455808877945, accuracy: 98.1 %\n",
      "Training round [112/200], qnn_train_step: [600/1000], loss: 0.05166348069906235, accuracy: 98.5 %\n",
      "Training round [112/200], qnn_train_step: [700/1000], loss: 0.05127623304724693, accuracy: 98.8 %\n",
      "Training round [112/200], qnn_train_step: [800/1000], loss: 0.050585001707077026, accuracy: 98.7 %\n",
      "Training round [112/200], qnn_train_step: [900/1000], loss: 0.050553034991025925, accuracy: 98.8 %\n",
      "Training round [112/200], qnn_train_step: [1000/1000], loss: 0.05019644647836685, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [113/200], Epoch [1/5], Step [20/47], Loss: 0.0351, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [1/5], Step [40/47], Loss: 0.2125, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [113/200], Epoch [2/5], Step [20/47], Loss: 0.0506, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [2/5], Step [40/47], Loss: 0.1497, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [3/5], Step [20/47], Loss: 0.0491, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [113/200], Epoch [3/5], Step [40/47], Loss: 0.0935, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [4/5], Step [20/47], Loss: 0.1397, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [113/200], Epoch [4/5], Step [40/47], Loss: 0.0569, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [113/200], Epoch [5/5], Step [20/47], Loss: 0.2058, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [113/200], Epoch [5/5], Step [40/47], Loss: 0.0924, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [113/200], qnn_train_step: [100/1000], loss: 0.05205444619059563, accuracy: 97.9 %\n",
      "Training round [113/200], qnn_train_step: [200/1000], loss: 0.12458427250385284, accuracy: 95.1 %\n",
      "Training round [113/200], qnn_train_step: [300/1000], loss: 0.05179373919963837, accuracy: 98.0 %\n",
      "Training round [113/200], qnn_train_step: [400/1000], loss: 0.04610314965248108, accuracy: 98.6 %\n",
      "Training round [113/200], qnn_train_step: [500/1000], loss: 0.04662768170237541, accuracy: 98.7 %\n",
      "Training round [113/200], qnn_train_step: [600/1000], loss: 0.04360955208539963, accuracy: 98.5 %\n",
      "Training round [113/200], qnn_train_step: [700/1000], loss: 0.04489431157708168, accuracy: 98.5 %\n",
      "Training round [113/200], qnn_train_step: [800/1000], loss: 0.043281201273202896, accuracy: 98.6 %\n",
      "Training round [113/200], qnn_train_step: [900/1000], loss: 0.045759811997413635, accuracy: 98.3 %\n",
      "Training round [113/200], qnn_train_step: [1000/1000], loss: 0.04431147873401642, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [114/200], Epoch [1/5], Step [20/47], Loss: 0.1051, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [1/5], Step [40/47], Loss: 0.0729, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [2/5], Step [20/47], Loss: 0.0750, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [114/200], Epoch [2/5], Step [40/47], Loss: 0.0343, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [114/200], Epoch [3/5], Step [20/47], Loss: 0.0261, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [114/200], Epoch [3/5], Step [40/47], Loss: 0.0905, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [4/5], Step [20/47], Loss: 0.1328, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [114/200], Epoch [4/5], Step [40/47], Loss: 0.0653, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [5/5], Step [20/47], Loss: 0.1114, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], Epoch [5/5], Step [40/47], Loss: 0.0938, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [114/200], qnn_train_step: [100/1000], loss: 0.05406017601490021, accuracy: 98.5 %\n",
      "Training round [114/200], qnn_train_step: [200/1000], loss: 0.21576903760433197, accuracy: 91.9 %\n",
      "Training round [114/200], qnn_train_step: [300/1000], loss: 0.060078684240579605, accuracy: 97.9 %\n",
      "Training round [114/200], qnn_train_step: [400/1000], loss: 0.04716610163450241, accuracy: 98.6 %\n",
      "Training round [114/200], qnn_train_step: [500/1000], loss: 0.04516202211380005, accuracy: 98.5 %\n",
      "Training round [114/200], qnn_train_step: [600/1000], loss: 0.04714387655258179, accuracy: 98.6 %\n",
      "Training round [114/200], qnn_train_step: [700/1000], loss: 0.043979331851005554, accuracy: 98.9 %\n",
      "Training round [114/200], qnn_train_step: [800/1000], loss: 0.043155886232852936, accuracy: 98.7 %\n",
      "Training round [114/200], qnn_train_step: [900/1000], loss: 0.04398658126592636, accuracy: 98.6 %\n",
      "Training round [114/200], qnn_train_step: [1000/1000], loss: 0.04332571104168892, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [115/200], Epoch [1/5], Step [20/47], Loss: 0.0654, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [1/5], Step [40/47], Loss: 0.1116, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [115/200], Epoch [2/5], Step [20/47], Loss: 0.0190, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [115/200], Epoch [2/5], Step [40/47], Loss: 0.0530, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [115/200], Epoch [3/5], Step [20/47], Loss: 0.0256, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [115/200], Epoch [3/5], Step [40/47], Loss: 0.0533, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [115/200], Epoch [4/5], Step [20/47], Loss: 0.0406, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [115/200], Epoch [4/5], Step [40/47], Loss: 0.0958, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [115/200], Epoch [5/5], Step [20/47], Loss: 0.0475, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [115/200], Epoch [5/5], Step [40/47], Loss: 0.0786, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [115/200], qnn_train_step: [100/1000], loss: 0.061851199716329575, accuracy: 98.0 %\n",
      "Training round [115/200], qnn_train_step: [200/1000], loss: 0.22315500676631927, accuracy: 92.6 %\n",
      "Training round [115/200], qnn_train_step: [300/1000], loss: 0.18342804908752441, accuracy: 93.8 %\n",
      "Training round [115/200], qnn_train_step: [400/1000], loss: 0.05480027571320534, accuracy: 98.6 %\n",
      "Training round [115/200], qnn_train_step: [500/1000], loss: 0.05204413831233978, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [600/1000], loss: 0.05094261094927788, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [700/1000], loss: 0.055226054042577744, accuracy: 98.6 %\n",
      "Training round [115/200], qnn_train_step: [800/1000], loss: 0.05057545006275177, accuracy: 98.5 %\n",
      "Training round [115/200], qnn_train_step: [900/1000], loss: 0.048284418880939484, accuracy: 98.7 %\n",
      "Training round [115/200], qnn_train_step: [1000/1000], loss: 0.06289267539978027, accuracy: 97.8 %\n",
      "-----------------------\n",
      "Training round [116/200], Epoch [1/5], Step [20/47], Loss: 0.0721, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [1/5], Step [40/47], Loss: 0.1151, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [116/200], Epoch [2/5], Step [20/47], Loss: 0.0945, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [2/5], Step [40/47], Loss: 0.0256, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [116/200], Epoch [3/5], Step [20/47], Loss: 0.0414, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [116/200], Epoch [3/5], Step [40/47], Loss: 0.0611, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [4/5], Step [20/47], Loss: 0.0433, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [116/200], Epoch [4/5], Step [40/47], Loss: 0.0411, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [116/200], Epoch [5/5], Step [20/47], Loss: 0.0699, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [116/200], Epoch [5/5], Step [40/47], Loss: 0.1537, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [116/200], qnn_train_step: [100/1000], loss: 0.03895634785294533, accuracy: 99.0 %\n",
      "Training round [116/200], qnn_train_step: [200/1000], loss: 0.21032263338565826, accuracy: 92.7 %\n",
      "Training round [116/200], qnn_train_step: [300/1000], loss: 0.034930113703012466, accuracy: 99.0 %\n",
      "Training round [116/200], qnn_train_step: [400/1000], loss: 0.03367993235588074, accuracy: 99.2 %\n",
      "Training round [116/200], qnn_train_step: [500/1000], loss: 0.0360434427857399, accuracy: 99.1 %\n",
      "Training round [116/200], qnn_train_step: [600/1000], loss: 0.03231382369995117, accuracy: 99.1 %\n",
      "Training round [116/200], qnn_train_step: [700/1000], loss: 0.032274309545755386, accuracy: 98.9 %\n",
      "Training round [116/200], qnn_train_step: [800/1000], loss: 0.03087000735104084, accuracy: 99.2 %\n",
      "Training round [116/200], qnn_train_step: [900/1000], loss: 0.030343713238835335, accuracy: 99.4 %\n",
      "Training round [116/200], qnn_train_step: [1000/1000], loss: 0.029518114402890205, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [117/200], Epoch [1/5], Step [20/47], Loss: 0.0776, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [1/5], Step [40/47], Loss: 0.0287, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [2/5], Step [20/47], Loss: 0.0448, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [2/5], Step [40/47], Loss: 0.0612, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [3/5], Step [20/47], Loss: 0.0499, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [117/200], Epoch [3/5], Step [40/47], Loss: 0.0273, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [117/200], Epoch [4/5], Step [20/47], Loss: 0.0483, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [117/200], Epoch [4/5], Step [40/47], Loss: 0.0559, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [117/200], Epoch [5/5], Step [20/47], Loss: 0.1240, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [117/200], Epoch [5/5], Step [40/47], Loss: 0.1025, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [117/200], qnn_train_step: [100/1000], loss: 0.03867005556821823, accuracy: 98.7 %\n",
      "Training round [117/200], qnn_train_step: [200/1000], loss: 0.3334728479385376, accuracy: 88.5 %\n",
      "Training round [117/200], qnn_train_step: [300/1000], loss: 0.04328756034374237, accuracy: 98.3 %\n",
      "Training round [117/200], qnn_train_step: [400/1000], loss: 0.0355975516140461, accuracy: 99.2 %\n",
      "Training round [117/200], qnn_train_step: [500/1000], loss: 0.03791787475347519, accuracy: 98.8 %\n",
      "Training round [117/200], qnn_train_step: [600/1000], loss: 0.03610598295927048, accuracy: 99.1 %\n",
      "Training round [117/200], qnn_train_step: [700/1000], loss: 0.037781234830617905, accuracy: 98.9 %\n",
      "Training round [117/200], qnn_train_step: [800/1000], loss: 0.03527810052037239, accuracy: 99.1 %\n",
      "Training round [117/200], qnn_train_step: [900/1000], loss: 0.04955011606216431, accuracy: 98.2 %\n",
      "Training round [117/200], qnn_train_step: [1000/1000], loss: 0.038240525871515274, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [118/200], Epoch [1/5], Step [20/47], Loss: 0.0742, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [1/5], Step [40/47], Loss: 0.0377, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [118/200], Epoch [2/5], Step [20/47], Loss: 0.1086, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [2/5], Step [40/47], Loss: 0.1838, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [118/200], Epoch [3/5], Step [20/47], Loss: 0.1305, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [118/200], Epoch [3/5], Step [40/47], Loss: 0.0603, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [4/5], Step [20/47], Loss: 0.0547, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [118/200], Epoch [4/5], Step [40/47], Loss: 0.1376, batch time: 0.05, accuracy:  92.19%\n",
      "Training round [118/200], Epoch [5/5], Step [20/47], Loss: 0.0683, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], Epoch [5/5], Step [40/47], Loss: 0.0588, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [118/200], qnn_train_step: [100/1000], loss: 0.05498303845524788, accuracy: 98.1 %\n",
      "Training round [118/200], qnn_train_step: [200/1000], loss: 0.34469208121299744, accuracy: 90.0 %\n",
      "Training round [118/200], qnn_train_step: [300/1000], loss: 0.09320802241563797, accuracy: 95.8 %\n",
      "Training round [118/200], qnn_train_step: [400/1000], loss: 0.04092009738087654, accuracy: 98.6 %\n",
      "Training round [118/200], qnn_train_step: [500/1000], loss: 0.039976976811885834, accuracy: 98.5 %\n",
      "Training round [118/200], qnn_train_step: [600/1000], loss: 0.039047591388225555, accuracy: 98.6 %\n",
      "Training round [118/200], qnn_train_step: [700/1000], loss: 0.038252659142017365, accuracy: 98.8 %\n",
      "Training round [118/200], qnn_train_step: [800/1000], loss: 0.038653239607810974, accuracy: 98.7 %\n",
      "Training round [118/200], qnn_train_step: [900/1000], loss: 0.04059913009405136, accuracy: 98.9 %\n",
      "Training round [118/200], qnn_train_step: [1000/1000], loss: 0.03724905848503113, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [119/200], Epoch [1/5], Step [20/47], Loss: 0.1483, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [119/200], Epoch [1/5], Step [40/47], Loss: 0.1021, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [2/5], Step [20/47], Loss: 0.0782, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [119/200], Epoch [2/5], Step [40/47], Loss: 0.0083, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [3/5], Step [20/47], Loss: 0.0162, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [119/200], Epoch [3/5], Step [40/47], Loss: 0.1265, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [119/200], Epoch [4/5], Step [20/47], Loss: 0.0102, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [119/200], Epoch [4/5], Step [40/47], Loss: 0.1646, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [119/200], Epoch [5/5], Step [20/47], Loss: 0.0958, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [119/200], Epoch [5/5], Step [40/47], Loss: 0.0345, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [119/200], qnn_train_step: [100/1000], loss: 0.051952335983514786, accuracy: 98.5 %\n",
      "Training round [119/200], qnn_train_step: [200/1000], loss: 0.06601253151893616, accuracy: 97.5 %\n",
      "Training round [119/200], qnn_train_step: [300/1000], loss: 0.048873357474803925, accuracy: 98.4 %\n",
      "Training round [119/200], qnn_train_step: [400/1000], loss: 0.0413186177611351, accuracy: 98.8 %\n",
      "Training round [119/200], qnn_train_step: [500/1000], loss: 0.040787048637866974, accuracy: 99.0 %\n",
      "Training round [119/200], qnn_train_step: [600/1000], loss: 0.04519013687968254, accuracy: 98.7 %\n",
      "Training round [119/200], qnn_train_step: [700/1000], loss: 0.04588939994573593, accuracy: 98.3 %\n",
      "Training round [119/200], qnn_train_step: [800/1000], loss: 0.04581591859459877, accuracy: 98.5 %\n",
      "Training round [119/200], qnn_train_step: [900/1000], loss: 0.040036287158727646, accuracy: 98.8 %\n",
      "Training round [119/200], qnn_train_step: [1000/1000], loss: 0.03752491623163223, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [120/200], Epoch [1/5], Step [20/47], Loss: 0.0212, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [120/200], Epoch [1/5], Step [40/47], Loss: 0.1825, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [120/200], Epoch [2/5], Step [20/47], Loss: 0.0453, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [2/5], Step [40/47], Loss: 0.0700, batch time: 0.31, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [3/5], Step [20/47], Loss: 0.0885, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [120/200], Epoch [3/5], Step [40/47], Loss: 0.0661, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [120/200], Epoch [4/5], Step [20/47], Loss: 0.0421, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [4/5], Step [40/47], Loss: 0.0923, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [120/200], Epoch [5/5], Step [20/47], Loss: 0.0282, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], Epoch [5/5], Step [40/47], Loss: 0.0564, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [120/200], qnn_train_step: [100/1000], loss: 0.04801646247506142, accuracy: 99.0 %\n",
      "Training round [120/200], qnn_train_step: [200/1000], loss: 0.04796087369322777, accuracy: 99.0 %\n",
      "Training round [120/200], qnn_train_step: [300/1000], loss: 0.04311441257596016, accuracy: 98.7 %\n",
      "Training round [120/200], qnn_train_step: [400/1000], loss: 0.03932635113596916, accuracy: 98.9 %\n",
      "Training round [120/200], qnn_train_step: [500/1000], loss: 0.03808175027370453, accuracy: 98.8 %\n",
      "Training round [120/200], qnn_train_step: [600/1000], loss: 0.03570392355322838, accuracy: 99.1 %\n",
      "Training round [120/200], qnn_train_step: [700/1000], loss: 0.039469484239816666, accuracy: 98.5 %\n",
      "Training round [120/200], qnn_train_step: [800/1000], loss: 0.033621884882450104, accuracy: 99.3 %\n",
      "Training round [120/200], qnn_train_step: [900/1000], loss: 0.03544892370700836, accuracy: 99.0 %\n",
      "Training round [120/200], qnn_train_step: [1000/1000], loss: 0.033198967576026917, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [121/200], Epoch [1/5], Step [20/47], Loss: 0.0500, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [1/5], Step [40/47], Loss: 0.0415, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [2/5], Step [20/47], Loss: 0.0430, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [2/5], Step [40/47], Loss: 0.0317, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [3/5], Step [20/47], Loss: 0.0270, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [121/200], Epoch [3/5], Step [40/47], Loss: 0.0732, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [4/5], Step [20/47], Loss: 0.0539, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [121/200], Epoch [4/5], Step [40/47], Loss: 0.1133, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [121/200], Epoch [5/5], Step [20/47], Loss: 0.0408, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [121/200], Epoch [5/5], Step [40/47], Loss: 0.1013, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [121/200], qnn_train_step: [100/1000], loss: 0.09256987273693085, accuracy: 97.3 %\n",
      "Training round [121/200], qnn_train_step: [200/1000], loss: 0.4416658878326416, accuracy: 84.4 %\n",
      "Training round [121/200], qnn_train_step: [300/1000], loss: 0.21034683287143707, accuracy: 93.7 %\n",
      "Training round [121/200], qnn_train_step: [400/1000], loss: 0.08315044641494751, accuracy: 97.7 %\n",
      "Training round [121/200], qnn_train_step: [500/1000], loss: 0.1161903366446495, accuracy: 96.7 %\n",
      "Training round [121/200], qnn_train_step: [600/1000], loss: 0.0770907774567604, accuracy: 97.8 %\n",
      "Training round [121/200], qnn_train_step: [700/1000], loss: 0.07527446746826172, accuracy: 97.7 %\n",
      "Training round [121/200], qnn_train_step: [800/1000], loss: 0.0734000951051712, accuracy: 98.1 %\n",
      "Training round [121/200], qnn_train_step: [900/1000], loss: 0.07345233857631683, accuracy: 98.1 %\n",
      "Training round [121/200], qnn_train_step: [1000/1000], loss: 0.08055529743432999, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [122/200], Epoch [1/5], Step [20/47], Loss: 0.0254, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [1/5], Step [40/47], Loss: 0.0656, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [2/5], Step [20/47], Loss: 0.0348, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [2/5], Step [40/47], Loss: 0.0902, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [3/5], Step [20/47], Loss: 0.0464, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [3/5], Step [40/47], Loss: 0.0363, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [122/200], Epoch [4/5], Step [20/47], Loss: 0.0185, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [122/200], Epoch [4/5], Step [40/47], Loss: 0.0406, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [122/200], Epoch [5/5], Step [20/47], Loss: 0.0461, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [122/200], Epoch [5/5], Step [40/47], Loss: 0.0742, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [122/200], qnn_train_step: [100/1000], loss: 0.05052950233221054, accuracy: 98.4 %\n",
      "Training round [122/200], qnn_train_step: [200/1000], loss: 0.6088781356811523, accuracy: 81.3 %\n",
      "Training round [122/200], qnn_train_step: [300/1000], loss: 0.05453431233763695, accuracy: 98.3 %\n",
      "Training round [122/200], qnn_train_step: [400/1000], loss: 0.05170029401779175, accuracy: 98.4 %\n",
      "Training round [122/200], qnn_train_step: [500/1000], loss: 0.05858248099684715, accuracy: 98.6 %\n",
      "Training round [122/200], qnn_train_step: [600/1000], loss: 0.054909318685531616, accuracy: 98.7 %\n",
      "Training round [122/200], qnn_train_step: [700/1000], loss: 0.05102700740098953, accuracy: 98.2 %\n",
      "Training round [122/200], qnn_train_step: [800/1000], loss: 0.050288476049900055, accuracy: 98.8 %\n",
      "Training round [122/200], qnn_train_step: [900/1000], loss: 0.04269846901297569, accuracy: 98.9 %\n",
      "Training round [122/200], qnn_train_step: [1000/1000], loss: 0.042298708111047745, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [123/200], Epoch [1/5], Step [20/47], Loss: 0.0420, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [1/5], Step [40/47], Loss: 0.0374, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [2/5], Step [20/47], Loss: 0.0479, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [2/5], Step [40/47], Loss: 0.1150, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [3/5], Step [20/47], Loss: 0.0524, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [3/5], Step [40/47], Loss: 0.0366, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [123/200], Epoch [4/5], Step [20/47], Loss: 0.0535, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [123/200], Epoch [4/5], Step [40/47], Loss: 0.1452, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [123/200], Epoch [5/5], Step [20/47], Loss: 0.0238, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [123/200], Epoch [5/5], Step [40/47], Loss: 0.0235, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [123/200], qnn_train_step: [100/1000], loss: 0.0572146475315094, accuracy: 98.6 %\n",
      "Training round [123/200], qnn_train_step: [200/1000], loss: 0.41886821389198303, accuracy: 86.9 %\n",
      "Training round [123/200], qnn_train_step: [300/1000], loss: 0.05591047182679176, accuracy: 98.4 %\n",
      "Training round [123/200], qnn_train_step: [400/1000], loss: 0.04954811558127403, accuracy: 98.7 %\n",
      "Training round [123/200], qnn_train_step: [500/1000], loss: 0.049034565687179565, accuracy: 98.5 %\n",
      "Training round [123/200], qnn_train_step: [600/1000], loss: 0.04794706031680107, accuracy: 99.0 %\n",
      "Training round [123/200], qnn_train_step: [700/1000], loss: 0.04788150265812874, accuracy: 99.0 %\n",
      "Training round [123/200], qnn_train_step: [800/1000], loss: 0.04682953283190727, accuracy: 99.1 %\n",
      "Training round [123/200], qnn_train_step: [900/1000], loss: 0.046672169119119644, accuracy: 98.9 %\n",
      "Training round [123/200], qnn_train_step: [1000/1000], loss: 0.04590919241309166, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [124/200], Epoch [1/5], Step [20/47], Loss: 0.0490, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [1/5], Step [40/47], Loss: 0.1038, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [124/200], Epoch [2/5], Step [20/47], Loss: 0.0419, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [2/5], Step [40/47], Loss: 0.0758, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [124/200], Epoch [3/5], Step [20/47], Loss: 0.0815, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [124/200], Epoch [3/5], Step [40/47], Loss: 0.0146, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [124/200], Epoch [4/5], Step [20/47], Loss: 0.0941, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [4/5], Step [40/47], Loss: 0.0612, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [124/200], Epoch [5/5], Step [20/47], Loss: 0.0255, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [124/200], Epoch [5/5], Step [40/47], Loss: 0.0378, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [124/200], qnn_train_step: [100/1000], loss: 0.03272486850619316, accuracy: 99.0 %\n",
      "Training round [124/200], qnn_train_step: [200/1000], loss: 0.032397255301475525, accuracy: 99.0 %\n",
      "Training round [124/200], qnn_train_step: [300/1000], loss: 0.029681755229830742, accuracy: 99.0 %\n",
      "Training round [124/200], qnn_train_step: [400/1000], loss: 0.028074707835912704, accuracy: 99.2 %\n",
      "Training round [124/200], qnn_train_step: [500/1000], loss: 0.02952347882091999, accuracy: 99.2 %\n",
      "Training round [124/200], qnn_train_step: [600/1000], loss: 0.031808096915483475, accuracy: 99.0 %\n",
      "Training round [124/200], qnn_train_step: [700/1000], loss: 0.03150628134608269, accuracy: 99.2 %\n",
      "Training round [124/200], qnn_train_step: [800/1000], loss: 0.027840381488204002, accuracy: 99.2 %\n",
      "Training round [124/200], qnn_train_step: [900/1000], loss: 0.08429741114377975, accuracy: 97.7 %\n",
      "Training round [124/200], qnn_train_step: [1000/1000], loss: 0.025046562775969505, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [125/200], Epoch [1/5], Step [20/47], Loss: 0.0686, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [1/5], Step [40/47], Loss: 0.0401, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [2/5], Step [20/47], Loss: 0.0431, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [2/5], Step [40/47], Loss: 0.0494, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [3/5], Step [20/47], Loss: 0.1033, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [125/200], Epoch [3/5], Step [40/47], Loss: 0.0555, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [4/5], Step [20/47], Loss: 0.0806, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [125/200], Epoch [4/5], Step [40/47], Loss: 0.1165, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [125/200], Epoch [5/5], Step [20/47], Loss: 0.0415, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [125/200], Epoch [5/5], Step [40/47], Loss: 0.0314, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [125/200], qnn_train_step: [100/1000], loss: 0.056249700486660004, accuracy: 98.1 %\n",
      "Training round [125/200], qnn_train_step: [200/1000], loss: 0.4666840732097626, accuracy: 84.7 %\n",
      "Training round [125/200], qnn_train_step: [300/1000], loss: 0.0465538464486599, accuracy: 98.7 %\n",
      "Training round [125/200], qnn_train_step: [400/1000], loss: 0.04777021333575249, accuracy: 98.4 %\n",
      "Training round [125/200], qnn_train_step: [500/1000], loss: 0.041488517075777054, accuracy: 98.5 %\n",
      "Training round [125/200], qnn_train_step: [600/1000], loss: 0.043555378913879395, accuracy: 98.7 %\n",
      "Training round [125/200], qnn_train_step: [700/1000], loss: 0.035385921597480774, accuracy: 99.0 %\n",
      "Training round [125/200], qnn_train_step: [800/1000], loss: 0.034522078931331635, accuracy: 98.7 %\n",
      "Training round [125/200], qnn_train_step: [900/1000], loss: 0.0345308743417263, accuracy: 98.6 %\n",
      "Training round [125/200], qnn_train_step: [1000/1000], loss: 0.04670896381139755, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [126/200], Epoch [1/5], Step [20/47], Loss: 0.1719, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [126/200], Epoch [1/5], Step [40/47], Loss: 0.0296, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [126/200], Epoch [2/5], Step [20/47], Loss: 0.0686, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [126/200], Epoch [2/5], Step [40/47], Loss: 0.1000, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [3/5], Step [20/47], Loss: 0.0657, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [3/5], Step [40/47], Loss: 0.0572, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [126/200], Epoch [4/5], Step [20/47], Loss: 0.1199, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [126/200], Epoch [4/5], Step [40/47], Loss: 0.0745, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [126/200], Epoch [5/5], Step [20/47], Loss: 0.0419, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [126/200], Epoch [5/5], Step [40/47], Loss: 0.0653, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [126/200], qnn_train_step: [100/1000], loss: 0.04609769210219383, accuracy: 98.6 %\n",
      "Training round [126/200], qnn_train_step: [200/1000], loss: 0.31201282143592834, accuracy: 89.5 %\n",
      "Training round [126/200], qnn_train_step: [300/1000], loss: 1.4227733612060547, accuracy: 74.3 %\n",
      "Training round [126/200], qnn_train_step: [400/1000], loss: 0.049306854605674744, accuracy: 98.3 %\n",
      "Training round [126/200], qnn_train_step: [500/1000], loss: 0.048412807285785675, accuracy: 98.4 %\n",
      "Training round [126/200], qnn_train_step: [600/1000], loss: 0.04596175253391266, accuracy: 98.6 %\n",
      "Training round [126/200], qnn_train_step: [700/1000], loss: 0.03583264723420143, accuracy: 98.9 %\n",
      "Training round [126/200], qnn_train_step: [800/1000], loss: 0.035028815269470215, accuracy: 99.1 %\n",
      "Training round [126/200], qnn_train_step: [900/1000], loss: 0.04278001934289932, accuracy: 98.3 %\n",
      "Training round [126/200], qnn_train_step: [1000/1000], loss: 0.034241288900375366, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [127/200], Epoch [1/5], Step [20/47], Loss: 0.0274, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [1/5], Step [40/47], Loss: 0.0452, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [2/5], Step [20/47], Loss: 0.0309, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [2/5], Step [40/47], Loss: 0.0412, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [3/5], Step [20/47], Loss: 0.0551, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [127/200], Epoch [3/5], Step [40/47], Loss: 0.0832, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [127/200], Epoch [4/5], Step [20/47], Loss: 0.0470, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [127/200], Epoch [4/5], Step [40/47], Loss: 0.0529, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [127/200], Epoch [5/5], Step [20/47], Loss: 0.1039, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [127/200], Epoch [5/5], Step [40/47], Loss: 0.1272, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [127/200], qnn_train_step: [100/1000], loss: 0.0883776918053627, accuracy: 96.9 %\n",
      "Training round [127/200], qnn_train_step: [200/1000], loss: 0.22882793843746185, accuracy: 91.6 %\n",
      "Training round [127/200], qnn_train_step: [300/1000], loss: 0.07434378564357758, accuracy: 97.3 %\n",
      "Training round [127/200], qnn_train_step: [400/1000], loss: 0.06791700422763824, accuracy: 97.5 %\n",
      "Training round [127/200], qnn_train_step: [500/1000], loss: 0.06815069913864136, accuracy: 97.5 %\n",
      "Training round [127/200], qnn_train_step: [600/1000], loss: 0.06392721086740494, accuracy: 97.8 %\n",
      "Training round [127/200], qnn_train_step: [700/1000], loss: 0.0652441680431366, accuracy: 97.8 %\n",
      "Training round [127/200], qnn_train_step: [800/1000], loss: 0.05948186665773392, accuracy: 97.9 %\n",
      "Training round [127/200], qnn_train_step: [900/1000], loss: 0.058401353657245636, accuracy: 98.1 %\n",
      "Training round [127/200], qnn_train_step: [1000/1000], loss: 0.062450431287288666, accuracy: 97.9 %\n",
      "-----------------------\n",
      "Training round [128/200], Epoch [1/5], Step [20/47], Loss: 0.1406, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [128/200], Epoch [1/5], Step [40/47], Loss: 0.0930, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [2/5], Step [20/47], Loss: 0.1338, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [2/5], Step [40/47], Loss: 0.0949, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [128/200], Epoch [3/5], Step [20/47], Loss: 0.0467, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [128/200], Epoch [3/5], Step [40/47], Loss: 0.0695, batch time: 0.09, accuracy:  96.88%\n",
      "Training round [128/200], Epoch [4/5], Step [20/47], Loss: 0.0288, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [4/5], Step [40/47], Loss: 0.0998, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [128/200], Epoch [5/5], Step [20/47], Loss: 0.0346, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [128/200], Epoch [5/5], Step [40/47], Loss: 0.0865, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [128/200], qnn_train_step: [100/1000], loss: 0.06115518510341644, accuracy: 98.0 %\n",
      "Training round [128/200], qnn_train_step: [200/1000], loss: 0.2598268985748291, accuracy: 91.3 %\n",
      "Training round [128/200], qnn_train_step: [300/1000], loss: 0.0690903514623642, accuracy: 97.8 %\n",
      "Training round [128/200], qnn_train_step: [400/1000], loss: 0.04857294633984566, accuracy: 98.5 %\n",
      "Training round [128/200], qnn_train_step: [500/1000], loss: 0.051519498229026794, accuracy: 98.4 %\n",
      "Training round [128/200], qnn_train_step: [600/1000], loss: 0.05211159959435463, accuracy: 98.2 %\n",
      "Training round [128/200], qnn_train_step: [700/1000], loss: 0.04515659064054489, accuracy: 98.6 %\n",
      "Training round [128/200], qnn_train_step: [800/1000], loss: 0.052103277295827866, accuracy: 98.4 %\n",
      "Training round [128/200], qnn_train_step: [900/1000], loss: 0.0491749607026577, accuracy: 98.7 %\n",
      "Training round [128/200], qnn_train_step: [1000/1000], loss: 0.0428374744951725, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [129/200], Epoch [1/5], Step [20/47], Loss: 0.0870, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [1/5], Step [40/47], Loss: 0.1351, batch time: 0.11, accuracy:  94.53%\n",
      "Training round [129/200], Epoch [2/5], Step [20/47], Loss: 0.0765, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [129/200], Epoch [2/5], Step [40/47], Loss: 0.1533, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [129/200], Epoch [3/5], Step [20/47], Loss: 0.0711, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [129/200], Epoch [3/5], Step [40/47], Loss: 0.0796, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [4/5], Step [20/47], Loss: 0.1252, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [4/5], Step [40/47], Loss: 0.1016, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [129/200], Epoch [5/5], Step [20/47], Loss: 0.0649, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [129/200], Epoch [5/5], Step [40/47], Loss: 0.0639, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [129/200], qnn_train_step: [100/1000], loss: 0.04625902324914932, accuracy: 98.9 %\n",
      "Training round [129/200], qnn_train_step: [200/1000], loss: 0.2402936965227127, accuracy: 91.6 %\n",
      "Training round [129/200], qnn_train_step: [300/1000], loss: 0.05124492570757866, accuracy: 98.6 %\n",
      "Training round [129/200], qnn_train_step: [400/1000], loss: 0.039989858865737915, accuracy: 98.8 %\n",
      "Training round [129/200], qnn_train_step: [500/1000], loss: 0.042336978018283844, accuracy: 98.7 %\n",
      "Training round [129/200], qnn_train_step: [600/1000], loss: 0.03906451165676117, accuracy: 98.8 %\n",
      "Training round [129/200], qnn_train_step: [700/1000], loss: 0.039604753255844116, accuracy: 98.8 %\n",
      "Training round [129/200], qnn_train_step: [800/1000], loss: 0.04680369794368744, accuracy: 98.8 %\n",
      "Training round [129/200], qnn_train_step: [900/1000], loss: 0.04163603484630585, accuracy: 98.7 %\n",
      "Training round [129/200], qnn_train_step: [1000/1000], loss: 0.040441833436489105, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [130/200], Epoch [1/5], Step [20/47], Loss: 0.0482, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [130/200], Epoch [1/5], Step [40/47], Loss: 0.0795, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [2/5], Step [20/47], Loss: 0.0469, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [130/200], Epoch [2/5], Step [40/47], Loss: 0.0333, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [130/200], Epoch [3/5], Step [20/47], Loss: 0.0859, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [3/5], Step [40/47], Loss: 0.0912, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [4/5], Step [20/47], Loss: 0.0975, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [130/200], Epoch [4/5], Step [40/47], Loss: 0.0235, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [130/200], Epoch [5/5], Step [20/47], Loss: 0.0659, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [130/200], Epoch [5/5], Step [40/47], Loss: 0.0277, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [130/200], qnn_train_step: [100/1000], loss: 0.06863725185394287, accuracy: 97.7 %\n",
      "Training round [130/200], qnn_train_step: [200/1000], loss: 0.2632905840873718, accuracy: 93.3 %\n",
      "Training round [130/200], qnn_train_step: [300/1000], loss: 0.14016295969486237, accuracy: 96.1 %\n",
      "Training round [130/200], qnn_train_step: [400/1000], loss: 0.061607345938682556, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [500/1000], loss: 0.0559004545211792, accuracy: 98.0 %\n",
      "Training round [130/200], qnn_train_step: [600/1000], loss: 0.054224736988544464, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [700/1000], loss: 0.05501686409115791, accuracy: 98.3 %\n",
      "Training round [130/200], qnn_train_step: [800/1000], loss: 0.05675534904003143, accuracy: 97.9 %\n",
      "Training round [130/200], qnn_train_step: [900/1000], loss: 0.05945346876978874, accuracy: 97.8 %\n",
      "Training round [130/200], qnn_train_step: [1000/1000], loss: 0.049830060452222824, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [131/200], Epoch [1/5], Step [20/47], Loss: 0.1124, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [131/200], Epoch [1/5], Step [40/47], Loss: 0.0364, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [2/5], Step [20/47], Loss: 0.0318, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [131/200], Epoch [2/5], Step [40/47], Loss: 0.0617, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [131/200], Epoch [3/5], Step [20/47], Loss: 0.0157, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [131/200], Epoch [3/5], Step [40/47], Loss: 0.0143, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [131/200], Epoch [4/5], Step [20/47], Loss: 0.1383, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [4/5], Step [40/47], Loss: 0.0707, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [131/200], Epoch [5/5], Step [20/47], Loss: 0.0252, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [131/200], Epoch [5/5], Step [40/47], Loss: 0.0993, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [131/200], qnn_train_step: [100/1000], loss: 0.07894176244735718, accuracy: 97.5 %\n",
      "Training round [131/200], qnn_train_step: [200/1000], loss: 0.21308909356594086, accuracy: 92.1 %\n",
      "Training round [131/200], qnn_train_step: [300/1000], loss: 0.06632934510707855, accuracy: 98.0 %\n",
      "Training round [131/200], qnn_train_step: [400/1000], loss: 0.06246871501207352, accuracy: 98.0 %\n",
      "Training round [131/200], qnn_train_step: [500/1000], loss: 0.061638735234737396, accuracy: 97.9 %\n",
      "Training round [131/200], qnn_train_step: [600/1000], loss: 0.06116866320371628, accuracy: 97.7 %\n",
      "Training round [131/200], qnn_train_step: [700/1000], loss: 0.06281960755586624, accuracy: 97.9 %\n",
      "Training round [131/200], qnn_train_step: [800/1000], loss: 0.058748506009578705, accuracy: 98.2 %\n",
      "Training round [131/200], qnn_train_step: [900/1000], loss: 0.07264021784067154, accuracy: 97.8 %\n",
      "Training round [131/200], qnn_train_step: [1000/1000], loss: 0.056339289993047714, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [132/200], Epoch [1/5], Step [20/47], Loss: 0.0966, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [1/5], Step [40/47], Loss: 0.0925, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [132/200], Epoch [2/5], Step [20/47], Loss: 0.0947, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [132/200], Epoch [2/5], Step [40/47], Loss: 0.0345, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [3/5], Step [20/47], Loss: 0.0312, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [132/200], Epoch [3/5], Step [40/47], Loss: 0.0225, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [132/200], Epoch [4/5], Step [20/47], Loss: 0.0697, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [132/200], Epoch [4/5], Step [40/47], Loss: 0.0408, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [132/200], Epoch [5/5], Step [20/47], Loss: 0.0657, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [132/200], Epoch [5/5], Step [40/47], Loss: 0.0898, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [132/200], qnn_train_step: [100/1000], loss: 0.05657171830534935, accuracy: 98.6 %\n",
      "Training round [132/200], qnn_train_step: [200/1000], loss: 0.06232795864343643, accuracy: 98.2 %\n",
      "Training round [132/200], qnn_train_step: [300/1000], loss: 0.053064048290252686, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [400/1000], loss: 0.05286218971014023, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [500/1000], loss: 0.05429723113775253, accuracy: 98.4 %\n",
      "Training round [132/200], qnn_train_step: [600/1000], loss: 0.04915366321802139, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [700/1000], loss: 0.0752953365445137, accuracy: 97.9 %\n",
      "Training round [132/200], qnn_train_step: [800/1000], loss: 0.04650391638278961, accuracy: 98.9 %\n",
      "Training round [132/200], qnn_train_step: [900/1000], loss: 0.04613933712244034, accuracy: 99.0 %\n",
      "Training round [132/200], qnn_train_step: [1000/1000], loss: 0.04567456617951393, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [133/200], Epoch [1/5], Step [20/47], Loss: 0.0475, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [1/5], Step [40/47], Loss: 0.0809, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [133/200], Epoch [2/5], Step [20/47], Loss: 0.1796, batch time: 0.05, accuracy:  92.97%\n",
      "Training round [133/200], Epoch [2/5], Step [40/47], Loss: 0.0524, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [133/200], Epoch [3/5], Step [20/47], Loss: 0.0741, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [133/200], Epoch [3/5], Step [40/47], Loss: 0.0433, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [133/200], Epoch [4/5], Step [20/47], Loss: 0.0615, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [133/200], Epoch [4/5], Step [40/47], Loss: 0.0236, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [133/200], Epoch [5/5], Step [20/47], Loss: 0.1010, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [133/200], Epoch [5/5], Step [40/47], Loss: 0.0207, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [133/200], qnn_train_step: [100/1000], loss: 0.03695892542600632, accuracy: 99.1 %\n",
      "Training round [133/200], qnn_train_step: [200/1000], loss: 0.062133897095918655, accuracy: 98.2 %\n",
      "Training round [133/200], qnn_train_step: [300/1000], loss: 0.03506126627326012, accuracy: 99.3 %\n",
      "Training round [133/200], qnn_train_step: [400/1000], loss: 0.03215543180704117, accuracy: 99.3 %\n",
      "Training round [133/200], qnn_train_step: [500/1000], loss: 0.044855739921331406, accuracy: 98.7 %\n",
      "Training round [133/200], qnn_train_step: [600/1000], loss: 0.0306608397513628, accuracy: 99.4 %\n",
      "Training round [133/200], qnn_train_step: [700/1000], loss: 0.03730563446879387, accuracy: 98.8 %\n",
      "Training round [133/200], qnn_train_step: [800/1000], loss: 0.0309615395963192, accuracy: 99.3 %\n",
      "Training round [133/200], qnn_train_step: [900/1000], loss: 0.029389817267656326, accuracy: 99.3 %\n",
      "Training round [133/200], qnn_train_step: [1000/1000], loss: 0.02875327132642269, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [134/200], Epoch [1/5], Step [20/47], Loss: 0.0473, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [1/5], Step [40/47], Loss: 0.0194, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [134/200], Epoch [2/5], Step [20/47], Loss: 0.0673, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [134/200], Epoch [2/5], Step [40/47], Loss: 0.0950, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [3/5], Step [20/47], Loss: 0.0587, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [134/200], Epoch [3/5], Step [40/47], Loss: 0.0505, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [4/5], Step [20/47], Loss: 0.0326, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [134/200], Epoch [4/5], Step [40/47], Loss: 0.0754, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [5/5], Step [20/47], Loss: 0.0546, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [134/200], Epoch [5/5], Step [40/47], Loss: 0.1294, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [134/200], qnn_train_step: [100/1000], loss: 0.04650192707777023, accuracy: 98.8 %\n",
      "Training round [134/200], qnn_train_step: [200/1000], loss: 0.2534916400909424, accuracy: 90.5 %\n",
      "Training round [134/200], qnn_train_step: [300/1000], loss: 0.04307221621274948, accuracy: 99.0 %\n",
      "Training round [134/200], qnn_train_step: [400/1000], loss: 0.042455777525901794, accuracy: 98.9 %\n",
      "Training round [134/200], qnn_train_step: [500/1000], loss: 0.04204839840531349, accuracy: 98.9 %\n",
      "Training round [134/200], qnn_train_step: [600/1000], loss: 0.07435788959264755, accuracy: 97.0 %\n",
      "Training round [134/200], qnn_train_step: [700/1000], loss: 0.04491829499602318, accuracy: 99.0 %\n",
      "Training round [134/200], qnn_train_step: [800/1000], loss: 0.04838724061846733, accuracy: 98.7 %\n",
      "Training round [134/200], qnn_train_step: [900/1000], loss: 0.03998927026987076, accuracy: 99.2 %\n",
      "Training round [134/200], qnn_train_step: [1000/1000], loss: 0.039848897606134415, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [135/200], Epoch [1/5], Step [20/47], Loss: 0.0201, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [135/200], Epoch [1/5], Step [40/47], Loss: 0.0535, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [2/5], Step [20/47], Loss: 0.0502, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [2/5], Step [40/47], Loss: 0.0934, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [135/200], Epoch [3/5], Step [20/47], Loss: 0.0687, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [135/200], Epoch [3/5], Step [40/47], Loss: 0.1072, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [4/5], Step [20/47], Loss: 0.1256, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [135/200], Epoch [4/5], Step [40/47], Loss: 0.0360, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [135/200], Epoch [5/5], Step [20/47], Loss: 0.0482, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [135/200], Epoch [5/5], Step [40/47], Loss: 0.0356, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [135/200], qnn_train_step: [100/1000], loss: 0.055053554475307465, accuracy: 97.8 %\n",
      "Training round [135/200], qnn_train_step: [200/1000], loss: 0.05547014996409416, accuracy: 97.8 %\n",
      "Training round [135/200], qnn_train_step: [300/1000], loss: 0.04819314181804657, accuracy: 98.4 %\n",
      "Training round [135/200], qnn_train_step: [400/1000], loss: 0.04674553498625755, accuracy: 98.1 %\n",
      "Training round [135/200], qnn_train_step: [500/1000], loss: 0.04912564530968666, accuracy: 97.9 %\n",
      "Training round [135/200], qnn_train_step: [600/1000], loss: 0.04395801201462746, accuracy: 98.5 %\n",
      "Training round [135/200], qnn_train_step: [700/1000], loss: 0.043353188782930374, accuracy: 98.5 %\n",
      "Training round [135/200], qnn_train_step: [800/1000], loss: 0.044841885566711426, accuracy: 98.4 %\n",
      "Training round [135/200], qnn_train_step: [900/1000], loss: 0.05582842230796814, accuracy: 98.2 %\n",
      "Training round [135/200], qnn_train_step: [1000/1000], loss: 0.04755307361483574, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [136/200], Epoch [1/5], Step [20/47], Loss: 0.0589, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [1/5], Step [40/47], Loss: 0.0989, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [136/200], Epoch [2/5], Step [20/47], Loss: 0.0049, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [136/200], Epoch [2/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [20/47], Loss: 0.0386, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [3/5], Step [40/47], Loss: 0.0717, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], Epoch [4/5], Step [20/47], Loss: 0.0764, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [136/200], Epoch [4/5], Step [40/47], Loss: 0.0197, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [136/200], Epoch [5/5], Step [20/47], Loss: 0.0889, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [136/200], Epoch [5/5], Step [40/47], Loss: 0.0549, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [136/200], qnn_train_step: [100/1000], loss: 0.041433852165937424, accuracy: 98.9 %\n",
      "Training round [136/200], qnn_train_step: [200/1000], loss: 0.045967184007167816, accuracy: 98.4 %\n",
      "Training round [136/200], qnn_train_step: [300/1000], loss: 0.04166613519191742, accuracy: 98.8 %\n",
      "Training round [136/200], qnn_train_step: [400/1000], loss: 0.039744045585393906, accuracy: 99.0 %\n",
      "Training round [136/200], qnn_train_step: [500/1000], loss: 0.03987179696559906, accuracy: 98.9 %\n",
      "Training round [136/200], qnn_train_step: [600/1000], loss: 0.05214099958539009, accuracy: 98.6 %\n",
      "Training round [136/200], qnn_train_step: [700/1000], loss: 0.04364587366580963, accuracy: 98.8 %\n",
      "Training round [136/200], qnn_train_step: [800/1000], loss: 0.04140877351164818, accuracy: 98.8 %\n",
      "Training round [136/200], qnn_train_step: [900/1000], loss: 0.04091339558362961, accuracy: 98.7 %\n",
      "Training round [136/200], qnn_train_step: [1000/1000], loss: 0.044526658952236176, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [137/200], Epoch [1/5], Step [20/47], Loss: 0.1062, batch time: 0.11, accuracy:  93.75%\n",
      "Training round [137/200], Epoch [1/5], Step [40/47], Loss: 0.0681, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [137/200], Epoch [2/5], Step [20/47], Loss: 0.0488, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [2/5], Step [40/47], Loss: 0.0229, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [137/200], Epoch [3/5], Step [20/47], Loss: 0.0428, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [137/200], Epoch [3/5], Step [40/47], Loss: 0.0079, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [137/200], Epoch [4/5], Step [20/47], Loss: 0.0287, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [4/5], Step [40/47], Loss: 0.0518, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [137/200], Epoch [5/5], Step [20/47], Loss: 0.0801, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [137/200], Epoch [5/5], Step [40/47], Loss: 0.0818, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [137/200], qnn_train_step: [100/1000], loss: 0.03784763813018799, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [200/1000], loss: 0.050443340092897415, accuracy: 98.7 %\n",
      "Training round [137/200], qnn_train_step: [300/1000], loss: 0.041215065866708755, accuracy: 98.8 %\n",
      "Training round [137/200], qnn_train_step: [400/1000], loss: 0.03398929163813591, accuracy: 99.1 %\n",
      "Training round [137/200], qnn_train_step: [500/1000], loss: 0.034006260335445404, accuracy: 99.1 %\n",
      "Training round [137/200], qnn_train_step: [600/1000], loss: 0.03738350421190262, accuracy: 98.8 %\n",
      "Training round [137/200], qnn_train_step: [700/1000], loss: 0.0336746908724308, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [800/1000], loss: 0.03298487886786461, accuracy: 99.2 %\n",
      "Training round [137/200], qnn_train_step: [900/1000], loss: 0.03431973606348038, accuracy: 99.0 %\n",
      "Training round [137/200], qnn_train_step: [1000/1000], loss: 0.03183961287140846, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [138/200], Epoch [1/5], Step [20/47], Loss: 0.0199, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [138/200], Epoch [1/5], Step [40/47], Loss: 0.0265, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [2/5], Step [20/47], Loss: 0.0842, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [2/5], Step [40/47], Loss: 0.0678, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [3/5], Step [20/47], Loss: 0.0734, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [138/200], Epoch [3/5], Step [40/47], Loss: 0.0340, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [4/5], Step [20/47], Loss: 0.0693, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [138/200], Epoch [4/5], Step [40/47], Loss: 0.1447, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [138/200], Epoch [5/5], Step [20/47], Loss: 0.0461, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [138/200], Epoch [5/5], Step [40/47], Loss: 0.0649, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [138/200], qnn_train_step: [100/1000], loss: 0.03214223310351372, accuracy: 98.8 %\n",
      "Training round [138/200], qnn_train_step: [200/1000], loss: 0.428283154964447, accuracy: 86.1 %\n",
      "Training round [138/200], qnn_train_step: [300/1000], loss: 0.029860949143767357, accuracy: 99.1 %\n",
      "Training round [138/200], qnn_train_step: [400/1000], loss: 0.03305371105670929, accuracy: 98.8 %\n",
      "Training round [138/200], qnn_train_step: [500/1000], loss: 0.02640165574848652, accuracy: 98.9 %\n",
      "Training round [138/200], qnn_train_step: [600/1000], loss: 0.03623952344059944, accuracy: 98.6 %\n",
      "Training round [138/200], qnn_train_step: [700/1000], loss: 0.02643940970301628, accuracy: 99.0 %\n",
      "Training round [138/200], qnn_train_step: [800/1000], loss: 0.022994250059127808, accuracy: 99.4 %\n",
      "Training round [138/200], qnn_train_step: [900/1000], loss: 0.03133648633956909, accuracy: 98.7 %\n",
      "Training round [138/200], qnn_train_step: [1000/1000], loss: 0.023127486929297447, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [139/200], Epoch [1/5], Step [20/47], Loss: 0.0293, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [1/5], Step [40/47], Loss: 0.0400, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [2/5], Step [20/47], Loss: 0.1115, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [139/200], Epoch [2/5], Step [40/47], Loss: 0.0146, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [139/200], Epoch [3/5], Step [20/47], Loss: 0.0386, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], Epoch [3/5], Step [40/47], Loss: 0.1334, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [139/200], Epoch [4/5], Step [20/47], Loss: 0.0318, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [139/200], Epoch [4/5], Step [40/47], Loss: 0.0709, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [139/200], Epoch [5/5], Step [20/47], Loss: 0.1371, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [139/200], Epoch [5/5], Step [40/47], Loss: 0.0468, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [139/200], qnn_train_step: [100/1000], loss: 0.056999824941158295, accuracy: 98.3 %\n",
      "Training round [139/200], qnn_train_step: [200/1000], loss: 0.05898977443575859, accuracy: 98.1 %\n",
      "Training round [139/200], qnn_train_step: [300/1000], loss: 0.06742586940526962, accuracy: 98.0 %\n",
      "Training round [139/200], qnn_train_step: [400/1000], loss: 0.05259278416633606, accuracy: 98.5 %\n",
      "Training round [139/200], qnn_train_step: [500/1000], loss: 0.05290466919541359, accuracy: 98.4 %\n",
      "Training round [139/200], qnn_train_step: [600/1000], loss: 0.051091089844703674, accuracy: 98.4 %\n",
      "Training round [139/200], qnn_train_step: [700/1000], loss: 0.054195065051317215, accuracy: 98.4 %\n",
      "Training round [139/200], qnn_train_step: [800/1000], loss: 0.04856865853071213, accuracy: 98.6 %\n",
      "Training round [139/200], qnn_train_step: [900/1000], loss: 0.05087994784116745, accuracy: 98.4 %\n",
      "Training round [139/200], qnn_train_step: [1000/1000], loss: 0.051764849573373795, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [140/200], Epoch [1/5], Step [20/47], Loss: 0.0285, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [140/200], Epoch [1/5], Step [40/47], Loss: 0.0662, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [2/5], Step [20/47], Loss: 0.0333, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], Epoch [2/5], Step [40/47], Loss: 0.0419, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [3/5], Step [20/47], Loss: 0.0766, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [3/5], Step [40/47], Loss: 0.1152, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [140/200], Epoch [4/5], Step [20/47], Loss: 0.0727, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [4/5], Step [40/47], Loss: 0.1038, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [140/200], Epoch [5/5], Step [20/47], Loss: 0.0454, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [140/200], Epoch [5/5], Step [40/47], Loss: 0.0470, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [140/200], qnn_train_step: [100/1000], loss: 0.060759346932172775, accuracy: 98.2 %\n",
      "Training round [140/200], qnn_train_step: [200/1000], loss: 0.15152113139629364, accuracy: 94.4 %\n",
      "Training round [140/200], qnn_train_step: [300/1000], loss: 0.12227245420217514, accuracy: 96.6 %\n",
      "Training round [140/200], qnn_train_step: [400/1000], loss: 0.046859920024871826, accuracy: 98.5 %\n",
      "Training round [140/200], qnn_train_step: [500/1000], loss: 0.04576212540268898, accuracy: 98.3 %\n",
      "Training round [140/200], qnn_train_step: [600/1000], loss: 0.05065985023975372, accuracy: 98.3 %\n",
      "Training round [140/200], qnn_train_step: [700/1000], loss: 0.050035711377859116, accuracy: 98.4 %\n",
      "Training round [140/200], qnn_train_step: [800/1000], loss: 0.04494507610797882, accuracy: 98.5 %\n",
      "Training round [140/200], qnn_train_step: [900/1000], loss: 0.046843282878398895, accuracy: 98.4 %\n",
      "Training round [140/200], qnn_train_step: [1000/1000], loss: 0.04094512388110161, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [141/200], Epoch [1/5], Step [20/47], Loss: 0.0625, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [141/200], Epoch [1/5], Step [40/47], Loss: 0.0523, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [2/5], Step [20/47], Loss: 0.0941, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [141/200], Epoch [2/5], Step [40/47], Loss: 0.0271, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [3/5], Step [20/47], Loss: 0.0135, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [141/200], Epoch [3/5], Step [40/47], Loss: 0.0284, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [4/5], Step [20/47], Loss: 0.0752, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [4/5], Step [40/47], Loss: 0.0735, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [141/200], Epoch [5/5], Step [20/47], Loss: 0.0550, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [141/200], Epoch [5/5], Step [40/47], Loss: 0.0462, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [141/200], qnn_train_step: [100/1000], loss: 0.05214477702975273, accuracy: 98.2 %\n",
      "Training round [141/200], qnn_train_step: [200/1000], loss: 0.18040412664413452, accuracy: 93.0 %\n",
      "Training round [141/200], qnn_train_step: [300/1000], loss: 0.04357592761516571, accuracy: 98.6 %\n",
      "Training round [141/200], qnn_train_step: [400/1000], loss: 0.03660400211811066, accuracy: 99.0 %\n",
      "Training round [141/200], qnn_train_step: [500/1000], loss: 0.046799033880233765, accuracy: 98.2 %\n",
      "Training round [141/200], qnn_train_step: [600/1000], loss: 0.03824925050139427, accuracy: 98.5 %\n",
      "Training round [141/200], qnn_train_step: [700/1000], loss: 0.03856709226965904, accuracy: 98.5 %\n",
      "Training round [141/200], qnn_train_step: [800/1000], loss: 0.036253672093153, accuracy: 99.1 %\n",
      "Training round [141/200], qnn_train_step: [900/1000], loss: 0.036133043467998505, accuracy: 98.8 %\n",
      "Training round [141/200], qnn_train_step: [1000/1000], loss: 0.04618099704384804, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [142/200], Epoch [1/5], Step [20/47], Loss: 0.0566, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [1/5], Step [40/47], Loss: 0.0651, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [2/5], Step [20/47], Loss: 0.0740, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [142/200], Epoch [2/5], Step [40/47], Loss: 0.0914, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [3/5], Step [20/47], Loss: 0.0344, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [142/200], Epoch [3/5], Step [40/47], Loss: 0.0660, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [142/200], Epoch [4/5], Step [20/47], Loss: 0.0501, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [4/5], Step [40/47], Loss: 0.0682, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [142/200], Epoch [5/5], Step [20/47], Loss: 0.1055, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [142/200], Epoch [5/5], Step [40/47], Loss: 0.0454, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [142/200], qnn_train_step: [100/1000], loss: 0.046228837221860886, accuracy: 98.6 %\n",
      "Training round [142/200], qnn_train_step: [200/1000], loss: 0.51163649559021, accuracy: 85.7 %\n",
      "Training round [142/200], qnn_train_step: [300/1000], loss: 0.04075317829847336, accuracy: 98.6 %\n",
      "Training round [142/200], qnn_train_step: [400/1000], loss: 0.17643870413303375, accuracy: 92.9 %\n",
      "Training round [142/200], qnn_train_step: [500/1000], loss: 0.029842354357242584, accuracy: 99.4 %\n",
      "Training round [142/200], qnn_train_step: [600/1000], loss: 0.03278316929936409, accuracy: 99.2 %\n",
      "Training round [142/200], qnn_train_step: [700/1000], loss: 0.02887239307165146, accuracy: 99.5 %\n",
      "Training round [142/200], qnn_train_step: [800/1000], loss: 0.03337182104587555, accuracy: 99.0 %\n",
      "Training round [142/200], qnn_train_step: [900/1000], loss: 0.027363931760191917, accuracy: 99.4 %\n",
      "Training round [142/200], qnn_train_step: [1000/1000], loss: 0.026808559894561768, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [143/200], Epoch [1/5], Step [20/47], Loss: 0.0736, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [1/5], Step [40/47], Loss: 0.0844, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [2/5], Step [20/47], Loss: 0.0643, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [2/5], Step [40/47], Loss: 0.0640, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [3/5], Step [20/47], Loss: 0.1078, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [143/200], Epoch [3/5], Step [40/47], Loss: 0.1009, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [4/5], Step [20/47], Loss: 0.0611, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [143/200], Epoch [4/5], Step [40/47], Loss: 0.0517, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [5/5], Step [20/47], Loss: 0.0185, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [143/200], Epoch [5/5], Step [40/47], Loss: 0.0151, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [143/200], qnn_train_step: [100/1000], loss: 0.06024594232439995, accuracy: 97.8 %\n",
      "Training round [143/200], qnn_train_step: [200/1000], loss: 0.8543217182159424, accuracy: 81.9 %\n",
      "Training round [143/200], qnn_train_step: [300/1000], loss: 0.050681110471487045, accuracy: 98.2 %\n",
      "Training round [143/200], qnn_train_step: [400/1000], loss: 0.14761143922805786, accuracy: 95.7 %\n",
      "Training round [143/200], qnn_train_step: [500/1000], loss: 0.04721906781196594, accuracy: 98.4 %\n",
      "Training round [143/200], qnn_train_step: [600/1000], loss: 0.0425746776163578, accuracy: 98.6 %\n",
      "Training round [143/200], qnn_train_step: [700/1000], loss: 0.04161522909998894, accuracy: 98.6 %\n",
      "Training round [143/200], qnn_train_step: [800/1000], loss: 0.04267890751361847, accuracy: 98.9 %\n",
      "Training round [143/200], qnn_train_step: [900/1000], loss: 0.039791300892829895, accuracy: 98.8 %\n",
      "Training round [143/200], qnn_train_step: [1000/1000], loss: 0.038673825562000275, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [144/200], Epoch [1/5], Step [20/47], Loss: 0.0824, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [1/5], Step [40/47], Loss: 0.1190, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [144/200], Epoch [2/5], Step [20/47], Loss: 0.1323, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [2/5], Step [40/47], Loss: 0.0618, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [144/200], Epoch [3/5], Step [20/47], Loss: 0.0321, batch time: 0.09, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [3/5], Step [40/47], Loss: 0.0457, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [144/200], Epoch [4/5], Step [20/47], Loss: 0.0454, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [144/200], Epoch [4/5], Step [40/47], Loss: 0.0877, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [144/200], Epoch [5/5], Step [20/47], Loss: 0.0174, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [144/200], Epoch [5/5], Step [40/47], Loss: 0.0315, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [144/200], qnn_train_step: [100/1000], loss: 0.10545218735933304, accuracy: 96.9 %\n",
      "Training round [144/200], qnn_train_step: [200/1000], loss: 0.6514277458190918, accuracy: 80.0 %\n",
      "Training round [144/200], qnn_train_step: [300/1000], loss: 0.19227905571460724, accuracy: 94.8 %\n",
      "Training round [144/200], qnn_train_step: [400/1000], loss: 0.3212473690509796, accuracy: 90.6 %\n",
      "Training round [144/200], qnn_train_step: [500/1000], loss: 0.07460402697324753, accuracy: 97.8 %\n",
      "Training round [144/200], qnn_train_step: [600/1000], loss: 0.07590027898550034, accuracy: 97.5 %\n",
      "Training round [144/200], qnn_train_step: [700/1000], loss: 0.07378209382295609, accuracy: 98.2 %\n",
      "Training round [144/200], qnn_train_step: [800/1000], loss: 0.06686848402023315, accuracy: 97.7 %\n",
      "Training round [144/200], qnn_train_step: [900/1000], loss: 0.06549790501594543, accuracy: 98.0 %\n",
      "Training round [144/200], qnn_train_step: [1000/1000], loss: 0.061771247535943985, accuracy: 98.1 %\n",
      "-----------------------\n",
      "Training round [145/200], Epoch [1/5], Step [20/47], Loss: 0.0333, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [1/5], Step [40/47], Loss: 0.0443, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [2/5], Step [20/47], Loss: 0.1096, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [145/200], Epoch [2/5], Step [40/47], Loss: 0.0499, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [3/5], Step [20/47], Loss: 0.0550, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [145/200], Epoch [3/5], Step [40/47], Loss: 0.0513, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [4/5], Step [20/47], Loss: 0.0438, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [145/200], Epoch [4/5], Step [40/47], Loss: 0.0503, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [5/5], Step [20/47], Loss: 0.0582, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [145/200], Epoch [5/5], Step [40/47], Loss: 0.0756, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [145/200], qnn_train_step: [100/1000], loss: 0.03014821745455265, accuracy: 98.9 %\n",
      "Training round [145/200], qnn_train_step: [200/1000], loss: 0.6246817708015442, accuracy: 81.3 %\n",
      "Training round [145/200], qnn_train_step: [300/1000], loss: 0.028547324240207672, accuracy: 98.9 %\n",
      "Training round [145/200], qnn_train_step: [400/1000], loss: 0.025184430181980133, accuracy: 99.4 %\n",
      "Training round [145/200], qnn_train_step: [500/1000], loss: 0.02145380713045597, accuracy: 99.4 %\n",
      "Training round [145/200], qnn_train_step: [600/1000], loss: 0.02031252346932888, accuracy: 99.6 %\n",
      "Training round [145/200], qnn_train_step: [700/1000], loss: 0.02265012636780739, accuracy: 99.4 %\n",
      "Training round [145/200], qnn_train_step: [800/1000], loss: 0.01935497671365738, accuracy: 99.7 %\n",
      "Training round [145/200], qnn_train_step: [900/1000], loss: 0.018834713846445084, accuracy: 99.5 %\n",
      "Training round [145/200], qnn_train_step: [1000/1000], loss: 0.018400035798549652, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [146/200], Epoch [1/5], Step [20/47], Loss: 0.0540, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [1/5], Step [40/47], Loss: 0.0741, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [146/200], Epoch [2/5], Step [20/47], Loss: 0.0124, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [146/200], Epoch [2/5], Step [40/47], Loss: 0.0727, batch time: 0.07, accuracy:  97.66%\n",
      "Training round [146/200], Epoch [3/5], Step [20/47], Loss: 0.0500, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [146/200], Epoch [3/5], Step [40/47], Loss: 0.0537, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [146/200], Epoch [4/5], Step [20/47], Loss: 0.0566, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [4/5], Step [40/47], Loss: 0.0316, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [146/200], Epoch [5/5], Step [20/47], Loss: 0.0087, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [146/200], Epoch [5/5], Step [40/47], Loss: 0.0691, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [146/200], qnn_train_step: [100/1000], loss: 0.06255541741847992, accuracy: 97.9 %\n",
      "Training round [146/200], qnn_train_step: [200/1000], loss: 0.24719633162021637, accuracy: 92.4 %\n",
      "Training round [146/200], qnn_train_step: [300/1000], loss: 0.0720641016960144, accuracy: 97.6 %\n",
      "Training round [146/200], qnn_train_step: [400/1000], loss: 0.04853598773479462, accuracy: 98.6 %\n",
      "Training round [146/200], qnn_train_step: [500/1000], loss: 0.05302891507744789, accuracy: 98.3 %\n",
      "Training round [146/200], qnn_train_step: [600/1000], loss: 0.03917147219181061, accuracy: 98.9 %\n",
      "Training round [146/200], qnn_train_step: [700/1000], loss: 0.03933171182870865, accuracy: 98.9 %\n",
      "Training round [146/200], qnn_train_step: [800/1000], loss: 0.041414763778448105, accuracy: 98.7 %\n",
      "Training round [146/200], qnn_train_step: [900/1000], loss: 0.05845355987548828, accuracy: 98.4 %\n",
      "Training round [146/200], qnn_train_step: [1000/1000], loss: 0.03861311823129654, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [147/200], Epoch [1/5], Step [20/47], Loss: 0.0554, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [1/5], Step [40/47], Loss: 0.1053, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [2/5], Step [20/47], Loss: 0.0959, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [147/200], Epoch [2/5], Step [40/47], Loss: 0.0172, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [147/200], Epoch [3/5], Step [20/47], Loss: 0.0227, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [147/200], Epoch [3/5], Step [40/47], Loss: 0.0857, batch time: 0.09, accuracy:  96.09%\n",
      "Training round [147/200], Epoch [4/5], Step [20/47], Loss: 0.1017, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [4/5], Step [40/47], Loss: 0.0188, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [147/200], Epoch [5/5], Step [20/47], Loss: 0.0102, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [147/200], Epoch [5/5], Step [40/47], Loss: 0.0693, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [147/200], qnn_train_step: [100/1000], loss: 0.04802631214261055, accuracy: 98.5 %\n",
      "Training round [147/200], qnn_train_step: [200/1000], loss: 0.1394214928150177, accuracy: 95.6 %\n",
      "Training round [147/200], qnn_train_step: [300/1000], loss: 0.049433160573244095, accuracy: 98.4 %\n",
      "Training round [147/200], qnn_train_step: [400/1000], loss: 0.043033767491579056, accuracy: 98.5 %\n",
      "Training round [147/200], qnn_train_step: [500/1000], loss: 0.0430007204413414, accuracy: 98.6 %\n",
      "Training round [147/200], qnn_train_step: [600/1000], loss: 0.04574679583311081, accuracy: 98.2 %\n",
      "Training round [147/200], qnn_train_step: [700/1000], loss: 0.04981550946831703, accuracy: 98.3 %\n",
      "Training round [147/200], qnn_train_step: [800/1000], loss: 0.04069161042571068, accuracy: 98.5 %\n",
      "Training round [147/200], qnn_train_step: [900/1000], loss: 0.041116271167993546, accuracy: 98.6 %\n",
      "Training round [147/200], qnn_train_step: [1000/1000], loss: 0.04035111516714096, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [148/200], Epoch [1/5], Step [20/47], Loss: 0.0076, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [148/200], Epoch [1/5], Step [40/47], Loss: 0.0876, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [148/200], Epoch [2/5], Step [20/47], Loss: 0.0600, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [148/200], Epoch [2/5], Step [40/47], Loss: 0.0397, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [3/5], Step [20/47], Loss: 0.0542, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [3/5], Step [40/47], Loss: 0.0358, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [4/5], Step [20/47], Loss: 0.0395, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [148/200], Epoch [4/5], Step [40/47], Loss: 0.0563, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [5/5], Step [20/47], Loss: 0.0646, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], Epoch [5/5], Step [40/47], Loss: 0.0985, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [148/200], qnn_train_step: [100/1000], loss: 0.05396442487835884, accuracy: 98.3 %\n",
      "Training round [148/200], qnn_train_step: [200/1000], loss: 0.7141022682189941, accuracy: 80.2 %\n",
      "Training round [148/200], qnn_train_step: [300/1000], loss: 0.05352703854441643, accuracy: 98.1 %\n",
      "Training round [148/200], qnn_train_step: [400/1000], loss: 0.0451824888586998, accuracy: 98.6 %\n",
      "Training round [148/200], qnn_train_step: [500/1000], loss: 0.04551148787140846, accuracy: 98.3 %\n",
      "Training round [148/200], qnn_train_step: [600/1000], loss: 0.043580375611782074, accuracy: 98.8 %\n",
      "Training round [148/200], qnn_train_step: [700/1000], loss: 0.0437045693397522, accuracy: 98.6 %\n",
      "Training round [148/200], qnn_train_step: [800/1000], loss: 0.04474980756640434, accuracy: 98.7 %\n",
      "Training round [148/200], qnn_train_step: [900/1000], loss: 0.038826532661914825, accuracy: 98.8 %\n",
      "Training round [148/200], qnn_train_step: [1000/1000], loss: 0.03701649233698845, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [149/200], Epoch [1/5], Step [20/47], Loss: 0.0853, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [1/5], Step [40/47], Loss: 0.0800, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [149/200], Epoch [2/5], Step [20/47], Loss: 0.1246, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [149/200], Epoch [2/5], Step [40/47], Loss: 0.0201, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [149/200], Epoch [3/5], Step [20/47], Loss: 0.0421, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [3/5], Step [40/47], Loss: 0.0577, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [149/200], Epoch [4/5], Step [20/47], Loss: 0.0277, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [149/200], Epoch [4/5], Step [40/47], Loss: 0.0370, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [149/200], Epoch [5/5], Step [20/47], Loss: 0.0374, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [149/200], Epoch [5/5], Step [40/47], Loss: 0.0932, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [149/200], qnn_train_step: [100/1000], loss: 0.07224807143211365, accuracy: 97.1 %\n",
      "Training round [149/200], qnn_train_step: [200/1000], loss: 0.6517646908760071, accuracy: 80.7 %\n",
      "Training round [149/200], qnn_train_step: [300/1000], loss: 0.14717762172222137, accuracy: 95.1 %\n",
      "Training round [149/200], qnn_train_step: [400/1000], loss: 0.07808644324541092, accuracy: 97.3 %\n",
      "Training round [149/200], qnn_train_step: [500/1000], loss: 0.06143099442124367, accuracy: 98.2 %\n",
      "Training round [149/200], qnn_train_step: [600/1000], loss: 0.0562758706510067, accuracy: 98.0 %\n",
      "Training round [149/200], qnn_train_step: [700/1000], loss: 0.07123199105262756, accuracy: 97.7 %\n",
      "Training round [149/200], qnn_train_step: [800/1000], loss: 0.05334180220961571, accuracy: 98.4 %\n",
      "Training round [149/200], qnn_train_step: [900/1000], loss: 0.053324464708566666, accuracy: 98.2 %\n",
      "Training round [149/200], qnn_train_step: [1000/1000], loss: 0.05496137589216232, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [150/200], Epoch [1/5], Step [20/47], Loss: 0.0737, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [150/200], Epoch [1/5], Step [40/47], Loss: 0.0283, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [2/5], Step [20/47], Loss: 0.1727, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [150/200], Epoch [2/5], Step [40/47], Loss: 0.0338, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [150/200], Epoch [3/5], Step [20/47], Loss: 0.0765, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [150/200], Epoch [3/5], Step [40/47], Loss: 0.0949, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [150/200], Epoch [4/5], Step [20/47], Loss: 0.0317, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [4/5], Step [40/47], Loss: 0.0543, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [150/200], Epoch [5/5], Step [20/47], Loss: 0.0982, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [150/200], Epoch [5/5], Step [40/47], Loss: 0.1124, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [150/200], qnn_train_step: [100/1000], loss: 0.03650147095322609, accuracy: 98.6 %\n",
      "Training round [150/200], qnn_train_step: [200/1000], loss: 1.164705514907837, accuracy: 71.7 %\n",
      "Training round [150/200], qnn_train_step: [300/1000], loss: 0.24285109341144562, accuracy: 92.5 %\n",
      "Training round [150/200], qnn_train_step: [400/1000], loss: 0.11193640530109406, accuracy: 96.2 %\n",
      "Training round [150/200], qnn_train_step: [500/1000], loss: 0.027092494070529938, accuracy: 99.1 %\n",
      "Training round [150/200], qnn_train_step: [600/1000], loss: 0.026475053280591965, accuracy: 99.3 %\n",
      "Training round [150/200], qnn_train_step: [700/1000], loss: 0.026106657460331917, accuracy: 99.3 %\n",
      "Training round [150/200], qnn_train_step: [800/1000], loss: 0.03205783665180206, accuracy: 99.0 %\n",
      "Training round [150/200], qnn_train_step: [900/1000], loss: 0.027248552069067955, accuracy: 99.1 %\n",
      "Training round [150/200], qnn_train_step: [1000/1000], loss: 0.0364353246986866, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [151/200], Epoch [1/5], Step [20/47], Loss: 0.0500, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [1/5], Step [40/47], Loss: 0.0416, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [151/200], Epoch [2/5], Step [20/47], Loss: 0.0679, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [151/200], Epoch [2/5], Step [40/47], Loss: 0.0435, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [3/5], Step [20/47], Loss: 0.1507, batch time: 0.08, accuracy:  96.09%\n",
      "Training round [151/200], Epoch [3/5], Step [40/47], Loss: 0.0905, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [4/5], Step [20/47], Loss: 0.0363, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [151/200], Epoch [4/5], Step [40/47], Loss: 0.1010, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [5/5], Step [20/47], Loss: 0.0790, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [151/200], Epoch [5/5], Step [40/47], Loss: 0.0898, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [151/200], qnn_train_step: [100/1000], loss: 0.055037721991539, accuracy: 97.9 %\n",
      "Training round [151/200], qnn_train_step: [200/1000], loss: 0.6365005970001221, accuracy: 80.2 %\n",
      "Training round [151/200], qnn_train_step: [300/1000], loss: 0.04915490746498108, accuracy: 98.2 %\n",
      "Training round [151/200], qnn_train_step: [400/1000], loss: 0.04850650951266289, accuracy: 98.3 %\n",
      "Training round [151/200], qnn_train_step: [500/1000], loss: 0.045804593712091446, accuracy: 98.5 %\n",
      "Training round [151/200], qnn_train_step: [600/1000], loss: 0.04478173702955246, accuracy: 98.5 %\n",
      "Training round [151/200], qnn_train_step: [700/1000], loss: 0.04663197696208954, accuracy: 98.4 %\n",
      "Training round [151/200], qnn_train_step: [800/1000], loss: 0.0702195093035698, accuracy: 97.7 %\n",
      "Training round [151/200], qnn_train_step: [900/1000], loss: 0.04630160704255104, accuracy: 98.2 %\n",
      "Training round [151/200], qnn_train_step: [1000/1000], loss: 0.04563898965716362, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [152/200], Epoch [1/5], Step [20/47], Loss: 0.0534, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [152/200], Epoch [1/5], Step [40/47], Loss: 0.0402, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [2/5], Step [20/47], Loss: 0.1525, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [2/5], Step [40/47], Loss: 0.0927, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [3/5], Step [20/47], Loss: 0.0989, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [3/5], Step [40/47], Loss: 0.0596, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [152/200], Epoch [4/5], Step [20/47], Loss: 0.0424, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [152/200], Epoch [4/5], Step [40/47], Loss: 0.1288, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [152/200], Epoch [5/5], Step [20/47], Loss: 0.0328, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [152/200], Epoch [5/5], Step [40/47], Loss: 0.0350, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [152/200], qnn_train_step: [100/1000], loss: 0.03915274143218994, accuracy: 98.8 %\n",
      "Training round [152/200], qnn_train_step: [200/1000], loss: 0.13762934505939484, accuracy: 94.6 %\n",
      "Training round [152/200], qnn_train_step: [300/1000], loss: 0.038402605801820755, accuracy: 98.9 %\n",
      "Training round [152/200], qnn_train_step: [400/1000], loss: 0.03681650385260582, accuracy: 99.0 %\n",
      "Training round [152/200], qnn_train_step: [500/1000], loss: 0.03658697009086609, accuracy: 99.0 %\n",
      "Training round [152/200], qnn_train_step: [600/1000], loss: 0.03616519644856453, accuracy: 99.0 %\n",
      "Training round [152/200], qnn_train_step: [700/1000], loss: 0.03859703242778778, accuracy: 98.9 %\n",
      "Training round [152/200], qnn_train_step: [800/1000], loss: 0.03428366780281067, accuracy: 99.2 %\n",
      "Training round [152/200], qnn_train_step: [900/1000], loss: 0.033566612750291824, accuracy: 99.3 %\n",
      "Training round [152/200], qnn_train_step: [1000/1000], loss: 0.03335290774703026, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [153/200], Epoch [1/5], Step [20/47], Loss: 0.1399, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [1/5], Step [40/47], Loss: 0.1196, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [2/5], Step [20/47], Loss: 0.0400, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [2/5], Step [40/47], Loss: 0.1020, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [153/200], Epoch [3/5], Step [20/47], Loss: 0.0303, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [3/5], Step [40/47], Loss: 0.0794, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [4/5], Step [20/47], Loss: 0.0200, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [153/200], Epoch [4/5], Step [40/47], Loss: 0.1239, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [153/200], Epoch [5/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [153/200], Epoch [5/5], Step [40/47], Loss: 0.0364, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [153/200], qnn_train_step: [100/1000], loss: 0.07330437749624252, accuracy: 97.9 %\n",
      "Training round [153/200], qnn_train_step: [200/1000], loss: 0.19829829037189484, accuracy: 93.8 %\n",
      "Training round [153/200], qnn_train_step: [300/1000], loss: 0.06706525385379791, accuracy: 98.3 %\n",
      "Training round [153/200], qnn_train_step: [400/1000], loss: 0.06351487338542938, accuracy: 98.4 %\n",
      "Training round [153/200], qnn_train_step: [500/1000], loss: 0.06197890639305115, accuracy: 98.4 %\n",
      "Training round [153/200], qnn_train_step: [600/1000], loss: 0.05947702005505562, accuracy: 98.4 %\n",
      "Training round [153/200], qnn_train_step: [700/1000], loss: 0.05911977216601372, accuracy: 98.6 %\n",
      "Training round [153/200], qnn_train_step: [800/1000], loss: 0.06645886600017548, accuracy: 97.9 %\n",
      "Training round [153/200], qnn_train_step: [900/1000], loss: 0.058786701411008835, accuracy: 98.6 %\n",
      "Training round [153/200], qnn_train_step: [1000/1000], loss: 0.05918189883232117, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [154/200], Epoch [1/5], Step [20/47], Loss: 0.0245, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [1/5], Step [40/47], Loss: 0.0401, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [2/5], Step [20/47], Loss: 0.0268, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [154/200], Epoch [2/5], Step [40/47], Loss: 0.0522, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [3/5], Step [20/47], Loss: 0.0548, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], Epoch [3/5], Step [40/47], Loss: 0.0306, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [154/200], Epoch [4/5], Step [20/47], Loss: 0.0147, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [4/5], Step [40/47], Loss: 0.0278, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [154/200], Epoch [5/5], Step [20/47], Loss: 0.0677, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [154/200], Epoch [5/5], Step [40/47], Loss: 0.0503, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [154/200], qnn_train_step: [100/1000], loss: 0.030200261622667313, accuracy: 99.1 %\n",
      "Training round [154/200], qnn_train_step: [200/1000], loss: 0.0508752278983593, accuracy: 98.7 %\n",
      "Training round [154/200], qnn_train_step: [300/1000], loss: 0.037959784269332886, accuracy: 98.3 %\n",
      "Training round [154/200], qnn_train_step: [400/1000], loss: 0.026625197380781174, accuracy: 99.2 %\n",
      "Training round [154/200], qnn_train_step: [500/1000], loss: 0.02339000441133976, accuracy: 99.4 %\n",
      "Training round [154/200], qnn_train_step: [600/1000], loss: 0.030402060598134995, accuracy: 99.0 %\n",
      "Training round [154/200], qnn_train_step: [700/1000], loss: 0.04003331810235977, accuracy: 98.3 %\n",
      "Training round [154/200], qnn_train_step: [800/1000], loss: 0.022941889241337776, accuracy: 99.5 %\n",
      "Training round [154/200], qnn_train_step: [900/1000], loss: 0.022380243986845016, accuracy: 99.3 %\n",
      "Training round [154/200], qnn_train_step: [1000/1000], loss: 0.025731243193149567, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [155/200], Epoch [1/5], Step [20/47], Loss: 0.0426, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [1/5], Step [40/47], Loss: 0.0141, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [155/200], Epoch [2/5], Step [20/47], Loss: 0.0612, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [2/5], Step [40/47], Loss: 0.0858, batch time: 0.08, accuracy:  95.31%\n",
      "Training round [155/200], Epoch [3/5], Step [20/47], Loss: 0.1085, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [155/200], Epoch [3/5], Step [40/47], Loss: 0.0800, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [4/5], Step [20/47], Loss: 0.0320, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [4/5], Step [40/47], Loss: 0.0832, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [155/200], Epoch [5/5], Step [20/47], Loss: 0.0366, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [155/200], Epoch [5/5], Step [40/47], Loss: 0.0486, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [155/200], qnn_train_step: [100/1000], loss: 0.035614561289548874, accuracy: 98.5 %\n",
      "Training round [155/200], qnn_train_step: [200/1000], loss: 0.3985695540904999, accuracy: 93.0 %\n",
      "Training round [155/200], qnn_train_step: [300/1000], loss: 0.05162568762898445, accuracy: 97.9 %\n",
      "Training round [155/200], qnn_train_step: [400/1000], loss: 0.02845240756869316, accuracy: 98.9 %\n",
      "Training round [155/200], qnn_train_step: [500/1000], loss: 0.027613067999482155, accuracy: 98.9 %\n",
      "Training round [155/200], qnn_train_step: [600/1000], loss: 0.025509752333164215, accuracy: 99.2 %\n",
      "Training round [155/200], qnn_train_step: [700/1000], loss: 0.027356404811143875, accuracy: 98.9 %\n",
      "Training round [155/200], qnn_train_step: [800/1000], loss: 0.02446833811700344, accuracy: 99.0 %\n",
      "Training round [155/200], qnn_train_step: [900/1000], loss: 0.031743552535772324, accuracy: 98.5 %\n",
      "Training round [155/200], qnn_train_step: [1000/1000], loss: 0.04154236987233162, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [156/200], Epoch [1/5], Step [20/47], Loss: 0.0230, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [156/200], Epoch [1/5], Step [40/47], Loss: 0.0760, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [156/200], Epoch [2/5], Step [20/47], Loss: 0.1625, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [156/200], Epoch [2/5], Step [40/47], Loss: 0.0160, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [156/200], Epoch [3/5], Step [20/47], Loss: 0.0724, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [156/200], Epoch [3/5], Step [40/47], Loss: 0.0081, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [156/200], Epoch [4/5], Step [20/47], Loss: 0.0600, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [4/5], Step [40/47], Loss: 0.0244, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [156/200], Epoch [5/5], Step [20/47], Loss: 0.0246, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [156/200], Epoch [5/5], Step [40/47], Loss: 0.0925, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [156/200], qnn_train_step: [100/1000], loss: 0.05613439157605171, accuracy: 98.3 %\n",
      "Training round [156/200], qnn_train_step: [200/1000], loss: 0.22924202680587769, accuracy: 92.1 %\n",
      "Training round [156/200], qnn_train_step: [300/1000], loss: 0.2881056070327759, accuracy: 92.1 %\n",
      "Training round [156/200], qnn_train_step: [400/1000], loss: 0.05034276098012924, accuracy: 98.7 %\n",
      "Training round [156/200], qnn_train_step: [500/1000], loss: 0.058695852756500244, accuracy: 98.5 %\n",
      "Training round [156/200], qnn_train_step: [600/1000], loss: 0.04484473168849945, accuracy: 99.0 %\n",
      "Training round [156/200], qnn_train_step: [700/1000], loss: 0.04410499334335327, accuracy: 99.0 %\n",
      "Training round [156/200], qnn_train_step: [800/1000], loss: 0.0486091673374176, accuracy: 98.7 %\n",
      "Training round [156/200], qnn_train_step: [900/1000], loss: 0.044455356895923615, accuracy: 98.7 %\n",
      "Training round [156/200], qnn_train_step: [1000/1000], loss: 0.04269838333129883, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [157/200], Epoch [1/5], Step [20/47], Loss: 0.0420, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [157/200], Epoch [1/5], Step [40/47], Loss: 0.1210, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [157/200], Epoch [2/5], Step [20/47], Loss: 0.0474, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [2/5], Step [40/47], Loss: 0.0889, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [3/5], Step [20/47], Loss: 0.0890, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [3/5], Step [40/47], Loss: 0.0697, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [157/200], Epoch [4/5], Step [20/47], Loss: 0.1082, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [157/200], Epoch [4/5], Step [40/47], Loss: 0.0838, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [157/200], Epoch [5/5], Step [20/47], Loss: 0.0545, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [157/200], Epoch [5/5], Step [40/47], Loss: 0.0373, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [157/200], qnn_train_step: [100/1000], loss: 0.046917930245399475, accuracy: 98.3 %\n",
      "Training round [157/200], qnn_train_step: [200/1000], loss: 0.665582537651062, accuracy: 83.4 %\n",
      "Training round [157/200], qnn_train_step: [300/1000], loss: 0.25637534260749817, accuracy: 94.1 %\n",
      "Training round [157/200], qnn_train_step: [400/1000], loss: 0.04054301604628563, accuracy: 98.8 %\n",
      "Training round [157/200], qnn_train_step: [500/1000], loss: 0.04182692989706993, accuracy: 98.4 %\n",
      "Training round [157/200], qnn_train_step: [600/1000], loss: 0.040595412254333496, accuracy: 98.9 %\n",
      "Training round [157/200], qnn_train_step: [700/1000], loss: 0.03745191544294357, accuracy: 99.0 %\n",
      "Training round [157/200], qnn_train_step: [800/1000], loss: 0.03660690039396286, accuracy: 99.0 %\n",
      "Training round [157/200], qnn_train_step: [900/1000], loss: 0.03526084125041962, accuracy: 99.0 %\n",
      "Training round [157/200], qnn_train_step: [1000/1000], loss: 0.03464756906032562, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [158/200], Epoch [1/5], Step [20/47], Loss: 0.0134, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [158/200], Epoch [1/5], Step [40/47], Loss: 0.0657, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [158/200], Epoch [2/5], Step [20/47], Loss: 0.0156, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [158/200], Epoch [2/5], Step [40/47], Loss: 0.0972, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [158/200], Epoch [3/5], Step [20/47], Loss: 0.0334, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [158/200], Epoch [3/5], Step [40/47], Loss: 0.0716, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [4/5], Step [20/47], Loss: 0.0308, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [158/200], Epoch [4/5], Step [40/47], Loss: 0.0353, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [158/200], Epoch [5/5], Step [20/47], Loss: 0.0774, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], Epoch [5/5], Step [40/47], Loss: 0.0291, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [158/200], qnn_train_step: [100/1000], loss: 0.04000077024102211, accuracy: 98.7 %\n",
      "Training round [158/200], qnn_train_step: [200/1000], loss: 0.43517348170280457, accuracy: 87.2 %\n",
      "Training round [158/200], qnn_train_step: [300/1000], loss: 0.09170868992805481, accuracy: 96.5 %\n",
      "Training round [158/200], qnn_train_step: [400/1000], loss: 0.03283614665269852, accuracy: 98.7 %\n",
      "Training round [158/200], qnn_train_step: [500/1000], loss: 0.03181440010666847, accuracy: 99.2 %\n",
      "Training round [158/200], qnn_train_step: [600/1000], loss: 0.032096073031425476, accuracy: 98.9 %\n",
      "Training round [158/200], qnn_train_step: [700/1000], loss: 0.03438312187790871, accuracy: 98.7 %\n",
      "Training round [158/200], qnn_train_step: [800/1000], loss: 0.028464872390031815, accuracy: 98.8 %\n",
      "Training round [158/200], qnn_train_step: [900/1000], loss: 0.02998899482190609, accuracy: 98.9 %\n",
      "Training round [158/200], qnn_train_step: [1000/1000], loss: 0.02676871232688427, accuracy: 99.1 %\n",
      "-----------------------\n",
      "Training round [159/200], Epoch [1/5], Step [20/47], Loss: 0.0459, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [1/5], Step [40/47], Loss: 0.0525, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [2/5], Step [20/47], Loss: 0.0826, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [2/5], Step [40/47], Loss: 0.0610, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [159/200], Epoch [3/5], Step [20/47], Loss: 0.0289, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [3/5], Step [40/47], Loss: 0.0580, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [159/200], Epoch [4/5], Step [20/47], Loss: 0.0294, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [159/200], Epoch [4/5], Step [40/47], Loss: 0.0562, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [159/200], Epoch [5/5], Step [20/47], Loss: 0.1808, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [159/200], Epoch [5/5], Step [40/47], Loss: 0.1338, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [159/200], qnn_train_step: [100/1000], loss: 0.04249769076704979, accuracy: 98.6 %\n",
      "Training round [159/200], qnn_train_step: [200/1000], loss: 0.23287568986415863, accuracy: 92.1 %\n",
      "Training round [159/200], qnn_train_step: [300/1000], loss: 0.7061183452606201, accuracy: 81.3 %\n",
      "Training round [159/200], qnn_train_step: [400/1000], loss: 0.03644971922039986, accuracy: 99.2 %\n",
      "Training round [159/200], qnn_train_step: [500/1000], loss: 0.034012481570243835, accuracy: 99.0 %\n",
      "Training round [159/200], qnn_train_step: [600/1000], loss: 0.033609919250011444, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [700/1000], loss: 0.034376900643110275, accuracy: 99.3 %\n",
      "Training round [159/200], qnn_train_step: [800/1000], loss: 0.03199212625622749, accuracy: 99.4 %\n",
      "Training round [159/200], qnn_train_step: [900/1000], loss: 0.03162290155887604, accuracy: 99.5 %\n",
      "Training round [159/200], qnn_train_step: [1000/1000], loss: 0.04183725267648697, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [160/200], Epoch [1/5], Step [20/47], Loss: 0.0437, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [1/5], Step [40/47], Loss: 0.0266, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [2/5], Step [20/47], Loss: 0.0462, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [2/5], Step [40/47], Loss: 0.0531, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [3/5], Step [20/47], Loss: 0.0695, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [160/200], Epoch [3/5], Step [40/47], Loss: 0.1439, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [160/200], Epoch [4/5], Step [20/47], Loss: 0.0950, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [160/200], Epoch [4/5], Step [40/47], Loss: 0.0278, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [160/200], Epoch [5/5], Step [20/47], Loss: 0.0990, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [160/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [160/200], qnn_train_step: [100/1000], loss: 0.06215918809175491, accuracy: 97.9 %\n",
      "Training round [160/200], qnn_train_step: [200/1000], loss: 0.5314626097679138, accuracy: 83.7 %\n",
      "Training round [160/200], qnn_train_step: [300/1000], loss: 0.1015903428196907, accuracy: 97.0 %\n",
      "Training round [160/200], qnn_train_step: [400/1000], loss: 0.05624447390437126, accuracy: 98.0 %\n",
      "Training round [160/200], qnn_train_step: [500/1000], loss: 0.04502757638692856, accuracy: 98.6 %\n",
      "Training round [160/200], qnn_train_step: [600/1000], loss: 0.03997096046805382, accuracy: 99.0 %\n",
      "Training round [160/200], qnn_train_step: [700/1000], loss: 0.04074873775243759, accuracy: 98.9 %\n",
      "Training round [160/200], qnn_train_step: [800/1000], loss: 0.037728384137153625, accuracy: 99.1 %\n",
      "Training round [160/200], qnn_train_step: [900/1000], loss: 0.04128032177686691, accuracy: 99.0 %\n",
      "Training round [160/200], qnn_train_step: [1000/1000], loss: 0.03771883621811867, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [161/200], Epoch [1/5], Step [20/47], Loss: 0.0182, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [1/5], Step [40/47], Loss: 0.1971, batch time: 0.11, accuracy:  92.97%\n",
      "Training round [161/200], Epoch [2/5], Step [20/47], Loss: 0.0297, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [2/5], Step [40/47], Loss: 0.0638, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [3/5], Step [20/47], Loss: 0.0308, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [161/200], Epoch [3/5], Step [40/47], Loss: 0.1045, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [4/5], Step [20/47], Loss: 0.1001, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [161/200], Epoch [4/5], Step [40/47], Loss: 0.0278, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [161/200], Epoch [5/5], Step [20/47], Loss: 0.0181, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [161/200], Epoch [5/5], Step [40/47], Loss: 0.0586, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [161/200], qnn_train_step: [100/1000], loss: 0.027139076963067055, accuracy: 98.9 %\n",
      "Training round [161/200], qnn_train_step: [200/1000], loss: 0.3387712240219116, accuracy: 90.5 %\n",
      "Training round [161/200], qnn_train_step: [300/1000], loss: 0.027537640184164047, accuracy: 99.0 %\n",
      "Training round [161/200], qnn_train_step: [400/1000], loss: 0.028581086546182632, accuracy: 99.0 %\n",
      "Training round [161/200], qnn_train_step: [500/1000], loss: 0.025553366169333458, accuracy: 99.2 %\n",
      "Training round [161/200], qnn_train_step: [600/1000], loss: 0.025290079414844513, accuracy: 99.1 %\n",
      "Training round [161/200], qnn_train_step: [700/1000], loss: 0.023643027991056442, accuracy: 99.1 %\n",
      "Training round [161/200], qnn_train_step: [800/1000], loss: 0.024159541353583336, accuracy: 99.2 %\n",
      "Training round [161/200], qnn_train_step: [900/1000], loss: 0.028531834483146667, accuracy: 99.2 %\n",
      "Training round [161/200], qnn_train_step: [1000/1000], loss: 0.02338092029094696, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [162/200], Epoch [1/5], Step [20/47], Loss: 0.0592, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [1/5], Step [40/47], Loss: 0.0372, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [162/200], Epoch [2/5], Step [20/47], Loss: 0.0682, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [2/5], Step [40/47], Loss: 0.0671, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [3/5], Step [20/47], Loss: 0.0423, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [162/200], Epoch [3/5], Step [40/47], Loss: 0.0875, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [4/5], Step [20/47], Loss: 0.0882, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [162/200], Epoch [4/5], Step [40/47], Loss: 0.0897, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [162/200], Epoch [5/5], Step [20/47], Loss: 0.0492, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [162/200], Epoch [5/5], Step [40/47], Loss: 0.0675, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [162/200], qnn_train_step: [100/1000], loss: 0.03825107961893082, accuracy: 98.3 %\n",
      "Training round [162/200], qnn_train_step: [200/1000], loss: 0.40775591135025024, accuracy: 88.0 %\n",
      "Training round [162/200], qnn_train_step: [300/1000], loss: 3.9285337924957275, accuracy: 61.4 %\n",
      "Training round [162/200], qnn_train_step: [400/1000], loss: 0.033817823976278305, accuracy: 98.7 %\n",
      "Training round [162/200], qnn_train_step: [500/1000], loss: 0.033134449273347855, accuracy: 98.6 %\n",
      "Training round [162/200], qnn_train_step: [600/1000], loss: 0.03220042958855629, accuracy: 98.6 %\n",
      "Training round [162/200], qnn_train_step: [700/1000], loss: 0.03109755739569664, accuracy: 98.5 %\n",
      "Training round [162/200], qnn_train_step: [800/1000], loss: 0.03050069883465767, accuracy: 98.6 %\n",
      "Training round [162/200], qnn_train_step: [900/1000], loss: 0.030396249145269394, accuracy: 98.5 %\n",
      "Training round [162/200], qnn_train_step: [1000/1000], loss: 0.029725462198257446, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [163/200], Epoch [1/5], Step [20/47], Loss: 0.0489, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [163/200], Epoch [1/5], Step [40/47], Loss: 0.0454, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [2/5], Step [20/47], Loss: 0.0343, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [2/5], Step [40/47], Loss: 0.0440, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [3/5], Step [20/47], Loss: 0.0520, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [163/200], Epoch [3/5], Step [40/47], Loss: 0.0701, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [4/5], Step [20/47], Loss: 0.0464, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [163/200], Epoch [4/5], Step [40/47], Loss: 0.0254, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [163/200], Epoch [5/5], Step [20/47], Loss: 0.0846, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [163/200], Epoch [5/5], Step [40/47], Loss: 0.0505, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [163/200], qnn_train_step: [100/1000], loss: 0.049379862844944, accuracy: 98.4 %\n",
      "Training round [163/200], qnn_train_step: [200/1000], loss: 0.41036269068717957, accuracy: 89.1 %\n",
      "Training round [163/200], qnn_train_step: [300/1000], loss: 0.05307978391647339, accuracy: 98.5 %\n",
      "Training round [163/200], qnn_train_step: [400/1000], loss: 0.05382240563631058, accuracy: 98.0 %\n",
      "Training round [163/200], qnn_train_step: [500/1000], loss: 0.048482026904821396, accuracy: 98.1 %\n",
      "Training round [163/200], qnn_train_step: [600/1000], loss: 0.04541498050093651, accuracy: 98.8 %\n",
      "Training round [163/200], qnn_train_step: [700/1000], loss: 0.06621810793876648, accuracy: 97.6 %\n",
      "Training round [163/200], qnn_train_step: [800/1000], loss: 0.04092738404870033, accuracy: 98.7 %\n",
      "Training round [163/200], qnn_train_step: [900/1000], loss: 0.042435865849256516, accuracy: 98.8 %\n",
      "Training round [163/200], qnn_train_step: [1000/1000], loss: 0.04036422446370125, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [164/200], Epoch [1/5], Step [20/47], Loss: 0.0425, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [1/5], Step [40/47], Loss: 0.0123, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [164/200], Epoch [2/5], Step [20/47], Loss: 0.0368, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [2/5], Step [40/47], Loss: 0.0870, batch time: 0.06, accuracy:  97.66%\n",
      "Training round [164/200], Epoch [3/5], Step [20/47], Loss: 0.0466, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [3/5], Step [40/47], Loss: 0.0865, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [4/5], Step [20/47], Loss: 0.0203, batch time: 0.07, accuracy:  99.22%\n",
      "Training round [164/200], Epoch [4/5], Step [40/47], Loss: 0.0642, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [164/200], Epoch [5/5], Step [20/47], Loss: 0.1534, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [164/200], Epoch [5/5], Step [40/47], Loss: 0.0537, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [164/200], qnn_train_step: [100/1000], loss: 0.055032990872859955, accuracy: 98.0 %\n",
      "Training round [164/200], qnn_train_step: [200/1000], loss: 0.5042843818664551, accuracy: 82.5 %\n",
      "Training round [164/200], qnn_train_step: [300/1000], loss: 0.22548368573188782, accuracy: 92.5 %\n",
      "Training round [164/200], qnn_train_step: [400/1000], loss: 0.0441950224339962, accuracy: 98.5 %\n",
      "Training round [164/200], qnn_train_step: [500/1000], loss: 0.05010822042822838, accuracy: 98.2 %\n",
      "Training round [164/200], qnn_train_step: [600/1000], loss: 0.0392642505466938, accuracy: 98.8 %\n",
      "Training round [164/200], qnn_train_step: [700/1000], loss: 0.040475279092788696, accuracy: 98.9 %\n",
      "Training round [164/200], qnn_train_step: [800/1000], loss: 0.03715517371892929, accuracy: 99.0 %\n",
      "Training round [164/200], qnn_train_step: [900/1000], loss: 0.04230014234781265, accuracy: 98.5 %\n",
      "Training round [164/200], qnn_train_step: [1000/1000], loss: 0.03568992391228676, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [165/200], Epoch [1/5], Step [20/47], Loss: 0.0524, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [1/5], Step [40/47], Loss: 0.0576, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [2/5], Step [20/47], Loss: 0.0991, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [165/200], Epoch [2/5], Step [40/47], Loss: 0.0353, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [3/5], Step [20/47], Loss: 0.0712, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [165/200], Epoch [3/5], Step [40/47], Loss: 0.0483, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [4/5], Step [20/47], Loss: 0.0892, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [165/200], Epoch [4/5], Step [40/47], Loss: 0.0702, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [5/5], Step [20/47], Loss: 0.0476, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [165/200], Epoch [5/5], Step [40/47], Loss: 0.0477, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [165/200], qnn_train_step: [100/1000], loss: 0.039602480828762054, accuracy: 98.3 %\n",
      "Training round [165/200], qnn_train_step: [200/1000], loss: 1.897033452987671, accuracy: 75.2 %\n",
      "Training round [165/200], qnn_train_step: [300/1000], loss: 0.0335969440639019, accuracy: 99.0 %\n",
      "Training round [165/200], qnn_train_step: [400/1000], loss: 0.03192267194390297, accuracy: 98.9 %\n",
      "Training round [165/200], qnn_train_step: [500/1000], loss: 0.03180118277668953, accuracy: 98.9 %\n",
      "Training round [165/200], qnn_train_step: [600/1000], loss: 0.030896615236997604, accuracy: 99.2 %\n",
      "Training round [165/200], qnn_train_step: [700/1000], loss: 0.030515145510435104, accuracy: 99.1 %\n",
      "Training round [165/200], qnn_train_step: [800/1000], loss: 0.028736567124724388, accuracy: 99.2 %\n",
      "Training round [165/200], qnn_train_step: [900/1000], loss: 0.02829659730195999, accuracy: 99.1 %\n",
      "Training round [165/200], qnn_train_step: [1000/1000], loss: 0.02743467688560486, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [166/200], Epoch [1/5], Step [20/47], Loss: 0.0174, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [166/200], Epoch [1/5], Step [40/47], Loss: 0.0269, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [2/5], Step [20/47], Loss: 0.0784, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [166/200], Epoch [2/5], Step [40/47], Loss: 0.0507, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [166/200], Epoch [3/5], Step [20/47], Loss: 0.0723, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [3/5], Step [40/47], Loss: 0.0483, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [166/200], Epoch [4/5], Step [20/47], Loss: 0.1208, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [166/200], Epoch [4/5], Step [40/47], Loss: 0.0379, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [166/200], Epoch [5/5], Step [20/47], Loss: 0.0740, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [166/200], Epoch [5/5], Step [40/47], Loss: 0.0456, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [166/200], qnn_train_step: [100/1000], loss: 0.03996005654335022, accuracy: 98.9 %\n",
      "Training round [166/200], qnn_train_step: [200/1000], loss: 1.5339046716690063, accuracy: 73.8 %\n",
      "Training round [166/200], qnn_train_step: [300/1000], loss: 0.043655671179294586, accuracy: 98.7 %\n",
      "Training round [166/200], qnn_train_step: [400/1000], loss: 0.05114195495843887, accuracy: 98.9 %\n",
      "Training round [166/200], qnn_train_step: [500/1000], loss: 0.04107232764363289, accuracy: 98.8 %\n",
      "Training round [166/200], qnn_train_step: [600/1000], loss: 1.134459137916565, accuracy: 81.1 %\n",
      "Training round [166/200], qnn_train_step: [700/1000], loss: 1.2644507884979248, accuracy: 79.2 %\n",
      "Training round [166/200], qnn_train_step: [800/1000], loss: 1.0552250146865845, accuracy: 81.9 %\n",
      "Training round [166/200], qnn_train_step: [900/1000], loss: 0.9868688583374023, accuracy: 82.4 %\n",
      "Training round [166/200], qnn_train_step: [1000/1000], loss: 0.9988240599632263, accuracy: 82.4 %\n",
      "-----------------------\n",
      "Training round [167/200], Epoch [1/5], Step [20/47], Loss: 0.0506, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [167/200], Epoch [1/5], Step [40/47], Loss: 0.0253, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [167/200], Epoch [2/5], Step [20/47], Loss: 0.0493, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [2/5], Step [40/47], Loss: 0.0847, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [3/5], Step [20/47], Loss: 0.0634, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [3/5], Step [40/47], Loss: 0.1101, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [4/5], Step [20/47], Loss: 0.0253, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [167/200], Epoch [4/5], Step [40/47], Loss: 0.0416, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [167/200], Epoch [5/5], Step [20/47], Loss: 0.0959, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [167/200], Epoch [5/5], Step [40/47], Loss: 0.0319, batch time: 0.45, accuracy:  99.22%\n",
      "Training round [167/200], qnn_train_step: [100/1000], loss: 0.029657820239663124, accuracy: 99.2 %\n",
      "Training round [167/200], qnn_train_step: [200/1000], loss: 0.04752738028764725, accuracy: 98.2 %\n",
      "Training round [167/200], qnn_train_step: [300/1000], loss: 0.10374166816473007, accuracy: 96.5 %\n",
      "Training round [167/200], qnn_train_step: [400/1000], loss: 0.13023623824119568, accuracy: 96.9 %\n",
      "Training round [167/200], qnn_train_step: [500/1000], loss: 0.02574799954891205, accuracy: 99.1 %\n",
      "Training round [167/200], qnn_train_step: [600/1000], loss: 0.02513960376381874, accuracy: 99.2 %\n",
      "Training round [167/200], qnn_train_step: [700/1000], loss: 0.024808302521705627, accuracy: 99.3 %\n",
      "Training round [167/200], qnn_train_step: [800/1000], loss: 0.026640435680747032, accuracy: 99.2 %\n",
      "Training round [167/200], qnn_train_step: [900/1000], loss: 0.0305959302932024, accuracy: 99.1 %\n",
      "Training round [167/200], qnn_train_step: [1000/1000], loss: 0.023571250960230827, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [168/200], Epoch [1/5], Step [20/47], Loss: 0.0563, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [1/5], Step [40/47], Loss: 0.0575, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [2/5], Step [20/47], Loss: 0.0626, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [2/5], Step [40/47], Loss: 0.1928, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [3/5], Step [20/47], Loss: 0.0669, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [3/5], Step [40/47], Loss: 0.1925, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [168/200], Epoch [4/5], Step [20/47], Loss: 0.0655, batch time: 0.35, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [4/5], Step [40/47], Loss: 0.0613, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], Epoch [5/5], Step [20/47], Loss: 0.1375, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [168/200], Epoch [5/5], Step [40/47], Loss: 0.0445, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [168/200], qnn_train_step: [100/1000], loss: 0.04180639237165451, accuracy: 98.6 %\n",
      "Training round [168/200], qnn_train_step: [200/1000], loss: 0.6649587154388428, accuracy: 83.4 %\n",
      "Training round [168/200], qnn_train_step: [300/1000], loss: 0.03866313025355339, accuracy: 98.9 %\n",
      "Training round [168/200], qnn_train_step: [400/1000], loss: 0.03656613826751709, accuracy: 98.8 %\n",
      "Training round [168/200], qnn_train_step: [500/1000], loss: 0.033739008009433746, accuracy: 99.1 %\n",
      "Training round [168/200], qnn_train_step: [600/1000], loss: 0.03350721299648285, accuracy: 99.2 %\n",
      "Training round [168/200], qnn_train_step: [700/1000], loss: 0.043172501027584076, accuracy: 98.6 %\n",
      "Training round [168/200], qnn_train_step: [800/1000], loss: 0.060593146830797195, accuracy: 98.1 %\n",
      "Training round [168/200], qnn_train_step: [900/1000], loss: 0.053620126098394394, accuracy: 97.8 %\n",
      "Training round [168/200], qnn_train_step: [1000/1000], loss: 0.037676140666007996, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [169/200], Epoch [1/5], Step [20/47], Loss: 0.0220, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [169/200], Epoch [1/5], Step [40/47], Loss: 0.0738, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [169/200], Epoch [2/5], Step [20/47], Loss: 0.0680, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [169/200], Epoch [2/5], Step [40/47], Loss: 0.0439, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [3/5], Step [20/47], Loss: 0.0474, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [3/5], Step [40/47], Loss: 0.0435, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [4/5], Step [20/47], Loss: 0.0715, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [169/200], Epoch [4/5], Step [40/47], Loss: 0.0509, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [169/200], Epoch [5/5], Step [20/47], Loss: 0.0392, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [169/200], Epoch [5/5], Step [40/47], Loss: 0.0929, batch time: 0.06, accuracy:  96.09%\n",
      "Training round [169/200], qnn_train_step: [100/1000], loss: 0.06840687990188599, accuracy: 97.2 %\n",
      "Training round [169/200], qnn_train_step: [200/1000], loss: 0.5916014313697815, accuracy: 84.0 %\n",
      "Training round [169/200], qnn_train_step: [300/1000], loss: 0.06641587615013123, accuracy: 97.9 %\n",
      "Training round [169/200], qnn_train_step: [400/1000], loss: 0.05386997014284134, accuracy: 98.0 %\n",
      "Training round [169/200], qnn_train_step: [500/1000], loss: 0.0454394593834877, accuracy: 98.5 %\n",
      "Training round [169/200], qnn_train_step: [600/1000], loss: 0.04468408599495888, accuracy: 98.6 %\n",
      "Training round [169/200], qnn_train_step: [700/1000], loss: 0.04444057494401932, accuracy: 98.4 %\n",
      "Training round [169/200], qnn_train_step: [800/1000], loss: 0.04838791489601135, accuracy: 98.5 %\n",
      "Training round [169/200], qnn_train_step: [900/1000], loss: 0.04856214299798012, accuracy: 98.3 %\n",
      "Training round [169/200], qnn_train_step: [1000/1000], loss: 0.039815228432416916, accuracy: 98.3 %\n",
      "-----------------------\n",
      "Training round [170/200], Epoch [1/5], Step [20/47], Loss: 0.0891, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [1/5], Step [40/47], Loss: 0.0298, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [2/5], Step [20/47], Loss: 0.0178, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [2/5], Step [40/47], Loss: 0.0788, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [3/5], Step [20/47], Loss: 0.0312, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [170/200], Epoch [3/5], Step [40/47], Loss: 0.0960, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [170/200], Epoch [4/5], Step [20/47], Loss: 0.0274, batch time: 0.07, accuracy:  100.00%\n",
      "Training round [170/200], Epoch [4/5], Step [40/47], Loss: 0.0455, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [170/200], Epoch [5/5], Step [20/47], Loss: 0.2099, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [170/200], Epoch [5/5], Step [40/47], Loss: 0.0587, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [170/200], qnn_train_step: [100/1000], loss: 0.04787129536271095, accuracy: 98.6 %\n",
      "Training round [170/200], qnn_train_step: [200/1000], loss: 0.3137766122817993, accuracy: 88.8 %\n",
      "Training round [170/200], qnn_train_step: [300/1000], loss: 0.5647732615470886, accuracy: 86.1 %\n",
      "Training round [170/200], qnn_train_step: [400/1000], loss: 0.039314910769462585, accuracy: 99.1 %\n",
      "Training round [170/200], qnn_train_step: [500/1000], loss: 0.03626202791929245, accuracy: 99.1 %\n",
      "Training round [170/200], qnn_train_step: [600/1000], loss: 0.03729120269417763, accuracy: 99.2 %\n",
      "Training round [170/200], qnn_train_step: [700/1000], loss: 0.035084109753370285, accuracy: 99.2 %\n",
      "Training round [170/200], qnn_train_step: [800/1000], loss: 0.0346517451107502, accuracy: 99.1 %\n",
      "Training round [170/200], qnn_train_step: [900/1000], loss: 0.03456326574087143, accuracy: 99.1 %\n",
      "Training round [170/200], qnn_train_step: [1000/1000], loss: 0.035736095160245895, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [171/200], Epoch [1/5], Step [20/47], Loss: 0.1170, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [1/5], Step [40/47], Loss: 0.1040, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [2/5], Step [20/47], Loss: 0.0271, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [2/5], Step [40/47], Loss: 0.0960, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [171/200], Epoch [3/5], Step [20/47], Loss: 0.0572, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [171/200], Epoch [3/5], Step [40/47], Loss: 0.0657, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [4/5], Step [20/47], Loss: 0.0894, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [171/200], Epoch [4/5], Step [40/47], Loss: 0.0178, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [171/200], Epoch [5/5], Step [20/47], Loss: 0.0121, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [171/200], Epoch [5/5], Step [40/47], Loss: 0.0384, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [171/200], qnn_train_step: [100/1000], loss: 0.04475455731153488, accuracy: 98.8 %\n",
      "Training round [171/200], qnn_train_step: [200/1000], loss: 0.5943145155906677, accuracy: 81.2 %\n",
      "Training round [171/200], qnn_train_step: [300/1000], loss: 0.04071648791432381, accuracy: 99.2 %\n",
      "Training round [171/200], qnn_train_step: [400/1000], loss: 0.03784574195742607, accuracy: 99.3 %\n",
      "Training round [171/200], qnn_train_step: [500/1000], loss: 0.036214061081409454, accuracy: 99.3 %\n",
      "Training round [171/200], qnn_train_step: [600/1000], loss: 0.036057110875844955, accuracy: 99.2 %\n",
      "Training round [171/200], qnn_train_step: [700/1000], loss: 0.03508903086185455, accuracy: 99.4 %\n",
      "Training round [171/200], qnn_train_step: [800/1000], loss: 0.04368749260902405, accuracy: 98.8 %\n",
      "Training round [171/200], qnn_train_step: [900/1000], loss: 0.03664875030517578, accuracy: 99.2 %\n",
      "Training round [171/200], qnn_train_step: [1000/1000], loss: 0.04345826432108879, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [172/200], Epoch [1/5], Step [20/47], Loss: 0.0299, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [172/200], Epoch [1/5], Step [40/47], Loss: 0.0737, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [2/5], Step [20/47], Loss: 0.1030, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [172/200], Epoch [2/5], Step [40/47], Loss: 0.0804, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [3/5], Step [20/47], Loss: 0.0663, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [3/5], Step [40/47], Loss: 0.0513, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [172/200], Epoch [4/5], Step [20/47], Loss: 0.0733, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [172/200], Epoch [4/5], Step [40/47], Loss: 0.0334, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [172/200], Epoch [5/5], Step [20/47], Loss: 0.0722, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [172/200], Epoch [5/5], Step [40/47], Loss: 0.0071, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [172/200], qnn_train_step: [100/1000], loss: 0.03636372089385986, accuracy: 98.5 %\n",
      "Training round [172/200], qnn_train_step: [200/1000], loss: 0.6800647377967834, accuracy: 82.5 %\n",
      "Training round [172/200], qnn_train_step: [300/1000], loss: 0.2277185320854187, accuracy: 93.7 %\n",
      "Training round [172/200], qnn_train_step: [400/1000], loss: 0.03300294652581215, accuracy: 98.6 %\n",
      "Training round [172/200], qnn_train_step: [500/1000], loss: 0.030805174261331558, accuracy: 99.0 %\n",
      "Training round [172/200], qnn_train_step: [600/1000], loss: 0.030197881162166595, accuracy: 98.9 %\n",
      "Training round [172/200], qnn_train_step: [700/1000], loss: 0.0344851054251194, accuracy: 98.9 %\n",
      "Training round [172/200], qnn_train_step: [800/1000], loss: 0.02632185071706772, accuracy: 99.3 %\n",
      "Training round [172/200], qnn_train_step: [900/1000], loss: 0.025849102064967155, accuracy: 99.1 %\n",
      "Training round [172/200], qnn_train_step: [1000/1000], loss: 0.04701319336891174, accuracy: 98.5 %\n",
      "-----------------------\n",
      "Training round [173/200], Epoch [1/5], Step [20/47], Loss: 0.0498, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [1/5], Step [40/47], Loss: 0.0282, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [2/5], Step [20/47], Loss: 0.1080, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [173/200], Epoch [2/5], Step [40/47], Loss: 0.0409, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [3/5], Step [20/47], Loss: 0.0428, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [3/5], Step [40/47], Loss: 0.0668, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [173/200], Epoch [4/5], Step [20/47], Loss: 0.0367, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [4/5], Step [40/47], Loss: 0.0536, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [173/200], Epoch [5/5], Step [20/47], Loss: 0.0254, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [173/200], Epoch [5/5], Step [40/47], Loss: 0.1353, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [173/200], qnn_train_step: [100/1000], loss: 0.057552989572286606, accuracy: 97.6 %\n",
      "Training round [173/200], qnn_train_step: [200/1000], loss: 0.42598384618759155, accuracy: 83.9 %\n",
      "Training round [173/200], qnn_train_step: [300/1000], loss: 0.05586281046271324, accuracy: 98.1 %\n",
      "Training round [173/200], qnn_train_step: [400/1000], loss: 0.05361073091626167, accuracy: 98.4 %\n",
      "Training round [173/200], qnn_train_step: [500/1000], loss: 0.05298200249671936, accuracy: 98.3 %\n",
      "Training round [173/200], qnn_train_step: [600/1000], loss: 0.052139222621917725, accuracy: 98.3 %\n",
      "Training round [173/200], qnn_train_step: [700/1000], loss: 0.048585981130599976, accuracy: 98.4 %\n",
      "Training round [173/200], qnn_train_step: [800/1000], loss: 0.047804027795791626, accuracy: 98.5 %\n",
      "Training round [173/200], qnn_train_step: [900/1000], loss: 0.05194975808262825, accuracy: 98.5 %\n",
      "Training round [173/200], qnn_train_step: [1000/1000], loss: 0.05503267049789429, accuracy: 98.2 %\n",
      "-----------------------\n",
      "Training round [174/200], Epoch [1/5], Step [20/47], Loss: 0.0391, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [1/5], Step [40/47], Loss: 0.0418, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [174/200], Epoch [2/5], Step [20/47], Loss: 0.0104, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [174/200], Epoch [2/5], Step [40/47], Loss: 0.1434, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [174/200], Epoch [3/5], Step [20/47], Loss: 0.0315, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [174/200], Epoch [3/5], Step [40/47], Loss: 0.0926, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [4/5], Step [20/47], Loss: 0.0606, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [174/200], Epoch [4/5], Step [40/47], Loss: 0.1197, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [5/5], Step [20/47], Loss: 0.0529, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [174/200], Epoch [5/5], Step [40/47], Loss: 0.0666, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [174/200], qnn_train_step: [100/1000], loss: 0.03980322554707527, accuracy: 98.9 %\n",
      "Training round [174/200], qnn_train_step: [200/1000], loss: 0.6813541054725647, accuracy: 81.1 %\n",
      "Training round [174/200], qnn_train_step: [300/1000], loss: 0.19243423640727997, accuracy: 95.0 %\n",
      "Training round [174/200], qnn_train_step: [400/1000], loss: 0.0342889204621315, accuracy: 99.1 %\n",
      "Training round [174/200], qnn_train_step: [500/1000], loss: 0.03283030539751053, accuracy: 99.1 %\n",
      "Training round [174/200], qnn_train_step: [600/1000], loss: 0.030996916815638542, accuracy: 99.5 %\n",
      "Training round [174/200], qnn_train_step: [700/1000], loss: 0.031081726774573326, accuracy: 99.2 %\n",
      "Training round [174/200], qnn_train_step: [800/1000], loss: 0.029100771993398666, accuracy: 99.4 %\n",
      "Training round [174/200], qnn_train_step: [900/1000], loss: 0.028606034815311432, accuracy: 99.3 %\n",
      "Training round [174/200], qnn_train_step: [1000/1000], loss: 0.030512984842061996, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [175/200], Epoch [1/5], Step [20/47], Loss: 0.1096, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [175/200], Epoch [1/5], Step [40/47], Loss: 0.0280, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [175/200], Epoch [2/5], Step [20/47], Loss: 0.0531, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [2/5], Step [40/47], Loss: 0.0075, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [175/200], Epoch [3/5], Step [20/47], Loss: 0.0433, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [3/5], Step [40/47], Loss: 0.0570, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [4/5], Step [20/47], Loss: 0.0113, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [175/200], Epoch [4/5], Step [40/47], Loss: 0.0736, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [175/200], Epoch [5/5], Step [20/47], Loss: 0.0554, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [175/200], Epoch [5/5], Step [40/47], Loss: 0.0426, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [175/200], qnn_train_step: [100/1000], loss: 0.03129740431904793, accuracy: 98.9 %\n",
      "Training round [175/200], qnn_train_step: [200/1000], loss: 0.3909785747528076, accuracy: 87.3 %\n",
      "Training round [175/200], qnn_train_step: [300/1000], loss: 0.746770441532135, accuracy: 85.0 %\n",
      "Training round [175/200], qnn_train_step: [400/1000], loss: 0.02780919522047043, accuracy: 99.1 %\n",
      "Training round [175/200], qnn_train_step: [500/1000], loss: 0.027720393612980843, accuracy: 99.2 %\n",
      "Training round [175/200], qnn_train_step: [600/1000], loss: 0.02621825784444809, accuracy: 99.3 %\n",
      "Training round [175/200], qnn_train_step: [700/1000], loss: 0.031756412237882614, accuracy: 98.8 %\n",
      "Training round [175/200], qnn_train_step: [800/1000], loss: 0.026285402476787567, accuracy: 99.2 %\n",
      "Training round [175/200], qnn_train_step: [900/1000], loss: 0.026604782789945602, accuracy: 99.3 %\n",
      "Training round [175/200], qnn_train_step: [1000/1000], loss: 0.024107899516820908, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [176/200], Epoch [1/5], Step [20/47], Loss: 0.0547, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [176/200], Epoch [1/5], Step [40/47], Loss: 0.0940, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [2/5], Step [20/47], Loss: 0.0671, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], Epoch [2/5], Step [40/47], Loss: 0.0234, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [3/5], Step [20/47], Loss: 0.0277, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [3/5], Step [40/47], Loss: 0.0341, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [4/5], Step [20/47], Loss: 0.0434, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [176/200], Epoch [4/5], Step [40/47], Loss: 0.0205, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [5/5], Step [20/47], Loss: 0.0180, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [176/200], Epoch [5/5], Step [40/47], Loss: 0.0447, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [176/200], qnn_train_step: [100/1000], loss: 0.03453350439667702, accuracy: 98.7 %\n",
      "Training round [176/200], qnn_train_step: [200/1000], loss: 0.6883844137191772, accuracy: 83.0 %\n",
      "Training round [176/200], qnn_train_step: [300/1000], loss: 0.04019811749458313, accuracy: 98.3 %\n",
      "Training round [176/200], qnn_train_step: [400/1000], loss: 0.027145588770508766, accuracy: 99.1 %\n",
      "Training round [176/200], qnn_train_step: [500/1000], loss: 0.026502031832933426, accuracy: 99.2 %\n",
      "Training round [176/200], qnn_train_step: [600/1000], loss: 0.02527923509478569, accuracy: 99.1 %\n",
      "Training round [176/200], qnn_train_step: [700/1000], loss: 0.02854783833026886, accuracy: 98.8 %\n",
      "Training round [176/200], qnn_train_step: [800/1000], loss: 0.027334734797477722, accuracy: 99.2 %\n",
      "Training round [176/200], qnn_train_step: [900/1000], loss: 0.044401150196790695, accuracy: 97.9 %\n",
      "Training round [176/200], qnn_train_step: [1000/1000], loss: 0.022794269025325775, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [177/200], Epoch [1/5], Step [20/47], Loss: 0.0450, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [1/5], Step [40/47], Loss: 0.0715, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [2/5], Step [20/47], Loss: 0.0476, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [2/5], Step [40/47], Loss: 0.0456, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [3/5], Step [20/47], Loss: 0.0447, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [3/5], Step [40/47], Loss: 0.0511, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [4/5], Step [20/47], Loss: 0.0332, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [177/200], Epoch [4/5], Step [40/47], Loss: 0.0597, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [177/200], Epoch [5/5], Step [20/47], Loss: 0.0259, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [177/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [177/200], qnn_train_step: [100/1000], loss: 0.02984141744673252, accuracy: 99.1 %\n",
      "Training round [177/200], qnn_train_step: [200/1000], loss: 0.5772812366485596, accuracy: 84.0 %\n",
      "Training round [177/200], qnn_train_step: [300/1000], loss: 0.023852087557315826, accuracy: 99.3 %\n",
      "Training round [177/200], qnn_train_step: [400/1000], loss: 0.019837994128465652, accuracy: 99.7 %\n",
      "Training round [177/200], qnn_train_step: [500/1000], loss: 0.02370169200003147, accuracy: 99.1 %\n",
      "Training round [177/200], qnn_train_step: [600/1000], loss: 0.020273739472031593, accuracy: 99.7 %\n",
      "Training round [177/200], qnn_train_step: [700/1000], loss: 0.054372020065784454, accuracy: 98.5 %\n",
      "Training round [177/200], qnn_train_step: [800/1000], loss: 0.01912444643676281, accuracy: 99.6 %\n",
      "Training round [177/200], qnn_train_step: [900/1000], loss: 0.019117921590805054, accuracy: 99.5 %\n",
      "Training round [177/200], qnn_train_step: [1000/1000], loss: 0.0212025735527277, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [178/200], Epoch [1/5], Step [20/47], Loss: 0.0664, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [1/5], Step [40/47], Loss: 0.0404, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [2/5], Step [20/47], Loss: 0.0795, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [2/5], Step [40/47], Loss: 0.0813, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [178/200], Epoch [3/5], Step [20/47], Loss: 0.0911, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [178/200], Epoch [3/5], Step [40/47], Loss: 0.0627, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [178/200], Epoch [4/5], Step [20/47], Loss: 0.0816, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [178/200], Epoch [4/5], Step [40/47], Loss: 0.0818, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [178/200], Epoch [5/5], Step [20/47], Loss: 0.1095, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [178/200], Epoch [5/5], Step [40/47], Loss: 0.0644, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [178/200], qnn_train_step: [100/1000], loss: 0.04151522368192673, accuracy: 98.5 %\n",
      "Training round [178/200], qnn_train_step: [200/1000], loss: 0.11446839570999146, accuracy: 96.1 %\n",
      "Training round [178/200], qnn_train_step: [300/1000], loss: 0.037185389548540115, accuracy: 99.0 %\n",
      "Training round [178/200], qnn_train_step: [400/1000], loss: 0.036064691841602325, accuracy: 98.9 %\n",
      "Training round [178/200], qnn_train_step: [500/1000], loss: 0.03473859652876854, accuracy: 99.1 %\n",
      "Training round [178/200], qnn_train_step: [600/1000], loss: 0.03422556072473526, accuracy: 98.9 %\n",
      "Training round [178/200], qnn_train_step: [700/1000], loss: 0.04362807795405388, accuracy: 98.6 %\n",
      "Training round [178/200], qnn_train_step: [800/1000], loss: 0.03268108144402504, accuracy: 98.9 %\n",
      "Training round [178/200], qnn_train_step: [900/1000], loss: 0.03409302979707718, accuracy: 98.9 %\n",
      "Training round [178/200], qnn_train_step: [1000/1000], loss: 0.03298339992761612, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [179/200], Epoch [1/5], Step [20/47], Loss: 0.0408, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [1/5], Step [40/47], Loss: 0.1489, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [2/5], Step [20/47], Loss: 0.0603, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [2/5], Step [40/47], Loss: 0.0377, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [179/200], Epoch [3/5], Step [20/47], Loss: 0.1677, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [179/200], Epoch [3/5], Step [40/47], Loss: 0.0608, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [4/5], Step [20/47], Loss: 0.0346, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [179/200], Epoch [4/5], Step [40/47], Loss: 0.0847, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [179/200], Epoch [5/5], Step [20/47], Loss: 0.0456, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [179/200], Epoch [5/5], Step [40/47], Loss: 0.0788, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [179/200], qnn_train_step: [100/1000], loss: 0.03404492139816284, accuracy: 99.0 %\n",
      "Training round [179/200], qnn_train_step: [200/1000], loss: 0.3063703179359436, accuracy: 90.7 %\n",
      "Training round [179/200], qnn_train_step: [300/1000], loss: 0.03381992131471634, accuracy: 98.7 %\n",
      "Training round [179/200], qnn_train_step: [400/1000], loss: 0.02910768613219261, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [500/1000], loss: 0.02894904650747776, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [600/1000], loss: 0.024789389222860336, accuracy: 99.2 %\n",
      "Training round [179/200], qnn_train_step: [700/1000], loss: 0.027751846238970757, accuracy: 99.3 %\n",
      "Training round [179/200], qnn_train_step: [800/1000], loss: 0.02299954742193222, accuracy: 99.4 %\n",
      "Training round [179/200], qnn_train_step: [900/1000], loss: 0.026051586493849754, accuracy: 99.1 %\n",
      "Training round [179/200], qnn_train_step: [1000/1000], loss: 0.022105209529399872, accuracy: 99.3 %\n",
      "-----------------------\n",
      "Training round [180/200], Epoch [1/5], Step [20/47], Loss: 0.0399, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [180/200], Epoch [1/5], Step [40/47], Loss: 0.0382, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [180/200], Epoch [2/5], Step [20/47], Loss: 0.0799, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [180/200], Epoch [2/5], Step [40/47], Loss: 0.0091, batch time: 0.40, accuracy:  100.00%\n",
      "Training round [180/200], Epoch [3/5], Step [20/47], Loss: 0.0245, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [180/200], Epoch [3/5], Step [40/47], Loss: 0.1111, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [4/5], Step [20/47], Loss: 0.1439, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [180/200], Epoch [4/5], Step [40/47], Loss: 0.0360, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [5/5], Step [20/47], Loss: 0.0688, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], Epoch [5/5], Step [40/47], Loss: 0.0398, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [180/200], qnn_train_step: [100/1000], loss: 0.03855450823903084, accuracy: 98.4 %\n",
      "Training round [180/200], qnn_train_step: [200/1000], loss: 0.11686291545629501, accuracy: 95.0 %\n",
      "Training round [180/200], qnn_train_step: [300/1000], loss: 0.11227446794509888, accuracy: 96.0 %\n",
      "Training round [180/200], qnn_train_step: [400/1000], loss: 0.0424325056374073, accuracy: 98.6 %\n",
      "Training round [180/200], qnn_train_step: [500/1000], loss: 0.04285602271556854, accuracy: 98.5 %\n",
      "Training round [180/200], qnn_train_step: [600/1000], loss: 0.03613222390413284, accuracy: 98.8 %\n",
      "Training round [180/200], qnn_train_step: [700/1000], loss: 0.04669800028204918, accuracy: 98.6 %\n",
      "Training round [180/200], qnn_train_step: [800/1000], loss: 0.041838228702545166, accuracy: 98.5 %\n",
      "Training round [180/200], qnn_train_step: [900/1000], loss: 0.03973755985498428, accuracy: 98.6 %\n",
      "Training round [180/200], qnn_train_step: [1000/1000], loss: 0.041427187621593475, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [181/200], Epoch [1/5], Step [20/47], Loss: 0.0691, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [181/200], Epoch [1/5], Step [40/47], Loss: 0.0302, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [181/200], Epoch [2/5], Step [20/47], Loss: 0.1031, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [181/200], Epoch [2/5], Step [40/47], Loss: 0.0599, batch time: 0.08, accuracy:  96.88%\n",
      "Training round [181/200], Epoch [3/5], Step [20/47], Loss: 0.0487, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [181/200], Epoch [3/5], Step [40/47], Loss: 0.0634, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [4/5], Step [20/47], Loss: 0.0930, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [181/200], Epoch [4/5], Step [40/47], Loss: 0.0241, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [181/200], Epoch [5/5], Step [20/47], Loss: 0.0154, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [181/200], Epoch [5/5], Step [40/47], Loss: 0.0235, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [181/200], qnn_train_step: [100/1000], loss: 0.03153235837817192, accuracy: 99.0 %\n",
      "Training round [181/200], qnn_train_step: [200/1000], loss: 0.03406808525323868, accuracy: 98.9 %\n",
      "Training round [181/200], qnn_train_step: [300/1000], loss: 0.25222283601760864, accuracy: 91.3 %\n",
      "Training round [181/200], qnn_train_step: [400/1000], loss: 0.11781740933656693, accuracy: 95.5 %\n",
      "Training round [181/200], qnn_train_step: [500/1000], loss: 0.027322836220264435, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [600/1000], loss: 0.02711472287774086, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [700/1000], loss: 0.03807110711932182, accuracy: 98.8 %\n",
      "Training round [181/200], qnn_train_step: [800/1000], loss: 0.02736916020512581, accuracy: 99.5 %\n",
      "Training round [181/200], qnn_train_step: [900/1000], loss: 0.027729572728276253, accuracy: 99.4 %\n",
      "Training round [181/200], qnn_train_step: [1000/1000], loss: 0.025976555421948433, accuracy: 99.6 %\n",
      "-----------------------\n",
      "Training round [182/200], Epoch [1/5], Step [20/47], Loss: 0.0731, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [1/5], Step [40/47], Loss: 0.1488, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [182/200], Epoch [2/5], Step [20/47], Loss: 0.0810, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [2/5], Step [40/47], Loss: 0.0383, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [182/200], Epoch [3/5], Step [20/47], Loss: 0.0087, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [182/200], Epoch [3/5], Step [40/47], Loss: 0.1566, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [182/200], Epoch [4/5], Step [20/47], Loss: 0.0386, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [182/200], Epoch [4/5], Step [40/47], Loss: 0.0966, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [182/200], Epoch [5/5], Step [20/47], Loss: 0.0685, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [182/200], Epoch [5/5], Step [40/47], Loss: 0.1629, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [182/200], qnn_train_step: [100/1000], loss: 0.023018674924969673, accuracy: 99.4 %\n",
      "Training round [182/200], qnn_train_step: [200/1000], loss: 0.24322529137134552, accuracy: 92.0 %\n",
      "Training round [182/200], qnn_train_step: [300/1000], loss: 0.023323308676481247, accuracy: 99.4 %\n",
      "Training round [182/200], qnn_train_step: [400/1000], loss: 0.021902568638324738, accuracy: 99.5 %\n",
      "Training round [182/200], qnn_train_step: [500/1000], loss: 0.02732975408434868, accuracy: 99.5 %\n",
      "Training round [182/200], qnn_train_step: [600/1000], loss: 0.021674636751413345, accuracy: 99.5 %\n",
      "Training round [182/200], qnn_train_step: [700/1000], loss: 0.02253630943596363, accuracy: 99.4 %\n",
      "Training round [182/200], qnn_train_step: [800/1000], loss: 0.02045600861310959, accuracy: 99.6 %\n",
      "Training round [182/200], qnn_train_step: [900/1000], loss: 0.02101118303835392, accuracy: 99.4 %\n",
      "Training round [182/200], qnn_train_step: [1000/1000], loss: 0.019557809457182884, accuracy: 99.7 %\n",
      "-----------------------\n",
      "Training round [183/200], Epoch [1/5], Step [20/47], Loss: 0.0551, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [1/5], Step [40/47], Loss: 0.0125, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [183/200], Epoch [2/5], Step [20/47], Loss: 0.0512, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [2/5], Step [40/47], Loss: 0.0283, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [183/200], Epoch [3/5], Step [20/47], Loss: 0.0884, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [183/200], Epoch [3/5], Step [40/47], Loss: 0.0137, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [4/5], Step [20/47], Loss: 0.0330, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [183/200], Epoch [4/5], Step [40/47], Loss: 0.1023, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [5/5], Step [20/47], Loss: 0.0969, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [183/200], Epoch [5/5], Step [40/47], Loss: 0.0488, batch time: 0.47, accuracy:  99.22%\n",
      "Training round [183/200], qnn_train_step: [100/1000], loss: 0.03878096118569374, accuracy: 98.3 %\n",
      "Training round [183/200], qnn_train_step: [200/1000], loss: 0.2561533451080322, accuracy: 91.6 %\n",
      "Training round [183/200], qnn_train_step: [300/1000], loss: 0.0361170768737793, accuracy: 98.9 %\n",
      "Training round [183/200], qnn_train_step: [400/1000], loss: 0.028235765174031258, accuracy: 99.0 %\n",
      "Training round [183/200], qnn_train_step: [500/1000], loss: 0.02767747826874256, accuracy: 98.8 %\n",
      "Training round [183/200], qnn_train_step: [600/1000], loss: 0.026993421837687492, accuracy: 99.3 %\n",
      "Training round [183/200], qnn_train_step: [700/1000], loss: 0.033967286348342896, accuracy: 98.8 %\n",
      "Training round [183/200], qnn_train_step: [800/1000], loss: 0.03341202810406685, accuracy: 98.8 %\n",
      "Training round [183/200], qnn_train_step: [900/1000], loss: 0.02870335429906845, accuracy: 99.2 %\n",
      "Training round [183/200], qnn_train_step: [1000/1000], loss: 0.03497643768787384, accuracy: 99.0 %\n",
      "-----------------------\n",
      "Training round [184/200], Epoch [1/5], Step [20/47], Loss: 0.0759, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [1/5], Step [40/47], Loss: 0.0130, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [2/5], Step [20/47], Loss: 0.0612, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [2/5], Step [40/47], Loss: 0.0365, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [184/200], Epoch [3/5], Step [20/47], Loss: 0.1902, batch time: 0.10, accuracy:  93.75%\n",
      "Training round [184/200], Epoch [3/5], Step [40/47], Loss: 0.0772, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [4/5], Step [20/47], Loss: 0.1072, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [184/200], Epoch [4/5], Step [40/47], Loss: 0.0885, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [184/200], Epoch [5/5], Step [20/47], Loss: 0.0478, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [184/200], Epoch [5/5], Step [40/47], Loss: 0.0289, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [184/200], qnn_train_step: [100/1000], loss: 0.045162130147218704, accuracy: 98.2 %\n",
      "Training round [184/200], qnn_train_step: [200/1000], loss: 0.2572840750217438, accuracy: 90.7 %\n",
      "Training round [184/200], qnn_train_step: [300/1000], loss: 0.5381606221199036, accuracy: 84.3 %\n",
      "Training round [184/200], qnn_train_step: [400/1000], loss: 0.040095675736665726, accuracy: 98.5 %\n",
      "Training round [184/200], qnn_train_step: [500/1000], loss: 0.03808799758553505, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [600/1000], loss: 0.03630196303129196, accuracy: 98.8 %\n",
      "Training round [184/200], qnn_train_step: [700/1000], loss: 0.035823892802000046, accuracy: 98.8 %\n",
      "Training round [184/200], qnn_train_step: [800/1000], loss: 0.036669593304395676, accuracy: 98.8 %\n",
      "Training round [184/200], qnn_train_step: [900/1000], loss: 0.03829747065901756, accuracy: 98.9 %\n",
      "Training round [184/200], qnn_train_step: [1000/1000], loss: 0.036324456334114075, accuracy: 98.9 %\n",
      "-----------------------\n",
      "Training round [185/200], Epoch [1/5], Step [20/47], Loss: 0.0872, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [1/5], Step [40/47], Loss: 0.1232, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [185/200], Epoch [2/5], Step [20/47], Loss: 0.0097, batch time: 0.07, accuracy:  100.00%\n",
      "Training round [185/200], Epoch [2/5], Step [40/47], Loss: 0.0869, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [3/5], Step [20/47], Loss: 0.0485, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [3/5], Step [40/47], Loss: 0.0350, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [185/200], Epoch [4/5], Step [20/47], Loss: 0.0993, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [185/200], Epoch [4/5], Step [40/47], Loss: 0.0237, batch time: 0.39, accuracy:  98.44%\n",
      "Training round [185/200], Epoch [5/5], Step [20/47], Loss: 0.0633, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [185/200], Epoch [5/5], Step [40/47], Loss: 0.0296, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [185/200], qnn_train_step: [100/1000], loss: 0.036506038159132004, accuracy: 99.2 %\n",
      "Training round [185/200], qnn_train_step: [200/1000], loss: 0.4728856086730957, accuracy: 83.8 %\n",
      "Training round [185/200], qnn_train_step: [300/1000], loss: 0.034193892031908035, accuracy: 99.3 %\n",
      "Training round [185/200], qnn_train_step: [400/1000], loss: 0.04322945699095726, accuracy: 98.7 %\n",
      "Training round [185/200], qnn_train_step: [500/1000], loss: 0.03856287896633148, accuracy: 98.8 %\n",
      "Training round [185/200], qnn_train_step: [600/1000], loss: 0.05437541753053665, accuracy: 98.4 %\n",
      "Training round [185/200], qnn_train_step: [700/1000], loss: 0.03304842486977577, accuracy: 99.2 %\n",
      "Training round [185/200], qnn_train_step: [800/1000], loss: 0.03199109435081482, accuracy: 99.3 %\n",
      "Training round [185/200], qnn_train_step: [900/1000], loss: 0.03125251084566116, accuracy: 99.2 %\n",
      "Training round [185/200], qnn_train_step: [1000/1000], loss: 0.031018411740660667, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [186/200], Epoch [1/5], Step [20/47], Loss: 0.0503, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [1/5], Step [40/47], Loss: 0.0674, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [2/5], Step [20/47], Loss: 0.0760, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [2/5], Step [40/47], Loss: 0.0451, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [3/5], Step [20/47], Loss: 0.0163, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [186/200], Epoch [3/5], Step [40/47], Loss: 0.0302, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [4/5], Step [20/47], Loss: 0.1359, batch time: 0.11, accuracy:  95.31%\n",
      "Training round [186/200], Epoch [4/5], Step [40/47], Loss: 0.0768, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [186/200], Epoch [5/5], Step [20/47], Loss: 0.0870, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [186/200], Epoch [5/5], Step [40/47], Loss: 0.1100, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [186/200], qnn_train_step: [100/1000], loss: 0.027349818497896194, accuracy: 99.3 %\n",
      "Training round [186/200], qnn_train_step: [200/1000], loss: 0.7946634292602539, accuracy: 80.0 %\n",
      "Training round [186/200], qnn_train_step: [300/1000], loss: 0.02942325547337532, accuracy: 99.4 %\n",
      "Training round [186/200], qnn_train_step: [400/1000], loss: 0.02826291136443615, accuracy: 99.3 %\n",
      "Training round [186/200], qnn_train_step: [500/1000], loss: 0.026653338223695755, accuracy: 99.4 %\n",
      "Training round [186/200], qnn_train_step: [600/1000], loss: 0.03144429996609688, accuracy: 99.1 %\n",
      "Training round [186/200], qnn_train_step: [700/1000], loss: 0.07004189491271973, accuracy: 98.2 %\n",
      "Training round [186/200], qnn_train_step: [800/1000], loss: 0.06343881785869598, accuracy: 98.4 %\n",
      "Training round [186/200], qnn_train_step: [900/1000], loss: 0.02152465097606182, accuracy: 99.7 %\n",
      "Training round [186/200], qnn_train_step: [1000/1000], loss: 0.021176936104893684, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [187/200], Epoch [1/5], Step [20/47], Loss: 0.0745, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [187/200], Epoch [1/5], Step [40/47], Loss: 0.0625, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [187/200], Epoch [2/5], Step [20/47], Loss: 0.0318, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [2/5], Step [40/47], Loss: 0.0220, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [187/200], Epoch [3/5], Step [20/47], Loss: 0.0359, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [3/5], Step [40/47], Loss: 0.1074, batch time: 0.48, accuracy:  98.44%\n",
      "Training round [187/200], Epoch [4/5], Step [20/47], Loss: 0.0487, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [4/5], Step [40/47], Loss: 0.0618, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [187/200], Epoch [5/5], Step [20/47], Loss: 0.0812, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [187/200], Epoch [5/5], Step [40/47], Loss: 0.0468, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [187/200], qnn_train_step: [100/1000], loss: 0.053807273507118225, accuracy: 98.2 %\n",
      "Training round [187/200], qnn_train_step: [200/1000], loss: 0.2327066957950592, accuracy: 91.7 %\n",
      "Training round [187/200], qnn_train_step: [300/1000], loss: 0.21848753094673157, accuracy: 92.3 %\n",
      "Training round [187/200], qnn_train_step: [400/1000], loss: 0.04701448604464531, accuracy: 98.5 %\n",
      "Training round [187/200], qnn_train_step: [500/1000], loss: 0.04552920535206795, accuracy: 98.5 %\n",
      "Training round [187/200], qnn_train_step: [600/1000], loss: 0.05100027844309807, accuracy: 98.1 %\n",
      "Training round [187/200], qnn_train_step: [700/1000], loss: 0.044271599501371384, accuracy: 98.7 %\n",
      "Training round [187/200], qnn_train_step: [800/1000], loss: 0.04471493884921074, accuracy: 98.4 %\n",
      "Training round [187/200], qnn_train_step: [900/1000], loss: 0.059770368039608, accuracy: 97.8 %\n",
      "Training round [187/200], qnn_train_step: [1000/1000], loss: 0.044347550719976425, accuracy: 98.4 %\n",
      "-----------------------\n",
      "Training round [188/200], Epoch [1/5], Step [20/47], Loss: 0.0919, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [1/5], Step [40/47], Loss: 0.0470, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [2/5], Step [20/47], Loss: 0.0300, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [2/5], Step [40/47], Loss: 0.0948, batch time: 0.11, accuracy:  96.88%\n",
      "Training round [188/200], Epoch [3/5], Step [20/47], Loss: 0.0585, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [3/5], Step [40/47], Loss: 0.0371, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [188/200], Epoch [4/5], Step [20/47], Loss: 0.0300, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [4/5], Step [40/47], Loss: 0.0293, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [188/200], Epoch [5/5], Step [20/47], Loss: 0.0971, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [188/200], Epoch [5/5], Step [40/47], Loss: 0.0574, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [188/200], qnn_train_step: [100/1000], loss: 0.04167647287249565, accuracy: 98.6 %\n",
      "Training round [188/200], qnn_train_step: [200/1000], loss: 0.5499820709228516, accuracy: 86.0 %\n",
      "Training round [188/200], qnn_train_step: [300/1000], loss: 0.05546703189611435, accuracy: 98.3 %\n",
      "Training round [188/200], qnn_train_step: [400/1000], loss: 0.03161432221531868, accuracy: 98.8 %\n",
      "Training round [188/200], qnn_train_step: [500/1000], loss: 0.03060734085738659, accuracy: 98.9 %\n",
      "Training round [188/200], qnn_train_step: [600/1000], loss: 0.029424211010336876, accuracy: 98.9 %\n",
      "Training round [188/200], qnn_train_step: [700/1000], loss: 0.028132157400250435, accuracy: 99.0 %\n",
      "Training round [188/200], qnn_train_step: [800/1000], loss: 0.02811857871711254, accuracy: 99.1 %\n",
      "Training round [188/200], qnn_train_step: [900/1000], loss: 0.0274967048317194, accuracy: 99.1 %\n",
      "Training round [188/200], qnn_train_step: [1000/1000], loss: 0.029910340905189514, accuracy: 98.8 %\n",
      "-----------------------\n",
      "Training round [189/200], Epoch [1/5], Step [20/47], Loss: 0.0710, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [1/5], Step [40/47], Loss: 0.1300, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [189/200], Epoch [2/5], Step [20/47], Loss: 0.0798, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [189/200], Epoch [2/5], Step [40/47], Loss: 0.0370, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [3/5], Step [20/47], Loss: 0.0527, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [3/5], Step [40/47], Loss: 0.0922, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [189/200], Epoch [4/5], Step [20/47], Loss: 0.0458, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [189/200], Epoch [4/5], Step [40/47], Loss: 0.0955, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [189/200], Epoch [5/5], Step [20/47], Loss: 0.0477, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [189/200], Epoch [5/5], Step [40/47], Loss: 0.0143, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [189/200], qnn_train_step: [100/1000], loss: 0.03466380387544632, accuracy: 98.9 %\n",
      "Training round [189/200], qnn_train_step: [200/1000], loss: 0.41801467537879944, accuracy: 86.8 %\n",
      "Training round [189/200], qnn_train_step: [300/1000], loss: 0.05719612538814545, accuracy: 97.8 %\n",
      "Training round [189/200], qnn_train_step: [400/1000], loss: 0.02945069968700409, accuracy: 98.9 %\n",
      "Training round [189/200], qnn_train_step: [500/1000], loss: 0.023598598316311836, accuracy: 99.1 %\n",
      "Training round [189/200], qnn_train_step: [600/1000], loss: 0.022674864158034325, accuracy: 99.0 %\n",
      "Training round [189/200], qnn_train_step: [700/1000], loss: 0.022748759016394615, accuracy: 99.3 %\n",
      "Training round [189/200], qnn_train_step: [800/1000], loss: 0.02119920402765274, accuracy: 99.3 %\n",
      "Training round [189/200], qnn_train_step: [900/1000], loss: 0.02308194898068905, accuracy: 99.1 %\n",
      "Training round [189/200], qnn_train_step: [1000/1000], loss: 0.02093404345214367, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [190/200], Epoch [1/5], Step [20/47], Loss: 0.1070, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [190/200], Epoch [1/5], Step [40/47], Loss: 0.0109, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [190/200], Epoch [2/5], Step [20/47], Loss: 0.0338, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [2/5], Step [40/47], Loss: 0.0486, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [190/200], Epoch [3/5], Step [20/47], Loss: 0.0591, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [190/200], Epoch [3/5], Step [40/47], Loss: 0.0461, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [4/5], Step [20/47], Loss: 0.0120, batch time: 0.11, accuracy:  100.00%\n",
      "Training round [190/200], Epoch [4/5], Step [40/47], Loss: 0.0144, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [190/200], Epoch [5/5], Step [20/47], Loss: 0.0591, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [190/200], Epoch [5/5], Step [40/47], Loss: 0.0275, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [190/200], qnn_train_step: [100/1000], loss: 0.03367341682314873, accuracy: 98.9 %\n",
      "Training round [190/200], qnn_train_step: [200/1000], loss: 0.8492816090583801, accuracy: 85.2 %\n",
      "Training round [190/200], qnn_train_step: [300/1000], loss: 0.32206854224205017, accuracy: 92.1 %\n",
      "Training round [190/200], qnn_train_step: [400/1000], loss: 0.026986630633473396, accuracy: 99.2 %\n",
      "Training round [190/200], qnn_train_step: [500/1000], loss: 0.02552790567278862, accuracy: 99.5 %\n",
      "Training round [190/200], qnn_train_step: [600/1000], loss: 0.025298062711954117, accuracy: 99.5 %\n",
      "Training round [190/200], qnn_train_step: [700/1000], loss: 0.027524130418896675, accuracy: 99.2 %\n",
      "Training round [190/200], qnn_train_step: [800/1000], loss: 0.06909309327602386, accuracy: 97.3 %\n",
      "Training round [190/200], qnn_train_step: [900/1000], loss: 0.028093475848436356, accuracy: 99.2 %\n",
      "Training round [190/200], qnn_train_step: [1000/1000], loss: 0.028637303039431572, accuracy: 98.7 %\n",
      "-----------------------\n",
      "Training round [191/200], Epoch [1/5], Step [20/47], Loss: 0.0781, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [1/5], Step [40/47], Loss: 0.0581, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [2/5], Step [20/47], Loss: 0.0497, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [2/5], Step [40/47], Loss: 0.0373, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [191/200], Epoch [3/5], Step [20/47], Loss: 0.0441, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [191/200], Epoch [3/5], Step [40/47], Loss: 0.1301, batch time: 0.05, accuracy:  94.53%\n",
      "Training round [191/200], Epoch [4/5], Step [20/47], Loss: 0.0252, batch time: 0.05, accuracy:  100.00%\n",
      "Training round [191/200], Epoch [4/5], Step [40/47], Loss: 0.0738, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [191/200], Epoch [5/5], Step [20/47], Loss: 0.0319, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [191/200], Epoch [5/5], Step [40/47], Loss: 0.0326, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [191/200], qnn_train_step: [100/1000], loss: 0.01868700422346592, accuracy: 99.4 %\n",
      "Training round [191/200], qnn_train_step: [200/1000], loss: 0.018588513135910034, accuracy: 99.3 %\n",
      "Training round [191/200], qnn_train_step: [300/1000], loss: 0.0245051346719265, accuracy: 99.2 %\n",
      "Training round [191/200], qnn_train_step: [400/1000], loss: 0.018038053065538406, accuracy: 99.3 %\n",
      "Training round [191/200], qnn_train_step: [500/1000], loss: 0.028242172673344612, accuracy: 99.2 %\n",
      "Training round [191/200], qnn_train_step: [600/1000], loss: 0.019991058856248856, accuracy: 99.5 %\n",
      "Training round [191/200], qnn_train_step: [700/1000], loss: 0.020882174372673035, accuracy: 99.4 %\n",
      "Training round [191/200], qnn_train_step: [800/1000], loss: 0.015790222212672234, accuracy: 99.6 %\n",
      "Training round [191/200], qnn_train_step: [900/1000], loss: 0.014855015091598034, accuracy: 99.4 %\n",
      "Training round [191/200], qnn_train_step: [1000/1000], loss: 0.01787119172513485, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [192/200], Epoch [1/5], Step [20/47], Loss: 0.0301, batch time: 0.11, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [1/5], Step [40/47], Loss: 0.0452, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [2/5], Step [20/47], Loss: 0.0163, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [2/5], Step [40/47], Loss: 0.0265, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [3/5], Step [20/47], Loss: 0.0505, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [192/200], Epoch [3/5], Step [40/47], Loss: 0.0331, batch time: 0.11, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [4/5], Step [20/47], Loss: 0.0984, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [192/200], Epoch [4/5], Step [40/47], Loss: 0.0594, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [192/200], Epoch [5/5], Step [20/47], Loss: 0.0118, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [192/200], Epoch [5/5], Step [40/47], Loss: 0.0954, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [192/200], qnn_train_step: [100/1000], loss: 0.034554291516542435, accuracy: 98.8 %\n",
      "Training round [192/200], qnn_train_step: [200/1000], loss: 0.034312278032302856, accuracy: 98.8 %\n",
      "Training round [192/200], qnn_train_step: [300/1000], loss: 0.04702090844511986, accuracy: 98.2 %\n",
      "Training round [192/200], qnn_train_step: [400/1000], loss: 0.030214879661798477, accuracy: 99.0 %\n",
      "Training round [192/200], qnn_train_step: [500/1000], loss: 0.03919485956430435, accuracy: 98.9 %\n",
      "Training round [192/200], qnn_train_step: [600/1000], loss: 0.026423877105116844, accuracy: 99.2 %\n",
      "Training round [192/200], qnn_train_step: [700/1000], loss: 0.026120102033019066, accuracy: 99.3 %\n",
      "Training round [192/200], qnn_train_step: [800/1000], loss: 0.027915487065911293, accuracy: 99.0 %\n",
      "Training round [192/200], qnn_train_step: [900/1000], loss: 0.026393301784992218, accuracy: 99.4 %\n",
      "Training round [192/200], qnn_train_step: [1000/1000], loss: 0.02663774974644184, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [193/200], Epoch [1/5], Step [20/47], Loss: 0.0686, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [193/200], Epoch [1/5], Step [40/47], Loss: 0.0952, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [2/5], Step [20/47], Loss: 0.0693, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [2/5], Step [40/47], Loss: 0.0346, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [3/5], Step [20/47], Loss: 0.0081, batch time: 0.09, accuracy:  100.00%\n",
      "Training round [193/200], Epoch [3/5], Step [40/47], Loss: 0.0885, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [193/200], Epoch [4/5], Step [20/47], Loss: 0.0691, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [4/5], Step [40/47], Loss: 0.0763, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [193/200], Epoch [5/5], Step [20/47], Loss: 0.0554, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [193/200], Epoch [5/5], Step [40/47], Loss: 0.0660, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [193/200], qnn_train_step: [100/1000], loss: 0.02454584278166294, accuracy: 99.3 %\n",
      "Training round [193/200], qnn_train_step: [200/1000], loss: 0.23838120698928833, accuracy: 93.5 %\n",
      "Training round [193/200], qnn_train_step: [300/1000], loss: 0.022318808361887932, accuracy: 99.7 %\n",
      "Training round [193/200], qnn_train_step: [400/1000], loss: 0.017128625884652138, accuracy: 99.9 %\n",
      "Training round [193/200], qnn_train_step: [500/1000], loss: 0.016764264553785324, accuracy: 99.9 %\n",
      "Training round [193/200], qnn_train_step: [600/1000], loss: 0.016113359481096268, accuracy: 99.7 %\n",
      "Training round [193/200], qnn_train_step: [700/1000], loss: 0.015988530591130257, accuracy: 99.8 %\n",
      "Training round [193/200], qnn_train_step: [800/1000], loss: 0.024265598505735397, accuracy: 99.3 %\n",
      "Training round [193/200], qnn_train_step: [900/1000], loss: 0.017057795077562332, accuracy: 99.7 %\n",
      "Training round [193/200], qnn_train_step: [1000/1000], loss: 0.021598506718873978, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [194/200], Epoch [1/5], Step [20/47], Loss: 0.0397, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [194/200], Epoch [1/5], Step [40/47], Loss: 0.0859, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [2/5], Step [20/47], Loss: 0.0793, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [2/5], Step [40/47], Loss: 0.0524, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [194/200], Epoch [3/5], Step [20/47], Loss: 0.0432, batch time: 0.09, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [3/5], Step [40/47], Loss: 0.0346, batch time: 0.06, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [4/5], Step [20/47], Loss: 0.0802, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [194/200], Epoch [4/5], Step [40/47], Loss: 0.0362, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [5/5], Step [20/47], Loss: 0.0979, batch time: 0.08, accuracy:  98.44%\n",
      "Training round [194/200], Epoch [5/5], Step [40/47], Loss: 0.0687, batch time: 0.06, accuracy:  99.22%\n",
      "Training round [194/200], qnn_train_step: [100/1000], loss: 0.03468327224254608, accuracy: 99.1 %\n",
      "Training round [194/200], qnn_train_step: [200/1000], loss: 0.0418630987405777, accuracy: 98.7 %\n",
      "Training round [194/200], qnn_train_step: [300/1000], loss: 0.028072338551282883, accuracy: 99.3 %\n",
      "Training round [194/200], qnn_train_step: [400/1000], loss: 0.03952973708510399, accuracy: 99.0 %\n",
      "Training round [194/200], qnn_train_step: [500/1000], loss: 0.026786599308252335, accuracy: 99.5 %\n",
      "Training round [194/200], qnn_train_step: [600/1000], loss: 0.026758575811982155, accuracy: 99.4 %\n",
      "Training round [194/200], qnn_train_step: [700/1000], loss: 0.025773227214813232, accuracy: 99.5 %\n",
      "Training round [194/200], qnn_train_step: [800/1000], loss: 0.025311335921287537, accuracy: 99.4 %\n",
      "Training round [194/200], qnn_train_step: [900/1000], loss: 0.024962972849607468, accuracy: 99.5 %\n",
      "Training round [194/200], qnn_train_step: [1000/1000], loss: 0.024536048993468285, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [195/200], Epoch [1/5], Step [20/47], Loss: 0.0698, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [1/5], Step [40/47], Loss: 0.1433, batch time: 0.05, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [2/5], Step [20/47], Loss: 0.0335, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [2/5], Step [40/47], Loss: 0.1525, batch time: 0.08, accuracy:  94.53%\n",
      "Training round [195/200], Epoch [3/5], Step [20/47], Loss: 0.0239, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [3/5], Step [40/47], Loss: 0.0662, batch time: 0.05, accuracy:  97.66%\n",
      "Training round [195/200], Epoch [4/5], Step [20/47], Loss: 0.0320, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [195/200], Epoch [4/5], Step [40/47], Loss: 0.0363, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [195/200], Epoch [5/5], Step [20/47], Loss: 0.0532, batch time: 0.11, accuracy:  96.09%\n",
      "Training round [195/200], Epoch [5/5], Step [40/47], Loss: 0.0490, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [195/200], qnn_train_step: [100/1000], loss: 0.03355545550584793, accuracy: 98.5 %\n",
      "Training round [195/200], qnn_train_step: [200/1000], loss: 0.04751288890838623, accuracy: 98.2 %\n",
      "Training round [195/200], qnn_train_step: [300/1000], loss: 0.03170567750930786, accuracy: 98.9 %\n",
      "Training round [195/200], qnn_train_step: [400/1000], loss: 0.03038850426673889, accuracy: 99.2 %\n",
      "Training round [195/200], qnn_train_step: [500/1000], loss: 0.02974587120115757, accuracy: 99.1 %\n",
      "Training round [195/200], qnn_train_step: [600/1000], loss: 0.028854217380285263, accuracy: 99.1 %\n",
      "Training round [195/200], qnn_train_step: [700/1000], loss: 0.04183044657111168, accuracy: 98.2 %\n",
      "Training round [195/200], qnn_train_step: [800/1000], loss: 0.03009428270161152, accuracy: 99.1 %\n",
      "Training round [195/200], qnn_train_step: [900/1000], loss: 0.0268268920481205, accuracy: 99.3 %\n",
      "Training round [195/200], qnn_train_step: [1000/1000], loss: 0.02611369639635086, accuracy: 99.4 %\n",
      "-----------------------\n",
      "Training round [196/200], Epoch [1/5], Step [20/47], Loss: 0.1101, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [1/5], Step [40/47], Loss: 0.0794, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [2/5], Step [20/47], Loss: 0.0609, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [2/5], Step [40/47], Loss: 0.0435, batch time: 0.10, accuracy:  96.88%\n",
      "Training round [196/200], Epoch [3/5], Step [20/47], Loss: 0.0153, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [196/200], Epoch [3/5], Step [40/47], Loss: 0.0078, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [196/200], Epoch [4/5], Step [20/47], Loss: 0.0762, batch time: 0.10, accuracy:  96.09%\n",
      "Training round [196/200], Epoch [4/5], Step [40/47], Loss: 0.0914, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [5/5], Step [20/47], Loss: 0.0419, batch time: 0.05, accuracy:  98.44%\n",
      "Training round [196/200], Epoch [5/5], Step [40/47], Loss: 0.0511, batch time: 0.11, accuracy:  97.66%\n",
      "Training round [196/200], qnn_train_step: [100/1000], loss: 0.05264315381646156, accuracy: 98.4 %\n",
      "Training round [196/200], qnn_train_step: [200/1000], loss: 0.31161144375801086, accuracy: 88.8 %\n",
      "Training round [196/200], qnn_train_step: [300/1000], loss: 0.04615810886025429, accuracy: 98.4 %\n",
      "Training round [196/200], qnn_train_step: [400/1000], loss: 0.04023679345846176, accuracy: 98.6 %\n",
      "Training round [196/200], qnn_train_step: [500/1000], loss: 0.03599838539958, accuracy: 98.6 %\n",
      "Training round [196/200], qnn_train_step: [600/1000], loss: 0.034406568855047226, accuracy: 98.8 %\n",
      "Training round [196/200], qnn_train_step: [700/1000], loss: 0.031148921698331833, accuracy: 99.0 %\n",
      "Training round [196/200], qnn_train_step: [800/1000], loss: 0.03239844739437103, accuracy: 99.1 %\n",
      "Training round [196/200], qnn_train_step: [900/1000], loss: 0.027900835499167442, accuracy: 99.4 %\n",
      "Training round [196/200], qnn_train_step: [1000/1000], loss: 0.030913053080439568, accuracy: 99.2 %\n",
      "-----------------------\n",
      "Training round [197/200], Epoch [1/5], Step [20/47], Loss: 0.0593, batch time: 0.05, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [1/5], Step [40/47], Loss: 0.0286, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [2/5], Step [20/47], Loss: 0.1048, batch time: 0.41, accuracy:  96.09%\n",
      "Training round [197/200], Epoch [2/5], Step [40/47], Loss: 0.0398, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [3/5], Step [20/47], Loss: 0.0106, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [197/200], Epoch [3/5], Step [40/47], Loss: 0.0581, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [197/200], Epoch [4/5], Step [20/47], Loss: 0.0770, batch time: 0.10, accuracy:  95.31%\n",
      "Training round [197/200], Epoch [4/5], Step [40/47], Loss: 0.0110, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [197/200], Epoch [5/5], Step [20/47], Loss: 0.0102, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [197/200], Epoch [5/5], Step [40/47], Loss: 0.0428, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [197/200], qnn_train_step: [100/1000], loss: 0.023625457659363747, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [200/1000], loss: 0.41871336102485657, accuracy: 88.0 %\n",
      "Training round [197/200], qnn_train_step: [300/1000], loss: 0.03260306268930435, accuracy: 99.1 %\n",
      "Training round [197/200], qnn_train_step: [400/1000], loss: 0.02145165205001831, accuracy: 99.4 %\n",
      "Training round [197/200], qnn_train_step: [500/1000], loss: 0.021302923560142517, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [600/1000], loss: 0.019477974623441696, accuracy: 99.5 %\n",
      "Training round [197/200], qnn_train_step: [700/1000], loss: 0.02125026099383831, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [800/1000], loss: 0.01841459423303604, accuracy: 99.6 %\n",
      "Training round [197/200], qnn_train_step: [900/1000], loss: 0.02321767434477806, accuracy: 99.2 %\n",
      "Training round [197/200], qnn_train_step: [1000/1000], loss: 0.017104845494031906, accuracy: 99.8 %\n",
      "-----------------------\n",
      "Training round [198/200], Epoch [1/5], Step [20/47], Loss: 0.0540, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [1/5], Step [40/47], Loss: 0.0464, batch time: 0.09, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [2/5], Step [20/47], Loss: 0.1142, batch time: 0.04, accuracy:  95.31%\n",
      "Training round [198/200], Epoch [2/5], Step [40/47], Loss: 0.0706, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [198/200], Epoch [3/5], Step [20/47], Loss: 0.0179, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [3/5], Step [40/47], Loss: 0.0592, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [198/200], Epoch [4/5], Step [20/47], Loss: 0.0082, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [198/200], Epoch [4/5], Step [40/47], Loss: 0.0682, batch time: 0.05, accuracy:  99.22%\n",
      "Training round [198/200], Epoch [5/5], Step [20/47], Loss: 0.0684, batch time: 0.05, accuracy:  96.88%\n",
      "Training round [198/200], Epoch [5/5], Step [40/47], Loss: 0.0452, batch time: 0.10, accuracy:  97.66%\n",
      "Training round [198/200], qnn_train_step: [100/1000], loss: 0.048815686255693436, accuracy: 98.5 %\n",
      "Training round [198/200], qnn_train_step: [200/1000], loss: 0.5339463353157043, accuracy: 86.1 %\n",
      "Training round [198/200], qnn_train_step: [300/1000], loss: 0.04552863538265228, accuracy: 98.6 %\n",
      "Training round [198/200], qnn_train_step: [400/1000], loss: 0.04076145216822624, accuracy: 98.5 %\n",
      "Training round [198/200], qnn_train_step: [500/1000], loss: 0.03993654623627663, accuracy: 98.6 %\n",
      "Training round [198/200], qnn_train_step: [600/1000], loss: 0.041485272347927094, accuracy: 98.8 %\n",
      "Training round [198/200], qnn_train_step: [700/1000], loss: 0.043110597878694534, accuracy: 98.0 %\n",
      "Training round [198/200], qnn_train_step: [800/1000], loss: 0.03976968675851822, accuracy: 98.7 %\n",
      "Training round [198/200], qnn_train_step: [900/1000], loss: 0.03606097400188446, accuracy: 98.7 %\n",
      "Training round [198/200], qnn_train_step: [1000/1000], loss: 0.038933586329221725, accuracy: 98.6 %\n",
      "-----------------------\n",
      "Training round [199/200], Epoch [1/5], Step [20/47], Loss: 0.0219, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [1/5], Step [40/47], Loss: 0.0562, batch time: 0.07, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [2/5], Step [20/47], Loss: 0.0604, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [2/5], Step [40/47], Loss: 0.2119, batch time: 0.05, accuracy:  93.75%\n",
      "Training round [199/200], Epoch [3/5], Step [20/47], Loss: 0.0045, batch time: 0.04, accuracy:  100.00%\n",
      "Training round [199/200], Epoch [3/5], Step [40/47], Loss: 0.0543, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [4/5], Step [20/47], Loss: 0.0389, batch time: 0.10, accuracy:  98.44%\n",
      "Training round [199/200], Epoch [4/5], Step [40/47], Loss: 0.0216, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [5/5], Step [20/47], Loss: 0.0092, batch time: 0.10, accuracy:  99.22%\n",
      "Training round [199/200], Epoch [5/5], Step [40/47], Loss: 0.0098, batch time: 0.10, accuracy:  100.00%\n",
      "Training round [199/200], qnn_train_step: [100/1000], loss: 0.025705544278025627, accuracy: 99.0 %\n",
      "Training round [199/200], qnn_train_step: [200/1000], loss: 0.16214853525161743, accuracy: 95.0 %\n",
      "Training round [199/200], qnn_train_step: [300/1000], loss: 0.02663305401802063, accuracy: 99.0 %\n",
      "Training round [199/200], qnn_train_step: [400/1000], loss: 0.01940217986702919, accuracy: 99.4 %\n",
      "Training round [199/200], qnn_train_step: [500/1000], loss: 0.016748739406466484, accuracy: 99.5 %\n",
      "Training round [199/200], qnn_train_step: [600/1000], loss: 0.016481289640069008, accuracy: 99.4 %\n",
      "Training round [199/200], qnn_train_step: [700/1000], loss: 0.01954025588929653, accuracy: 99.4 %\n",
      "Training round [199/200], qnn_train_step: [800/1000], loss: 0.01652134209871292, accuracy: 99.6 %\n",
      "Training round [199/200], qnn_train_step: [900/1000], loss: 0.019324859604239464, accuracy: 99.4 %\n",
      "Training round [199/200], qnn_train_step: [1000/1000], loss: 0.016605690121650696, accuracy: 99.5 %\n",
      "-----------------------\n",
      "Training round [200/200], Epoch [1/5], Step [20/47], Loss: 0.0671, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [1/5], Step [40/47], Loss: 0.0666, batch time: 0.04, accuracy:  96.88%\n",
      "Training round [200/200], Epoch [2/5], Step [20/47], Loss: 0.0197, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [2/5], Step [40/47], Loss: 0.0521, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [200/200], Epoch [3/5], Step [20/47], Loss: 0.0443, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [3/5], Step [40/47], Loss: 0.0242, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [4/5], Step [20/47], Loss: 0.0241, batch time: 0.04, accuracy:  98.44%\n",
      "Training round [200/200], Epoch [4/5], Step [40/47], Loss: 0.1028, batch time: 0.04, accuracy:  96.09%\n",
      "Training round [200/200], Epoch [5/5], Step [20/47], Loss: 0.0220, batch time: 0.04, accuracy:  99.22%\n",
      "Training round [200/200], Epoch [5/5], Step [40/47], Loss: 0.0590, batch time: 0.04, accuracy:  97.66%\n",
      "Training round [200/200], qnn_train_step: [100/1000], loss: 0.052164480090141296, accuracy: 97.7 %\n",
      "Training round [200/200], qnn_train_step: [200/1000], loss: 0.05254475399851799, accuracy: 97.7 %\n",
      "Training round [200/200], qnn_train_step: [300/1000], loss: 0.052691247314214706, accuracy: 97.8 %\n",
      "Training round [200/200], qnn_train_step: [400/1000], loss: 0.039376892149448395, accuracy: 98.5 %\n",
      "Training round [200/200], qnn_train_step: [500/1000], loss: 0.04073936119675636, accuracy: 97.8 %\n",
      "Training round [200/200], qnn_train_step: [600/1000], loss: 0.035440459847450256, accuracy: 98.4 %\n",
      "Training round [200/200], qnn_train_step: [700/1000], loss: 0.03653958812355995, accuracy: 98.8 %\n",
      "Training round [200/200], qnn_train_step: [800/1000], loss: 0.03016108088195324, accuracy: 98.7 %\n",
      "Training round [200/200], qnn_train_step: [900/1000], loss: 0.0345829539000988, accuracy: 98.4 %\n",
      "Training round [200/200], qnn_train_step: [1000/1000], loss: 0.02861122414469719, accuracy: 98.8 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 200\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "loss_list_epoch = [] \n",
    "acc_list_epoch  = [] \n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{1000}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 1000, 'adaptive': True} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "    loss_list_epoch.append(loss)\n",
    "    acc_list_epoch.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot([loss_i.cpu().detach() for loss_i in loss_list_epoch])\n",
    "# plt.ylim(0.5, 2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(acc_list_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.029899001121521, 0.43250590562820435, 0.5692499876022339, 0.3347778618335724, 0.3189838230609894, 0.39029285311698914, 0.1414300501346588, 0.08128093928098679, 0.27098435163497925, 0.426920622587204, 0.30427980422973633, 0.19780458509922028, 0.23390762507915497, 0.18581189215183258, 0.15892146527767181, 0.2804160416126251, 0.1761610507965088, 0.21272139251232147, 0.3811495304107666, 0.08705585449934006, 0.1473361700773239, 0.13479046523571014, 0.18439161777496338, 0.08085237443447113, 0.07088090479373932, 0.23570874333381653, 0.2488597333431244, 0.15052950382232666, 0.1151902824640274, 0.1313190907239914, 0.0590776726603508, 0.1739804446697235, 0.053440265357494354, 0.23631992936134338, 0.07169311493635178, 0.10592049360275269, 0.06145009398460388, 0.09667492657899857, 0.11027254164218903, 0.09434621781110764, 0.11729522049427032, 0.1228569746017456, 0.17763566970825195, 0.12180071324110031, 0.09725216776132584, 0.13180726766586304, 0.16668465733528137, 0.08471595495939255, 0.14120197296142578, 0.07881525903940201, 0.22492648661136627, 0.10645367205142975, 0.08670360594987869, 0.060924362391233444, 0.13459961116313934, 0.14222416281700134, 0.07526665925979614, 0.15815678238868713, 0.04948123171925545, 0.10387266427278519, 0.20379948616027832, 0.1211775690317154, 0.12639738619327545, 0.01982572302222252, 0.08488469570875168, 0.06659214943647385, 0.04741201549768448, 0.07438783347606659, 0.01985110156238079, 0.08220815658569336, 0.053001243621110916, 0.1023239716887474, 0.09493986517190933, 0.040142592042684555, 0.1957087516784668, 0.12577033042907715, 0.09472357481718063, 0.1082381010055542, 0.1996782273054123, 0.044886160641908646, 0.04520268365740776, 0.09766222536563873, 0.0955696702003479, 0.09045413881540298, 0.08974701166152954, 0.12215877324342728, 0.027670223265886307, 0.07864762097597122, 0.08925469219684601, 0.06391013413667679, 0.036888573318719864, 0.11894964426755905, 0.1218334510922432, 0.036016225814819336, 0.043516725301742554, 0.13297292590141296, 0.16996470093727112, 0.03294314071536064, 0.09092126786708832, 0.16619209945201874, 0.06211154907941818, 0.05855154991149902, 0.04916118457913399, 0.0731320008635521, 0.16062085330486298, 0.0815855860710144, 0.09174344688653946, 0.055675484240055084, 0.0472806878387928, 0.051172517240047455, 0.06391377002000809, 0.06142190843820572, 0.03536036238074303, 0.09267126768827438, 0.11035876721143723, 0.05544131249189377, 0.08920229226350784, 0.11784394085407257, 0.13284605741500854, 0.044377028942108154, 0.07009689509868622, 0.02927311882376671, 0.034877385944128036, 0.16613508760929108, 0.03279149904847145, 0.10420560091733932, 0.11647810786962509, 0.05072847008705139, 0.08450867235660553, 0.03608163818717003, 0.07593714445829391, 0.17188259959220886, 0.12321823835372925, 0.0465458519756794, 0.09500318765640259, 0.04107993096113205, 0.061801254749298096, 0.051741600036621094, 0.04795214533805847, 0.041751760989427567, 0.07092057913541794, 0.030243264511227608, 0.23463276028633118, 0.11007128655910492, 0.038686662912368774, 0.047679491341114044, 0.021391721442341805, 0.08129068464040756, 0.0559670552611351, 0.10454940795898438, 0.10527031123638153, 0.0680873841047287, 0.052414510399103165, 0.11460421234369278, 0.04528268054127693, 0.09710291773080826, 0.09687430411577225, 0.06588466465473175, 0.04646828770637512, 0.03688729554414749, 0.022682612761855125, 0.06738071143627167, 0.019069239497184753, 0.07947558909654617, 0.008780100382864475, 0.055894434452056885, 0.042836423963308334, 0.05557307228446007, 0.054909009486436844, 0.06219526007771492, 0.1408580094575882, 0.03309182450175285, 0.020209860056638718, 0.11891310662031174, 0.08959994465112686, 0.0828738734126091, 0.08961206674575806, 0.1747448593378067, 0.007622276432812214, 0.09414472430944443, 0.10141138732433319, 0.05470465496182442, 0.14576582610607147, 0.027364084497094154, 0.021260375156998634, 0.018782081082463264, 0.050533052533864975, 0.033083073794841766, 0.02301624044775963, 0.05008208006620407, 0.021934019401669502, 0.07786048203706741, 0.03169449418783188, 0.048020921647548676, 0.026701439172029495, 0.08132778108119965, 0.04222101718187332, 0.09553772956132889, 0.020881252363324165, 0.0603727288544178]\n",
      "[63.392857142857146, 89.28571428571429, 79.46428571428571, 90.17857142857143, 84.82142857142857, 92.85714285714286, 94.64285714285714, 96.42857142857143, 90.17857142857143, 87.5, 91.96428571428571, 92.85714285714286, 92.85714285714286, 93.75, 94.64285714285714, 91.07142857142857, 93.75, 96.42857142857143, 89.28571428571429, 97.32142857142857, 96.42857142857143, 96.42857142857143, 96.42857142857143, 97.32142857142857, 95.53571428571429, 92.85714285714286, 95.53571428571429, 94.64285714285714, 96.42857142857143, 96.42857142857143, 98.21428571428571, 95.53571428571429, 98.21428571428571, 94.64285714285714, 97.32142857142857, 96.42857142857143, 97.32142857142857, 98.21428571428571, 96.42857142857143, 96.42857142857143, 97.32142857142857, 97.32142857142857, 95.53571428571429, 96.42857142857143, 96.42857142857143, 96.42857142857143, 94.64285714285714, 96.42857142857143, 92.85714285714286, 97.32142857142857, 94.64285714285714, 93.75, 97.32142857142857, 98.21428571428571, 94.64285714285714, 95.53571428571429, 96.42857142857143, 92.85714285714286, 98.21428571428571, 96.42857142857143, 93.75, 94.64285714285714, 95.53571428571429, 100.0, 96.42857142857143, 97.32142857142857, 98.21428571428571, 98.21428571428571, 99.10714285714286, 95.53571428571429, 98.21428571428571, 97.32142857142857, 98.21428571428571, 99.10714285714286, 93.75, 97.32142857142857, 95.53571428571429, 95.53571428571429, 94.64285714285714, 100.0, 98.21428571428571, 92.85714285714286, 97.32142857142857, 97.32142857142857, 96.42857142857143, 96.42857142857143, 99.10714285714286, 96.42857142857143, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 99.10714285714286, 96.42857142857143, 97.32142857142857, 99.10714285714286, 97.32142857142857, 95.53571428571429, 99.10714285714286, 97.32142857142857, 99.10714285714286, 97.32142857142857, 95.53571428571429, 97.32142857142857, 96.42857142857143, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 98.21428571428571, 99.10714285714286, 98.21428571428571, 97.32142857142857, 96.42857142857143, 95.53571428571429, 98.21428571428571, 99.10714285714286, 97.32142857142857, 97.32142857142857, 99.10714285714286, 99.10714285714286, 96.42857142857143, 99.10714285714286, 96.42857142857143, 96.42857142857143, 98.21428571428571, 99.10714285714286, 99.10714285714286, 97.32142857142857, 93.75, 96.42857142857143, 99.10714285714286, 97.32142857142857, 99.10714285714286, 99.10714285714286, 97.32142857142857, 98.21428571428571, 99.10714285714286, 94.64285714285714, 99.10714285714286, 95.53571428571429, 95.53571428571429, 97.32142857142857, 97.32142857142857, 100.0, 98.21428571428571, 97.32142857142857, 97.32142857142857, 97.32142857142857, 98.21428571428571, 95.53571428571429, 96.42857142857143, 98.21428571428571, 97.32142857142857, 99.10714285714286, 97.32142857142857, 98.21428571428571, 99.10714285714286, 100.0, 96.42857142857143, 100.0, 95.53571428571429, 100.0, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 98.21428571428571, 95.53571428571429, 99.10714285714286, 100.0, 96.42857142857143, 96.42857142857143, 97.32142857142857, 98.21428571428571, 97.32142857142857, 100.0, 97.32142857142857, 97.32142857142857, 98.21428571428571, 94.64285714285714, 99.10714285714286, 100.0, 100.0, 97.32142857142857, 98.21428571428571, 99.10714285714286, 97.32142857142857, 99.10714285714286, 97.32142857142857, 98.21428571428571, 99.10714285714286, 99.10714285714286, 96.42857142857143, 99.10714285714286, 95.53571428571429, 99.10714285714286, 97.32142857142857]\n"
     ]
    }
   ],
   "source": [
    "print([float(loss_i.cpu().detach()) for loss_i in loss_list_epoch])\n",
    "print(acc_list_epoch)\n",
    "# loss_list_epoch_ = [0.7295889258384705, 0.37225136160850525, 0.3794281482696533, 0.2908739149570465, 0.43344172835350037, 0.27880460023880005, 0.2807650566101074, 0.20331154763698578, 0.2101973593235016, 0.23116184771060944, 0.10327416658401489, 0.16498956084251404, 0.14733383059501648, 0.2357337772846222, 0.14088773727416992, 0.2627231776714325, 0.14592070877552032, 0.15164850652217865, 0.14312252402305603, 0.2999897301197052, 0.1543511301279068, 0.1168191209435463, 0.09149902313947678, 0.08818130195140839, 0.17483066022396088, 0.09331480413675308, 0.10903004556894302, 0.0604548379778862, 0.054661791771650314, 0.21482913196086884, 0.21005532145500183, 0.11599947512149811, 0.12199731916189194, 0.17060816287994385, 0.09656911343336105, 0.12076913565397263, 0.14223608374595642, 0.12214209884405136, 0.12598419189453125, 0.20774959027767181, 0.12562747299671173, 0.05798206105828285, 0.08537358045578003, 0.09132971614599228, 0.08395314961671829, 0.0925174281001091, 0.09165353327989578, 0.07104451954364777, 0.12592284381389618, 0.07290033251047134, 0.11653145402669907, 0.1407156139612198, 0.16472028195858002, 0.06895224004983902, 0.07666359841823578, 0.09128779917955399, 0.1064082533121109, 0.16540132462978363, 0.13058657944202423, 0.058192748576402664, 0.15255580842494965, 0.09045841544866562, 0.12273383140563965, 0.06930835545063019, 0.12350992858409882, 0.1495860517024994, 0.10747058689594269, 0.019945060834288597, 0.07585586607456207, 0.06168632581830025, 0.10841090977191925, 0.09259108453989029, 0.08358635753393173, 0.15307806432247162, 0.03157993406057358, 0.03353184834122658, 0.059821370989084244, 0.07532096654176712, 0.058051008731126785, 0.12870363891124725, 0.06339791417121887, 0.10408617556095123, 0.0348079688847065, 0.144712433218956, 0.03777512535452843, 0.0347035750746727, 0.04901571944355965, 0.08264226466417313, 0.07996805012226105, 0.10003707557916641, 0.04558798298239708, 0.06215759739279747, 0.09527444839477539, 0.15841999650001526, 0.08665261417627335, 0.06608270853757858, 0.1392325609922409, 0.05976185202598572, 0.04475388675928116, 0.05046752095222473, 0.01770208589732647, 0.11257561296224594, 0.08217576891183853, 0.06886246055364609, 0.0647527351975441, 0.11289358884096146, 0.032170556485652924, 0.05809175223112106, 0.02198861353099346, 0.08662623167037964, 0.01977292262017727, 0.1252555102109909, 0.036538153886795044, 0.08487582206726074, 0.03319808468222618, 0.07845177501440048, 0.050174862146377563, 0.08033042401075363, 0.03926192596554756, 0.03789876773953438, 0.03437197580933571, 0.031702954322099686, 0.07776973396539688, 0.03937016800045967, 0.07443903386592865, 0.06496304273605347, 0.07748646289110184, 0.04136805608868599, 0.09650576114654541, 0.058662254363298416, 0.14430248737335205, 0.0198906809091568, 0.057144645601511, 0.0636909008026123, 0.10880546271800995, 0.0641055628657341, 0.018843606114387512, 0.016618089750409126, 0.05505039915442467, 0.05061089247465134, 0.029107557609677315, 0.04825565963983536, 0.0770605057477951, 0.21265654265880585, 0.10228103399276733, 0.01519146841019392, 0.05302998423576355, 0.15496017038822174, 0.06060909107327461, 0.14264516532421112, 0.10289585590362549, 0.03408132866024971, 0.05106412246823311, 0.047193557024002075, 0.0915614441037178, 0.04980822280049324, 0.06825781613588333, 0.06853891164064407, 0.012041662819683552, 0.05680778995156288, 0.06900779157876968, 0.059922512620687485, 0.01982785202562809, 0.011271284893155098, 0.07022994011640549, 0.019407110288739204, 0.036349233239889145, 0.04349904507398605, 0.03552144765853882, 0.028772681951522827, 0.031061330810189247, 0.020731929689645767, 0.005126524716615677, 0.05172169953584671, 0.02199605293571949, 0.04478580504655838, 0.02919742278754711, 0.07082671672105789, 0.060766302049160004, 0.05465696379542351, 0.030511735007166862, 0.09941203892230988, 0.04756160452961922, 0.04810870438814163, 0.10716278105974197, 0.044292207807302475, 0.07319533079862595, 0.09031356871128082, 0.02215258777141571, 0.022291241213679314, 0.006363868713378906, 0.06773566454648972, 0.07918117940425873, 0.07341770827770233, 0.02614496275782585, 0.1454424411058426, 0.05506273731589317, 0.05775485187768936, 0.09766823053359985, 0.09280663728713989]\n",
    "# acc_list_epoch_ = [76.78571428571429, 87.5, 85.71428571428571, 89.28571428571429, 88.39285714285714, 91.07142857142857, 89.28571428571429, 91.96428571428571, 91.07142857142857, 92.85714285714286, 97.32142857142857, 92.85714285714286, 96.42857142857143, 93.75, 95.53571428571429, 91.07142857142857, 96.42857142857143, 95.53571428571429, 94.64285714285714, 92.85714285714286, 94.64285714285714, 97.32142857142857, 95.53571428571429, 97.32142857142857, 93.75, 97.32142857142857, 98.21428571428571, 98.21428571428571, 99.10714285714286, 94.64285714285714, 94.64285714285714, 96.42857142857143, 98.21428571428571, 96.42857142857143, 97.32142857142857, 96.42857142857143, 95.53571428571429, 96.42857142857143, 94.64285714285714, 93.75, 98.21428571428571, 97.32142857142857, 95.53571428571429, 97.32142857142857, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 95.53571428571429, 97.32142857142857, 95.53571428571429, 95.53571428571429, 95.53571428571429, 97.32142857142857, 98.21428571428571, 97.32142857142857, 96.42857142857143, 95.53571428571429, 96.42857142857143, 99.10714285714286, 97.32142857142857, 95.53571428571429, 95.53571428571429, 98.21428571428571, 96.42857142857143, 94.64285714285714, 96.42857142857143, 100.0, 97.32142857142857, 97.32142857142857, 97.32142857142857, 95.53571428571429, 96.42857142857143, 94.64285714285714, 99.10714285714286, 99.10714285714286, 98.21428571428571, 97.32142857142857, 97.32142857142857, 95.53571428571429, 97.32142857142857, 95.53571428571429, 99.10714285714286, 97.32142857142857, 99.10714285714286, 98.21428571428571, 98.21428571428571, 97.32142857142857, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 96.42857142857143, 96.42857142857143, 96.42857142857143, 97.32142857142857, 95.53571428571429, 96.42857142857143, 99.10714285714286, 98.21428571428571, 100.0, 95.53571428571429, 96.42857142857143, 96.42857142857143, 95.53571428571429, 96.42857142857143, 99.10714285714286, 97.32142857142857, 99.10714285714286, 97.32142857142857, 99.10714285714286, 96.42857142857143, 99.10714285714286, 96.42857142857143, 98.21428571428571, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 99.10714285714286, 100.0, 99.10714285714286, 96.42857142857143, 98.21428571428571, 96.42857142857143, 96.42857142857143, 96.42857142857143, 99.10714285714286, 96.42857142857143, 98.21428571428571, 95.53571428571429, 100.0, 98.21428571428571, 98.21428571428571, 98.21428571428571, 97.32142857142857, 100.0, 99.10714285714286, 98.21428571428571, 98.21428571428571, 99.10714285714286, 98.21428571428571, 97.32142857142857, 94.64285714285714, 95.53571428571429, 99.10714285714286, 99.10714285714286, 94.64285714285714, 97.32142857142857, 93.75, 98.21428571428571, 98.21428571428571, 97.32142857142857, 97.32142857142857, 95.53571428571429, 99.10714285714286, 98.21428571428571, 98.21428571428571, 100.0, 97.32142857142857, 98.21428571428571, 96.42857142857143, 99.10714285714286, 100.0, 98.21428571428571, 100.0, 99.10714285714286, 98.21428571428571, 98.21428571428571, 98.21428571428571, 99.10714285714286, 100.0, 100.0, 98.21428571428571, 100.0, 98.21428571428571, 100.0, 98.21428571428571, 97.32142857142857, 97.32142857142857, 99.10714285714286, 95.53571428571429, 98.21428571428571, 99.10714285714286, 98.21428571428571, 98.21428571428571, 97.32142857142857, 96.42857142857143, 99.10714285714286, 99.10714285714286, 100.0, 98.21428571428571, 97.32142857142857, 97.32142857142857, 99.10714285714286, 93.75, 97.32142857142857, 97.32142857142857, 96.42857142857143, 95.53571428571429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 98.47%\n",
      "Loss on the train set: 0.04\n",
      "Accuracy on the test set: 96.50%\n",
      "Loss on the test set: 0.23\n",
      "Generalization error: 0.19254664\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing train loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_train_list = []\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_train_list.append(loss_train)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# loss_test_list = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         outputs = model(images)\n",
    "#         loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "#         loss_test_list.append(loss_test)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "# print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "# print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
