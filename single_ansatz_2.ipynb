{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# # Assuming evaluate is defined elsewhere\n",
    "# # from your_module import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections.abc import Iterable\n",
    "import perceval as pcvl\n",
    "from boson_sampler import BosonSampler\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "# from model import MnistModel, evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# simulator = pcvl.Simulator(pcvl.NaiveBackend())\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 234, and embedding size = 1287\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"2400.0\" height=\"843.75\" viewBox=\"-35.0 0 1920.0 675.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,425.0 L25,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,475.0 L25,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,525.0 L25,525.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,575.0 L25,575.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,625.0 L25,625.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L53,25 L72,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,44 L97,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L53,75 L72,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,56 L97,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,43 L100,43 L100,57 L50,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.353524</text>\n",
       "<path d=\"M50,43 L100,43 L100,47 L50,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,50 L103,50 L103,60 L93,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,25 L175,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,40 L139,40 L153,10 L144,10 L130,40 L139,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.858102</text>\n",
       "<path d=\"M125,75 L175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,90 L139,90 L153,60 L144,60 L130,90 L139,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.680173</text>\n",
       "<path d=\"M25,125 L53,125 L72,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,144 L97,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L53,175 L72,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,156 L97,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,143 L100,143 L100,157 L50,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.113183</text>\n",
       "<path d=\"M50,143 L100,143 L100,147 L50,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,150 L103,150 L103,160 L93,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,125 L175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,140 L139,140 L153,110 L144,110 L130,140 L139,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.335815</text>\n",
       "<path d=\"M125,175 L175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,190 L139,190 L153,160 L144,160 L130,190 L139,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.403215</text>\n",
       "<path d=\"M25,225 L53,225 L72,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,244 L97,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L53,275 L72,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,256 L97,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,243 L100,243 L100,257 L50,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.590331</text>\n",
       "<path d=\"M50,243 L100,243 L100,247 L50,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,250 L103,250 L103,260 L93,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,225 L175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,240 L139,240 L153,210 L144,210 L130,240 L139,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.156114</text>\n",
       "<path d=\"M125,275 L175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,290 L139,290 L153,260 L144,260 L130,290 L139,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.147773</text>\n",
       "<path d=\"M25,325 L53,325 L72,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,344 L97,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,375 L53,375 L72,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,356 L97,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,343 L100,343 L100,357 L50,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.570683</text>\n",
       "<path d=\"M50,343 L100,343 L100,347 L50,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,350 L103,350 L103,360 L93,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,325 L175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,340 L139,340 L153,310 L144,310 L130,340 L139,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.816276</text>\n",
       "<path d=\"M125,375 L175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,390 L139,390 L153,360 L144,360 L130,390 L139,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.103109</text>\n",
       "<path d=\"M25,425 L53,425 L72,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,444 L97,425 L125,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,475 L53,475 L72,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,456 L97,475 L125,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,443 L100,443 L100,457 L50,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.2852</text>\n",
       "<path d=\"M50,443 L100,443 L100,447 L50,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,450 L103,450 L103,460 L93,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,425 L175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,440 L139,440 L153,410 L144,410 L130,440 L139,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.918067</text>\n",
       "<path d=\"M125,475 L175,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,490 L139,490 L153,460 L144,460 L130,490 L139,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.035533</text>\n",
       "<path d=\"M25,525 L53,525 L72,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,544 L97,525 L125,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,575 L53,575 L72,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M78,556 L97,575 L125,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M50,543 L100,543 L100,557 L50,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"75\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"75\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.129298</text>\n",
       "<path d=\"M50,543 L100,543 L100,547 L50,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M93,550 L103,550 L103,560 L93,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"98\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M125,525 L175,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,540 L139,540 L153,510 L144,510 L130,540 L139,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.065054</text>\n",
       "<path d=\"M125,575 L175,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M130,590 L139,590 L153,560 L144,560 L130,590 L139,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"147\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.760791</text>\n",
       "<path d=\"M175,75 L203,75 L222,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,94 L247,75 L275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,125 L203,125 L222,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,106 L247,125 L275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,93 L250,93 L250,107 L200,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.105594</text>\n",
       "<path d=\"M200,93 L250,93 L250,97 L200,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,100 L253,100 L253,110 L243,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,90 L289,90 L303,60 L294,60 L280,90 L289,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.356035</text>\n",
       "<path d=\"M275,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,140 L289,140 L303,110 L294,110 L280,140 L289,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.656975</text>\n",
       "<path d=\"M175,175 L203,175 L222,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,194 L247,175 L275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,225 L203,225 L222,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,206 L247,225 L275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,193 L250,193 L250,207 L200,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.757817</text>\n",
       "<path d=\"M200,193 L250,193 L250,197 L200,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,200 L253,200 L253,210 L243,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,190 L289,190 L303,160 L294,160 L280,190 L289,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.563413</text>\n",
       "<path d=\"M275,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,240 L289,240 L303,210 L294,210 L280,240 L289,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.399948</text>\n",
       "<path d=\"M175,275 L203,275 L222,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,294 L247,275 L275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,325 L203,325 L222,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,306 L247,325 L275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,293 L250,293 L250,307 L200,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.400328</text>\n",
       "<path d=\"M200,293 L250,293 L250,297 L200,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,300 L253,300 L253,310 L243,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,290 L289,290 L303,260 L294,260 L280,290 L289,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.057466</text>\n",
       "<path d=\"M275,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,340 L289,340 L303,310 L294,310 L280,340 L289,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.884389</text>\n",
       "<path d=\"M175,375 L203,375 L222,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,394 L247,375 L275,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,425 L203,425 L222,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,406 L247,425 L275,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,393 L250,393 L250,407 L200,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.015191</text>\n",
       "<path d=\"M200,393 L250,393 L250,397 L200,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,400 L253,400 L253,410 L243,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,390 L289,390 L303,360 L294,360 L280,390 L289,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.44238</text>\n",
       "<path d=\"M275,425 L325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,440 L289,440 L303,410 L294,410 L280,440 L289,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.108934</text>\n",
       "<path d=\"M175,475 L203,475 L222,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,494 L247,475 L275,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,525 L203,525 L222,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,506 L247,525 L275,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,493 L250,493 L250,507 L200,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.22129</text>\n",
       "<path d=\"M200,493 L250,493 L250,497 L200,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,500 L253,500 L253,510 L243,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,475 L325,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,490 L289,490 L303,460 L294,460 L280,490 L289,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.922306</text>\n",
       "<path d=\"M275,525 L325,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,540 L289,540 L303,510 L294,510 L280,540 L289,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.076948</text>\n",
       "<path d=\"M25,625.0 L175,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,575 L203,575 L222,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,594 L247,575 L275,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M175,625 L203,625 L222,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M228,606 L247,625 L275,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M200,593 L250,593 L250,607 L200,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"225\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"225\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.694703</text>\n",
       "<path d=\"M200,593 L250,593 L250,597 L200,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M243,600 L253,600 L253,610 L243,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"248\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M275,575 L325,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,590 L289,590 L303,560 L294,560 L280,590 L289,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.465808</text>\n",
       "<path d=\"M275,625 L325,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M280,640 L289,640 L303,610 L294,610 L280,640 L289,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"297\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.5341</text>\n",
       "<path d=\"M175,25.0 L325,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,25 L353,25 L372,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,44 L397,25 L425,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,75 L353,75 L372,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,56 L397,75 L425,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,43 L400,43 L400,57 L350,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.562266</text>\n",
       "<path d=\"M350,43 L400,43 L400,47 L350,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,50 L403,50 L403,60 L393,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,40 L439,40 L453,10 L444,10 L430,40 L439,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.758916</text>\n",
       "<path d=\"M425,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,90 L439,90 L453,60 L444,60 L430,90 L439,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.648447</text>\n",
       "<path d=\"M325,125 L353,125 L372,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,144 L397,125 L425,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,175 L353,175 L372,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,156 L397,175 L425,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,143 L400,143 L400,157 L350,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.533015</text>\n",
       "<path d=\"M350,143 L400,143 L400,147 L350,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,150 L403,150 L403,160 L393,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,140 L439,140 L453,110 L444,110 L430,140 L439,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.626985</text>\n",
       "<path d=\"M425,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,190 L439,190 L453,160 L444,160 L430,190 L439,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.425015</text>\n",
       "<path d=\"M325,225 L353,225 L372,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,244 L397,225 L425,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,275 L353,275 L372,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,256 L397,275 L425,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,243 L400,243 L400,257 L350,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.933286</text>\n",
       "<path d=\"M350,243 L400,243 L400,247 L350,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,250 L403,250 L403,260 L393,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,240 L439,240 L453,210 L444,210 L430,240 L439,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.27078</text>\n",
       "<path d=\"M425,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,290 L439,290 L453,260 L444,260 L430,290 L439,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.971158</text>\n",
       "<path d=\"M325,325 L353,325 L372,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,344 L397,325 L425,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,375 L353,375 L372,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,356 L397,375 L425,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,343 L400,343 L400,357 L350,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.426189</text>\n",
       "<path d=\"M350,343 L400,343 L400,347 L350,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,350 L403,350 L403,360 L393,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,340 L439,340 L453,310 L444,310 L430,340 L439,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.945629</text>\n",
       "<path d=\"M425,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,390 L439,390 L453,360 L444,360 L430,390 L439,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.666075</text>\n",
       "<path d=\"M325,425 L353,425 L372,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,444 L397,425 L425,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,475 L353,475 L372,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,456 L397,475 L425,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,443 L400,443 L400,457 L350,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.119933</text>\n",
       "<path d=\"M350,443 L400,443 L400,447 L350,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,450 L403,450 L403,460 L393,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,425 L475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,440 L439,440 L453,410 L444,410 L430,440 L439,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.742379</text>\n",
       "<path d=\"M425,475 L475,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,490 L439,490 L453,460 L444,460 L430,490 L439,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.187317</text>\n",
       "<path d=\"M325,525 L353,525 L372,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,544 L397,525 L425,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M325,575 L353,575 L372,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M378,556 L397,575 L425,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M350,543 L400,543 L400,557 L350,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"375\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"375\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.971801</text>\n",
       "<path d=\"M350,543 L400,543 L400,547 L350,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M393,550 L403,550 L403,560 L393,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"398\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M425,525 L475,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,540 L439,540 L453,510 L444,510 L430,540 L439,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.847875</text>\n",
       "<path d=\"M425,575 L475,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M430,590 L439,590 L453,560 L444,560 L430,590 L439,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"447\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.885693</text>\n",
       "<path d=\"M475,75 L503,75 L522,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,94 L547,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,125 L503,125 L522,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,106 L547,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,93 L550,93 L550,107 L500,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.169761</text>\n",
       "<path d=\"M500,93 L550,93 L550,97 L500,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,100 L553,100 L553,110 L543,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,75 L625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,90 L589,90 L603,60 L594,60 L580,90 L589,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.841685</text>\n",
       "<path d=\"M575,125 L625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,140 L589,140 L603,110 L594,110 L580,140 L589,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.234983</text>\n",
       "<path d=\"M475,175 L503,175 L522,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,194 L547,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,225 L503,225 L522,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,206 L547,225 L575,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,193 L550,193 L550,207 L500,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.399</text>\n",
       "<path d=\"M500,193 L550,193 L550,197 L500,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,200 L553,200 L553,210 L543,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,175 L625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,190 L589,190 L603,160 L594,160 L580,190 L589,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.380299</text>\n",
       "<path d=\"M575,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,240 L589,240 L603,210 L594,210 L580,240 L589,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.301728</text>\n",
       "<path d=\"M475,275 L503,275 L522,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,294 L547,275 L575,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,325 L503,325 L522,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,306 L547,325 L575,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,293 L550,293 L550,307 L500,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.692803</text>\n",
       "<path d=\"M500,293 L550,293 L550,297 L500,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,300 L553,300 L553,310 L543,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,290 L589,290 L603,260 L594,260 L580,290 L589,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.481506</text>\n",
       "<path d=\"M575,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,340 L589,340 L603,310 L594,310 L580,340 L589,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.025092</text>\n",
       "<path d=\"M475,375 L503,375 L522,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,394 L547,375 L575,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,425 L503,425 L522,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,406 L547,425 L575,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,393 L550,393 L550,407 L500,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.686634</text>\n",
       "<path d=\"M500,393 L550,393 L550,397 L500,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,400 L553,400 L553,410 L543,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,390 L589,390 L603,360 L594,360 L580,390 L589,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.458319</text>\n",
       "<path d=\"M575,425 L625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,440 L589,440 L603,410 L594,410 L580,440 L589,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.897889</text>\n",
       "<path d=\"M475,475 L503,475 L522,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,494 L547,475 L575,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,525 L503,525 L522,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,506 L547,525 L575,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,493 L550,493 L550,507 L500,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.190213</text>\n",
       "<path d=\"M500,493 L550,493 L550,497 L500,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,500 L553,500 L553,510 L543,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,475 L625,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,490 L589,490 L603,460 L594,460 L580,490 L589,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.106604</text>\n",
       "<path d=\"M575,525 L625,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,540 L589,540 L603,510 L594,510 L580,540 L589,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.85381</text>\n",
       "<path d=\"M325,625.0 L475,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,575 L503,575 L522,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,594 L547,575 L575,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M475,625 L503,625 L522,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M528,606 L547,625 L575,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M500,593 L550,593 L550,607 L500,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"525\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"525\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.940775</text>\n",
       "<path d=\"M500,593 L550,593 L550,597 L500,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M543,600 L553,600 L553,610 L543,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"548\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M575,575 L625,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,590 L589,590 L603,560 L594,560 L580,590 L589,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.205007</text>\n",
       "<path d=\"M575,625 L625,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M580,640 L589,640 L603,610 L594,610 L580,640 L589,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"597\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.822374</text>\n",
       "<path d=\"M475,25.0 L625,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,25 L653,25 L672,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,44 L697,25 L725,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,75 L653,75 L672,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,56 L697,75 L725,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,43 L700,43 L700,57 L650,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.979669</text>\n",
       "<path d=\"M650,43 L700,43 L700,47 L650,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,50 L703,50 L703,60 L693,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,40 L739,40 L753,10 L744,10 L730,40 L739,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.079541</text>\n",
       "<path d=\"M725,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,90 L739,90 L753,60 L744,60 L730,90 L739,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.543974</text>\n",
       "<path d=\"M625,125 L653,125 L672,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,144 L697,125 L725,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,175 L653,175 L672,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,156 L697,175 L725,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,143 L700,143 L700,157 L650,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.908277</text>\n",
       "<path d=\"M650,143 L700,143 L700,147 L650,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,150 L703,150 L703,160 L693,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,140 L739,140 L753,110 L744,110 L730,140 L739,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.001888</text>\n",
       "<path d=\"M725,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,190 L739,190 L753,160 L744,160 L730,190 L739,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.248693</text>\n",
       "<path d=\"M625,225 L653,225 L672,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,244 L697,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,275 L653,275 L672,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,256 L697,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,243 L700,243 L700,257 L650,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.982056</text>\n",
       "<path d=\"M650,243 L700,243 L700,247 L650,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,250 L703,250 L703,260 L693,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,225 L775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,240 L739,240 L753,210 L744,210 L730,240 L739,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.442465</text>\n",
       "<path d=\"M725,275 L775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,290 L739,290 L753,260 L744,260 L730,290 L739,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.147661</text>\n",
       "<path d=\"M625,325 L653,325 L672,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,344 L697,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,375 L653,375 L672,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,356 L697,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,343 L700,343 L700,357 L650,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.140884</text>\n",
       "<path d=\"M650,343 L700,343 L700,347 L650,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,350 L703,350 L703,360 L693,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,325 L775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,340 L739,340 L753,310 L744,310 L730,340 L739,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.994142</text>\n",
       "<path d=\"M725,375 L775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,390 L739,390 L753,360 L744,360 L730,390 L739,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.203026</text>\n",
       "<path d=\"M625,425 L653,425 L672,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,444 L697,425 L725,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,475 L653,475 L672,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,456 L697,475 L725,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,443 L700,443 L700,457 L650,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.774667</text>\n",
       "<path d=\"M650,443 L700,443 L700,447 L650,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,450 L703,450 L703,460 L693,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,425 L775,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,440 L739,440 L753,410 L744,410 L730,440 L739,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.213101</text>\n",
       "<path d=\"M725,475 L775,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,490 L739,490 L753,460 L744,460 L730,490 L739,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.626438</text>\n",
       "<path d=\"M625,525 L653,525 L672,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,544 L697,525 L725,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M625,575 L653,575 L672,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M678,556 L697,575 L725,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M650,543 L700,543 L700,557 L650,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"675\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"675\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.595523</text>\n",
       "<path d=\"M650,543 L700,543 L700,547 L650,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M693,550 L703,550 L703,560 L693,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"698\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M725,525 L775,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,540 L739,540 L753,510 L744,510 L730,540 L739,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.336118</text>\n",
       "<path d=\"M725,575 L775,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M730,590 L739,590 L753,560 L744,560 L730,590 L739,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"747\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.810551</text>\n",
       "<path d=\"M775,75 L803,75 L822,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,94 L847,75 L875,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,125 L803,125 L822,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,106 L847,125 L875,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,93 L850,93 L850,107 L800,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.609573</text>\n",
       "<path d=\"M800,93 L850,93 L850,97 L800,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,100 L853,100 L853,110 L843,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,90 L889,90 L903,60 L894,60 L880,90 L889,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.963383</text>\n",
       "<path d=\"M875,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,140 L889,140 L903,110 L894,110 L880,140 L889,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.755706</text>\n",
       "<path d=\"M775,175 L803,175 L822,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,194 L847,175 L875,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,225 L803,225 L822,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,206 L847,225 L875,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,193 L850,193 L850,207 L800,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.976252</text>\n",
       "<path d=\"M800,193 L850,193 L850,197 L800,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,200 L853,200 L853,210 L843,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,190 L889,190 L903,160 L894,160 L880,190 L889,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.171853</text>\n",
       "<path d=\"M875,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,240 L889,240 L903,210 L894,210 L880,240 L889,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.486584</text>\n",
       "<path d=\"M775,275 L803,275 L822,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,294 L847,275 L875,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,325 L803,325 L822,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,306 L847,325 L875,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,293 L850,293 L850,307 L800,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.440374</text>\n",
       "<path d=\"M800,293 L850,293 L850,297 L800,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,300 L853,300 L853,310 L843,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,290 L889,290 L903,260 L894,260 L880,290 L889,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.577263</text>\n",
       "<path d=\"M875,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,340 L889,340 L903,310 L894,310 L880,340 L889,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.136647</text>\n",
       "<path d=\"M775,375 L803,375 L822,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,394 L847,375 L875,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,425 L803,425 L822,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,406 L847,425 L875,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,393 L850,393 L850,407 L800,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.296251</text>\n",
       "<path d=\"M800,393 L850,393 L850,397 L800,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,400 L853,400 L853,410 L843,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,375 L925,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,390 L889,390 L903,360 L894,360 L880,390 L889,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.865821</text>\n",
       "<path d=\"M875,425 L925,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,440 L889,440 L903,410 L894,410 L880,440 L889,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.330937</text>\n",
       "<path d=\"M775,475 L803,475 L822,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,494 L847,475 L875,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,525 L803,525 L822,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,506 L847,525 L875,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,493 L850,493 L850,507 L800,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.633063</text>\n",
       "<path d=\"M800,493 L850,493 L850,497 L800,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,500 L853,500 L853,510 L843,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,475 L925,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,490 L889,490 L903,460 L894,460 L880,490 L889,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.899688</text>\n",
       "<path d=\"M875,525 L925,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,540 L889,540 L903,510 L894,510 L880,540 L889,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.265332</text>\n",
       "<path d=\"M625,625.0 L775,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,575 L803,575 L822,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,594 L847,575 L875,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M775,625 L803,625 L822,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M828,606 L847,625 L875,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M800,593 L850,593 L850,607 L800,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"825\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"825\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.923768</text>\n",
       "<path d=\"M800,593 L850,593 L850,597 L800,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M843,600 L853,600 L853,610 L843,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"848\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M875,575 L925,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,590 L889,590 L903,560 L894,560 L880,590 L889,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.125769</text>\n",
       "<path d=\"M875,625 L925,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M880,640 L889,640 L903,610 L894,610 L880,640 L889,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"897\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.965331</text>\n",
       "<path d=\"M775,25.0 L925,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,25 L953,25 L972,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,44 L997,25 L1025,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,75 L953,75 L972,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,56 L997,75 L1025,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,43 L1000,43 L1000,57 L950,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.335926</text>\n",
       "<path d=\"M950,43 L1000,43 L1000,47 L950,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,50 L1003,50 L1003,60 L993,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,25 L1075,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,40 L1039,40 L1053,10 L1044,10 L1030,40 L1039,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.288364</text>\n",
       "<path d=\"M1025,75 L1075,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,90 L1039,90 L1053,60 L1044,60 L1030,90 L1039,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.159556</text>\n",
       "<path d=\"M925,125 L953,125 L972,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,144 L997,125 L1025,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,175 L953,175 L972,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,156 L997,175 L1025,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,143 L1000,143 L1000,157 L950,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.675413</text>\n",
       "<path d=\"M950,143 L1000,143 L1000,147 L950,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,150 L1003,150 L1003,160 L993,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,125 L1075,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,140 L1039,140 L1053,110 L1044,110 L1030,140 L1039,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.027629</text>\n",
       "<path d=\"M1025,175 L1075,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,190 L1039,190 L1053,160 L1044,160 L1030,190 L1039,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.251361</text>\n",
       "<path d=\"M925,225 L953,225 L972,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,244 L997,225 L1025,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,275 L953,275 L972,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,256 L997,275 L1025,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,243 L1000,243 L1000,257 L950,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.726937</text>\n",
       "<path d=\"M950,243 L1000,243 L1000,247 L950,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,250 L1003,250 L1003,260 L993,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,225 L1075,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,240 L1039,240 L1053,210 L1044,210 L1030,240 L1039,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.297497</text>\n",
       "<path d=\"M1025,275 L1075,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,290 L1039,290 L1053,260 L1044,260 L1030,290 L1039,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.849266</text>\n",
       "<path d=\"M925,325 L953,325 L972,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,344 L997,325 L1025,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,375 L953,375 L972,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,356 L997,375 L1025,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,343 L1000,343 L1000,357 L950,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.102736</text>\n",
       "<path d=\"M950,343 L1000,343 L1000,347 L950,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,350 L1003,350 L1003,360 L993,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,325 L1075,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,340 L1039,340 L1053,310 L1044,310 L1030,340 L1039,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.230572</text>\n",
       "<path d=\"M1025,375 L1075,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,390 L1039,390 L1053,360 L1044,360 L1030,390 L1039,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.421834</text>\n",
       "<path d=\"M925,425 L953,425 L972,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,444 L997,425 L1025,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,475 L953,475 L972,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,456 L997,475 L1025,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,443 L1000,443 L1000,457 L950,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.776003</text>\n",
       "<path d=\"M950,443 L1000,443 L1000,447 L950,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,450 L1003,450 L1003,460 L993,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,425 L1075,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,440 L1039,440 L1053,410 L1044,410 L1030,440 L1039,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.353057</text>\n",
       "<path d=\"M1025,475 L1075,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,490 L1039,490 L1053,460 L1044,460 L1030,490 L1039,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.537135</text>\n",
       "<path d=\"M925,525 L953,525 L972,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,544 L997,525 L1025,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M925,575 L953,575 L972,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M978,556 L997,575 L1025,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M950,543 L1000,543 L1000,557 L950,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"975\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"975\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.64942</text>\n",
       "<path d=\"M950,543 L1000,543 L1000,547 L950,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M993,550 L1003,550 L1003,560 L993,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"998\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1025,525 L1075,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,540 L1039,540 L1053,510 L1044,510 L1030,540 L1039,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.446882</text>\n",
       "<path d=\"M1025,575 L1075,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1030,590 L1039,590 L1053,560 L1044,560 L1030,590 L1039,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1047\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.858787</text>\n",
       "<path d=\"M1075,75 L1103,75 L1122,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,94 L1147,75 L1175,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,125 L1103,125 L1122,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,106 L1147,125 L1175,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,93 L1150,93 L1150,107 L1100,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.690909</text>\n",
       "<path d=\"M1100,93 L1150,93 L1150,97 L1100,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,100 L1153,100 L1153,110 L1143,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,75 L1225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,90 L1189,90 L1203,60 L1194,60 L1180,90 L1189,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.143774</text>\n",
       "<path d=\"M1175,125 L1225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,140 L1189,140 L1203,110 L1194,110 L1180,140 L1189,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.66728</text>\n",
       "<path d=\"M1075,175 L1103,175 L1122,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,194 L1147,175 L1175,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,225 L1103,225 L1122,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,206 L1147,225 L1175,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,193 L1150,193 L1150,207 L1100,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.364024</text>\n",
       "<path d=\"M1100,193 L1150,193 L1150,197 L1100,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,200 L1153,200 L1153,210 L1143,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,175 L1225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,190 L1189,190 L1203,160 L1194,160 L1180,190 L1189,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.720467</text>\n",
       "<path d=\"M1175,225 L1225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,240 L1189,240 L1203,210 L1194,210 L1180,240 L1189,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.079447</text>\n",
       "<path d=\"M1075,275 L1103,275 L1122,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,294 L1147,275 L1175,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,325 L1103,325 L1122,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,306 L1147,325 L1175,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,293 L1150,293 L1150,307 L1100,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.32144</text>\n",
       "<path d=\"M1100,293 L1150,293 L1150,297 L1100,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,300 L1153,300 L1153,310 L1143,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,275 L1225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,290 L1189,290 L1203,260 L1194,260 L1180,290 L1189,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.702614</text>\n",
       "<path d=\"M1175,325 L1225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,340 L1189,340 L1203,310 L1194,310 L1180,340 L1189,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.789377</text>\n",
       "<path d=\"M1075,375 L1103,375 L1122,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,394 L1147,375 L1175,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,425 L1103,425 L1122,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,406 L1147,425 L1175,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,393 L1150,393 L1150,407 L1100,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.739287</text>\n",
       "<path d=\"M1100,393 L1150,393 L1150,397 L1100,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,400 L1153,400 L1153,410 L1143,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,375 L1225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,390 L1189,390 L1203,360 L1194,360 L1180,390 L1189,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.842373</text>\n",
       "<path d=\"M1175,425 L1225,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,440 L1189,440 L1203,410 L1194,410 L1180,440 L1189,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.719959</text>\n",
       "<path d=\"M1075,475 L1103,475 L1122,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,494 L1147,475 L1175,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,525 L1103,525 L1122,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,506 L1147,525 L1175,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,493 L1150,493 L1150,507 L1100,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.407064</text>\n",
       "<path d=\"M1100,493 L1150,493 L1150,497 L1100,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,500 L1153,500 L1153,510 L1143,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,475 L1225,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,490 L1189,490 L1203,460 L1194,460 L1180,490 L1189,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.851767</text>\n",
       "<path d=\"M1175,525 L1225,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,540 L1189,540 L1203,510 L1194,510 L1180,540 L1189,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.215201</text>\n",
       "<path d=\"M925,625.0 L1075,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,575 L1103,575 L1122,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,594 L1147,575 L1175,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1075,625 L1103,625 L1122,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1128,606 L1147,625 L1175,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1100,593 L1150,593 L1150,607 L1100,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1125\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1125\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.378599</text>\n",
       "<path d=\"M1100,593 L1150,593 L1150,597 L1100,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1143,600 L1153,600 L1153,610 L1143,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1148\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1175,575 L1225,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,590 L1189,590 L1203,560 L1194,560 L1180,590 L1189,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.374167</text>\n",
       "<path d=\"M1175,625 L1225,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1180,640 L1189,640 L1203,610 L1194,610 L1180,640 L1189,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1197\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.080932</text>\n",
       "<path d=\"M1075,25.0 L1225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,25 L1253,25 L1272,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,44 L1297,25 L1325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,75 L1253,75 L1272,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,56 L1297,75 L1325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,43 L1300,43 L1300,57 L1250,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.398544</text>\n",
       "<path d=\"M1250,43 L1300,43 L1300,47 L1250,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,50 L1303,50 L1303,60 L1293,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,25 L1375,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,40 L1339,40 L1353,10 L1344,10 L1330,40 L1339,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.6859</text>\n",
       "<path d=\"M1325,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,90 L1339,90 L1353,60 L1344,60 L1330,90 L1339,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.193619</text>\n",
       "<path d=\"M1225,125 L1253,125 L1272,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,144 L1297,125 L1325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,175 L1253,175 L1272,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,156 L1297,175 L1325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,143 L1300,143 L1300,157 L1250,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.67609</text>\n",
       "<path d=\"M1250,143 L1300,143 L1300,147 L1250,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,150 L1303,150 L1303,160 L1293,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,140 L1339,140 L1353,110 L1344,110 L1330,140 L1339,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.122136</text>\n",
       "<path d=\"M1325,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,190 L1339,190 L1353,160 L1344,160 L1330,190 L1339,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.17099</text>\n",
       "<path d=\"M1225,225 L1253,225 L1272,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,244 L1297,225 L1325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,275 L1253,275 L1272,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,256 L1297,275 L1325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,243 L1300,243 L1300,257 L1250,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.557513</text>\n",
       "<path d=\"M1250,243 L1300,243 L1300,247 L1250,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,250 L1303,250 L1303,260 L1293,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,240 L1339,240 L1353,210 L1344,210 L1330,240 L1339,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.473224</text>\n",
       "<path d=\"M1325,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,290 L1339,290 L1353,260 L1344,260 L1330,290 L1339,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.781071</text>\n",
       "<path d=\"M1225,325 L1253,325 L1272,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,344 L1297,325 L1325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,375 L1253,375 L1272,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,356 L1297,375 L1325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,343 L1300,343 L1300,357 L1250,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.139775</text>\n",
       "<path d=\"M1250,343 L1300,343 L1300,347 L1250,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,350 L1303,350 L1303,360 L1293,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,340 L1339,340 L1353,310 L1344,310 L1330,340 L1339,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.669006</text>\n",
       "<path d=\"M1325,375 L1375,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,390 L1339,390 L1353,360 L1344,360 L1330,390 L1339,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.731707</text>\n",
       "<path d=\"M1225,425 L1253,425 L1272,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,444 L1297,425 L1325,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,475 L1253,475 L1272,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,456 L1297,475 L1325,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,443 L1300,443 L1300,457 L1250,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.968815</text>\n",
       "<path d=\"M1250,443 L1300,443 L1300,447 L1250,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,450 L1303,450 L1303,460 L1293,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,425 L1375,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,440 L1339,440 L1353,410 L1344,410 L1330,440 L1339,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.297392</text>\n",
       "<path d=\"M1325,475 L1375,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,490 L1339,490 L1353,460 L1344,460 L1330,490 L1339,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.468487</text>\n",
       "<path d=\"M1225,525 L1253,525 L1272,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,544 L1297,525 L1325,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1225,575 L1253,575 L1272,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1278,556 L1297,575 L1325,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1250,543 L1300,543 L1300,557 L1250,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1275\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1275\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.880013</text>\n",
       "<path d=\"M1250,543 L1300,543 L1300,547 L1250,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1293,550 L1303,550 L1303,560 L1293,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1298\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1325,525 L1375,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,540 L1339,540 L1353,510 L1344,510 L1330,540 L1339,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.949948</text>\n",
       "<path d=\"M1325,575 L1375,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1330,590 L1339,590 L1353,560 L1344,560 L1330,590 L1339,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1347\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.194109</text>\n",
       "<path d=\"M1375,75 L1403,75 L1422,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,94 L1447,75 L1475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,125 L1403,125 L1422,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,106 L1447,125 L1475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,93 L1450,93 L1450,107 L1400,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.601056</text>\n",
       "<path d=\"M1400,93 L1450,93 L1450,97 L1400,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,100 L1453,100 L1453,110 L1443,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,75 L1525,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,90 L1489,90 L1503,60 L1494,60 L1480,90 L1489,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.845336</text>\n",
       "<path d=\"M1475,125 L1525,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,140 L1489,140 L1503,110 L1494,110 L1480,140 L1489,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.818597</text>\n",
       "<path d=\"M1375,175 L1403,175 L1422,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,194 L1447,175 L1475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,225 L1403,225 L1422,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,206 L1447,225 L1475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,193 L1450,193 L1450,207 L1400,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.040401</text>\n",
       "<path d=\"M1400,193 L1450,193 L1450,197 L1400,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,200 L1453,200 L1453,210 L1443,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,175 L1525,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,190 L1489,190 L1503,160 L1494,160 L1480,190 L1489,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=33*sqrt(2)/59</text>\n",
       "<path d=\"M1475,225 L1525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,240 L1489,240 L1503,210 L1494,210 L1480,240 L1489,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.37458</text>\n",
       "<path d=\"M1375,275 L1403,275 L1422,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,294 L1447,275 L1475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,325 L1403,325 L1422,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,306 L1447,325 L1475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,293 L1450,293 L1450,307 L1400,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.20972</text>\n",
       "<path d=\"M1400,293 L1450,293 L1450,297 L1400,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,300 L1453,300 L1453,310 L1443,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,275 L1525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,290 L1489,290 L1503,260 L1494,260 L1480,290 L1489,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.308013</text>\n",
       "<path d=\"M1475,325 L1525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,340 L1489,340 L1503,310 L1494,310 L1480,340 L1489,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.019029</text>\n",
       "<path d=\"M1375,375 L1403,375 L1422,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,394 L1447,375 L1475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,425 L1403,425 L1422,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,406 L1447,425 L1475,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,393 L1450,393 L1450,407 L1400,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.593097</text>\n",
       "<path d=\"M1400,393 L1450,393 L1450,397 L1400,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,400 L1453,400 L1453,410 L1443,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,375 L1525,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,390 L1489,390 L1503,360 L1494,360 L1480,390 L1489,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.412924</text>\n",
       "<path d=\"M1475,425 L1525,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,440 L1489,440 L1503,410 L1494,410 L1480,440 L1489,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.736421</text>\n",
       "<path d=\"M1375,475 L1403,475 L1422,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,494 L1447,475 L1475,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,525 L1403,525 L1422,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,506 L1447,525 L1475,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,493 L1450,493 L1450,507 L1400,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.776906</text>\n",
       "<path d=\"M1400,493 L1450,493 L1450,497 L1400,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,500 L1453,500 L1453,510 L1443,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,475 L1525,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,490 L1489,490 L1503,460 L1494,460 L1480,490 L1489,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.822328</text>\n",
       "<path d=\"M1475,525 L1525,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,540 L1489,540 L1503,510 L1494,510 L1480,540 L1489,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.407088</text>\n",
       "<path d=\"M1225,625.0 L1375,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,575 L1403,575 L1422,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,594 L1447,575 L1475,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1375,625 L1403,625 L1422,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1428,606 L1447,625 L1475,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1400,593 L1450,593 L1450,607 L1400,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1425\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1425\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.719644</text>\n",
       "<path d=\"M1400,593 L1450,593 L1450,597 L1400,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1443,600 L1453,600 L1453,610 L1443,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1448\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1475,575 L1525,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,590 L1489,590 L1503,560 L1494,560 L1480,590 L1489,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.303715</text>\n",
       "<path d=\"M1475,625 L1525,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1480,640 L1489,640 L1503,610 L1494,610 L1480,640 L1489,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1497\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.555364</text>\n",
       "<path d=\"M1375,25.0 L1525,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,25 L1553,25 L1572,44\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,44 L1597,25 L1625,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,75 L1553,75 L1572,56\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,56 L1597,75 L1625,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,43 L1600,43 L1600,57 L1550,57 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"80\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"26\" font-size=\"7\" text-anchor=\"middle\">Θ=0.329444</text>\n",
       "<path d=\"M1550,43 L1600,43 L1600,47 L1550,47 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,50 L1603,50 L1603,60 L1593,60 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"57\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,25 L1675,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,40 L1639,40 L1653,10 L1644,10 L1630,40 L1639,40 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"38\" font-size=\"7\" text-anchor=\"start\">Φ=0.678359</text>\n",
       "<path d=\"M1625,75 L1675,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,90 L1639,90 L1653,60 L1644,60 L1630,90 L1639,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.924867</text>\n",
       "<path d=\"M1525,125 L1553,125 L1572,144\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,144 L1597,125 L1625,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,175 L1553,175 L1572,156\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,156 L1597,175 L1625,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,143 L1600,143 L1600,157 L1550,157 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"180\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"126\" font-size=\"7\" text-anchor=\"middle\">Θ=0.513222</text>\n",
       "<path d=\"M1550,143 L1600,143 L1600,147 L1550,147 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,150 L1603,150 L1603,160 L1593,160 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"157\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,125 L1675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,140 L1639,140 L1653,110 L1644,110 L1630,140 L1639,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.438147</text>\n",
       "<path d=\"M1625,175 L1675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,190 L1639,190 L1653,160 L1644,160 L1630,190 L1639,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.556719</text>\n",
       "<path d=\"M1525,225 L1553,225 L1572,244\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,244 L1597,225 L1625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,275 L1553,275 L1572,256\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,256 L1597,275 L1625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,243 L1600,243 L1600,257 L1550,257 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"280\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"226\" font-size=\"7\" text-anchor=\"middle\">Θ=0.559827</text>\n",
       "<path d=\"M1550,243 L1600,243 L1600,247 L1550,247 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,250 L1603,250 L1603,260 L1593,260 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"257\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,225 L1675,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,240 L1639,240 L1653,210 L1644,210 L1630,240 L1639,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.071614</text>\n",
       "<path d=\"M1625,275 L1675,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,290 L1639,290 L1653,260 L1644,260 L1630,290 L1639,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.10489</text>\n",
       "<path d=\"M1525,325 L1553,325 L1572,344\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,344 L1597,325 L1625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,375 L1553,375 L1572,356\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,356 L1597,375 L1625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,343 L1600,343 L1600,357 L1550,357 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"380\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"326\" font-size=\"7\" text-anchor=\"middle\">Θ=0.462886</text>\n",
       "<path d=\"M1550,343 L1600,343 L1600,347 L1550,347 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,350 L1603,350 L1603,360 L1593,360 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"357\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,325 L1675,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,340 L1639,340 L1653,310 L1644,310 L1630,340 L1639,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.010425</text>\n",
       "<path d=\"M1625,375 L1675,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,390 L1639,390 L1653,360 L1644,360 L1630,390 L1639,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.031823</text>\n",
       "<path d=\"M1525,425 L1553,425 L1572,444\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,444 L1597,425 L1625,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,475 L1553,475 L1572,456\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,456 L1597,475 L1625,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,443 L1600,443 L1600,457 L1550,457 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"480\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"426\" font-size=\"7\" text-anchor=\"middle\">Θ=0.558132</text>\n",
       "<path d=\"M1550,443 L1600,443 L1600,447 L1550,447 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,450 L1603,450 L1603,460 L1593,460 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"457\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,425 L1675,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,440 L1639,440 L1653,410 L1644,410 L1630,440 L1639,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.971727</text>\n",
       "<path d=\"M1625,475 L1675,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,490 L1639,490 L1653,460 L1644,460 L1630,490 L1639,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.299319</text>\n",
       "<path d=\"M1525,525 L1553,525 L1572,544\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,544 L1597,525 L1625,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1525,575 L1553,575 L1572,556\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1578,556 L1597,575 L1625,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1550,543 L1600,543 L1600,557 L1550,557 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1575\" y=\"580\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1575\" y=\"526\" font-size=\"7\" text-anchor=\"middle\">Θ=0.785856</text>\n",
       "<path d=\"M1550,543 L1600,543 L1600,547 L1550,547 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1593,550 L1603,550 L1603,560 L1593,560 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1598\" y=\"557\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1625,525 L1675,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,540 L1639,540 L1653,510 L1644,510 L1630,540 L1639,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.668108</text>\n",
       "<path d=\"M1625,575 L1675,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1630,590 L1639,590 L1653,560 L1644,560 L1630,590 L1639,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1647\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.913043</text>\n",
       "<path d=\"M1675,75 L1703,75 L1722,94\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,94 L1747,75 L1775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,125 L1703,125 L1722,106\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,106 L1747,125 L1775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,93 L1750,93 L1750,107 L1700,107 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"130\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"76\" font-size=\"7\" text-anchor=\"middle\">Θ=0.728586</text>\n",
       "<path d=\"M1700,93 L1750,93 L1750,97 L1700,97 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,100 L1753,100 L1753,110 L1743,110 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"107\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,75 L1825,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,90 L1789,90 L1803,60 L1794,60 L1780,90 L1789,90 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"88\" font-size=\"7\" text-anchor=\"start\">Φ=0.426292</text>\n",
       "<path d=\"M1775,125 L1825,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,140 L1789,140 L1803,110 L1794,110 L1780,140 L1789,140 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"138\" font-size=\"7\" text-anchor=\"start\">Φ=0.883451</text>\n",
       "<path d=\"M1675,175 L1703,175 L1722,194\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,194 L1747,175 L1775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,225 L1703,225 L1722,206\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,206 L1747,225 L1775,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,193 L1750,193 L1750,207 L1700,207 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"230\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"176\" font-size=\"7\" text-anchor=\"middle\">Θ=0.640942</text>\n",
       "<path d=\"M1700,193 L1750,193 L1750,197 L1700,197 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,200 L1753,200 L1753,210 L1743,210 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"207\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,175 L1825,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,190 L1789,190 L1803,160 L1794,160 L1780,190 L1789,190 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"188\" font-size=\"7\" text-anchor=\"start\">Φ=0.876055</text>\n",
       "<path d=\"M1775,225 L1825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,240 L1789,240 L1803,210 L1794,210 L1780,240 L1789,240 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"238\" font-size=\"7\" text-anchor=\"start\">Φ=0.356308</text>\n",
       "<path d=\"M1675,275 L1703,275 L1722,294\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,294 L1747,275 L1775,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,325 L1703,325 L1722,306\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,306 L1747,325 L1775,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,293 L1750,293 L1750,307 L1700,307 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"330\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"276\" font-size=\"7\" text-anchor=\"middle\">Θ=0.45511</text>\n",
       "<path d=\"M1700,293 L1750,293 L1750,297 L1700,297 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,300 L1753,300 L1753,310 L1743,310 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"307\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,275 L1825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,290 L1789,290 L1803,260 L1794,260 L1780,290 L1789,290 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"288\" font-size=\"7\" text-anchor=\"start\">Φ=0.896139</text>\n",
       "<path d=\"M1775,325 L1825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,340 L1789,340 L1803,310 L1794,310 L1780,340 L1789,340 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"338\" font-size=\"7\" text-anchor=\"start\">Φ=0.3797</text>\n",
       "<path d=\"M1675,375 L1703,375 L1722,394\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,394 L1747,375 L1775,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,425 L1703,425 L1722,406\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,406 L1747,425 L1775,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,393 L1750,393 L1750,407 L1700,407 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"430\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"376\" font-size=\"7\" text-anchor=\"middle\">Θ=0.541947</text>\n",
       "<path d=\"M1700,393 L1750,393 L1750,397 L1700,397 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,400 L1753,400 L1753,410 L1743,410 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"407\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,375 L1825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,390 L1789,390 L1803,360 L1794,360 L1780,390 L1789,390 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"388\" font-size=\"7\" text-anchor=\"start\">Φ=0.433102</text>\n",
       "<path d=\"M1775,425 L1825,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,440 L1789,440 L1803,410 L1794,410 L1780,440 L1789,440 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"438\" font-size=\"7\" text-anchor=\"start\">Φ=0.981488</text>\n",
       "<path d=\"M1675,475 L1703,475 L1722,494\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,494 L1747,475 L1775,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,525 L1703,525 L1722,506\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,506 L1747,525 L1775,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,493 L1750,493 L1750,507 L1700,507 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"530\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"476\" font-size=\"7\" text-anchor=\"middle\">Θ=0.514321</text>\n",
       "<path d=\"M1700,493 L1750,493 L1750,497 L1700,497 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,500 L1753,500 L1753,510 L1743,510 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"507\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,475 L1825,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,490 L1789,490 L1803,460 L1794,460 L1780,490 L1789,490 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"488\" font-size=\"7\" text-anchor=\"start\">Φ=0.285664</text>\n",
       "<path d=\"M1775,525 L1825,525\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,540 L1789,540 L1803,510 L1794,510 L1780,540 L1789,540 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"538\" font-size=\"7\" text-anchor=\"start\">Φ=0.091907</text>\n",
       "<path d=\"M1525,625.0 L1675,625.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,575 L1703,575 L1722,594\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,594 L1747,575 L1775,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1675,625 L1703,625 L1722,606\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1728,606 L1747,625 L1775,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1700,593 L1750,593 L1750,607 L1700,607 Z\" stroke=\"black\" fill=\"black\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1725\" y=\"630\" font-size=\"7\" text-anchor=\"middle\"></text>\n",
       "<text x=\"1725\" y=\"576\" font-size=\"7\" text-anchor=\"middle\">Θ=0.412303</text>\n",
       "<path d=\"M1700,593 L1750,593 L1750,597 L1700,597 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n",
       "<path d=\"M1743,600 L1753,600 L1753,610 L1743,610 Z\" stroke=\"black\" fill=\"thistle\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1748\" y=\"607\" font-size=\"6\" text-anchor=\"middle\">Rx</text>\n",
       "<path d=\"M1775,575 L1825,575\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,590 L1789,590 L1803,560 L1794,560 L1780,590 L1789,590 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"588\" font-size=\"7\" text-anchor=\"start\">Φ=0.676785</text>\n",
       "<path d=\"M1775,625 L1825,625\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1780,640 L1789,640 L1803,610 L1794,610 L1780,640 L1789,640 Z\" stroke=\"black\" fill=\"gray\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1797\" y=\"638\" font-size=\"7\" text-anchor=\"start\">Φ=0.936198</text>\n",
       "<path d=\"M1675,25.0 L1825,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1825,25.0 L1840,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,75.0 L1840,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,125.0 L1840,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,175.0 L1840,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,225.0 L1840,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,275.0 L1840,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,325.0 L1840,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,375.0 L1840,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,425.0 L1840,425.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,475.0 L1840,475.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,525.0 L1840,525.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,575.0 L1840,575.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,625.0 L1840,625.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"1850\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n",
       "<text x=\"1850\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n",
       "<text x=\"1850\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n",
       "<text x=\"1850\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n",
       "<text x=\"1850\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n",
       "<text x=\"1850\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n",
       "<text x=\"1850\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n",
       "<text x=\"1850\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n",
       "<text x=\"1850\" y=\"428.0\" font-size=\"10\" text-anchor=\"end\">8</text>\n",
       "<text x=\"1850\" y=\"478.0\" font-size=\"10\" text-anchor=\"end\">9</text>\n",
       "<text x=\"1850\" y=\"528.0\" font-size=\"10\" text-anchor=\"end\">10</text>\n",
       "<text x=\"1850\" y=\"578.0\" font-size=\"10\" text-anchor=\"end\">11</text>\n",
       "<text x=\"1850\" y=\"628.0\" font-size=\"10\" text-anchor=\"end\">12</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n",
       "<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n",
       "<text x=\"0\" y=\"428.0\" font-size=\"10\" text-anchor=\"start\">8</text>\n",
       "<text x=\"0\" y=\"478.0\" font-size=\"10\" text-anchor=\"start\">9</text>\n",
       "<text x=\"0\" y=\"528.0\" font-size=\"10\" text-anchor=\"start\">10</text>\n",
       "<text x=\"0\" y=\"578.0\" font-size=\"10\" text-anchor=\"start\">11</text>\n",
       "<text x=\"0\" y=\"628.0\" font-size=\"10\" text-anchor=\"start\">12</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x720be0843280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### START SCALEWAY SESSION ####\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "\n",
    "#### BOSON SAMPLER DEFINITION ####\n",
    "\n",
    "bs = BosonSampler(m = 13, n = 5, postselect = 0, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "#to display it\n",
    "pcvl.pdisplay(bs.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_para_tensor = torch.randn(165)\n",
    "# res = bs.run(\n",
    "#     parameters=random_para_tensor,\n",
    "#     samples=100000\n",
    "# )\n",
    "\n",
    "# trans_res = bs.translate_results(res = res)\n",
    "# print(trans_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(trans_res))\n",
    "\n",
    "# trans_res = trans_res/torch.mean(trans_res)\n",
    "\n",
    "# print(torch.mean(trans_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in trans_res:\n",
    "#     if i != 0:\n",
    "#         count += 1\n",
    "#     # print(i)\n",
    "# print(\"non zero counts:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(trans_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(4*4*4, 10)\n",
    "        # self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        # x = self.fc2(x)\n",
    "    #     super(CNNModel, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "    #     self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #     self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "    #     self.fc1 = nn.Linear(12*4*4, 20)\n",
    "    #     self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     x = self.pool(self.conv1(x))\n",
    "    #     x = self.pool(self.conv2(x))\n",
    "    #     x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters in classical CNN model:  978\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_classical_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of parameters in classical CNN model: \", num_classical_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 31.67%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = [] \n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  978\n",
      "Required qubit number:  10\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class PhotonicQuantumTrain(nn.Module):\n",
    "\n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [8], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        # self.QuantumNN = nn.parameter(135)\n",
    "\n",
    "        #self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x, qnn_parameters):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.q_params = qnn_parameters#nn.Parameter(q_delta * torch.randn(135)).to(device)  \n",
    "\n",
    "        device = x.device\n",
    "        res = bs.run(\n",
    "            parameters=self.q_params,\n",
    "            samples=100000\n",
    "        )\n",
    "\n",
    "        trans_res = bs.translate_results(res = res)\n",
    "        trans_res = trans_res/torch.mean(trans_res)\n",
    "        probs_ = trans_res.to(device)  \n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        probs_ = probs_.reshape(len(nw_list_normal),1)\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # # Fully connected layer 2 parameters\n",
    "        # fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        # fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # # Fully connected 2\n",
    "        # x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  105\n",
      "# of trainable parameter in QNN model:  234\n",
      "# of trainable parameter in full model:  339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "num_epochs = 5\n",
    "step = 1e-3               # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 2 * np.pi        # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "init_qnn_parameters = q_delta * np.random.rand(234)\n",
    "\n",
    "qnn_parameters = init_qnn_parameters\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "qt_model = PhotonicQuantumTrain().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(qt_model.parameters(), lr=step) #, weight_decay=1e-5, eps=1e-6)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "# num_trainable_params_MM = sum(p.numel() for p in PhotonicQuantumTrain.MappingModel(n_qubit+1,  [20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in qt_model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params)\n",
    "print(\"# of trainable parameter in QNN model: \", bs.nb_parameters)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params + bs.nb_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single random batch\n",
    "# train_iter = iter(train_loader)  # Create an iterator\n",
    "# images, labels = next(train_iter) \n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Training round [1/100], Epoch [1/5], Step [20/24], Loss: 31.4167, batch time: 0.09, accuracy:  12.11%\n",
      "Training round [1/100], Epoch [2/5], Step [20/24], Loss: 2.9385, batch time: 0.09, accuracy:  10.55%\n",
      "Training round [1/100], Epoch [3/5], Step [20/24], Loss: 2.7399, batch time: 0.09, accuracy:  13.67%\n",
      "Training round [1/100], Epoch [4/5], Step [20/24], Loss: 2.6246, batch time: 0.09, accuracy:  9.38%\n",
      "Training round [1/100], Epoch [5/5], Step [20/24], Loss: 2.5042, batch time: 0.09, accuracy:  13.67%\n",
      "Training round [1/100], qnn_train_step: [100/500], loss: 2.409219980239868, accuracy: 14.9 %\n",
      "Training round [1/100], qnn_train_step: [200/500], loss: 2.4027645587921143, accuracy: 15.6 %\n",
      "Training round [1/100], qnn_train_step: [300/500], loss: 2.393280506134033, accuracy: 15.3 %\n",
      "Training round [1/100], qnn_train_step: [400/500], loss: 2.388360023498535, accuracy: 16.0 %\n",
      "Training round [1/100], qnn_train_step: [500/500], loss: 2.3920185565948486, accuracy: 16.0 %\n",
      "-----------------------\n",
      "Training round [2/100], Epoch [1/5], Step [20/24], Loss: 2.4509, batch time: 0.09, accuracy:  15.23%\n",
      "Training round [2/100], Epoch [2/5], Step [20/24], Loss: 2.2900, batch time: 0.09, accuracy:  19.92%\n",
      "Training round [2/100], Epoch [3/5], Step [20/24], Loss: 2.3631, batch time: 0.10, accuracy:  17.97%\n",
      "Training round [2/100], Epoch [4/5], Step [20/24], Loss: 2.3873, batch time: 0.09, accuracy:  16.02%\n",
      "Training round [2/100], Epoch [5/5], Step [20/24], Loss: 2.3153, batch time: 0.09, accuracy:  15.62%\n",
      "Training round [2/100], qnn_train_step: [100/500], loss: 2.326951265335083, accuracy: 22.5 %\n",
      "Training round [2/100], qnn_train_step: [200/500], loss: 2.3083415031433105, accuracy: 20.7 %\n",
      "Training round [2/100], qnn_train_step: [300/500], loss: 2.341972589492798, accuracy: 19.1 %\n",
      "Training round [2/100], qnn_train_step: [400/500], loss: 2.307020425796509, accuracy: 23.5 %\n",
      "Training round [2/100], qnn_train_step: [500/500], loss: 2.2854974269866943, accuracy: 21.6 %\n",
      "-----------------------\n",
      "Training round [3/100], Epoch [1/5], Step [20/24], Loss: 2.2201, batch time: 0.09, accuracy:  21.88%\n",
      "Training round [3/100], Epoch [2/5], Step [20/24], Loss: 2.1901, batch time: 0.09, accuracy:  23.05%\n",
      "Training round [3/100], Epoch [3/5], Step [20/24], Loss: 2.1291, batch time: 0.09, accuracy:  26.17%\n",
      "Training round [3/100], Epoch [4/5], Step [20/24], Loss: 2.0573, batch time: 0.09, accuracy:  28.12%\n",
      "Training round [3/100], Epoch [5/5], Step [20/24], Loss: 2.1239, batch time: 0.09, accuracy:  21.48%\n",
      "Training round [3/100], qnn_train_step: [100/500], loss: 2.157257318496704, accuracy: 24.8 %\n",
      "Training round [3/100], qnn_train_step: [200/500], loss: 2.1587445735931396, accuracy: 26.0 %\n",
      "Training round [3/100], qnn_train_step: [300/500], loss: 2.1689844131469727, accuracy: 25.5 %\n",
      "Training round [3/100], qnn_train_step: [400/500], loss: 2.139592409133911, accuracy: 26.3 %\n",
      "Training round [3/100], qnn_train_step: [500/500], loss: 2.1294381618499756, accuracy: 27.1 %\n",
      "-----------------------\n",
      "Training round [4/100], Epoch [1/5], Step [20/24], Loss: 2.0802, batch time: 0.09, accuracy:  32.42%\n",
      "Training round [4/100], Epoch [2/5], Step [20/24], Loss: 2.1197, batch time: 0.09, accuracy:  24.61%\n",
      "Training round [4/100], Epoch [3/5], Step [20/24], Loss: 2.0392, batch time: 0.09, accuracy:  31.64%\n",
      "Training round [4/100], Epoch [4/5], Step [20/24], Loss: 2.1022, batch time: 0.09, accuracy:  27.34%\n",
      "Training round [4/100], Epoch [5/5], Step [20/24], Loss: 2.0057, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [4/100], qnn_train_step: [100/500], loss: 2.1111769676208496, accuracy: 27.0 %\n",
      "Training round [4/100], qnn_train_step: [200/500], loss: 2.116881847381592, accuracy: 26.9 %\n",
      "Training round [4/100], qnn_train_step: [300/500], loss: 2.101879835128784, accuracy: 27.4 %\n",
      "Training round [4/100], qnn_train_step: [400/500], loss: 2.100001811981201, accuracy: 26.9 %\n",
      "Training round [4/100], qnn_train_step: [500/500], loss: 2.0896570682525635, accuracy: 27.3 %\n",
      "-----------------------\n",
      "Training round [5/100], Epoch [1/5], Step [20/24], Loss: 2.0302, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [5/100], Epoch [2/5], Step [20/24], Loss: 2.0093, batch time: 0.09, accuracy:  30.08%\n",
      "Training round [5/100], Epoch [3/5], Step [20/24], Loss: 2.0553, batch time: 0.09, accuracy:  26.95%\n",
      "Training round [5/100], Epoch [4/5], Step [20/24], Loss: 2.0578, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [5/100], Epoch [5/5], Step [20/24], Loss: 2.0283, batch time: 0.09, accuracy:  30.08%\n",
      "Training round [5/100], qnn_train_step: [100/500], loss: 2.0503830909729004, accuracy: 30.9 %\n",
      "Training round [5/100], qnn_train_step: [200/500], loss: 2.0519516468048096, accuracy: 29.0 %\n",
      "Training round [5/100], qnn_train_step: [300/500], loss: 2.1316444873809814, accuracy: 30.4 %\n",
      "Training round [5/100], qnn_train_step: [400/500], loss: 2.027564525604248, accuracy: 30.8 %\n",
      "Training round [5/100], qnn_train_step: [500/500], loss: 2.032092809677124, accuracy: 33.2 %\n",
      "-----------------------\n",
      "Training round [6/100], Epoch [1/5], Step [20/24], Loss: 1.9785, batch time: 0.09, accuracy:  37.11%\n",
      "Training round [6/100], Epoch [2/5], Step [20/24], Loss: 2.0380, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [6/100], Epoch [3/5], Step [20/24], Loss: 1.9770, batch time: 0.09, accuracy:  33.98%\n",
      "Training round [6/100], Epoch [4/5], Step [20/24], Loss: 2.0196, batch time: 0.09, accuracy:  34.77%\n",
      "Training round [6/100], Epoch [5/5], Step [20/24], Loss: 2.0844, batch time: 0.09, accuracy:  32.42%\n",
      "Training round [6/100], qnn_train_step: [100/500], loss: 2.0221400260925293, accuracy: 29.3 %\n",
      "Training round [6/100], qnn_train_step: [200/500], loss: 2.03472900390625, accuracy: 27.1 %\n",
      "Training round [6/100], qnn_train_step: [300/500], loss: 1.9983655214309692, accuracy: 31.8 %\n",
      "Training round [6/100], qnn_train_step: [400/500], loss: 1.997564435005188, accuracy: 32.9 %\n",
      "Training round [6/100], qnn_train_step: [500/500], loss: 1.9877361059188843, accuracy: 32.3 %\n",
      "-----------------------\n",
      "Training round [7/100], Epoch [1/5], Step [20/24], Loss: 1.9602, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [7/100], Epoch [2/5], Step [20/24], Loss: 2.0203, batch time: 0.09, accuracy:  33.20%\n",
      "Training round [7/100], Epoch [3/5], Step [20/24], Loss: 2.0572, batch time: 0.09, accuracy:  28.91%\n",
      "Training round [7/100], Epoch [4/5], Step [20/24], Loss: 2.0168, batch time: 0.09, accuracy:  30.47%\n",
      "Training round [7/100], Epoch [5/5], Step [20/24], Loss: 2.0174, batch time: 0.09, accuracy:  33.98%\n",
      "Training round [7/100], qnn_train_step: [100/500], loss: 1.970636010169983, accuracy: 34.1 %\n",
      "Training round [7/100], qnn_train_step: [200/500], loss: 1.9498406648635864, accuracy: 33.4 %\n",
      "Training round [7/100], qnn_train_step: [300/500], loss: 1.9481453895568848, accuracy: 34.7 %\n",
      "Training round [7/100], qnn_train_step: [400/500], loss: 1.942384123802185, accuracy: 35.6 %\n",
      "Training round [7/100], qnn_train_step: [500/500], loss: 1.9384300708770752, accuracy: 35.3 %\n",
      "-----------------------\n",
      "Training round [8/100], Epoch [1/5], Step [20/24], Loss: 1.9682, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [8/100], Epoch [2/5], Step [20/24], Loss: 1.9576, batch time: 0.09, accuracy:  33.20%\n",
      "Training round [8/100], Epoch [3/5], Step [20/24], Loss: 1.9537, batch time: 0.09, accuracy:  34.38%\n",
      "Training round [8/100], Epoch [4/5], Step [20/24], Loss: 1.9825, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [8/100], Epoch [5/5], Step [20/24], Loss: 1.8595, batch time: 0.09, accuracy:  42.58%\n",
      "Training round [8/100], qnn_train_step: [100/500], loss: 1.9861648082733154, accuracy: 32.5 %\n",
      "Training round [8/100], qnn_train_step: [200/500], loss: 1.9648070335388184, accuracy: 32.9 %\n",
      "Training round [8/100], qnn_train_step: [300/500], loss: 1.9491056203842163, accuracy: 34.5 %\n",
      "Training round [8/100], qnn_train_step: [400/500], loss: 1.9437578916549683, accuracy: 34.3 %\n",
      "Training round [8/100], qnn_train_step: [500/500], loss: 1.9395354986190796, accuracy: 34.7 %\n",
      "-----------------------\n",
      "Training round [9/100], Epoch [1/5], Step [20/24], Loss: 1.9561, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [9/100], Epoch [2/5], Step [20/24], Loss: 1.9675, batch time: 0.09, accuracy:  32.81%\n",
      "Training round [9/100], Epoch [3/5], Step [20/24], Loss: 1.9800, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [9/100], Epoch [4/5], Step [20/24], Loss: 1.9255, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [9/100], Epoch [5/5], Step [20/24], Loss: 1.9742, batch time: 0.09, accuracy:  33.98%\n",
      "Training round [9/100], qnn_train_step: [100/500], loss: 1.9905389547348022, accuracy: 32.7 %\n",
      "Training round [9/100], qnn_train_step: [200/500], loss: 2.0110368728637695, accuracy: 31.3 %\n",
      "Training round [9/100], qnn_train_step: [300/500], loss: 2.0251564979553223, accuracy: 29.3 %\n",
      "Training round [9/100], qnn_train_step: [400/500], loss: 2.7519781589508057, accuracy: 17.1 %\n",
      "Training round [9/100], qnn_train_step: [500/500], loss: 1.944044828414917, accuracy: 36.0 %\n",
      "-----------------------\n",
      "Training round [10/100], Epoch [1/5], Step [20/24], Loss: 1.8688, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [10/100], Epoch [2/5], Step [20/24], Loss: 1.8696, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [10/100], Epoch [3/5], Step [20/24], Loss: 1.9048, batch time: 0.09, accuracy:  37.50%\n",
      "Training round [10/100], Epoch [4/5], Step [20/24], Loss: 1.9188, batch time: 0.09, accuracy:  35.55%\n",
      "Training round [10/100], Epoch [5/5], Step [20/24], Loss: 1.9290, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [10/100], qnn_train_step: [100/500], loss: 1.9668874740600586, accuracy: 34.7 %\n",
      "Training round [10/100], qnn_train_step: [200/500], loss: 1.9702494144439697, accuracy: 33.2 %\n",
      "Training round [10/100], qnn_train_step: [300/500], loss: 1.926719307899475, accuracy: 36.1 %\n",
      "Training round [10/100], qnn_train_step: [400/500], loss: 1.9285759925842285, accuracy: 35.7 %\n",
      "Training round [10/100], qnn_train_step: [500/500], loss: 1.9085054397583008, accuracy: 37.7 %\n",
      "-----------------------\n",
      "Training round [11/100], Epoch [1/5], Step [20/24], Loss: 1.8792, batch time: 0.09, accuracy:  40.23%\n",
      "Training round [11/100], Epoch [2/5], Step [20/24], Loss: 1.8856, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [11/100], Epoch [3/5], Step [20/24], Loss: 1.8519, batch time: 0.09, accuracy:  35.55%\n",
      "Training round [11/100], Epoch [4/5], Step [20/24], Loss: 1.9047, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [11/100], Epoch [5/5], Step [20/24], Loss: 1.9747, batch time: 0.09, accuracy:  33.59%\n",
      "Training round [11/100], qnn_train_step: [100/500], loss: 1.9143626689910889, accuracy: 37.1 %\n",
      "Training round [11/100], qnn_train_step: [200/500], loss: 1.9562456607818604, accuracy: 33.2 %\n",
      "Training round [11/100], qnn_train_step: [300/500], loss: 1.8984928131103516, accuracy: 36.3 %\n",
      "Training round [11/100], qnn_train_step: [400/500], loss: 1.8901760578155518, accuracy: 37.7 %\n",
      "Training round [11/100], qnn_train_step: [500/500], loss: 1.887137770652771, accuracy: 37.5 %\n",
      "-----------------------\n",
      "Training round [12/100], Epoch [1/5], Step [20/24], Loss: 1.8592, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [12/100], Epoch [2/5], Step [20/24], Loss: 1.8710, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [12/100], Epoch [3/5], Step [20/24], Loss: 2.0635, batch time: 0.09, accuracy:  27.73%\n",
      "Training round [12/100], Epoch [4/5], Step [20/24], Loss: 1.8327, batch time: 0.09, accuracy:  41.02%\n",
      "Training round [12/100], Epoch [5/5], Step [20/24], Loss: 1.8118, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [12/100], qnn_train_step: [100/500], loss: 1.865826964378357, accuracy: 38.7 %\n",
      "Training round [12/100], qnn_train_step: [200/500], loss: 1.9424827098846436, accuracy: 37.1 %\n",
      "Training round [12/100], qnn_train_step: [300/500], loss: 1.8364717960357666, accuracy: 41.3 %\n",
      "Training round [12/100], qnn_train_step: [400/500], loss: 1.8371385335922241, accuracy: 40.0 %\n",
      "Training round [12/100], qnn_train_step: [500/500], loss: 1.8276417255401611, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [13/100], Epoch [1/5], Step [20/24], Loss: 1.6923, batch time: 0.23, accuracy:  44.14%\n",
      "Training round [13/100], Epoch [2/5], Step [20/24], Loss: 1.7855, batch time: 0.09, accuracy:  39.45%\n",
      "Training round [13/100], Epoch [3/5], Step [20/24], Loss: 1.7521, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [13/100], Epoch [4/5], Step [20/24], Loss: 1.8134, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [13/100], Epoch [5/5], Step [20/24], Loss: 1.8056, batch time: 0.09, accuracy:  41.02%\n",
      "Training round [13/100], qnn_train_step: [100/500], loss: 1.8847947120666504, accuracy: 38.8 %\n",
      "Training round [13/100], qnn_train_step: [200/500], loss: 1.943021297454834, accuracy: 33.5 %\n",
      "Training round [13/100], qnn_train_step: [300/500], loss: 1.914042353630066, accuracy: 33.8 %\n",
      "Training round [13/100], qnn_train_step: [400/500], loss: 1.8577446937561035, accuracy: 37.9 %\n",
      "Training round [13/100], qnn_train_step: [500/500], loss: 1.855974555015564, accuracy: 37.9 %\n",
      "-----------------------\n",
      "Training round [14/100], Epoch [1/5], Step [20/24], Loss: 1.7519, batch time: 0.09, accuracy:  44.14%\n",
      "Training round [14/100], Epoch [2/5], Step [20/24], Loss: 1.8427, batch time: 0.09, accuracy:  36.33%\n",
      "Training round [14/100], Epoch [3/5], Step [20/24], Loss: 1.7701, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [14/100], Epoch [4/5], Step [20/24], Loss: 1.9256, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [14/100], Epoch [5/5], Step [20/24], Loss: 1.8424, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [14/100], qnn_train_step: [100/500], loss: 1.844634771347046, accuracy: 39.3 %\n",
      "Training round [14/100], qnn_train_step: [200/500], loss: 1.9401541948318481, accuracy: 34.8 %\n",
      "Training round [14/100], qnn_train_step: [300/500], loss: 1.8322557210922241, accuracy: 39.9 %\n",
      "Training round [14/100], qnn_train_step: [400/500], loss: 1.799081563949585, accuracy: 41.4 %\n",
      "Training round [14/100], qnn_train_step: [500/500], loss: 1.7948964834213257, accuracy: 41.3 %\n",
      "-----------------------\n",
      "Training round [15/100], Epoch [1/5], Step [20/24], Loss: 1.7320, batch time: 0.09, accuracy:  40.23%\n",
      "Training round [15/100], Epoch [2/5], Step [20/24], Loss: 1.8472, batch time: 0.09, accuracy:  35.55%\n",
      "Training round [15/100], Epoch [3/5], Step [20/24], Loss: 1.7187, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [15/100], Epoch [4/5], Step [20/24], Loss: 1.7860, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [15/100], Epoch [5/5], Step [20/24], Loss: 1.8356, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [15/100], qnn_train_step: [100/500], loss: 1.849011778831482, accuracy: 40.9 %\n",
      "Training round [15/100], qnn_train_step: [200/500], loss: 1.9594154357910156, accuracy: 32.1 %\n",
      "Training round [15/100], qnn_train_step: [300/500], loss: 1.8163795471191406, accuracy: 38.2 %\n",
      "Training round [15/100], qnn_train_step: [400/500], loss: 1.8136402368545532, accuracy: 40.1 %\n",
      "Training round [15/100], qnn_train_step: [500/500], loss: 1.8049999475479126, accuracy: 39.2 %\n",
      "-----------------------\n",
      "Training round [16/100], Epoch [1/5], Step [20/24], Loss: 1.7867, batch time: 0.09, accuracy:  40.23%\n",
      "Training round [16/100], Epoch [2/5], Step [20/24], Loss: 1.8572, batch time: 0.09, accuracy:  38.28%\n",
      "Training round [16/100], Epoch [3/5], Step [20/24], Loss: 1.8045, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [16/100], Epoch [4/5], Step [20/24], Loss: 1.7635, batch time: 0.09, accuracy:  44.14%\n",
      "Training round [16/100], Epoch [5/5], Step [20/24], Loss: 1.8011, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [16/100], qnn_train_step: [100/500], loss: 1.855231761932373, accuracy: 37.4 %\n",
      "Training round [16/100], qnn_train_step: [200/500], loss: 1.9623379707336426, accuracy: 31.0 %\n",
      "Training round [16/100], qnn_train_step: [300/500], loss: 1.941914677619934, accuracy: 30.5 %\n",
      "Training round [16/100], qnn_train_step: [400/500], loss: 1.8245025873184204, accuracy: 38.3 %\n",
      "Training round [16/100], qnn_train_step: [500/500], loss: 1.8137991428375244, accuracy: 38.9 %\n",
      "-----------------------\n",
      "Training round [17/100], Epoch [1/5], Step [20/24], Loss: 1.7064, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [17/100], Epoch [2/5], Step [20/24], Loss: 1.7348, batch time: 0.09, accuracy:  43.36%\n",
      "Training round [17/100], Epoch [3/5], Step [20/24], Loss: 1.8006, batch time: 0.09, accuracy:  40.23%\n",
      "Training round [17/100], Epoch [4/5], Step [20/24], Loss: 1.7738, batch time: 0.09, accuracy:  36.72%\n",
      "Training round [17/100], Epoch [5/5], Step [20/24], Loss: 1.8862, batch time: 0.09, accuracy:  35.16%\n",
      "Training round [17/100], qnn_train_step: [100/500], loss: 1.8015341758728027, accuracy: 40.5 %\n",
      "Training round [17/100], qnn_train_step: [200/500], loss: 1.8883403539657593, accuracy: 37.8 %\n",
      "Training round [17/100], qnn_train_step: [300/500], loss: 2.131075382232666, accuracy: 33.2 %\n",
      "Training round [17/100], qnn_train_step: [400/500], loss: 1.7722177505493164, accuracy: 41.2 %\n",
      "Training round [17/100], qnn_train_step: [500/500], loss: 1.7650423049926758, accuracy: 41.9 %\n",
      "-----------------------\n",
      "Training round [18/100], Epoch [1/5], Step [20/24], Loss: 1.7135, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [18/100], Epoch [2/5], Step [20/24], Loss: 1.7046, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [18/100], Epoch [3/5], Step [20/24], Loss: 1.7765, batch time: 0.10, accuracy:  43.36%\n",
      "Training round [18/100], Epoch [4/5], Step [20/24], Loss: 1.7555, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [18/100], Epoch [5/5], Step [20/24], Loss: 1.7140, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [18/100], qnn_train_step: [100/500], loss: 1.772975206375122, accuracy: 41.4 %\n",
      "Training round [18/100], qnn_train_step: [200/500], loss: 1.8060688972473145, accuracy: 38.4 %\n",
      "Training round [18/100], qnn_train_step: [300/500], loss: 1.7421897649765015, accuracy: 41.9 %\n",
      "Training round [18/100], qnn_train_step: [400/500], loss: 1.7409896850585938, accuracy: 42.0 %\n",
      "Training round [18/100], qnn_train_step: [500/500], loss: 1.7696644067764282, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [19/100], Epoch [1/5], Step [20/24], Loss: 1.8496, batch time: 0.10, accuracy:  34.77%\n",
      "Training round [19/100], Epoch [2/5], Step [20/24], Loss: 1.7266, batch time: 0.09, accuracy:  40.23%\n",
      "Training round [19/100], Epoch [3/5], Step [20/24], Loss: 1.7088, batch time: 0.09, accuracy:  38.67%\n",
      "Training round [19/100], Epoch [4/5], Step [20/24], Loss: 1.8540, batch time: 0.09, accuracy:  37.89%\n",
      "Training round [19/100], Epoch [5/5], Step [20/24], Loss: 1.7861, batch time: 0.09, accuracy:  41.02%\n",
      "Training round [19/100], qnn_train_step: [100/500], loss: 1.8280912637710571, accuracy: 39.9 %\n",
      "Training round [19/100], qnn_train_step: [200/500], loss: 1.8848737478256226, accuracy: 35.6 %\n",
      "Training round [19/100], qnn_train_step: [300/500], loss: 1.7709070444107056, accuracy: 40.1 %\n",
      "Training round [19/100], qnn_train_step: [400/500], loss: 1.796583652496338, accuracy: 39.4 %\n",
      "Training round [19/100], qnn_train_step: [500/500], loss: 1.7657015323638916, accuracy: 40.9 %\n",
      "-----------------------\n",
      "Training round [20/100], Epoch [1/5], Step [20/24], Loss: 1.7231, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [20/100], Epoch [2/5], Step [20/24], Loss: 1.7644, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [20/100], Epoch [3/5], Step [20/24], Loss: 1.8247, batch time: 0.10, accuracy:  39.45%\n",
      "Training round [20/100], Epoch [4/5], Step [20/24], Loss: 1.7791, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [20/100], Epoch [5/5], Step [20/24], Loss: 1.7113, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [20/100], qnn_train_step: [100/500], loss: 1.8877326250076294, accuracy: 36.1 %\n",
      "Training round [20/100], qnn_train_step: [200/500], loss: 1.933884620666504, accuracy: 34.3 %\n",
      "Training round [20/100], qnn_train_step: [300/500], loss: 1.8275245428085327, accuracy: 37.6 %\n",
      "Training round [20/100], qnn_train_step: [400/500], loss: 1.8283082246780396, accuracy: 39.7 %\n",
      "Training round [20/100], qnn_train_step: [500/500], loss: 1.7994968891143799, accuracy: 39.3 %\n",
      "-----------------------\n",
      "Training round [21/100], Epoch [1/5], Step [20/24], Loss: 1.7429, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [21/100], Epoch [2/5], Step [20/24], Loss: 1.8376, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [21/100], Epoch [3/5], Step [20/24], Loss: 1.9260, batch time: 0.10, accuracy:  35.16%\n",
      "Training round [21/100], Epoch [4/5], Step [20/24], Loss: 1.6976, batch time: 0.10, accuracy:  44.92%\n",
      "Training round [21/100], Epoch [5/5], Step [20/24], Loss: 1.8511, batch time: 0.09, accuracy:  38.67%\n",
      "Training round [21/100], qnn_train_step: [100/500], loss: 1.8218374252319336, accuracy: 39.5 %\n",
      "Training round [21/100], qnn_train_step: [200/500], loss: 1.8439160585403442, accuracy: 37.9 %\n",
      "Training round [21/100], qnn_train_step: [300/500], loss: 1.7739919424057007, accuracy: 40.5 %\n",
      "Training round [21/100], qnn_train_step: [400/500], loss: 1.7577027082443237, accuracy: 42.7 %\n",
      "Training round [21/100], qnn_train_step: [500/500], loss: 1.755933403968811, accuracy: 43.1 %\n",
      "-----------------------\n",
      "Training round [22/100], Epoch [1/5], Step [20/24], Loss: 1.7158, batch time: 0.09, accuracy:  44.53%\n",
      "Training round [22/100], Epoch [2/5], Step [20/24], Loss: 1.8328, batch time: 0.10, accuracy:  36.72%\n",
      "Training round [22/100], Epoch [3/5], Step [20/24], Loss: 1.8096, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [22/100], Epoch [4/5], Step [20/24], Loss: 1.7493, batch time: 0.09, accuracy:  41.41%\n",
      "Training round [22/100], Epoch [5/5], Step [20/24], Loss: 1.8307, batch time: 0.09, accuracy:  39.45%\n",
      "Training round [22/100], qnn_train_step: [100/500], loss: 1.7817063331604004, accuracy: 41.8 %\n",
      "Training round [22/100], qnn_train_step: [200/500], loss: 1.8113867044448853, accuracy: 37.0 %\n",
      "Training round [22/100], qnn_train_step: [300/500], loss: 1.7322754859924316, accuracy: 43.6 %\n",
      "Training round [22/100], qnn_train_step: [400/500], loss: 1.757197380065918, accuracy: 44.3 %\n",
      "Training round [22/100], qnn_train_step: [500/500], loss: 1.7273619174957275, accuracy: 43.2 %\n",
      "-----------------------\n",
      "Training round [23/100], Epoch [1/5], Step [20/24], Loss: 1.8371, batch time: 0.10, accuracy:  33.20%\n",
      "Training round [23/100], Epoch [2/5], Step [20/24], Loss: 1.8593, batch time: 0.10, accuracy:  41.02%\n",
      "Training round [23/100], Epoch [3/5], Step [20/24], Loss: 1.7772, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [23/100], Epoch [4/5], Step [20/24], Loss: 1.7313, batch time: 0.10, accuracy:  41.02%\n",
      "Training round [23/100], Epoch [5/5], Step [20/24], Loss: 1.7797, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [23/100], qnn_train_step: [100/500], loss: 1.816388487815857, accuracy: 41.0 %\n",
      "Training round [23/100], qnn_train_step: [200/500], loss: 1.8647077083587646, accuracy: 35.4 %\n",
      "Training round [23/100], qnn_train_step: [300/500], loss: 1.752711296081543, accuracy: 42.1 %\n",
      "Training round [23/100], qnn_train_step: [400/500], loss: 1.7465537786483765, accuracy: 43.4 %\n",
      "Training round [23/100], qnn_train_step: [500/500], loss: 1.7342153787612915, accuracy: 43.0 %\n",
      "-----------------------\n",
      "Training round [24/100], Epoch [1/5], Step [20/24], Loss: 1.7728, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [24/100], Epoch [2/5], Step [20/24], Loss: 1.7561, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [24/100], Epoch [3/5], Step [20/24], Loss: 1.6980, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [24/100], Epoch [4/5], Step [20/24], Loss: 1.8136, batch time: 0.10, accuracy:  39.45%\n",
      "Training round [24/100], Epoch [5/5], Step [20/24], Loss: 1.7706, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [24/100], qnn_train_step: [100/500], loss: 1.8967314958572388, accuracy: 40.2 %\n",
      "Training round [24/100], qnn_train_step: [200/500], loss: 1.893139123916626, accuracy: 33.1 %\n",
      "Training round [24/100], qnn_train_step: [300/500], loss: 1.8073400259017944, accuracy: 38.7 %\n",
      "Training round [24/100], qnn_train_step: [400/500], loss: 1.7970669269561768, accuracy: 41.1 %\n",
      "Training round [24/100], qnn_train_step: [500/500], loss: 1.782532811164856, accuracy: 42.1 %\n",
      "-----------------------\n",
      "Training round [25/100], Epoch [1/5], Step [20/24], Loss: 1.7924, batch time: 0.10, accuracy:  40.23%\n",
      "Training round [25/100], Epoch [2/5], Step [20/24], Loss: 1.7450, batch time: 0.09, accuracy:  44.92%\n",
      "Training round [25/100], Epoch [3/5], Step [20/24], Loss: 1.6881, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [25/100], Epoch [4/5], Step [20/24], Loss: 1.7310, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [25/100], Epoch [5/5], Step [20/24], Loss: 1.6618, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [25/100], qnn_train_step: [100/500], loss: 1.871953010559082, accuracy: 39.9 %\n",
      "Training round [25/100], qnn_train_step: [200/500], loss: 1.8972300291061401, accuracy: 32.2 %\n",
      "Training round [25/100], qnn_train_step: [300/500], loss: 1.7907015085220337, accuracy: 41.2 %\n",
      "Training round [25/100], qnn_train_step: [400/500], loss: 1.7771495580673218, accuracy: 40.9 %\n",
      "Training round [25/100], qnn_train_step: [500/500], loss: 1.774159550666809, accuracy: 42.1 %\n",
      "-----------------------\n",
      "Training round [26/100], Epoch [1/5], Step [20/24], Loss: 1.6707, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [26/100], Epoch [2/5], Step [20/24], Loss: 1.6522, batch time: 0.10, accuracy:  44.92%\n",
      "Training round [26/100], Epoch [3/5], Step [20/24], Loss: 1.7742, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [26/100], Epoch [4/5], Step [20/24], Loss: 1.7900, batch time: 0.10, accuracy:  38.67%\n",
      "Training round [26/100], Epoch [5/5], Step [20/24], Loss: 1.6608, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [26/100], qnn_train_step: [100/500], loss: 1.858345866203308, accuracy: 39.5 %\n",
      "Training round [26/100], qnn_train_step: [200/500], loss: 1.8103049993515015, accuracy: 41.2 %\n",
      "Training round [26/100], qnn_train_step: [300/500], loss: 1.7506494522094727, accuracy: 43.2 %\n",
      "Training round [26/100], qnn_train_step: [400/500], loss: 1.7405308485031128, accuracy: 42.5 %\n",
      "Training round [26/100], qnn_train_step: [500/500], loss: 1.7377408742904663, accuracy: 43.3 %\n",
      "-----------------------\n",
      "Training round [27/100], Epoch [1/5], Step [20/24], Loss: 1.8036, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [27/100], Epoch [2/5], Step [20/24], Loss: 1.8138, batch time: 0.10, accuracy:  38.67%\n",
      "Training round [27/100], Epoch [3/5], Step [20/24], Loss: 1.7412, batch time: 0.09, accuracy:  42.19%\n",
      "Training round [27/100], Epoch [4/5], Step [20/24], Loss: 1.7055, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [27/100], Epoch [5/5], Step [20/24], Loss: 1.6685, batch time: 0.09, accuracy:  45.70%\n",
      "Training round [27/100], qnn_train_step: [100/500], loss: 1.789428949356079, accuracy: 39.9 %\n",
      "Training round [27/100], qnn_train_step: [200/500], loss: 1.7442539930343628, accuracy: 40.9 %\n",
      "Training round [27/100], qnn_train_step: [300/500], loss: 1.6797314882278442, accuracy: 43.1 %\n",
      "Training round [27/100], qnn_train_step: [400/500], loss: 1.6758817434310913, accuracy: 42.7 %\n",
      "Training round [27/100], qnn_train_step: [500/500], loss: 1.6967202425003052, accuracy: 44.4 %\n",
      "-----------------------\n",
      "Training round [28/100], Epoch [1/5], Step [20/24], Loss: 1.6199, batch time: 0.10, accuracy:  46.48%\n",
      "Training round [28/100], Epoch [2/5], Step [20/24], Loss: 1.8013, batch time: 0.10, accuracy:  37.89%\n",
      "Training round [28/100], Epoch [3/5], Step [20/24], Loss: 1.7613, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [28/100], Epoch [4/5], Step [20/24], Loss: 1.7366, batch time: 0.09, accuracy:  43.36%\n",
      "Training round [28/100], Epoch [5/5], Step [20/24], Loss: 1.7435, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [28/100], qnn_train_step: [100/500], loss: 1.80409836769104, accuracy: 39.5 %\n",
      "Training round [28/100], qnn_train_step: [200/500], loss: 1.7386847734451294, accuracy: 41.2 %\n",
      "Training round [28/100], qnn_train_step: [300/500], loss: 1.6946711540222168, accuracy: 41.9 %\n",
      "Training round [28/100], qnn_train_step: [400/500], loss: 1.6519134044647217, accuracy: 44.6 %\n",
      "Training round [28/100], qnn_train_step: [500/500], loss: 1.6483550071716309, accuracy: 45.4 %\n",
      "-----------------------\n",
      "Training round [29/100], Epoch [1/5], Step [20/24], Loss: 1.7489, batch time: 0.09, accuracy:  39.84%\n",
      "Training round [29/100], Epoch [2/5], Step [20/24], Loss: 1.6787, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [29/100], Epoch [3/5], Step [20/24], Loss: 1.6993, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [29/100], Epoch [4/5], Step [20/24], Loss: 1.8486, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [29/100], Epoch [5/5], Step [20/24], Loss: 1.6251, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [29/100], qnn_train_step: [100/500], loss: 1.8240658044815063, accuracy: 38.8 %\n",
      "Training round [29/100], qnn_train_step: [200/500], loss: 1.7757126092910767, accuracy: 40.6 %\n",
      "Training round [29/100], qnn_train_step: [300/500], loss: 1.7387601137161255, accuracy: 41.7 %\n",
      "Training round [29/100], qnn_train_step: [400/500], loss: 1.6855247020721436, accuracy: 45.0 %\n",
      "Training round [29/100], qnn_train_step: [500/500], loss: 1.7210772037506104, accuracy: 43.5 %\n",
      "-----------------------\n",
      "Training round [30/100], Epoch [1/5], Step [20/24], Loss: 1.7672, batch time: 0.10, accuracy:  39.45%\n",
      "Training round [30/100], Epoch [2/5], Step [20/24], Loss: 1.6578, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [30/100], Epoch [3/5], Step [20/24], Loss: 1.5949, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [30/100], Epoch [4/5], Step [20/24], Loss: 1.7518, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [30/100], Epoch [5/5], Step [20/24], Loss: 1.7789, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [30/100], qnn_train_step: [100/500], loss: 1.827929973602295, accuracy: 37.8 %\n",
      "Training round [30/100], qnn_train_step: [200/500], loss: 1.781995177268982, accuracy: 41.6 %\n",
      "Training round [30/100], qnn_train_step: [300/500], loss: 1.7102336883544922, accuracy: 42.6 %\n",
      "Training round [30/100], qnn_train_step: [400/500], loss: 1.6995327472686768, accuracy: 42.3 %\n",
      "Training round [30/100], qnn_train_step: [500/500], loss: 1.7174530029296875, accuracy: 40.5 %\n",
      "-----------------------\n",
      "Training round [31/100], Epoch [1/5], Step [20/24], Loss: 1.6760, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [31/100], Epoch [2/5], Step [20/24], Loss: 1.7878, batch time: 0.09, accuracy:  39.06%\n",
      "Training round [31/100], Epoch [3/5], Step [20/24], Loss: 1.7086, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [31/100], Epoch [4/5], Step [20/24], Loss: 1.7629, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [31/100], Epoch [5/5], Step [20/24], Loss: 1.7285, batch time: 0.09, accuracy:  41.02%\n",
      "Training round [31/100], qnn_train_step: [100/500], loss: 1.8117470741271973, accuracy: 37.1 %\n",
      "Training round [31/100], qnn_train_step: [200/500], loss: 1.8009402751922607, accuracy: 40.5 %\n",
      "Training round [31/100], qnn_train_step: [300/500], loss: 1.7251734733581543, accuracy: 41.0 %\n",
      "Training round [31/100], qnn_train_step: [400/500], loss: 1.7032314538955688, accuracy: 40.8 %\n",
      "Training round [31/100], qnn_train_step: [500/500], loss: 1.7523733377456665, accuracy: 41.7 %\n",
      "-----------------------\n",
      "Training round [32/100], Epoch [1/5], Step [20/24], Loss: 1.7943, batch time: 0.10, accuracy:  35.55%\n",
      "Training round [32/100], Epoch [2/5], Step [20/24], Loss: 1.6308, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [32/100], Epoch [3/5], Step [20/24], Loss: 1.7393, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [32/100], Epoch [4/5], Step [20/24], Loss: 1.8373, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [32/100], Epoch [5/5], Step [20/24], Loss: 1.7180, batch time: 0.09, accuracy:  40.62%\n",
      "Training round [32/100], qnn_train_step: [100/500], loss: 1.846644401550293, accuracy: 35.6 %\n",
      "Training round [32/100], qnn_train_step: [200/500], loss: 1.8053569793701172, accuracy: 39.4 %\n",
      "Training round [32/100], qnn_train_step: [300/500], loss: 1.7465602159500122, accuracy: 39.2 %\n",
      "Training round [32/100], qnn_train_step: [400/500], loss: 1.6989802122116089, accuracy: 41.5 %\n",
      "Training round [32/100], qnn_train_step: [500/500], loss: 1.6899986267089844, accuracy: 42.2 %\n",
      "-----------------------\n",
      "Training round [33/100], Epoch [1/5], Step [20/24], Loss: 1.6844, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [33/100], Epoch [2/5], Step [20/24], Loss: 1.7456, batch time: 0.10, accuracy:  39.84%\n",
      "Training round [33/100], Epoch [3/5], Step [20/24], Loss: 1.6859, batch time: 0.10, accuracy:  43.36%\n",
      "Training round [33/100], Epoch [4/5], Step [20/24], Loss: 1.6338, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [33/100], Epoch [5/5], Step [20/24], Loss: 1.6012, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [33/100], qnn_train_step: [100/500], loss: 1.8088585138320923, accuracy: 38.4 %\n",
      "Training round [33/100], qnn_train_step: [200/500], loss: 1.7503340244293213, accuracy: 41.8 %\n",
      "Training round [33/100], qnn_train_step: [300/500], loss: 1.658952236175537, accuracy: 43.2 %\n",
      "Training round [33/100], qnn_train_step: [400/500], loss: 1.631074070930481, accuracy: 44.0 %\n",
      "Training round [33/100], qnn_train_step: [500/500], loss: 1.6206400394439697, accuracy: 46.2 %\n",
      "-----------------------\n",
      "Training round [34/100], Epoch [1/5], Step [20/24], Loss: 1.6336, batch time: 0.10, accuracy:  46.48%\n",
      "Training round [34/100], Epoch [2/5], Step [20/24], Loss: 1.7246, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [34/100], Epoch [3/5], Step [20/24], Loss: 1.7721, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [34/100], Epoch [4/5], Step [20/24], Loss: 1.7498, batch time: 0.10, accuracy:  40.23%\n",
      "Training round [34/100], Epoch [5/5], Step [20/24], Loss: 1.6507, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [34/100], qnn_train_step: [100/500], loss: 1.797652244567871, accuracy: 39.8 %\n",
      "Training round [34/100], qnn_train_step: [200/500], loss: 1.721821904182434, accuracy: 43.3 %\n",
      "Training round [34/100], qnn_train_step: [300/500], loss: 1.6392912864685059, accuracy: 43.4 %\n",
      "Training round [34/100], qnn_train_step: [400/500], loss: 1.6276551485061646, accuracy: 45.4 %\n",
      "Training round [34/100], qnn_train_step: [500/500], loss: 1.6883867979049683, accuracy: 44.8 %\n",
      "-----------------------\n",
      "Training round [35/100], Epoch [1/5], Step [20/24], Loss: 1.7125, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [35/100], Epoch [2/5], Step [20/24], Loss: 1.5805, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [35/100], Epoch [3/5], Step [20/24], Loss: 1.6609, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [35/100], Epoch [4/5], Step [20/24], Loss: 1.5570, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [35/100], Epoch [5/5], Step [20/24], Loss: 1.6230, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [35/100], qnn_train_step: [100/500], loss: 1.8259409666061401, accuracy: 38.8 %\n",
      "Training round [35/100], qnn_train_step: [200/500], loss: 1.721222162246704, accuracy: 41.5 %\n",
      "Training round [35/100], qnn_train_step: [300/500], loss: 1.6536815166473389, accuracy: 44.4 %\n",
      "Training round [35/100], qnn_train_step: [400/500], loss: 1.6483770608901978, accuracy: 43.3 %\n",
      "Training round [35/100], qnn_train_step: [500/500], loss: 1.6345456838607788, accuracy: 45.3 %\n",
      "-----------------------\n",
      "Training round [36/100], Epoch [1/5], Step [20/24], Loss: 1.5874, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [36/100], Epoch [2/5], Step [20/24], Loss: 1.7006, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [36/100], Epoch [3/5], Step [20/24], Loss: 1.6038, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [36/100], Epoch [4/5], Step [20/24], Loss: 1.7169, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [36/100], Epoch [5/5], Step [20/24], Loss: 1.7012, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [36/100], qnn_train_step: [100/500], loss: 1.896476149559021, accuracy: 36.9 %\n",
      "Training round [36/100], qnn_train_step: [200/500], loss: 1.8933475017547607, accuracy: 35.7 %\n",
      "Training round [36/100], qnn_train_step: [300/500], loss: 1.6883652210235596, accuracy: 39.9 %\n",
      "Training round [36/100], qnn_train_step: [400/500], loss: 1.6870582103729248, accuracy: 41.7 %\n",
      "Training round [36/100], qnn_train_step: [500/500], loss: 1.7158076763153076, accuracy: 40.3 %\n",
      "-----------------------\n",
      "Training round [37/100], Epoch [1/5], Step [20/24], Loss: 1.6378, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [37/100], Epoch [2/5], Step [20/24], Loss: 1.6446, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [37/100], Epoch [3/5], Step [20/24], Loss: 1.6294, batch time: 0.09, accuracy:  46.48%\n",
      "Training round [37/100], Epoch [4/5], Step [20/24], Loss: 1.7278, batch time: 0.10, accuracy:  43.36%\n",
      "Training round [37/100], Epoch [5/5], Step [20/24], Loss: 1.6839, batch time: 0.10, accuracy:  46.48%\n",
      "Training round [37/100], qnn_train_step: [100/500], loss: 1.9483269453048706, accuracy: 36.0 %\n",
      "Training round [37/100], qnn_train_step: [200/500], loss: 1.9193978309631348, accuracy: 33.3 %\n",
      "Training round [37/100], qnn_train_step: [300/500], loss: 1.648416519165039, accuracy: 45.3 %\n",
      "Training round [37/100], qnn_train_step: [400/500], loss: 1.6497050523757935, accuracy: 43.1 %\n",
      "Training round [37/100], qnn_train_step: [500/500], loss: 1.7224167585372925, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [38/100], Epoch [1/5], Step [20/24], Loss: 1.5816, batch time: 0.29, accuracy:  46.09%\n",
      "Training round [38/100], Epoch [2/5], Step [20/24], Loss: 1.4976, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [38/100], Epoch [3/5], Step [20/24], Loss: 1.6252, batch time: 0.11, accuracy:  45.70%\n",
      "Training round [38/100], Epoch [4/5], Step [20/24], Loss: 1.6506, batch time: 0.11, accuracy:  45.31%\n",
      "Training round [38/100], Epoch [5/5], Step [20/24], Loss: 1.6241, batch time: 0.10, accuracy:  48.05%\n",
      "Training round [38/100], qnn_train_step: [100/500], loss: 2.0133132934570312, accuracy: 34.3 %\n",
      "Training round [38/100], qnn_train_step: [200/500], loss: 1.8665262460708618, accuracy: 33.5 %\n",
      "Training round [38/100], qnn_train_step: [300/500], loss: 1.703917384147644, accuracy: 39.7 %\n",
      "Training round [38/100], qnn_train_step: [400/500], loss: 1.6843630075454712, accuracy: 44.3 %\n",
      "Training round [38/100], qnn_train_step: [500/500], loss: 1.6686006784439087, accuracy: 43.6 %\n",
      "-----------------------\n",
      "Training round [39/100], Epoch [1/5], Step [20/24], Loss: 1.5811, batch time: 0.10, accuracy:  50.39%\n",
      "Training round [39/100], Epoch [2/5], Step [20/24], Loss: 1.7448, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [39/100], Epoch [3/5], Step [20/24], Loss: 1.6505, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [39/100], Epoch [4/5], Step [20/24], Loss: 1.5519, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [39/100], Epoch [5/5], Step [20/24], Loss: 1.7386, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [39/100], qnn_train_step: [100/500], loss: 1.8541465997695923, accuracy: 39.0 %\n",
      "Training round [39/100], qnn_train_step: [200/500], loss: 1.801604986190796, accuracy: 36.2 %\n",
      "Training round [39/100], qnn_train_step: [300/500], loss: 1.6560704708099365, accuracy: 44.8 %\n",
      "Training round [39/100], qnn_train_step: [400/500], loss: 1.6507441997528076, accuracy: 42.9 %\n",
      "Training round [39/100], qnn_train_step: [500/500], loss: 1.6464747190475464, accuracy: 44.2 %\n",
      "-----------------------\n",
      "Training round [40/100], Epoch [1/5], Step [20/24], Loss: 1.6055, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [40/100], Epoch [2/5], Step [20/24], Loss: 1.7149, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [40/100], Epoch [3/5], Step [20/24], Loss: 1.6223, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [40/100], Epoch [4/5], Step [20/24], Loss: 1.5421, batch time: 0.30, accuracy:  45.70%\n",
      "Training round [40/100], Epoch [5/5], Step [20/24], Loss: 1.6218, batch time: 0.10, accuracy:  43.36%\n",
      "Training round [40/100], qnn_train_step: [100/500], loss: 1.9314037561416626, accuracy: 38.7 %\n",
      "Training round [40/100], qnn_train_step: [200/500], loss: 1.7488939762115479, accuracy: 41.1 %\n",
      "Training round [40/100], qnn_train_step: [300/500], loss: 1.681013584136963, accuracy: 44.2 %\n",
      "Training round [40/100], qnn_train_step: [400/500], loss: 1.6228972673416138, accuracy: 44.1 %\n",
      "Training round [40/100], qnn_train_step: [500/500], loss: 1.6168773174285889, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [41/100], Epoch [1/5], Step [20/24], Loss: 1.6122, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [41/100], Epoch [2/5], Step [20/24], Loss: 1.5831, batch time: 0.10, accuracy:  45.31%\n",
      "Training round [41/100], Epoch [3/5], Step [20/24], Loss: 1.6339, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [41/100], Epoch [4/5], Step [20/24], Loss: 1.6773, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [41/100], Epoch [5/5], Step [20/24], Loss: 1.6404, batch time: 0.10, accuracy:  44.92%\n",
      "Training round [41/100], qnn_train_step: [100/500], loss: 1.9539515972137451, accuracy: 37.1 %\n",
      "Training round [41/100], qnn_train_step: [200/500], loss: 1.7315937280654907, accuracy: 40.5 %\n",
      "Training round [41/100], qnn_train_step: [300/500], loss: 1.6442779302597046, accuracy: 42.6 %\n",
      "Training round [41/100], qnn_train_step: [400/500], loss: 1.6321724653244019, accuracy: 44.5 %\n",
      "Training round [41/100], qnn_train_step: [500/500], loss: 1.6300604343414307, accuracy: 41.8 %\n",
      "-----------------------\n",
      "Training round [42/100], Epoch [1/5], Step [20/24], Loss: 1.5991, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [42/100], Epoch [2/5], Step [20/24], Loss: 1.5414, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [42/100], Epoch [3/5], Step [20/24], Loss: 1.5654, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [42/100], Epoch [4/5], Step [20/24], Loss: 1.5990, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [42/100], Epoch [5/5], Step [20/24], Loss: 1.6152, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [42/100], qnn_train_step: [100/500], loss: 1.867422103881836, accuracy: 36.4 %\n",
      "Training round [42/100], qnn_train_step: [200/500], loss: 1.7427854537963867, accuracy: 39.1 %\n",
      "Training round [42/100], qnn_train_step: [300/500], loss: 1.6797232627868652, accuracy: 38.7 %\n",
      "Training round [42/100], qnn_train_step: [400/500], loss: 1.65318763256073, accuracy: 41.0 %\n",
      "Training round [42/100], qnn_train_step: [500/500], loss: 1.6490892171859741, accuracy: 41.4 %\n",
      "-----------------------\n",
      "Training round [43/100], Epoch [1/5], Step [20/24], Loss: 1.6870, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [43/100], Epoch [2/5], Step [20/24], Loss: 1.7448, batch time: 0.10, accuracy:  39.06%\n",
      "Training round [43/100], Epoch [3/5], Step [20/24], Loss: 1.6373, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [43/100], Epoch [4/5], Step [20/24], Loss: 1.6163, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [43/100], Epoch [5/5], Step [20/24], Loss: 1.6813, batch time: 0.10, accuracy:  41.02%\n",
      "Training round [43/100], qnn_train_step: [100/500], loss: 1.8743394613265991, accuracy: 36.9 %\n",
      "Training round [43/100], qnn_train_step: [200/500], loss: 1.7359600067138672, accuracy: 40.8 %\n",
      "Training round [43/100], qnn_train_step: [300/500], loss: 1.6847046613693237, accuracy: 43.8 %\n",
      "Training round [43/100], qnn_train_step: [400/500], loss: 1.635144829750061, accuracy: 44.2 %\n",
      "Training round [43/100], qnn_train_step: [500/500], loss: 1.6769423484802246, accuracy: 41.0 %\n",
      "-----------------------\n",
      "Training round [44/100], Epoch [1/5], Step [20/24], Loss: 1.6627, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [44/100], Epoch [2/5], Step [20/24], Loss: 1.6846, batch time: 0.10, accuracy:  43.36%\n",
      "Training round [44/100], Epoch [3/5], Step [20/24], Loss: 1.5627, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [44/100], Epoch [4/5], Step [20/24], Loss: 1.6469, batch time: 0.10, accuracy:  44.92%\n",
      "Training round [44/100], Epoch [5/5], Step [20/24], Loss: 1.6536, batch time: 0.10, accuracy:  41.02%\n",
      "Training round [44/100], qnn_train_step: [100/500], loss: 1.938774585723877, accuracy: 36.7 %\n",
      "Training round [44/100], qnn_train_step: [200/500], loss: 1.7242918014526367, accuracy: 40.7 %\n",
      "Training round [44/100], qnn_train_step: [300/500], loss: 1.6142940521240234, accuracy: 44.9 %\n",
      "Training round [44/100], qnn_train_step: [400/500], loss: 1.6164441108703613, accuracy: 46.3 %\n",
      "Training round [44/100], qnn_train_step: [500/500], loss: 1.6049823760986328, accuracy: 44.7 %\n",
      "-----------------------\n",
      "Training round [45/100], Epoch [1/5], Step [20/24], Loss: 1.5529, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [45/100], Epoch [2/5], Step [20/24], Loss: 1.6365, batch time: 0.10, accuracy:  40.23%\n",
      "Training round [45/100], Epoch [3/5], Step [20/24], Loss: 1.6597, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [45/100], Epoch [4/5], Step [20/24], Loss: 1.7470, batch time: 0.10, accuracy:  38.28%\n",
      "Training round [45/100], Epoch [5/5], Step [20/24], Loss: 1.6995, batch time: 0.09, accuracy:  44.14%\n",
      "Training round [45/100], qnn_train_step: [100/500], loss: 1.8198349475860596, accuracy: 40.9 %\n",
      "Training round [45/100], qnn_train_step: [200/500], loss: 1.7150287628173828, accuracy: 41.9 %\n",
      "Training round [45/100], qnn_train_step: [300/500], loss: 1.6061105728149414, accuracy: 45.4 %\n",
      "Training round [45/100], qnn_train_step: [400/500], loss: 1.6039916276931763, accuracy: 45.5 %\n",
      "Training round [45/100], qnn_train_step: [500/500], loss: 1.6800715923309326, accuracy: 45.1 %\n",
      "-----------------------\n",
      "Training round [46/100], Epoch [1/5], Step [20/24], Loss: 1.5446, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [46/100], Epoch [2/5], Step [20/24], Loss: 1.7834, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [46/100], Epoch [3/5], Step [20/24], Loss: 1.7396, batch time: 0.10, accuracy:  42.19%\n",
      "Training round [46/100], Epoch [4/5], Step [20/24], Loss: 1.6366, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [46/100], Epoch [5/5], Step [20/24], Loss: 1.5842, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [46/100], qnn_train_step: [100/500], loss: 1.790624737739563, accuracy: 38.9 %\n",
      "Training round [46/100], qnn_train_step: [200/500], loss: 1.7342511415481567, accuracy: 40.3 %\n",
      "Training round [46/100], qnn_train_step: [300/500], loss: 1.5430307388305664, accuracy: 48.7 %\n",
      "Training round [46/100], qnn_train_step: [400/500], loss: 1.543368935585022, accuracy: 49.5 %\n",
      "Training round [46/100], qnn_train_step: [500/500], loss: 1.558273196220398, accuracy: 44.9 %\n",
      "-----------------------\n",
      "Training round [47/100], Epoch [1/5], Step [20/24], Loss: 1.5702, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [47/100], Epoch [2/5], Step [20/24], Loss: 1.6827, batch time: 0.10, accuracy:  41.80%\n",
      "Training round [47/100], Epoch [3/5], Step [20/24], Loss: 1.6219, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [47/100], Epoch [4/5], Step [20/24], Loss: 1.6501, batch time: 0.10, accuracy:  41.41%\n",
      "Training round [47/100], Epoch [5/5], Step [20/24], Loss: 1.6637, batch time: 0.10, accuracy:  48.05%\n",
      "Training round [47/100], qnn_train_step: [100/500], loss: 1.9614911079406738, accuracy: 35.5 %\n",
      "Training round [47/100], qnn_train_step: [200/500], loss: 1.8638451099395752, accuracy: 37.2 %\n",
      "Training round [47/100], qnn_train_step: [300/500], loss: 1.619278907775879, accuracy: 42.8 %\n",
      "Training round [47/100], qnn_train_step: [400/500], loss: 1.6328284740447998, accuracy: 42.6 %\n",
      "Training round [47/100], qnn_train_step: [500/500], loss: 1.5789580345153809, accuracy: 46.1 %\n",
      "-----------------------\n",
      "Training round [48/100], Epoch [1/5], Step [20/24], Loss: 1.6029, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [48/100], Epoch [2/5], Step [20/24], Loss: 1.6889, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [48/100], Epoch [3/5], Step [20/24], Loss: 1.4518, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [48/100], Epoch [4/5], Step [20/24], Loss: 1.5156, batch time: 0.11, accuracy:  49.61%\n",
      "Training round [48/100], Epoch [5/5], Step [20/24], Loss: 1.5606, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [48/100], qnn_train_step: [100/500], loss: 2.003695011138916, accuracy: 35.7 %\n",
      "Training round [48/100], qnn_train_step: [200/500], loss: 1.726231336593628, accuracy: 44.0 %\n",
      "Training round [48/100], qnn_train_step: [300/500], loss: 1.6146256923675537, accuracy: 45.7 %\n",
      "Training round [48/100], qnn_train_step: [400/500], loss: 1.5807039737701416, accuracy: 46.5 %\n",
      "Training round [48/100], qnn_train_step: [500/500], loss: 1.5806885957717896, accuracy: 46.6 %\n",
      "-----------------------\n",
      "Training round [49/100], Epoch [1/5], Step [20/24], Loss: 1.6783, batch time: 0.10, accuracy:  39.45%\n",
      "Training round [49/100], Epoch [2/5], Step [20/24], Loss: 1.6351, batch time: 0.09, accuracy:  44.14%\n",
      "Training round [49/100], Epoch [3/5], Step [20/24], Loss: 1.5883, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [49/100], Epoch [4/5], Step [20/24], Loss: 1.5924, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [49/100], Epoch [5/5], Step [20/24], Loss: 1.5691, batch time: 0.09, accuracy:  49.61%\n",
      "Training round [49/100], qnn_train_step: [100/500], loss: 2.0102555751800537, accuracy: 33.3 %\n",
      "Training round [49/100], qnn_train_step: [200/500], loss: 1.7250572443008423, accuracy: 42.4 %\n",
      "Training round [49/100], qnn_train_step: [300/500], loss: 1.6161186695098877, accuracy: 45.4 %\n",
      "Training round [49/100], qnn_train_step: [400/500], loss: 1.5571056604385376, accuracy: 48.0 %\n",
      "Training round [49/100], qnn_train_step: [500/500], loss: 1.5528126955032349, accuracy: 47.8 %\n",
      "-----------------------\n",
      "Training round [50/100], Epoch [1/5], Step [20/24], Loss: 1.4617, batch time: 0.09, accuracy:  48.83%\n",
      "Training round [50/100], Epoch [2/5], Step [20/24], Loss: 1.5569, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [50/100], Epoch [3/5], Step [20/24], Loss: 1.5220, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [50/100], Epoch [4/5], Step [20/24], Loss: 1.5262, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [50/100], Epoch [5/5], Step [20/24], Loss: 1.4579, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [50/100], qnn_train_step: [100/500], loss: 2.0625057220458984, accuracy: 34.1 %\n",
      "Training round [50/100], qnn_train_step: [200/500], loss: 1.716962456703186, accuracy: 43.0 %\n",
      "Training round [50/100], qnn_train_step: [300/500], loss: 1.6215966939926147, accuracy: 45.6 %\n",
      "Training round [50/100], qnn_train_step: [400/500], loss: 1.5538910627365112, accuracy: 47.3 %\n",
      "Training round [50/100], qnn_train_step: [500/500], loss: 1.5445693731307983, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [51/100], Epoch [1/5], Step [20/24], Loss: 1.5134, batch time: 0.10, accuracy:  48.05%\n",
      "Training round [51/100], Epoch [2/5], Step [20/24], Loss: 1.5305, batch time: 0.09, accuracy:  43.75%\n",
      "Training round [51/100], Epoch [3/5], Step [20/24], Loss: 1.6661, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [51/100], Epoch [4/5], Step [20/24], Loss: 1.5403, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [51/100], Epoch [5/5], Step [20/24], Loss: 1.4368, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [51/100], qnn_train_step: [100/500], loss: 2.0569722652435303, accuracy: 33.1 %\n",
      "Training round [51/100], qnn_train_step: [200/500], loss: 1.7424529790878296, accuracy: 41.3 %\n",
      "Training round [51/100], qnn_train_step: [300/500], loss: 1.587910532951355, accuracy: 46.7 %\n",
      "Training round [51/100], qnn_train_step: [400/500], loss: 1.5621833801269531, accuracy: 46.0 %\n",
      "Training round [51/100], qnn_train_step: [500/500], loss: 1.545120120048523, accuracy: 47.8 %\n",
      "-----------------------\n",
      "Training round [52/100], Epoch [1/5], Step [20/24], Loss: 1.5589, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [52/100], Epoch [2/5], Step [20/24], Loss: 1.6012, batch time: 0.09, accuracy:  45.70%\n",
      "Training round [52/100], Epoch [3/5], Step [20/24], Loss: 1.5347, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [52/100], Epoch [4/5], Step [20/24], Loss: 1.5164, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [52/100], Epoch [5/5], Step [20/24], Loss: 1.5128, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [52/100], qnn_train_step: [100/500], loss: 1.94092857837677, accuracy: 36.7 %\n",
      "Training round [52/100], qnn_train_step: [200/500], loss: 1.728715419769287, accuracy: 42.8 %\n",
      "Training round [52/100], qnn_train_step: [300/500], loss: 1.5858290195465088, accuracy: 45.4 %\n",
      "Training round [52/100], qnn_train_step: [400/500], loss: 1.5763680934906006, accuracy: 45.7 %\n",
      "Training round [52/100], qnn_train_step: [500/500], loss: 1.6402344703674316, accuracy: 42.5 %\n",
      "-----------------------\n",
      "Training round [53/100], Epoch [1/5], Step [20/24], Loss: 1.5550, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [53/100], Epoch [2/5], Step [20/24], Loss: 1.4131, batch time: 0.09, accuracy:  51.17%\n",
      "Training round [53/100], Epoch [3/5], Step [20/24], Loss: 1.4741, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [53/100], Epoch [4/5], Step [20/24], Loss: 1.6229, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [53/100], Epoch [5/5], Step [20/24], Loss: 1.4616, batch time: 0.09, accuracy:  52.73%\n",
      "Training round [53/100], qnn_train_step: [100/500], loss: 1.9211140871047974, accuracy: 38.1 %\n",
      "Training round [53/100], qnn_train_step: [200/500], loss: 1.8025298118591309, accuracy: 40.3 %\n",
      "Training round [53/100], qnn_train_step: [300/500], loss: 1.6676092147827148, accuracy: 43.1 %\n",
      "Training round [53/100], qnn_train_step: [400/500], loss: 1.5489203929901123, accuracy: 46.9 %\n",
      "Training round [53/100], qnn_train_step: [500/500], loss: 1.5596708059310913, accuracy: 46.4 %\n",
      "-----------------------\n",
      "Training round [54/100], Epoch [1/5], Step [20/24], Loss: 1.5232, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [54/100], Epoch [2/5], Step [20/24], Loss: 1.5901, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [54/100], Epoch [3/5], Step [20/24], Loss: 1.5318, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [54/100], Epoch [4/5], Step [20/24], Loss: 1.4790, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [54/100], Epoch [5/5], Step [20/24], Loss: 1.4829, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [54/100], qnn_train_step: [100/500], loss: 1.9654535055160522, accuracy: 36.7 %\n",
      "Training round [54/100], qnn_train_step: [200/500], loss: 1.7203575372695923, accuracy: 43.6 %\n",
      "Training round [54/100], qnn_train_step: [300/500], loss: 1.5708413124084473, accuracy: 47.2 %\n",
      "Training round [54/100], qnn_train_step: [400/500], loss: 1.5411924123764038, accuracy: 48.7 %\n",
      "Training round [54/100], qnn_train_step: [500/500], loss: 1.5675923824310303, accuracy: 48.0 %\n",
      "-----------------------\n",
      "Training round [55/100], Epoch [1/5], Step [20/24], Loss: 1.4695, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [55/100], Epoch [2/5], Step [20/24], Loss: 1.5077, batch time: 0.09, accuracy:  48.83%\n",
      "Training round [55/100], Epoch [3/5], Step [20/24], Loss: 1.5611, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [55/100], Epoch [4/5], Step [20/24], Loss: 1.5011, batch time: 0.09, accuracy:  48.83%\n",
      "Training round [55/100], Epoch [5/5], Step [20/24], Loss: 1.4585, batch time: 0.09, accuracy:  51.17%\n",
      "Training round [55/100], qnn_train_step: [100/500], loss: 1.9120547771453857, accuracy: 36.0 %\n",
      "Training round [55/100], qnn_train_step: [200/500], loss: 1.7242307662963867, accuracy: 44.9 %\n",
      "Training round [55/100], qnn_train_step: [300/500], loss: 1.5940674543380737, accuracy: 46.7 %\n",
      "Training round [55/100], qnn_train_step: [400/500], loss: 1.5555833578109741, accuracy: 45.8 %\n",
      "Training round [55/100], qnn_train_step: [500/500], loss: 1.654990553855896, accuracy: 45.6 %\n",
      "-----------------------\n",
      "Training round [56/100], Epoch [1/5], Step [20/24], Loss: 1.4768, batch time: 0.09, accuracy:  48.83%\n",
      "Training round [56/100], Epoch [2/5], Step [20/24], Loss: 1.4613, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [56/100], Epoch [3/5], Step [20/24], Loss: 1.4278, batch time: 0.09, accuracy:  49.22%\n",
      "Training round [56/100], Epoch [4/5], Step [20/24], Loss: 1.5330, batch time: 0.09, accuracy:  45.70%\n",
      "Training round [56/100], Epoch [5/5], Step [20/24], Loss: 1.6921, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [56/100], qnn_train_step: [100/500], loss: 1.8503221273422241, accuracy: 37.2 %\n",
      "Training round [56/100], qnn_train_step: [200/500], loss: 1.6832342147827148, accuracy: 46.2 %\n",
      "Training round [56/100], qnn_train_step: [300/500], loss: 1.5423387289047241, accuracy: 46.1 %\n",
      "Training round [56/100], qnn_train_step: [400/500], loss: 1.5300471782684326, accuracy: 46.7 %\n",
      "Training round [56/100], qnn_train_step: [500/500], loss: 1.515763759613037, accuracy: 46.0 %\n",
      "-----------------------\n",
      "Training round [57/100], Epoch [1/5], Step [20/24], Loss: 1.6147, batch time: 0.09, accuracy:  42.97%\n",
      "Training round [57/100], Epoch [2/5], Step [20/24], Loss: 1.5486, batch time: 0.09, accuracy:  46.48%\n",
      "Training round [57/100], Epoch [3/5], Step [20/24], Loss: 1.5972, batch time: 0.10, accuracy:  44.14%\n",
      "Training round [57/100], Epoch [4/5], Step [20/24], Loss: 1.4221, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [57/100], Epoch [5/5], Step [20/24], Loss: 1.5810, batch time: 0.10, accuracy:  46.48%\n",
      "Training round [57/100], qnn_train_step: [100/500], loss: 1.9319185018539429, accuracy: 34.8 %\n",
      "Training round [57/100], qnn_train_step: [200/500], loss: 1.6618366241455078, accuracy: 43.7 %\n",
      "Training round [57/100], qnn_train_step: [300/500], loss: 1.5418370962142944, accuracy: 47.0 %\n",
      "Training round [57/100], qnn_train_step: [400/500], loss: 1.5173022747039795, accuracy: 46.1 %\n",
      "Training round [57/100], qnn_train_step: [500/500], loss: 1.5277231931686401, accuracy: 47.7 %\n",
      "-----------------------\n",
      "Training round [58/100], Epoch [1/5], Step [20/24], Loss: 1.4501, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [58/100], Epoch [2/5], Step [20/24], Loss: 1.5994, batch time: 0.10, accuracy:  46.09%\n",
      "Training round [58/100], Epoch [3/5], Step [20/24], Loss: 1.4697, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [58/100], Epoch [4/5], Step [20/24], Loss: 1.5367, batch time: 0.09, accuracy:  45.70%\n",
      "Training round [58/100], Epoch [5/5], Step [20/24], Loss: 1.5425, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [58/100], qnn_train_step: [100/500], loss: 2.067429304122925, accuracy: 34.6 %\n",
      "Training round [58/100], qnn_train_step: [200/500], loss: 1.6026794910430908, accuracy: 46.4 %\n",
      "Training round [58/100], qnn_train_step: [300/500], loss: 1.5165045261383057, accuracy: 48.5 %\n",
      "Training round [58/100], qnn_train_step: [400/500], loss: 1.5697296857833862, accuracy: 46.4 %\n",
      "Training round [58/100], qnn_train_step: [500/500], loss: 1.469067096710205, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [59/100], Epoch [1/5], Step [20/24], Loss: 1.4699, batch time: 0.09, accuracy:  50.00%\n",
      "Training round [59/100], Epoch [2/5], Step [20/24], Loss: 1.4946, batch time: 0.09, accuracy:  46.48%\n",
      "Training round [59/100], Epoch [3/5], Step [20/24], Loss: 1.5009, batch time: 0.11, accuracy:  48.44%\n",
      "Training round [59/100], Epoch [4/5], Step [20/24], Loss: 1.5742, batch time: 0.09, accuracy:  44.92%\n",
      "Training round [59/100], Epoch [5/5], Step [20/24], Loss: 1.5093, batch time: 0.09, accuracy:  47.66%\n",
      "Training round [59/100], qnn_train_step: [100/500], loss: 2.0497472286224365, accuracy: 36.6 %\n",
      "Training round [59/100], qnn_train_step: [200/500], loss: 1.6453427076339722, accuracy: 46.9 %\n",
      "Training round [59/100], qnn_train_step: [300/500], loss: 1.5594935417175293, accuracy: 48.9 %\n",
      "Training round [59/100], qnn_train_step: [400/500], loss: 1.8797473907470703, accuracy: 40.3 %\n",
      "Training round [59/100], qnn_train_step: [500/500], loss: 1.4901371002197266, accuracy: 48.4 %\n",
      "-----------------------\n",
      "Training round [60/100], Epoch [1/5], Step [20/24], Loss: 1.5498, batch time: 0.09, accuracy:  48.83%\n",
      "Training round [60/100], Epoch [2/5], Step [20/24], Loss: 1.5321, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [60/100], Epoch [3/5], Step [20/24], Loss: 1.4907, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [60/100], Epoch [4/5], Step [20/24], Loss: 1.5334, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [60/100], Epoch [5/5], Step [20/24], Loss: 1.5108, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [60/100], qnn_train_step: [100/500], loss: 2.1933820247650146, accuracy: 34.0 %\n",
      "Training round [60/100], qnn_train_step: [200/500], loss: 1.766355276107788, accuracy: 44.9 %\n",
      "Training round [60/100], qnn_train_step: [300/500], loss: 1.5582351684570312, accuracy: 47.6 %\n",
      "Training round [60/100], qnn_train_step: [400/500], loss: 1.5274983644485474, accuracy: 48.5 %\n",
      "Training round [60/100], qnn_train_step: [500/500], loss: 1.5218738317489624, accuracy: 49.4 %\n",
      "-----------------------\n",
      "Training round [61/100], Epoch [1/5], Step [20/24], Loss: 1.4793, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [61/100], Epoch [2/5], Step [20/24], Loss: 1.5533, batch time: 0.09, accuracy:  45.31%\n",
      "Training round [61/100], Epoch [3/5], Step [20/24], Loss: 1.5478, batch time: 0.09, accuracy:  46.88%\n",
      "Training round [61/100], Epoch [4/5], Step [20/24], Loss: 1.4699, batch time: 0.09, accuracy:  50.39%\n",
      "Training round [61/100], Epoch [5/5], Step [20/24], Loss: 1.4299, batch time: 0.09, accuracy:  49.61%\n",
      "Training round [61/100], qnn_train_step: [100/500], loss: 2.0971622467041016, accuracy: 32.3 %\n",
      "Training round [61/100], qnn_train_step: [200/500], loss: 1.807186484336853, accuracy: 42.3 %\n",
      "Training round [61/100], qnn_train_step: [300/500], loss: 1.5300583839416504, accuracy: 48.2 %\n",
      "Training round [61/100], qnn_train_step: [400/500], loss: 1.5198391675949097, accuracy: 48.2 %\n",
      "Training round [61/100], qnn_train_step: [500/500], loss: 1.5368971824645996, accuracy: 47.2 %\n",
      "-----------------------\n",
      "Training round [62/100], Epoch [1/5], Step [20/24], Loss: 1.4465, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [62/100], Epoch [2/5], Step [20/24], Loss: 1.5399, batch time: 0.09, accuracy:  44.14%\n",
      "Training round [62/100], Epoch [3/5], Step [20/24], Loss: 1.4365, batch time: 0.09, accuracy:  50.39%\n",
      "Training round [62/100], Epoch [4/5], Step [20/24], Loss: 1.4399, batch time: 0.09, accuracy:  51.17%\n",
      "Training round [62/100], Epoch [5/5], Step [20/24], Loss: 1.4942, batch time: 0.09, accuracy:  51.95%\n",
      "Training round [62/100], qnn_train_step: [100/500], loss: 2.130286455154419, accuracy: 34.5 %\n",
      "Training round [62/100], qnn_train_step: [200/500], loss: 2.0764358043670654, accuracy: 33.9 %\n",
      "Training round [62/100], qnn_train_step: [300/500], loss: 1.5977922677993774, accuracy: 46.4 %\n",
      "Training round [62/100], qnn_train_step: [400/500], loss: 1.549696445465088, accuracy: 44.8 %\n",
      "Training round [62/100], qnn_train_step: [500/500], loss: 1.6099188327789307, accuracy: 43.9 %\n",
      "-----------------------\n",
      "Training round [63/100], Epoch [1/5], Step [20/24], Loss: 1.5640, batch time: 0.09, accuracy:  41.80%\n",
      "Training round [63/100], Epoch [2/5], Step [20/24], Loss: 1.6258, batch time: 0.10, accuracy:  40.62%\n",
      "Training round [63/100], Epoch [3/5], Step [20/24], Loss: 1.4610, batch time: 0.09, accuracy:  48.44%\n",
      "Training round [63/100], Epoch [4/5], Step [20/24], Loss: 1.5367, batch time: 0.09, accuracy:  46.48%\n",
      "Training round [63/100], Epoch [5/5], Step [20/24], Loss: 1.5439, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [63/100], qnn_train_step: [100/500], loss: 2.2569937705993652, accuracy: 31.1 %\n",
      "Training round [63/100], qnn_train_step: [200/500], loss: 2.0701041221618652, accuracy: 35.6 %\n",
      "Training round [63/100], qnn_train_step: [300/500], loss: 1.5921434164047241, accuracy: 45.5 %\n",
      "Training round [63/100], qnn_train_step: [400/500], loss: 1.535285234451294, accuracy: 48.7 %\n",
      "Training round [63/100], qnn_train_step: [500/500], loss: 1.6121296882629395, accuracy: 44.3 %\n",
      "-----------------------\n",
      "Training round [64/100], Epoch [1/5], Step [20/24], Loss: 1.5035, batch time: 0.09, accuracy:  48.05%\n",
      "Training round [64/100], Epoch [2/5], Step [20/24], Loss: 1.5179, batch time: 0.09, accuracy:  50.39%\n",
      "Training round [64/100], Epoch [3/5], Step [20/24], Loss: 1.4712, batch time: 0.09, accuracy:  48.05%\n",
      "Training round [64/100], Epoch [4/5], Step [20/24], Loss: 1.4951, batch time: 0.09, accuracy:  48.05%\n",
      "Training round [64/100], Epoch [5/5], Step [20/24], Loss: 1.5371, batch time: 0.09, accuracy:  53.52%\n",
      "Training round [64/100], qnn_train_step: [100/500], loss: 2.0967915058135986, accuracy: 34.4 %\n",
      "Training round [64/100], qnn_train_step: [200/500], loss: 2.153383493423462, accuracy: 32.3 %\n",
      "Training round [64/100], qnn_train_step: [300/500], loss: 1.5094146728515625, accuracy: 46.3 %\n",
      "Training round [64/100], qnn_train_step: [400/500], loss: 1.4928704500198364, accuracy: 47.4 %\n",
      "Training round [64/100], qnn_train_step: [500/500], loss: 1.4888198375701904, accuracy: 46.8 %\n",
      "-----------------------\n",
      "Training round [65/100], Epoch [1/5], Step [20/24], Loss: 1.4154, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [65/100], Epoch [2/5], Step [20/24], Loss: 1.4848, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [65/100], Epoch [3/5], Step [20/24], Loss: 1.3964, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [65/100], Epoch [4/5], Step [20/24], Loss: 1.5297, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [65/100], Epoch [5/5], Step [20/24], Loss: 1.4749, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [65/100], qnn_train_step: [100/500], loss: 2.1994521617889404, accuracy: 34.5 %\n",
      "Training round [65/100], qnn_train_step: [200/500], loss: 1.8725610971450806, accuracy: 37.6 %\n",
      "Training round [65/100], qnn_train_step: [300/500], loss: 1.5022433996200562, accuracy: 46.7 %\n",
      "Training round [65/100], qnn_train_step: [400/500], loss: 1.4644348621368408, accuracy: 48.4 %\n",
      "Training round [65/100], qnn_train_step: [500/500], loss: 1.498816728591919, accuracy: 47.3 %\n",
      "-----------------------\n",
      "Training round [66/100], Epoch [1/5], Step [20/24], Loss: 1.4752, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [66/100], Epoch [2/5], Step [20/24], Loss: 1.6244, batch time: 0.10, accuracy:  43.75%\n",
      "Training round [66/100], Epoch [3/5], Step [20/24], Loss: 1.4478, batch time: 0.10, accuracy:  44.92%\n",
      "Training round [66/100], Epoch [4/5], Step [20/24], Loss: 1.4624, batch time: 0.10, accuracy:  49.61%\n",
      "Training round [66/100], Epoch [5/5], Step [20/24], Loss: 1.5705, batch time: 0.10, accuracy:  44.53%\n",
      "Training round [66/100], qnn_train_step: [100/500], loss: 2.1724114418029785, accuracy: 36.1 %\n",
      "Training round [66/100], qnn_train_step: [200/500], loss: 1.9521965980529785, accuracy: 36.6 %\n",
      "Training round [66/100], qnn_train_step: [300/500], loss: 1.7484854459762573, accuracy: 41.2 %\n",
      "Training round [66/100], qnn_train_step: [400/500], loss: 1.5704398155212402, accuracy: 47.3 %\n",
      "Training round [66/100], qnn_train_step: [500/500], loss: 1.5551656484603882, accuracy: 48.2 %\n",
      "-----------------------\n",
      "Training round [67/100], Epoch [1/5], Step [20/24], Loss: 1.3472, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [67/100], Epoch [2/5], Step [20/24], Loss: 1.5220, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [67/100], Epoch [3/5], Step [20/24], Loss: 1.3244, batch time: 0.10, accuracy:  55.86%\n",
      "Training round [67/100], Epoch [4/5], Step [20/24], Loss: 1.5119, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [67/100], Epoch [5/5], Step [20/24], Loss: 1.4647, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [67/100], qnn_train_step: [100/500], loss: 2.281057834625244, accuracy: 34.4 %\n",
      "Training round [67/100], qnn_train_step: [200/500], loss: 1.898850917816162, accuracy: 36.5 %\n",
      "Training round [67/100], qnn_train_step: [300/500], loss: 1.9666996002197266, accuracy: 39.0 %\n",
      "Training round [67/100], qnn_train_step: [400/500], loss: 1.4796195030212402, accuracy: 48.6 %\n",
      "Training round [67/100], qnn_train_step: [500/500], loss: 1.4536590576171875, accuracy: 48.7 %\n",
      "-----------------------\n",
      "Training round [68/100], Epoch [1/5], Step [20/24], Loss: 1.4029, batch time: 0.10, accuracy:  49.61%\n",
      "Training round [68/100], Epoch [2/5], Step [20/24], Loss: 1.4345, batch time: 0.10, accuracy:  49.61%\n",
      "Training round [68/100], Epoch [3/5], Step [20/24], Loss: 1.4774, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [68/100], Epoch [4/5], Step [20/24], Loss: 1.3616, batch time: 0.09, accuracy:  51.95%\n",
      "Training round [68/100], Epoch [5/5], Step [20/24], Loss: 1.4646, batch time: 0.10, accuracy:  49.61%\n",
      "Training round [68/100], qnn_train_step: [100/500], loss: 2.4458322525024414, accuracy: 32.5 %\n",
      "Training round [68/100], qnn_train_step: [200/500], loss: 2.2065038681030273, accuracy: 33.0 %\n",
      "Training round [68/100], qnn_train_step: [300/500], loss: 1.4704864025115967, accuracy: 50.3 %\n",
      "Training round [68/100], qnn_train_step: [400/500], loss: 1.4495611190795898, accuracy: 50.0 %\n",
      "Training round [68/100], qnn_train_step: [500/500], loss: 1.4543020725250244, accuracy: 51.2 %\n",
      "-----------------------\n",
      "Training round [69/100], Epoch [1/5], Step [20/24], Loss: 1.5034, batch time: 0.10, accuracy:  46.88%\n",
      "Training round [69/100], Epoch [2/5], Step [20/24], Loss: 1.4208, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [69/100], Epoch [3/5], Step [20/24], Loss: 1.5300, batch time: 0.10, accuracy:  49.61%\n",
      "Training round [69/100], Epoch [4/5], Step [20/24], Loss: 1.5742, batch time: 0.12, accuracy:  51.17%\n",
      "Training round [69/100], Epoch [5/5], Step [20/24], Loss: 1.4794, batch time: 0.10, accuracy:  50.39%\n",
      "Training round [69/100], qnn_train_step: [100/500], loss: 2.422240972518921, accuracy: 32.8 %\n",
      "Training round [69/100], qnn_train_step: [200/500], loss: 2.128864288330078, accuracy: 34.2 %\n",
      "Training round [69/100], qnn_train_step: [300/500], loss: 1.4331302642822266, accuracy: 50.3 %\n",
      "Training round [69/100], qnn_train_step: [400/500], loss: 1.407342791557312, accuracy: 52.0 %\n",
      "Training round [69/100], qnn_train_step: [500/500], loss: 1.5183866024017334, accuracy: 47.9 %\n",
      "-----------------------\n",
      "Training round [70/100], Epoch [1/5], Step [20/24], Loss: 1.3161, batch time: 0.10, accuracy:  57.42%\n",
      "Training round [70/100], Epoch [2/5], Step [20/24], Loss: 1.4862, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [70/100], Epoch [3/5], Step [20/24], Loss: 1.3954, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [70/100], Epoch [4/5], Step [20/24], Loss: 1.4454, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [70/100], Epoch [5/5], Step [20/24], Loss: 1.4242, batch time: 0.09, accuracy:  52.73%\n",
      "Training round [70/100], qnn_train_step: [100/500], loss: 2.397245407104492, accuracy: 32.4 %\n",
      "Training round [70/100], qnn_train_step: [200/500], loss: 2.156381130218506, accuracy: 34.3 %\n",
      "Training round [70/100], qnn_train_step: [300/500], loss: 1.5580657720565796, accuracy: 46.4 %\n",
      "Training round [70/100], qnn_train_step: [400/500], loss: 1.5118908882141113, accuracy: 47.6 %\n",
      "Training round [70/100], qnn_train_step: [500/500], loss: 1.5315403938293457, accuracy: 48.0 %\n",
      "-----------------------\n",
      "Training round [71/100], Epoch [1/5], Step [20/24], Loss: 1.4175, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [71/100], Epoch [2/5], Step [20/24], Loss: 1.4329, batch time: 0.09, accuracy:  52.73%\n",
      "Training round [71/100], Epoch [3/5], Step [20/24], Loss: 1.5603, batch time: 0.10, accuracy:  42.97%\n",
      "Training round [71/100], Epoch [4/5], Step [20/24], Loss: 1.4190, batch time: 0.10, accuracy:  51.17%\n",
      "Training round [71/100], Epoch [5/5], Step [20/24], Loss: 1.4756, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [71/100], qnn_train_step: [100/500], loss: 2.280118227005005, accuracy: 33.6 %\n",
      "Training round [71/100], qnn_train_step: [200/500], loss: 2.1809141635894775, accuracy: 33.6 %\n",
      "Training round [71/100], qnn_train_step: [300/500], loss: 1.6109434366226196, accuracy: 45.2 %\n",
      "Training round [71/100], qnn_train_step: [400/500], loss: 1.4672586917877197, accuracy: 49.1 %\n",
      "Training round [71/100], qnn_train_step: [500/500], loss: 1.5027129650115967, accuracy: 48.3 %\n",
      "-----------------------\n",
      "Training round [72/100], Epoch [1/5], Step [20/24], Loss: 1.3612, batch time: 0.10, accuracy:  54.30%\n",
      "Training round [72/100], Epoch [2/5], Step [20/24], Loss: 1.3699, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [72/100], Epoch [3/5], Step [20/24], Loss: 1.4103, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [72/100], Epoch [4/5], Step [20/24], Loss: 1.4526, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [72/100], Epoch [5/5], Step [20/24], Loss: 1.3551, batch time: 0.10, accuracy:  51.17%\n",
      "Training round [72/100], qnn_train_step: [100/500], loss: 2.499723196029663, accuracy: 29.7 %\n",
      "Training round [72/100], qnn_train_step: [200/500], loss: 2.10665225982666, accuracy: 37.2 %\n",
      "Training round [72/100], qnn_train_step: [300/500], loss: 1.474415898323059, accuracy: 47.0 %\n",
      "Training round [72/100], qnn_train_step: [400/500], loss: 1.4667459726333618, accuracy: 47.4 %\n",
      "Training round [72/100], qnn_train_step: [500/500], loss: 1.4618459939956665, accuracy: 48.6 %\n",
      "-----------------------\n",
      "Training round [73/100], Epoch [1/5], Step [20/24], Loss: 1.4145, batch time: 0.10, accuracy:  51.95%\n",
      "Training round [73/100], Epoch [2/5], Step [20/24], Loss: 1.4167, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [73/100], Epoch [3/5], Step [20/24], Loss: 1.4487, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [73/100], Epoch [4/5], Step [20/24], Loss: 1.4149, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [73/100], Epoch [5/5], Step [20/24], Loss: 1.5605, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [73/100], qnn_train_step: [100/500], loss: 2.1359479427337646, accuracy: 33.1 %\n",
      "Training round [73/100], qnn_train_step: [200/500], loss: 2.2215423583984375, accuracy: 34.4 %\n",
      "Training round [73/100], qnn_train_step: [300/500], loss: 1.4354941844940186, accuracy: 50.6 %\n",
      "Training round [73/100], qnn_train_step: [400/500], loss: 1.4352295398712158, accuracy: 51.4 %\n",
      "Training round [73/100], qnn_train_step: [500/500], loss: 1.4401205778121948, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [74/100], Epoch [1/5], Step [20/24], Loss: 1.5120, batch time: 0.10, accuracy:  42.58%\n",
      "Training round [74/100], Epoch [2/5], Step [20/24], Loss: 1.3955, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [74/100], Epoch [3/5], Step [20/24], Loss: 1.3407, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [74/100], Epoch [4/5], Step [20/24], Loss: 1.5483, batch time: 0.10, accuracy:  47.27%\n",
      "Training round [74/100], Epoch [5/5], Step [20/24], Loss: 1.4314, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [74/100], qnn_train_step: [100/500], loss: 2.664313554763794, accuracy: 29.5 %\n",
      "Training round [74/100], qnn_train_step: [200/500], loss: 2.2319302558898926, accuracy: 32.2 %\n",
      "Training round [74/100], qnn_train_step: [300/500], loss: 1.6437864303588867, accuracy: 45.7 %\n",
      "Training round [74/100], qnn_train_step: [400/500], loss: 1.5443875789642334, accuracy: 45.4 %\n",
      "Training round [74/100], qnn_train_step: [500/500], loss: 1.4646387100219727, accuracy: 48.5 %\n",
      "-----------------------\n",
      "Training round [75/100], Epoch [1/5], Step [20/24], Loss: 1.3655, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [75/100], Epoch [2/5], Step [20/24], Loss: 1.4700, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [75/100], Epoch [3/5], Step [20/24], Loss: 1.4669, batch time: 0.09, accuracy:  51.56%\n",
      "Training round [75/100], Epoch [4/5], Step [20/24], Loss: 1.3384, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [75/100], Epoch [5/5], Step [20/24], Loss: 1.3129, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [75/100], qnn_train_step: [100/500], loss: 2.1726861000061035, accuracy: 38.1 %\n",
      "Training round [75/100], qnn_train_step: [200/500], loss: 2.1571998596191406, accuracy: 36.2 %\n",
      "Training round [75/100], qnn_train_step: [300/500], loss: 1.5807427167892456, accuracy: 49.6 %\n",
      "Training round [75/100], qnn_train_step: [400/500], loss: 1.4785360097885132, accuracy: 50.4 %\n",
      "Training round [75/100], qnn_train_step: [500/500], loss: 1.601645827293396, accuracy: 45.7 %\n",
      "-----------------------\n",
      "Training round [76/100], Epoch [1/5], Step [20/24], Loss: 1.5102, batch time: 0.10, accuracy:  48.05%\n",
      "Training round [76/100], Epoch [2/5], Step [20/24], Loss: 1.3639, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [76/100], Epoch [3/5], Step [20/24], Loss: 1.4893, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [76/100], Epoch [4/5], Step [20/24], Loss: 1.3917, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [76/100], Epoch [5/5], Step [20/24], Loss: 1.5344, batch time: 0.09, accuracy:  46.48%\n",
      "Training round [76/100], qnn_train_step: [100/500], loss: 2.45253586769104, accuracy: 33.1 %\n",
      "Training round [76/100], qnn_train_step: [200/500], loss: 2.22739577293396, accuracy: 37.7 %\n",
      "Training round [76/100], qnn_train_step: [300/500], loss: 1.6068748235702515, accuracy: 49.1 %\n",
      "Training round [76/100], qnn_train_step: [400/500], loss: 1.5436465740203857, accuracy: 49.4 %\n",
      "Training round [76/100], qnn_train_step: [500/500], loss: 1.7109241485595703, accuracy: 44.1 %\n",
      "-----------------------\n",
      "Training round [77/100], Epoch [1/5], Step [20/24], Loss: 1.3811, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [77/100], Epoch [2/5], Step [20/24], Loss: 1.3956, batch time: 0.10, accuracy:  54.30%\n",
      "Training round [77/100], Epoch [3/5], Step [20/24], Loss: 1.4388, batch time: 0.10, accuracy:  50.39%\n",
      "Training round [77/100], Epoch [4/5], Step [20/24], Loss: 1.3919, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [77/100], Epoch [5/5], Step [20/24], Loss: 1.4948, batch time: 0.10, accuracy:  51.17%\n",
      "Training round [77/100], qnn_train_step: [100/500], loss: 2.2266998291015625, accuracy: 34.7 %\n",
      "Training round [77/100], qnn_train_step: [200/500], loss: 2.2733399868011475, accuracy: 35.2 %\n",
      "Training round [77/100], qnn_train_step: [300/500], loss: 2.5681333541870117, accuracy: 32.4 %\n",
      "Training round [77/100], qnn_train_step: [400/500], loss: 1.4628174304962158, accuracy: 51.3 %\n",
      "Training round [77/100], qnn_train_step: [500/500], loss: 1.5673253536224365, accuracy: 47.0 %\n",
      "-----------------------\n",
      "Training round [78/100], Epoch [1/5], Step [20/24], Loss: 1.4208, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [78/100], Epoch [2/5], Step [20/24], Loss: 1.3570, batch time: 0.09, accuracy:  55.08%\n",
      "Training round [78/100], Epoch [3/5], Step [20/24], Loss: 1.3762, batch time: 0.09, accuracy:  54.30%\n",
      "Training round [78/100], Epoch [4/5], Step [20/24], Loss: 1.5350, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [78/100], Epoch [5/5], Step [20/24], Loss: 1.3693, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [78/100], qnn_train_step: [100/500], loss: 2.3650104999542236, accuracy: 31.5 %\n",
      "Training round [78/100], qnn_train_step: [200/500], loss: 2.1726229190826416, accuracy: 38.7 %\n",
      "Training round [78/100], qnn_train_step: [300/500], loss: 1.4053270816802979, accuracy: 53.8 %\n",
      "Training round [78/100], qnn_train_step: [400/500], loss: 1.4173328876495361, accuracy: 53.6 %\n",
      "Training round [78/100], qnn_train_step: [500/500], loss: 1.420814037322998, accuracy: 51.8 %\n",
      "-----------------------\n",
      "Training round [79/100], Epoch [1/5], Step [20/24], Loss: 1.4360, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [79/100], Epoch [2/5], Step [20/24], Loss: 1.3606, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [79/100], Epoch [3/5], Step [20/24], Loss: 1.4708, batch time: 0.09, accuracy:  50.78%\n",
      "Training round [79/100], Epoch [4/5], Step [20/24], Loss: 1.3897, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [79/100], Epoch [5/5], Step [20/24], Loss: 1.5037, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [79/100], qnn_train_step: [100/500], loss: 2.479194402694702, accuracy: 33.4 %\n",
      "Training round [79/100], qnn_train_step: [200/500], loss: 2.25736927986145, accuracy: 37.6 %\n",
      "Training round [79/100], qnn_train_step: [300/500], loss: 1.4325993061065674, accuracy: 51.6 %\n",
      "Training round [79/100], qnn_train_step: [400/500], loss: 1.5862852334976196, accuracy: 47.7 %\n",
      "Training round [79/100], qnn_train_step: [500/500], loss: 1.5662589073181152, accuracy: 50.7 %\n",
      "-----------------------\n",
      "Training round [80/100], Epoch [1/5], Step [20/24], Loss: 1.3247, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [80/100], Epoch [2/5], Step [20/24], Loss: 1.4267, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [80/100], Epoch [3/5], Step [20/24], Loss: 1.5543, batch time: 0.10, accuracy:  49.22%\n",
      "Training round [80/100], Epoch [4/5], Step [20/24], Loss: 1.3853, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [80/100], Epoch [5/5], Step [20/24], Loss: 1.4515, batch time: 0.10, accuracy:  48.44%\n",
      "Training round [80/100], qnn_train_step: [100/500], loss: 2.3706822395324707, accuracy: 33.4 %\n",
      "Training round [80/100], qnn_train_step: [200/500], loss: 2.048525810241699, accuracy: 40.1 %\n",
      "Training round [80/100], qnn_train_step: [300/500], loss: 1.366547703742981, accuracy: 53.8 %\n",
      "Training round [80/100], qnn_train_step: [400/500], loss: 1.337084174156189, accuracy: 54.8 %\n",
      "Training round [80/100], qnn_train_step: [500/500], loss: 1.4071389436721802, accuracy: 53.1 %\n",
      "-----------------------\n",
      "Training round [81/100], Epoch [1/5], Step [20/24], Loss: 1.2679, batch time: 0.10, accuracy:  57.42%\n",
      "Training round [81/100], Epoch [2/5], Step [20/24], Loss: 1.5277, batch time: 0.10, accuracy:  45.70%\n",
      "Training round [81/100], Epoch [3/5], Step [20/24], Loss: 1.3839, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [81/100], Epoch [4/5], Step [20/24], Loss: 1.4256, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [81/100], Epoch [5/5], Step [20/24], Loss: 1.2659, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [81/100], qnn_train_step: [100/500], loss: 2.4985859394073486, accuracy: 30.5 %\n",
      "Training round [81/100], qnn_train_step: [200/500], loss: 2.520200729370117, accuracy: 33.2 %\n",
      "Training round [81/100], qnn_train_step: [300/500], loss: 1.4631999731063843, accuracy: 49.3 %\n",
      "Training round [81/100], qnn_train_step: [400/500], loss: 1.3962424993515015, accuracy: 53.3 %\n",
      "Training round [81/100], qnn_train_step: [500/500], loss: 1.3602505922317505, accuracy: 53.4 %\n",
      "-----------------------\n",
      "Training round [82/100], Epoch [1/5], Step [20/24], Loss: 1.4553, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [82/100], Epoch [2/5], Step [20/24], Loss: 1.4021, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [82/100], Epoch [3/5], Step [20/24], Loss: 1.4061, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [82/100], Epoch [4/5], Step [20/24], Loss: 1.4718, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [82/100], Epoch [5/5], Step [20/24], Loss: 1.4523, batch time: 0.10, accuracy:  51.17%\n",
      "Training round [82/100], qnn_train_step: [100/500], loss: 2.4815762042999268, accuracy: 29.1 %\n",
      "Training round [82/100], qnn_train_step: [200/500], loss: 2.3751132488250732, accuracy: 37.2 %\n",
      "Training round [82/100], qnn_train_step: [300/500], loss: 1.4155197143554688, accuracy: 54.5 %\n",
      "Training round [82/100], qnn_train_step: [400/500], loss: 1.3762359619140625, accuracy: 55.1 %\n",
      "Training round [82/100], qnn_train_step: [500/500], loss: 1.4819676876068115, accuracy: 50.3 %\n",
      "-----------------------\n",
      "Training round [83/100], Epoch [1/5], Step [20/24], Loss: 1.4361, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [83/100], Epoch [2/5], Step [20/24], Loss: 1.1466, batch time: 0.10, accuracy:  62.50%\n",
      "Training round [83/100], Epoch [3/5], Step [20/24], Loss: 1.5242, batch time: 0.09, accuracy:  47.27%\n",
      "Training round [83/100], Epoch [4/5], Step [20/24], Loss: 1.4259, batch time: 0.10, accuracy:  50.39%\n",
      "Training round [83/100], Epoch [5/5], Step [20/24], Loss: 1.3254, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [83/100], qnn_train_step: [100/500], loss: 2.4046919345855713, accuracy: 33.5 %\n",
      "Training round [83/100], qnn_train_step: [200/500], loss: 2.4244468212127686, accuracy: 35.0 %\n",
      "Training round [83/100], qnn_train_step: [300/500], loss: 1.4753390550613403, accuracy: 50.2 %\n",
      "Training round [83/100], qnn_train_step: [400/500], loss: 1.4273804426193237, accuracy: 51.1 %\n",
      "Training round [83/100], qnn_train_step: [500/500], loss: 1.5581597089767456, accuracy: 49.5 %\n",
      "-----------------------\n",
      "Training round [84/100], Epoch [1/5], Step [20/24], Loss: 1.3994, batch time: 0.10, accuracy:  48.83%\n",
      "Training round [84/100], Epoch [2/5], Step [20/24], Loss: 1.3287, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [84/100], Epoch [3/5], Step [20/24], Loss: 1.4568, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [84/100], Epoch [4/5], Step [20/24], Loss: 1.2732, batch time: 0.10, accuracy:  59.38%\n",
      "Training round [84/100], Epoch [5/5], Step [20/24], Loss: 1.4159, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [84/100], qnn_train_step: [100/500], loss: 2.1794416904449463, accuracy: 33.3 %\n",
      "Training round [84/100], qnn_train_step: [200/500], loss: 2.1430225372314453, accuracy: 37.4 %\n",
      "Training round [84/100], qnn_train_step: [300/500], loss: 1.4196935892105103, accuracy: 54.4 %\n",
      "Training round [84/100], qnn_train_step: [400/500], loss: 1.3863121271133423, accuracy: 54.1 %\n",
      "Training round [84/100], qnn_train_step: [500/500], loss: 1.3685494661331177, accuracy: 55.2 %\n",
      "-----------------------\n",
      "Training round [85/100], Epoch [1/5], Step [20/24], Loss: 1.2817, batch time: 0.09, accuracy:  58.20%\n",
      "Training round [85/100], Epoch [2/5], Step [20/24], Loss: 1.2584, batch time: 0.10, accuracy:  57.42%\n",
      "Training round [85/100], Epoch [3/5], Step [20/24], Loss: 1.3194, batch time: 0.10, accuracy:  59.77%\n",
      "Training round [85/100], Epoch [4/5], Step [20/24], Loss: 1.2023, batch time: 0.11, accuracy:  61.72%\n",
      "Training round [85/100], Epoch [5/5], Step [20/24], Loss: 1.4237, batch time: 0.10, accuracy:  53.91%\n",
      "Training round [85/100], qnn_train_step: [100/500], loss: 2.5770206451416016, accuracy: 31.3 %\n",
      "Training round [85/100], qnn_train_step: [200/500], loss: 1.9827930927276611, accuracy: 39.8 %\n",
      "Training round [85/100], qnn_train_step: [300/500], loss: 1.4751763343811035, accuracy: 54.6 %\n",
      "Training round [85/100], qnn_train_step: [400/500], loss: 1.3807342052459717, accuracy: 54.9 %\n",
      "Training round [85/100], qnn_train_step: [500/500], loss: 1.4315078258514404, accuracy: 52.5 %\n",
      "-----------------------\n",
      "Training round [86/100], Epoch [1/5], Step [20/24], Loss: 1.3151, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [86/100], Epoch [2/5], Step [20/24], Loss: 1.3394, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [86/100], Epoch [3/5], Step [20/24], Loss: 1.3455, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [86/100], Epoch [4/5], Step [20/24], Loss: 1.4678, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [86/100], Epoch [5/5], Step [20/24], Loss: 1.4665, batch time: 0.10, accuracy:  48.05%\n",
      "Training round [86/100], qnn_train_step: [100/500], loss: 2.0719094276428223, accuracy: 36.0 %\n",
      "Training round [86/100], qnn_train_step: [200/500], loss: 2.0688459873199463, accuracy: 39.5 %\n",
      "Training round [86/100], qnn_train_step: [300/500], loss: 1.3545538187026978, accuracy: 55.3 %\n",
      "Training round [86/100], qnn_train_step: [400/500], loss: 1.3477798700332642, accuracy: 54.9 %\n",
      "Training round [86/100], qnn_train_step: [500/500], loss: 1.343164086341858, accuracy: 54.6 %\n",
      "-----------------------\n",
      "Training round [87/100], Epoch [1/5], Step [20/24], Loss: 1.3476, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [87/100], Epoch [2/5], Step [20/24], Loss: 1.3614, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [87/100], Epoch [3/5], Step [20/24], Loss: 1.2800, batch time: 0.09, accuracy:  55.47%\n",
      "Training round [87/100], Epoch [4/5], Step [20/24], Loss: 1.3369, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [87/100], Epoch [5/5], Step [20/24], Loss: 1.3470, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [87/100], qnn_train_step: [100/500], loss: 2.164635419845581, accuracy: 36.6 %\n",
      "Training round [87/100], qnn_train_step: [200/500], loss: 1.993693232536316, accuracy: 44.4 %\n",
      "Training round [87/100], qnn_train_step: [300/500], loss: 1.4619228839874268, accuracy: 53.8 %\n",
      "Training round [87/100], qnn_train_step: [400/500], loss: 1.410534381866455, accuracy: 53.4 %\n",
      "Training round [87/100], qnn_train_step: [500/500], loss: 1.4314278364181519, accuracy: 52.6 %\n",
      "-----------------------\n",
      "Training round [88/100], Epoch [1/5], Step [20/24], Loss: 1.2465, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [88/100], Epoch [2/5], Step [20/24], Loss: 1.4373, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [88/100], Epoch [3/5], Step [20/24], Loss: 1.3065, batch time: 0.09, accuracy:  57.81%\n",
      "Training round [88/100], Epoch [4/5], Step [20/24], Loss: 1.3886, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [88/100], Epoch [5/5], Step [20/24], Loss: 1.2915, batch time: 0.10, accuracy:  60.55%\n",
      "Training round [88/100], qnn_train_step: [100/500], loss: 2.408081531524658, accuracy: 31.4 %\n",
      "Training round [88/100], qnn_train_step: [200/500], loss: 2.044166088104248, accuracy: 40.5 %\n",
      "Training round [88/100], qnn_train_step: [300/500], loss: 1.450993299484253, accuracy: 49.0 %\n",
      "Training round [88/100], qnn_train_step: [400/500], loss: 1.4094394445419312, accuracy: 51.3 %\n",
      "Training round [88/100], qnn_train_step: [500/500], loss: 1.3924113512039185, accuracy: 52.9 %\n",
      "-----------------------\n",
      "Training round [89/100], Epoch [1/5], Step [20/24], Loss: 1.4018, batch time: 0.10, accuracy:  52.73%\n",
      "Training round [89/100], Epoch [2/5], Step [20/24], Loss: 1.3427, batch time: 0.10, accuracy:  54.30%\n",
      "Training round [89/100], Epoch [3/5], Step [20/24], Loss: 1.4110, batch time: 0.10, accuracy:  50.78%\n",
      "Training round [89/100], Epoch [4/5], Step [20/24], Loss: 1.2533, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [89/100], Epoch [5/5], Step [20/24], Loss: 1.3683, batch time: 0.09, accuracy:  55.86%\n",
      "Training round [89/100], qnn_train_step: [100/500], loss: 2.3669497966766357, accuracy: 32.5 %\n",
      "Training round [89/100], qnn_train_step: [200/500], loss: 2.0281715393066406, accuracy: 42.8 %\n",
      "Training round [89/100], qnn_train_step: [300/500], loss: 1.436743974685669, accuracy: 51.3 %\n",
      "Training round [89/100], qnn_train_step: [400/500], loss: 1.3806298971176147, accuracy: 53.2 %\n",
      "Training round [89/100], qnn_train_step: [500/500], loss: 1.3610305786132812, accuracy: 53.3 %\n",
      "-----------------------\n",
      "Training round [90/100], Epoch [1/5], Step [20/24], Loss: 1.3360, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [90/100], Epoch [2/5], Step [20/24], Loss: 1.3618, batch time: 0.09, accuracy:  54.30%\n",
      "Training round [90/100], Epoch [3/5], Step [20/24], Loss: 1.4300, batch time: 0.10, accuracy:  51.17%\n",
      "Training round [90/100], Epoch [4/5], Step [20/24], Loss: 1.3494, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [90/100], Epoch [5/5], Step [20/24], Loss: 1.3712, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [90/100], qnn_train_step: [100/500], loss: 2.4408185482025146, accuracy: 29.5 %\n",
      "Training round [90/100], qnn_train_step: [200/500], loss: 1.9348078966140747, accuracy: 45.9 %\n",
      "Training round [90/100], qnn_train_step: [300/500], loss: 1.391742467880249, accuracy: 54.4 %\n",
      "Training round [90/100], qnn_train_step: [400/500], loss: 1.3499263525009155, accuracy: 55.0 %\n",
      "Training round [90/100], qnn_train_step: [500/500], loss: 1.3318133354187012, accuracy: 55.8 %\n",
      "-----------------------\n",
      "Training round [91/100], Epoch [1/5], Step [20/24], Loss: 1.4423, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [91/100], Epoch [2/5], Step [20/24], Loss: 1.5156, batch time: 0.09, accuracy:  48.05%\n",
      "Training round [91/100], Epoch [3/5], Step [20/24], Loss: 1.2544, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [91/100], Epoch [4/5], Step [20/24], Loss: 1.3785, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [91/100], Epoch [5/5], Step [20/24], Loss: 1.3528, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [91/100], qnn_train_step: [100/500], loss: 2.595731496810913, accuracy: 31.5 %\n",
      "Training round [91/100], qnn_train_step: [200/500], loss: 1.8758735656738281, accuracy: 43.8 %\n",
      "Training round [91/100], qnn_train_step: [300/500], loss: 1.4854927062988281, accuracy: 48.6 %\n",
      "Training round [91/100], qnn_train_step: [400/500], loss: 1.3464785814285278, accuracy: 55.0 %\n",
      "Training round [91/100], qnn_train_step: [500/500], loss: 1.472028136253357, accuracy: 50.9 %\n",
      "-----------------------\n",
      "Training round [92/100], Epoch [1/5], Step [20/24], Loss: 1.4097, batch time: 0.10, accuracy:  54.30%\n",
      "Training round [92/100], Epoch [2/5], Step [20/24], Loss: 1.4006, batch time: 0.09, accuracy:  52.34%\n",
      "Training round [92/100], Epoch [3/5], Step [20/24], Loss: 1.3891, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [92/100], Epoch [4/5], Step [20/24], Loss: 1.3495, batch time: 0.10, accuracy:  51.95%\n",
      "Training round [92/100], Epoch [5/5], Step [20/24], Loss: 1.3969, batch time: 0.09, accuracy:  52.73%\n",
      "Training round [92/100], qnn_train_step: [100/500], loss: 2.3443500995635986, accuracy: 32.7 %\n",
      "Training round [92/100], qnn_train_step: [200/500], loss: 1.9853850603103638, accuracy: 42.4 %\n",
      "Training round [92/100], qnn_train_step: [300/500], loss: 1.2896250486373901, accuracy: 55.4 %\n",
      "Training round [92/100], qnn_train_step: [400/500], loss: 1.2763080596923828, accuracy: 55.0 %\n",
      "Training round [92/100], qnn_train_step: [500/500], loss: 2.7461485862731934, accuracy: 30.4 %\n",
      "-----------------------\n",
      "Training round [93/100], Epoch [1/5], Step [20/24], Loss: 1.5070, batch time: 0.10, accuracy:  50.39%\n",
      "Training round [93/100], Epoch [2/5], Step [20/24], Loss: 1.2930, batch time: 0.09, accuracy:  59.38%\n",
      "Training round [93/100], Epoch [3/5], Step [20/24], Loss: 1.2399, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [93/100], Epoch [4/5], Step [20/24], Loss: 1.2893, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [93/100], Epoch [5/5], Step [20/24], Loss: 1.3640, batch time: 0.09, accuracy:  53.52%\n",
      "Training round [93/100], qnn_train_step: [100/500], loss: 2.5700347423553467, accuracy: 28.6 %\n",
      "Training round [93/100], qnn_train_step: [200/500], loss: 2.3373258113861084, accuracy: 39.0 %\n",
      "Training round [93/100], qnn_train_step: [300/500], loss: 1.3963587284088135, accuracy: 54.8 %\n",
      "Training round [93/100], qnn_train_step: [400/500], loss: 1.3396512269973755, accuracy: 55.0 %\n",
      "Training round [93/100], qnn_train_step: [500/500], loss: 1.3366807699203491, accuracy: 54.5 %\n",
      "-----------------------\n",
      "Training round [94/100], Epoch [1/5], Step [20/24], Loss: 1.3319, batch time: 0.10, accuracy:  54.30%\n",
      "Training round [94/100], Epoch [2/5], Step [20/24], Loss: 1.2270, batch time: 0.09, accuracy:  59.77%\n",
      "Training round [94/100], Epoch [3/5], Step [20/24], Loss: 1.2843, batch time: 0.10, accuracy:  57.03%\n",
      "Training round [94/100], Epoch [4/5], Step [20/24], Loss: 1.5196, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [94/100], Epoch [5/5], Step [20/24], Loss: 1.3397, batch time: 0.10, accuracy:  51.56%\n",
      "Training round [94/100], qnn_train_step: [100/500], loss: 2.532965898513794, accuracy: 30.3 %\n",
      "Training round [94/100], qnn_train_step: [200/500], loss: 2.165631055831909, accuracy: 42.4 %\n",
      "Training round [94/100], qnn_train_step: [300/500], loss: 1.3927234411239624, accuracy: 53.8 %\n",
      "Training round [94/100], qnn_train_step: [400/500], loss: 1.4341602325439453, accuracy: 50.6 %\n",
      "Training round [94/100], qnn_train_step: [500/500], loss: 1.3998032808303833, accuracy: 55.5 %\n",
      "-----------------------\n",
      "Training round [95/100], Epoch [1/5], Step [20/24], Loss: 1.2408, batch time: 0.10, accuracy:  58.59%\n",
      "Training round [95/100], Epoch [2/5], Step [20/24], Loss: 1.3150, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [95/100], Epoch [3/5], Step [20/24], Loss: 1.4825, batch time: 0.10, accuracy:  47.66%\n",
      "Training round [95/100], Epoch [4/5], Step [20/24], Loss: 1.4005, batch time: 0.10, accuracy:  50.00%\n",
      "Training round [95/100], Epoch [5/5], Step [20/24], Loss: 1.3006, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [95/100], qnn_train_step: [100/500], loss: 2.4316792488098145, accuracy: 32.8 %\n",
      "Training round [95/100], qnn_train_step: [200/500], loss: 2.219238519668579, accuracy: 41.1 %\n",
      "Training round [95/100], qnn_train_step: [300/500], loss: 1.4501569271087646, accuracy: 51.2 %\n",
      "Training round [95/100], qnn_train_step: [400/500], loss: 1.349534034729004, accuracy: 56.4 %\n",
      "Training round [95/100], qnn_train_step: [500/500], loss: 1.3536807298660278, accuracy: 57.6 %\n",
      "-----------------------\n",
      "Training round [96/100], Epoch [1/5], Step [20/24], Loss: 1.2672, batch time: 0.10, accuracy:  60.16%\n",
      "Training round [96/100], Epoch [2/5], Step [20/24], Loss: 1.3599, batch time: 0.10, accuracy:  57.42%\n",
      "Training round [96/100], Epoch [3/5], Step [20/24], Loss: 1.2844, batch time: 0.10, accuracy:  55.86%\n",
      "Training round [96/100], Epoch [4/5], Step [20/24], Loss: 1.3258, batch time: 0.10, accuracy:  58.20%\n",
      "Training round [96/100], Epoch [5/5], Step [20/24], Loss: 1.2804, batch time: 0.10, accuracy:  58.20%\n",
      "Training round [96/100], qnn_train_step: [100/500], loss: 2.276934862136841, accuracy: 34.6 %\n",
      "Training round [96/100], qnn_train_step: [200/500], loss: 2.302659511566162, accuracy: 41.2 %\n",
      "Training round [96/100], qnn_train_step: [300/500], loss: 1.4300267696380615, accuracy: 53.0 %\n",
      "Training round [96/100], qnn_train_step: [400/500], loss: 1.3957321643829346, accuracy: 51.9 %\n",
      "Training round [96/100], qnn_train_step: [500/500], loss: 1.3974672555923462, accuracy: 52.1 %\n",
      "-----------------------\n",
      "Training round [97/100], Epoch [1/5], Step [20/24], Loss: 1.3088, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [97/100], Epoch [2/5], Step [20/24], Loss: 1.4479, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [97/100], Epoch [3/5], Step [20/24], Loss: 1.3585, batch time: 0.10, accuracy:  52.34%\n",
      "Training round [97/100], Epoch [4/5], Step [20/24], Loss: 1.4427, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [97/100], Epoch [5/5], Step [20/24], Loss: 1.3412, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [97/100], qnn_train_step: [100/500], loss: 2.254149913787842, accuracy: 32.6 %\n",
      "Training round [97/100], qnn_train_step: [200/500], loss: 2.1957755088806152, accuracy: 40.7 %\n",
      "Training round [97/100], qnn_train_step: [300/500], loss: 1.2912325859069824, accuracy: 57.1 %\n",
      "Training round [97/100], qnn_train_step: [400/500], loss: 1.3066514730453491, accuracy: 56.6 %\n",
      "Training round [97/100], qnn_train_step: [500/500], loss: 1.2850100994110107, accuracy: 56.8 %\n",
      "-----------------------\n",
      "Training round [98/100], Epoch [1/5], Step [20/24], Loss: 1.3855, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [98/100], Epoch [2/5], Step [20/24], Loss: 1.2644, batch time: 0.10, accuracy:  58.98%\n",
      "Training round [98/100], Epoch [3/5], Step [20/24], Loss: 1.3347, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [98/100], Epoch [4/5], Step [20/24], Loss: 1.3306, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [98/100], Epoch [5/5], Step [20/24], Loss: 1.3630, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [98/100], qnn_train_step: [100/500], loss: 1.9292547702789307, accuracy: 37.7 %\n",
      "Training round [98/100], qnn_train_step: [200/500], loss: 1.9460797309875488, accuracy: 41.8 %\n",
      "Training round [98/100], qnn_train_step: [300/500], loss: 1.3535586595535278, accuracy: 54.2 %\n",
      "Training round [98/100], qnn_train_step: [400/500], loss: 1.3361060619354248, accuracy: 54.7 %\n",
      "Training round [98/100], qnn_train_step: [500/500], loss: 1.4467480182647705, accuracy: 52.3 %\n",
      "-----------------------\n",
      "Training round [99/100], Epoch [1/5], Step [20/24], Loss: 1.2983, batch time: 0.10, accuracy:  55.08%\n",
      "Training round [99/100], Epoch [2/5], Step [20/24], Loss: 1.3642, batch time: 0.35, accuracy:  54.69%\n",
      "Training round [99/100], Epoch [3/5], Step [20/24], Loss: 1.2853, batch time: 0.10, accuracy:  56.25%\n",
      "Training round [99/100], Epoch [4/5], Step [20/24], Loss: 1.3189, batch time: 0.09, accuracy:  56.25%\n",
      "Training round [99/100], Epoch [5/5], Step [20/24], Loss: 1.3204, batch time: 0.10, accuracy:  53.52%\n",
      "Training round [99/100], qnn_train_step: [100/500], loss: 2.2200233936309814, accuracy: 35.3 %\n",
      "Training round [99/100], qnn_train_step: [200/500], loss: 1.868327260017395, accuracy: 47.4 %\n",
      "Training round [99/100], qnn_train_step: [300/500], loss: 1.3653377294540405, accuracy: 54.1 %\n",
      "Training round [99/100], qnn_train_step: [400/500], loss: 1.3384954929351807, accuracy: 55.9 %\n",
      "Training round [99/100], qnn_train_step: [500/500], loss: 1.3674395084381104, accuracy: 56.2 %\n",
      "-----------------------\n",
      "Training round [100/100], Epoch [1/5], Step [20/24], Loss: 1.2185, batch time: 0.10, accuracy:  56.64%\n",
      "Training round [100/100], Epoch [2/5], Step [20/24], Loss: 1.3661, batch time: 0.10, accuracy:  55.47%\n",
      "Training round [100/100], Epoch [3/5], Step [20/24], Loss: 1.2833, batch time: 0.10, accuracy:  53.12%\n",
      "Training round [100/100], Epoch [4/5], Step [20/24], Loss: 1.2466, batch time: 0.10, accuracy:  57.81%\n",
      "Training round [100/100], Epoch [5/5], Step [20/24], Loss: 1.2910, batch time: 0.10, accuracy:  54.69%\n",
      "Training round [100/100], qnn_train_step: [100/500], loss: 2.199693441390991, accuracy: 34.5 %\n",
      "Training round [100/100], qnn_train_step: [200/500], loss: 1.9248597621917725, accuracy: 44.4 %\n",
      "Training round [100/100], qnn_train_step: [300/500], loss: 1.7138798236846924, accuracy: 47.8 %\n",
      "Training round [100/100], qnn_train_step: [400/500], loss: 1.2958706617355347, accuracy: 56.4 %\n",
      "Training round [100/100], qnn_train_step: [500/500], loss: 1.2977908849716187, accuracy: 56.7 %\n"
     ]
    }
   ],
   "source": [
    "num_training_rounds = 100\n",
    "batch_size_qnn = 1000\n",
    "train_loader_qnn = DataLoader(train_dataset, batch_size_qnn, shuffle = True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "\n",
    "global images, labels\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "\n",
    "\n",
    "for round_ in range(num_training_rounds): \n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    acc_list = [] \n",
    "    acc_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        qt_model.train()\n",
    "        train_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            since_batch = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters)\n",
    "            # print(\"output: \", outputs)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            # log_loss = torch.log(loss + 1e-6)\n",
    "            \n",
    "            loss_list.append(loss.cpu().detach().numpy())\n",
    "            acc = 100 * correct / total\n",
    "            acc_list.append(acc)\n",
    "            train_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            # np.array(loss_list).dump(\"L1/3/loss_list.dat\")\n",
    "            # np.array(acc_list).dump(\"L1/3/acc_list.dat\")\n",
    "            if acc > acc_best:\n",
    "                # torch.save(model, 'L1/3/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "                acc_best = acc\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        # scheduler.step(train_loss)\n",
    "        \n",
    "    #############################################\n",
    "\n",
    "\n",
    "    num_batch_qnn = 1\n",
    "\n",
    "    for batch_ in range(num_batch_qnn):\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}]\")\n",
    "        # print(f\"Training round [{round_+1}/{num_training_rounds}], qnn batch {batch_ + 1}\")\n",
    "        global qnn_train_step\n",
    "        qnn_train_step = 0 \n",
    "        \n",
    "        # Get a single random batch\n",
    "        train_iter = iter(train_loader_qnn)  # Create an iterator\n",
    "        images, labels = next(train_iter) \n",
    "\n",
    "        def qnn_minimize_loss(qnn_parameters_=None):\n",
    "            global qnn_train_step\n",
    "            global images, labels\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = qt_model(images, qnn_parameters = qnn_parameters_)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            acc = 100 * correct / total\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            qnn_train_step += 1 \n",
    "            if qnn_train_step % 100 == 0:\n",
    "                # print(\"qnn_train_step :\", qnn_train_step, \", loss :\", loss, \", acc : \", acc)\n",
    "                print(f\"Training round [{round_+1}/{num_training_rounds}], qnn_train_step: [{qnn_train_step}/{500}], loss: {loss}, accuracy: {acc} %\")\n",
    "\n",
    "            # print(\"qnn_parameters [:10] :\", qnn_parameters_[:10])\n",
    "            return loss\n",
    "\n",
    "\n",
    "        # Nelder-Mead\n",
    "        # COBYLA \n",
    "        # SLSQP\n",
    "\n",
    "        init_param = qnn_parameters\n",
    "        result = minimize(qnn_minimize_loss, init_param, method='COBYLA', options = {'maxiter': 500, 'adaptive': True, 'rhobeg': 0.5} )\n",
    "\n",
    "        qnn_parameters = result.x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.ylim(0.5, 9.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 56.23%\n",
      "Loss on the train set: 1.31\n",
      "Accuracy on the test set: 53.17%\n",
      "Loss on the test set: 1.32\n",
      "Generalization error: 0.0068300962\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n",
    "\n",
    "# Testing loop\n",
    "qt_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = qt_model(images, qnn_parameters)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(\n",
    "#     epochs: int,\n",
    "#     lr: float,\n",
    "#     model: torch.nn.Module,\n",
    "#     train_loader: DataLoader,\n",
    "#     val_loader: DataLoader,\n",
    "#     bs: BosonSampler,\n",
    "#     opt_func=torch.optim.SGD,\n",
    "#     save_csv: bool = True,\n",
    "#     csv_path: str = \"training_history\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Trains the model for a specified number of epochs, evaluates on validation data,\n",
    "#     and optionally saves the training history to a CSV file with a timestamp.\n",
    "\n",
    "#     Args:\n",
    "#         epochs (int): Number of epochs to train.\n",
    "#         lr (float): Learning rate.\n",
    "#         model (torch.nn.Module): The neural network model to train.\n",
    "#         train_loader (DataLoader): DataLoader for training data.\n",
    "#         val_loader (DataLoader): DataLoader for validation data.\n",
    "#         bs (BosonSampler): BosonSampler instance for embedding.\n",
    "#         opt_func (torch.optim.Optimizer, optional): Optimizer constructor. Defaults to torch.optim.SGD.\n",
    "#         save_csv (bool, optional): Whether to save the training history to a CSV file. Defaults to True.\n",
    "#         csv_path (str, optional): Base path/name for the CSV file. A timestamp will be appended. Defaults to \"training_history\".\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing training and validation metrics per epoch.\n",
    "#     \"\"\"\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = opt_func(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Initialize history dictionary\n",
    "#     history = {\n",
    "#         'epoch': [],\n",
    "#         'train_loss': [],\n",
    "#         'train_acc': [],\n",
    "#         'val_loss': [],\n",
    "#         'val_acc': []\n",
    "#     }\n",
    "\n",
    "#     # Determine the device from the model\n",
    "#     device = next(model.parameters()).device\n",
    "#     print(f\"Training on device: {device}\")\n",
    "\n",
    "#     # Create a progress bar for epochs\n",
    "#     epoch_bar = tqdm(range(1, epochs + 1), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "#     for epoch in epoch_bar:\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         # Iterate over training data\n",
    "#         for batch in train_loader:\n",
    "#             if model.embedding_size:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Generate embeddings and move them to the device\n",
    "#                 embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                 # Forward pass with embeddings\n",
    "#                 outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#             else:\n",
    "#                 images, labels = batch\n",
    "#                 # Move images and labels to the device\n",
    "#                 images = images.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 # Forward pass without embeddings\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#             # Compute loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Compute accuracy\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate loss and accuracy\n",
    "#             running_loss += loss.item() * images.size(0)\n",
    "#             running_corrects += acc\n",
    "#             total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate epoch metrics\n",
    "#         epoch_train_loss = running_loss / total_samples\n",
    "#         epoch_train_acc = running_corrects / total_samples\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_running_corrects = 0\n",
    "#         val_total_samples = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 if model.embedding_size:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Generate embeddings and move them to the device\n",
    "#                     embs = bs.embed(images, n_sample=1000).to(device)\n",
    "\n",
    "#                     # Forward pass with embeddings\n",
    "#                     outputs = model(images, emb=embs.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     images, labels = batch\n",
    "#                     # Move images and labels to the device\n",
    "#                     images = images.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Forward pass without embeddings\n",
    "#                     outputs = model(images)\n",
    "\n",
    "#                 # Compute loss\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 # Compute accuracy\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 acc = torch.sum(preds == labels.data).item()\n",
    "\n",
    "#                 # Accumulate loss and accuracy\n",
    "#                 val_running_loss += loss.item() * images.size(0)\n",
    "#                 val_running_corrects += acc\n",
    "#                 val_total_samples += images.size(0)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         epoch_val_loss = val_running_loss / val_total_samples\n",
    "#         epoch_val_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "#         # Update history\n",
    "#         history['epoch'].append(epoch)\n",
    "#         history['train_loss'].append(epoch_train_loss)\n",
    "#         history['train_acc'].append(epoch_train_acc)\n",
    "#         history['val_loss'].append(epoch_val_loss)\n",
    "#         history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "#         # Update the progress bar description\n",
    "#         epoch_bar.set_postfix({\n",
    "#             'Train Loss': f\"{epoch_train_loss:.4f}\",\n",
    "#             'Train Acc': f\"{epoch_train_acc:.4f}\",\n",
    "#             'Val Loss': f\"{epoch_val_loss:.4f}\",\n",
    "#             'Val Acc': f\"{epoch_val_acc:.4f}\"\n",
    "#         })\n",
    "\n",
    "#     # Save history to CSV with timestamp\n",
    "#     if save_csv:\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         csv_filename = f\"{csv_path}_{timestamp}.csv\"\n",
    "#         history_df = pd.DataFrame(history)\n",
    "#         history_df.to_csv(csv_filename, index=False)\n",
    "#         print(f\"\\nTraining history saved to '{csv_filename}'.\")\n",
    "\n",
    "#     return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quandela",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
